{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of HW4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a94b6fa1934042079b30bba4296c21ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_591e0064bfe24da997448b62d92086ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4bf69a55b31b44bd946dc6ee93d0513c",
              "IPY_MODEL_7f68321de56d47869d7fb0706318922f"
            ]
          }
        },
        "591e0064bfe24da997448b62d92086ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bf69a55b31b44bd946dc6ee93d0513c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_93851b2387474c6a9c86bada690c3b10",
            "_dom_classes": [],
            "description": "Dl Completed...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59cad425206d457d8acca6ca07b40f6d"
          }
        },
        "7f68321de56d47869d7fb0706318922f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7328e83963f645d0bec196478b7d6d90",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:08&lt;00:00,  2.14s/ file]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bfa83f84aaa441d4af260e4e41e743bf"
          }
        },
        "93851b2387474c6a9c86bada690c3b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59cad425206d457d8acca6ca07b40f6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7328e83963f645d0bec196478b7d6d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bfa83f84aaa441d4af260e4e41e743bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t-mesq/Apre_HW4/blob/master/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxKa5r7Ll7Dg",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning\n",
        "\n",
        "## Homework 4\n",
        "\n",
        "In this collab we continue the study of the mnist dataset, already started in lab9. We will study how the type and number of layers affects the performance. Every NN will use Adam optimizer in order to converge quicker.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icnrt-Vg3lXw",
        "colab_type": "text"
      },
      "source": [
        "Let's start by importing the libraries that will be used in this tutorial:\n",
        "\n",
        "* [tensorflow](https://www.tensorflow.org/): the neural network library\n",
        "* [tensorflow_datasets](https://www.tensorflow.org/datasets): provides the datasets that we will use\n",
        "* [numpy](https://numpy.org/): we will use it to store the data in array format for visualization\n",
        "* [sklearn](https://scikit-learn.org/): provides a [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) implementation that we will use for visualization\n",
        "* [matplotlib](https://matplotlib.org/): plotting library for visualization\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6VTCny05XSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import sklearn.decomposition\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU6ybgf-_fo-",
        "colab_type": "text"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "In this part of the tutorial we will use the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset, which is widely used for introducing image classification problems: \n",
        "\n",
        "* 70k examples of handwritten digits\n",
        "* Image size: 28x28\n",
        "* 1 channel\n",
        "* 10 classes: [0-9]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Ziy61Bn1h8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202,
          "referenced_widgets": [
            "a94b6fa1934042079b30bba4296c21ae",
            "591e0064bfe24da997448b62d92086ea",
            "4bf69a55b31b44bd946dc6ee93d0513c",
            "7f68321de56d47869d7fb0706318922f",
            "93851b2387474c6a9c86bada690c3b10",
            "59cad425206d457d8acca6ca07b40f6d",
            "7328e83963f645d0bec196478b7d6d90",
            "bfa83f84aaa441d4af260e4e41e743bf"
          ]
        },
        "outputId": "67d31d52-5a7b-4a5d-ceb5-944c08e79d5a"
      },
      "source": [
        "mnist_data, mnist_info = tfds.load('mnist', with_info=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.0 (download: 11.06 MiB, generated: Unknown size, total: 11.06 MiB) to /root/tensorflow_datasets/mnist/3.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a94b6fa1934042079b30bba4296c21ae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Dl Completed...', max=4.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cwqnl7N7uqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "61d3b11f-347b-43e5-cb58-022187405f5a"
      },
      "source": [
        "print(mnist_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='mnist',\n",
            "    version=3.0.0,\n",
            "    description='The MNIST database of handwritten digits.',\n",
            "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
            "    }),\n",
            "    total_num_examples=70000,\n",
            "    splits={\n",
            "        'test': 10000,\n",
            "        'train': 60000,\n",
            "    },\n",
            "    supervised_keys=('image', 'label'),\n",
            "    citation=\"\"\"@article{lecun2010mnist,\n",
            "      title={MNIST handwritten digit database},\n",
            "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
            "      journal={ATT Labs [Online]. Available: http://yann. lecun. com/exdb/mnist},\n",
            "      volume={2},\n",
            "      year={2010}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqdICHPJA4jb",
        "colab_type": "text"
      },
      "source": [
        "We can see that, in this case, the dataset has a standard partition of 60k examples for training and 10k for testing. Let's convert them to [NumPy](https://numpy.org/) arrays:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSQ9WCSiBObp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_train_x = np.asarray([instance['image']/255 for instance in tfds.as_numpy(mnist_data['train'])])\n",
        "mnist_train_y = np.asarray([instance['label'] for instance in tfds.as_numpy(mnist_data['train'])])\n",
        "\n",
        "mnist_test_x = np.asarray([instance['image']/255 for instance in tfds.as_numpy(mnist_data['test'])])\n",
        "mnist_test_y = np.asarray([instance['label'] for instance in tfds.as_numpy(mnist_data['test'])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYOyCAHvBZrR",
        "colab_type": "text"
      },
      "source": [
        "Furthermore, the dataset includes methods for visualizing examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PgJ0xqU73vR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0586fb5-cfdd-4606-b0f2-441628320eb1"
      },
      "source": [
        "tfds.show_examples(mnist_info, mnist_data['test'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAIFCAYAAACtXuUzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3de7zVY97/8felrZJS5NBxhJRDdGCqnxSim9uhhtE43IWKm07kNE4Tt+PQGDHlQehOplFICRWhlBgk0l0koShSURPJTtP1+2Ovsr/fz7Vba6+99lpr7/16Ph7zeHS99/X97gtXaz5996fr67z3AgAAVdsuuV4AAADIPQoCAABAQQAAACgIAACAKAgAAIAoCAAAgKSC0kx2zvF3FGF4712u11AW7GuUYJ33fp9cL6Is2NsIKekzmycEABC2ItcLALKJggAAAFAQAAAACgIAACAKAgAAIAoCAAAgCgIAACAKAgAAIAoCAAAgCgIAACAKAgAAIAoCAAAgCgIAACAKAgAAIAoCAAAgCgIAACAKAgAAIKkg1wuA1LBhQ5PttddeJtu6dWtk/Mknn5TbmpCf2rVrZ7J+/fqZrH///pHxlClTzJwZM2akvY6PPvooMp49e3ba9wKQH3hCAAAAKAgAAAAFAQAAEAUBAACQ5Lz3qU92LvXJCGrevLnJZs2aZbJQo+Evv/wSGT/00ENmzlVXXVWG1aXHe++y/k0zKF/3dZs2bUw2bdo0k+23337ZWE7E+vXrI+M5c+aYOffdd5/JVq5cabLly5dnbF0ZNt97f3SuF1EW+bq3kVslfWbzhAAAAFAQAAAACgIAACAKAgAAIJoKjS5dupjsmWeeMVno39uYMWOS3q9Vq1ZmTu3atVO6f1y8yVCS3nzzTZOddNJJSe9VFjQVll2ogXDSpEkm23///bOxnKSci/4nT/VzJH7CoSQ9+eSTkfG9995r5oT2ehbQVJiG+GfczJkzzZxRo0aZbOjQoeW2pkzr1auXyXr27Gmyvn37Rsbfffddua2pNGgqBAAAJaIgAAAAFAQAAIAeAtWrVy8ynj9/vpnTrFkzk5Xm31txX3/9tclSPUzolltuiYwPPfRQMyf0BrtTTz01xdWlhx6Csvvwww9NFuo3yRfp9hCkYsSIESYbMmRIxu5fCvQQpCF+INWVV15p5ixcuNBkPXr0MFm+Hlq1ePFikx122GEmmzhxYmQc6jPIBXoIAABAiSgIAAAABQEAAKAgAAAAkgpyvYBsat++vcnuuOOOyLgsB7+EDib6/PPPk85ZvXp1Sve//fbbk8757LPPUroXqpYlS5aYLNTEVVhYaLLzzjvPZJ07d46M4825knTMMceUZok7DBgwwGTxJkZJuvrqq022devWtL4n0hP6796kSZO0rqtRo0ZG1pRpoabyWrVqpXTtiSeemOHVlC+eEAAAAAoCAABAQQAAAERBAAAAVMWaCkMn9qXS9BF6g2Co0WrVqlXpLSxFe+21V2QcarT6/vvvy3UNyIzTTjstMs70WwzXrl0bGXfv3t3MSbUBddiwYUmz+N6UpBNOOMFkjzzyiMniDWbVqlUzcwYNGmSy4cOHmyxfT7arrI488kiTpXIa3xNPPGGyTz75JCNryrRLLrnEZKFGw8qAJwQAAICCAAAAUBAAAABREAAAAFWxpsLQKyufeeaZyHjRokVmTvw0w2y4+OKLTbbHHntExqFXzj711FPltiZkzm9+85vIuE6dOhm9//jx4yPj8j7BMtTM+uyzz5rs4IMPNtmdd96Z1vd84YUXTHbGGWeYjEbD8hNqEq3oWrduHRmHTs5M1YoVK8q6nKziCQEAAKAgAAAAFAQAAEAUBAAAQJILNaaVONm51CejTGbOnGmyLl26RMavvfaamRM/AU8q/1fCeu/tkYkVSC729ebNmyPj6tWrZ/T+S5cujYwPPfTQjN4/XaFX3MZPUZwwYULa9583b57JOnbsmO7t5nvvj057MXmgvPf2hg0bTFa3bt2k14UatYcOHZqRNZVV+/btI+N33nkn7XvFXxM+d+7ctO+VSSV9ZvOEAAAAUBAAAAAKAgAAoCp2MFG+6tChg8kOO+ywpNc9+uijJivvfgFkRvxn6aXp5UlF/O2JvXr1MnPGjRuX0e+ZisLCQpPFe2HeeustM+eYY45J6f41a9ZMb2FI6tZbbzVZ7dq1k14XOhTr4YcfzsiakFk8IQAAABQEAACAggAAAIiCAAAAiKbCrGvVqpXJpk6darJ69eqZbM6cOZHxjBkzMrcwVCrxpsXGjRvnaCXJxd+UGDrsBrkXb1SVpGrVqiW9rlatWiZr0qSJyVatWpXewpAxPCEAAAAUBAAAgIIAAACIggAAAKiSvO3w8MMPN9nvfvc7k8XfqiZJRx+d/GVmu+xi66Zt27aZLPSmtXh23nnnmTn169c3WaixqkePHpFxvMkwV3jbYenF/9sde+yx5fr9brzxRpPdfffd5fo90xVqXvviiy9M5pzddqHPs4EDB0bGDz30UKpL4W2HxYQaokOfQXvuuWfSe4X+ey5btiy9hWVY/G2N8bcflsasWbMi41NOOcXM2bJlS9r3TxdvOwQAACWiIAAAABQEAACAggAAAKgCnFR49tlnR8YDBgwwc4477jiTpdosmcq8UANh6LpQg2IqTYuh+4f+OfOliRBlN378+Mi4U6dOad8r1Mz6zTffRMajR49O+/7ZduCBB5os9Pstk7/HkdyiRYtMFnot9XPPPRcZt2zZ0sw54IADUsoquhNOOCEyDr32uW/fvtlaTlI8IQAAABQEAACAggAAAIiCAAAAKM+aCs8880yTPfHEE5Fx9erVzZy1a9eaLNRINGbMGJP9/PPPkfGECRPMnPXr15vstttuM9kll1xisnR9/fXXGbsXKreePXua7KuvvsrBSjLjqquuSvva0D/3q6++WpblYCeWLFlisnPPPTcyPumkk8ycv/zlL+W2pnzy448/RsahpsJ8whMCAABAQQAAACgIAACActhDED9wSLL9ApLtGQj1AWTyZ/chN998s8lC/Q6Z9F//9V8m++c//xkZ5+ItWUCmNW/ePDI+6KCD0r5X6C2h+fIWvapiwYIFkfHChQvNnJEjR5rsr3/9q8mWLl1qslGjRkXGnTt3NnOuueaapOssyfHHHx8Zh/rWQh544AGTXXfddZFxYWFh2uvKBp4QAAAACgIAAEBBAAAAREEAAAAkudK8Ccw5l7HXhs2cOdNkXbp0MVm8iXDQoEFmTlkaNRo3bhwZ33TTTWbOpZdearLQv7fQW+fuuuuuyLhPnz5mTo8ePVK6/5VXXhkZjxgxwszJBe+9y/UayiKT+zpVtWvXjozfffddMyf0lriQcePGmezCCy9Mb2HlLN5AKEkvvvhiZHzwwQenff8nn3zSZL179073dvO998lfV5rHcrG3K7r4m0IbNGhg5qxbt85koc/xt956K3MLy6CSPrN5QgAAACgIAAAABQEAABAFAQAAUJaaCo899liTzZ4922SffPKJyQ477LB0vqWaNWtmsvgJVJJ04403RsahU9JCJwLee++9JpsyZYrJ3nvvvZ2sssh3331nsnr16plszpw5kXGoiWXjxo1Jv1+m0VRYdh9++KHJWrVqldK1a9asMdkrr7wSGQ8ePNjM+de//pXi6pKrWbOmyfbff3+TTZ482WSpNk/GrVy50mS///3vTZbK78ES0FRYBaXSVPjZZ5+ZLNQwm69oKgQAACWiIAAAABQEAACAggAAAChLrz8Onf4XamacMGFC0nuFGjdOPPFEk8VPCJSkunXrJr3/yy+/bLLQ64/L0KhknHrqqSZ77rnnTBZ/zeeDDz5o5pThVDbkUKghNdWmwn333ddk8ddnN2nSxMx5++23Tfb888+brHv37iZzLtqTFLr/+eefbxebQUcccYTJctFUC1QWPCEAAAAUBAAAgIIAAAAoSwcT/fvf/zZZ6PuGDiuKH3gS+rlq/M1xkvTzzz+b7NtvvzVZ/Oecod6ArVu3mqy8TZo0yWRnnHFGZPzll1+aOaG3QU6fPj1zCwvgYKKyKyiw7Tzxt1tK0t13312u6wj9vgkdOrTLLtE/S2zbti1jawjt/X79+pnshx9+MFlpPs9SwMFElVyoP2zo0KGRcej3JgcTAQCASouCAAAAUBAAAAAKAgAAoCwdTDRmzBiTXXTRRSY77rjjTPbRRx9Fxo8//riZ88Ybb5gs9Ca00EEs+eqss84y2dixYyPj+OEzktSmTRuTlXdTIcou1Lg6fPhwk4UaaK+77jqT7brrrmmtI9RAGJJu897atWtNFn8z4+WXX27mcOAQykPDhg1NFmoijAsdHFcZ8IQAAABQEAAAAAoCAAAgCgIAAKAsnVRYo0YNkx100EEpXRtvDqzKzUX77LPPTsdS+AStwsLCcluTxEmFudarVy+TNW3aNDK+4447Mvo94ycVLl261MwJNUV+8MEHJnvnnXcyt7DM4qTCSu6hhx4y2WWXXZb0utCJuYsXL87ImrKBkwoBAECJKAgAAAAFAQAAoCAAAADK0kmFoaa2+AmESC5+ylvo1DdUPePGjUs6589//nMWVgKgIuMJAQAAoCAAAAAUBAAAQBQEAABAWWoqBAAg34ROKmzXrl1kfOedd5o5X375ZbmtKZd4QgAAACgIAAAABQEAAFCW3naIyo23HaKS4m2HqJR42yEAACgRBQEAAKAgAAAAFAQAAEAUBAAAQBQEAABAFAQAAEAUBAAAQBQEAABApX/b4TpJK8pjIaiw9s/1AjKAfY0Q9jYqoxL3damOLgYAAJUTPzIAAAAUBAAAgIIAAACIgmAH51xT59ws59xHzrnFzrkrdjJ3iHPugsSv/+KcW+KcW+icm+ycq5fIj3DOPZ6l5QMlcs6d4pz7xDm3zDl3/U7m3e+c65L49QHOuXcS1zzlnKueyAc55/pma+1AMs65as65D5xzL+5kzo69XSz7m3Pux2LjKr+3KQh+tVXS1d77wyR1lDTQOXdYfJJzrkBSX0lPJqJXJLXy3h8paamkGyTJe/9/kpo4536TjcUDIc65apIelPSfkg6TdF4J+7q+pI7e+zmJ6B5Jw733zSWtl9Qvkf+vpMHlvnAgdVdI+rikLwb2tpxzR0vaMza1yu9tCoIE7/033vv3E7/+QUUbrHFgaldJ73vvtybmztj+a0lvS2pSbO4Lks4tv1UDSbWXtMx7/7n3foukCZJ6BOb9XtJLkuSccyra5xMTXxsr6XeS5L3/SdJy51z78l44kIxzromk0yQ9tpNpO/Z24ppqkv4i6Y/FJ7G3KQiCnHPNJLWV9E7gy50kzS/h0r6SphcbvyepcybXBpRSY0lfFRuvVLjQLb6v60vaUKzQjV/Dvka+uF9F/8e+bSdz4p/ZgyQ9773/JjC3Su9tCoIY51xtSc9KGuK93xiY0lDS2sB1N6noxw7/KBavkdSoPNYJZFhwX5eAfY2cc86dLmmN976kP6Btt2NvO+caSeopaUQJc6v03i7tSYWVmnNuVxUVA//w3k8qYdpmSTVj110k6XRJJ/roSU81E/OBXFklqWmxcZNEFld8X38nqZ5zriDxlCB+Dfsa+aCTpO7OuVNVtCf3cM6N8973is0rvrfbSmouaVnRT8ZUyzm3LNErI1Xxvc0TgoTEz01HS/rYe3/fTqZ+rKINtf26U1T0yKp74mdQxbWQtCjTawVKYZ6kgxN/a6C6inpang/M27GvE0XtLElnJ752oaQpxeayr5Fz3vsbvPdNvPfNVLSvZwaKASm6t6d67xt475slrvupWDEgVfG9TUHwq06Sekvq6pxbkPjfqYF50yUV/+srIyXVkfRK4pqHi33tBElTy23FQBKJP+EPkvSyij4Yn/beLw5MnSrp+GLj6yRd5ZxbpqKegtHFvtZJRX+7BqgI4nt7Z6r03uZdBmlwzk2W9Efv/ac7mVND0mxJxxZrzgLylnNurqTTvfcbdjKnraSrvPe9s7cyoGzY26mhIEiDc66lpP2K/73WwJyDJTX23r+etYUBZeCc6yBps/d+4U7mdJP0qfd+edYWBpQRezs1FAQAAIAeAgAAQEEAAABEQQAAAERBAAAAREEAAABEQQAAAERBAAAAREEAAABEQQAAAERBAAAAREEAAABEQQAAAERBAAAAREEAAABEQQAAAERBAAAAREEAAABEQQAAAERBAAAAREEAAABEQQAAAERBAAAAREEAAABEQQAAAERBAAAAREEAAABEQQAAAERBAAAAJBWUZrJzzpfXQlBxee9drtdQFuxrlGCd936fXC+iLNjbCCnpM5snBAAQtiLXCwCyiYIAAABQEAAAAAoCAAAgCgIAACAKAgAAIAoCAAAgCgIAACAKAgAAIAoCAAAgCgIAACAKAgAAIAoCAACgUr7tEACAqqRbt24mGzhwoMm6d+9usmHDhkXG119/feYWVg54QgAAACgIAAAABQEAABAFAQAAEE2FAIAqqmHDhiY7+eSTI+P77rvPzKlbt67JvPcmGzJkSGT86aefmjmjR49Ous5s4QkBAACgIAAAABQEAABAFAQAAEA0FQIAKpnatWubrFevXibr27evyY466qiMraNatWqRcZ06dTJ27/LAEwIAAEBBAAAAKAgAAIAoCAAAgCQXOl2pxMnOpT4ZQfvtt5/Jzj//fJO1adMm6b1GjBhhsvfeey+9hZWB995l/ZtmEPsaJZjvvT8614soi6q6t+fMmWOyTp06mcw5+9EV///EwsJCM2f48OEmC70Sef369ZHxAQccYBebAyV9ZvOEAAAAUBAAAAAKAgAAIA4myqj4IRSS9Mc//jEyvuqqq8yc0M+x9tprr6Tfr1GjRibr1q1b0uuQe4ccckhkfP/995s5jRs3NlmoRyR07YcffliG1QH5K/57Z8qUKWZO06ZN077/999/HxlfcsklZs5zzz1nstCbE8ePH5/2OnKBJwQAAICCAAAAUBAAAABREAAAAHEwUdpat25tsv/5n/8xWY8ePSLjsWPHmjm33nqryb766iuTPfHEE5Fx165dzZxQY0tIgwYNTLZ69eqUro3jYKLSO+644yLj119/Pe17bd261WRLly6NjOfOnZv2/adNm2ayzZs3R8ZnnXWWmZNuQ9Xy5ctNtmLFirTuVUYcTJRjBQW27/2BBx6IjC+77LK07x/6nL3yyisj48mTJ6d9/3zFwUQAAKBEFAQAAICCAAAAUBAAAADRVJiSjh07muzxxx832UEHHWSyeMPLmDFjzJxt27altI74yXXTp083c/r06WOyW265xWShk+yGDh2a0jriaCosvRo1akTGoX1x3nnnZWs5eeWHH34w2bvvvmuyk046qbyXQlNhFsVPIJSkwYMHm6wsTYRxodNlqwKaCgEAQIkoCAAAAAUBAACgIAAAAOL1xym5+uqrTdayZUuTxU8llKTnn38+Y+vYtGlTZBx6/fG8efNMdvPNN5vsvvvuy9i6UHqFhYWRcd++fc2c2267zWQnn3yyyTZu3GiyCy64IDIuy+tgUxE6ITPULFu7du2k96pTp47JPvjgg/QWhgojlabsVL3yyismGzFiRFr3qkp4QgAAACgIAAAABQEAABAFAQAAEE2FRrNmzUwWerXrqFGjTPbCCy9kbB2/+c1vTBZvitlzzz1TWte9995rsp9//rkMq0Omhf57LFmyJKUsJHTyYXlq0aKFyQ499FCTTZo0yWS77BL9c8m///1vM2fRokVlWB0qglDzdio2bNhgsuuvv95kCxYsSOv+VQlPCAAAAAUBAACgIAAAAKKHwGjQoIHJnLMvhpo9e7bJQm+OLCiI/ivu37+/mdO1a1eTnXLKKSZbtmxZZHz22WebOZMnTzYZUN4+/fRTk919990mi/cLSPb3zbXXXmvmjB07tgyrQ0Vw4IEHpnVd/BAuiX6BdPGEAAAAUBAAAAAKAgAAIAoCAAAgmgqNNm3apDRv3bp1Jgu9mWvgwIGR8eGHH27mrF+/3mT33HOPyeIHE3333XdJ1wlkw/HHH2+yM888M6Vr42/eHD58eCaWhDx2ww03mCx0GFsq3njjjbTX0apVK5N17tw56XWht45279496XVTpkwx2TnnnGOyLVu2JL1XeeAJAQAAoCAAAAAUBAAAQBQEAABANBUa9evXT2neiy++aLL4qYSS9MEHH0TGffr0MXMmTJhgssLCwpTWAeTCxRdfHBk/+uijKV33/fffm+zOO+/MyJqQn0Kfi6EGwtBJryH3339/ZLxp0yYzp3Xr1iarU6eOyZ566imThU6rTUUq6w81HtasWdNkNBUCAICcoSAAAAAUBAAAgIIAAACIpkL9x3/8R2R83XXXpXRdqOmjR48eJnvppZfSWxiQJ5o0aWKyK664Iq17XXrppSYLndSJymP33Xc32X//93+nfb+NGzdGxqHXx48bN85ke++9t8lCr7ZPpTkw1PS96667miz0uu98VrFWCwAAygUFAQAAoCAAAAAUBAAAQFWsqbBfv34me+SRRyLjZcuWmTlr1qwx2VFHHWWyUFMJUNE9++yzJgu9Njbu4YcfNtlzzz2XkTWh6rr55puz+v2ef/55k4X29qhRo0zWtGnTcllTeeEJAQAAoCAAAAAUBAAAQJWkh2C//fYz2bBhw0x26qmnmizeV/Dkk0+aOaE3c40ZM8ZkI0eONNm8efMi49WrV5s5QL449thjTRZ6c1zcW2+9ZbL+/ftnZE1AeZk6darJHnzwwcg49JbE0047zWSNGjVK+v2WLFlisq1btya9Llt4QgAAACgIAAAABQEAABAFAQAAUAVsKiwosEteunSpyUJvsQq9Feu9995L+j1DhxWNGDHCZBMmTDBZhw4dIuMpU6Yk/X5ANhx99NEme+2110xWvXp1k40fPz4yHjBgQOYWBpTRL7/8YrL77rvPZH/+859NFn8DbuhzPVWffPJJZNy9e3cz56effkr7/pnGEwIAAEBBAAAAKAgAAIAoCAAAgCpAU2H8DYJz5swxcwoLC00WbwyRpAULFmRsXfXr109p3rp16zL2PYF07bKLrf2feOIJk4UaCN955x2TxZsIN2zYUIbVAZmV6n585plnTNatW7eMrePqq6+OjD/77LOM3bs88IQAAABQEAAAAAoCAAAgCgIAAKA8ayrce++9TXb77bdHxvGT/yTpmGOOMVkmGwhr1Khhst69e5tsy5YtJgudoghkW+h13YceeqjJNm7caLJrrrnGZDQRIlWhU2PL2z777GOy6667zmShZttt27Ylvf/ixYtN9uSTT5rslVdeSXqvfMITAgAAQEEAAAAoCAAAgPKshyB0iE+tWrUi4++//97MqVmzpslCb0UMadOmTWTctGlTMyf0lqzQvNtuu81ka9euTWkdQCYNHDgwMr7gggtSuu5vf/ubyebOnZuRNaFq+vHHH03WpUsXkz3wwAMma9u2bbmsaTvvfdI5oT6wM844w2QrVqzIyJpyiScEAACAggAAAFAQAAAAURAAAABJLpWmih2TnUt9cobEm/5Gjx5t5mSy8SR0KMXs2bNNdvnll5ssdFhFVeC9z/7JIxmUi32dSbvttpvJ4gcHhd5iOGPGDJP17NnTZKHDiqqI+d77o3O9iLKoSHt7//33N9kLL7xgssMPPzxj3/ONN94w2YQJEyLjV1991cxZtmxZxtaQCyV9ZvOEAAAAUBAAAAAKAgAAIAoCAACgCtBUGNegQQOTnXjiiWnfL3661JIlS8yc0AmK+BVNhbl15513muzGG2+MjENNUEceeaTJNm/enLmFVXw0FaJSoqkQAACUiIIAAABQEAAAAAoCAACgCthUiPxDU2H21K9f32TLly83We3atSPjk08+2cwJnVSICJoKUSnRVAgAAEpEQQAAACgIAAAABQEAAJBUkOsFAEjdGWecYbJ4A2FI6DWvAFAcTwgAAAAFAQAAoCAAAACihwCoUFLpFwi55pprTHb77beXdTkAKhGeEAAAAAoCAABAQQAAAERBAAAAxNsOkQG87RCVFG87RKXE2w4BAECJKAgAAAAFAQAAoCAAAAAq/UmF6yStKI+FoMLaP9cLyAD2NULY26iMStzXpfpbBgAAoHLiRwYAAICCAAAAUBAAAABREEQ45650zi12zi1yzo13ztUsYd79zrkuiV+f6Jx73zm3wDk31znXPJEPcs71zeb6gTjnXMvE3tz+v43OuSElzB3inLsg8eunil2z3Dm3IJEf4Zx7PIv/CECJnHP1nHMTnXNLnHMfO+f+XwnzduztxHhw4prFzrlhiazK722aChOcc40lzZV0mPd+s3PuaUnTvPePx+bVlzTVe98xMV4qqYf3/mPn3ABJ7b33Fznnakl603vfNrv/JECYc66apFWSOnjvV8S+ViDpfUntvPdbY1/7q6R/ee9vS4xfldTXe/9ldlYOhDnnxkp6w3v/mHOuuqRa3vsNsTmRve2cO0HSTZJO894XOuf29d6vScyt0nubJwRRBZJ2S2ygWpK+Dsz5vaSXio29pD0Sv667/Rrv/U+Sljvn2pffcoFSOVHSZ/FiIKGrpPcDxYCT9AdJ44vFL0g6t9xWCaTAOVdXUhdJoyXJe78lXgwkxPd2f0l3e+8LE9etKTa3Su9tCoIE7/0qSfdK+lLSNyr6E9GMwNROkuYXG18saZpzbqWk3pLuLva19yR1Lp8VA6V2rqL/x15cfF9v11nSt977T4tl7GvkgwMkrZU0xjn3gXPuMefc7oF58b3dQlJn59w7zrnZzrnfFvtald7bFAQJzrk9JfVQ0SZrJGl351yvwNSGKtqE210p6VTvfRNJYyTdV+xraxL3AnIq8Ti1u6RnSpgS39fbnSdbRLCvkQ8KJLWT9FDiR7ObJF0fmBff2wWS9pLUUdK1kp5OPAmTqvjepiD41UmSvvDer/Xe/yJpkqRjAvM2S6opSc65fSS19t6/k/jaU7FraibmA7n2nyp6bPptCV/fsa+3S/zo7CwV7evi2NfIByslrSz2+TtRRQVCXHxvr5Q0yRd5V9I2SXsnvlal9zYFwa++lNTROVcrUS2eKOnjwLyPJTVP/Hq9pLrOuRaJcbfYNS0kLYmWZPQAABKOSURBVCqn9QKlEfqTfnHF9/V2J0la4r1fGcvZ18g57/1qSV8551omohMlfRSYGt/bz0k6QZISn93VVXTEs1TF9zYFQUKiypyoom7U/1PRv5tHAlOnSjo+cc1WSZdIetY596GKegiuLTa3k6RXym/VQHKJn6t2U9FTr5JMV1GDVnEl9RycoKLfB0CuDZb0D+fcQkltJN0VmBPf2/8r6UDn3CJJEyRd6H/963ZVem/z1w7T4JybK+n0Ejpat89pK+kq733v7K0MSJ9zbrKkP8YaCONzakiaLenY+N9IAPIVezs1FARpcM51kLTZe79wJ3O6SfrUe788awsDyiDx6HU/7/2cncw5WFJj7/3rWVsYUEbs7dRQEAAAAHoIAAAABQEAABAFAQAAEAUBAAAQBQEAABAFAQAAEAUBAAAQBQEAABAFAQAAEAUBAAAQBQEAABAFAQAAEAUBAAAQBQEAABAFAQAAEAUBAAAQBQEAABAFAQAAEAUBAAAQBQEAABAFAQAAEAUBAAAQBQEAABAFAQAAEAUBAAAQBQEAABAFAQAAEAUBAACQVFCayc45X14LQcXlvXe5XkNZsK9RgnXe+31yvYiyYG8jpKTPbJ4QAEDYilwvAMgmCgIAAEBBAAAAKAgAAIAoCAAAgCgIAACAKAgAAIAoCAAAgCgIAACAKAgAAIAoCAAAgCgIAACAKAgAAIAoCAAAgCgIAACAKAgAAIAoCAAAgCgIAACApIJcLwBAxVO7du3I+NFHHzVzzj33XJO9/fbbJjv55JMj440bN5ZxdajqqlevbrIaNWqkdO1JJ50UGd9yyy1mzhFHHJHSveLX3nHHHSldlys8IQAAABQEAACAggAAAIiCAAAAqBI3FRYU2H+0iy++2GQHH3xw0nv9+OOPJnvsscdMtmbNGpMVFhYmvT+Qzw455BCTTZs2LTJu1qyZmeO9N1mHDh1M1rt378j4wQcfLOUKkU+qVasWGbds2dLMufTSS8t1DUceeaTJOnfubDLnnMlC+zadOVJ4v+cznhAAAAAKAgAAQEEAAABEQQAAAFSJmwr/9Kc/pZSlItR4ctNNN5ls1qxZJnv11Vd3Opak+fPnp7UuINMaNmxospdfftlkTZs2jYwfeeQRM+e2224z2bJly0wWagBGxbXvvvtGxgsXLszRSrJr8+bNJps0aVIOVpI+nhAAAAAKAgAAQEEAAAAkuVQPWJAk51zqk7PovPPOM9m4ceNMVpp/1uLSPbwi5JdffjHZ+++/b7KnnnrKZLNnz46MP/zww7TWkGnee/svqALJ131d3nbbbTeTjRkzxmR/+MMfTPbSSy9Fxj179jRzNm3aZLKnn37aZKNGjYqMX3vtNbvY3JjvvT8614soi1zs7XgfyldffZXtJaQsk5/t11xzjcnuv//+tO5V3kr6zOYJAQAAoCAAAAAUBAAAQBQEAABAlaSpcPHixSYLvaEtH5oKy3Kv+FsXx48fb+b0798/rXWVBU2FFVNor4TeNPjFF1+YrHXr1pFx6I2gIaG3Iq5atSoyDjXe5ghNhWmoUaNGZDxy5Egzp0+fPmnf/4MPPoiMQ5/1oYbZkFQ+j0MHDg0dOtRk//jHP0y2du3alNaRbTQVAgCAElEQAAAACgIAAEBBAAAAVAGbCkeMGGGyAQMGmGyXXWyts23btrS+Z+i6r7/+2mQTJkww2bRp0yLj+GmDktSoUSOTnXPOOSa78sorI+MmTZqYOfEGLUk688wzTbZgwQKTbd261WSpoKkw/x19tO2Ne/PNN032ww8/mOzkk082WRV5QydNhRkQavA76qij0r5f/LMrtBcPOuiglO4Vair8+eefI+NBgwaZOaETPSsSmgoBAECJKAgAAAAFAQAAoCAAAACSCnK9gGTq1KkTGXfp0sXMCTVGhhoBQw1TY8eOjYzbtWtn5syYMcNkt99+u11smkINisOHDzfZN998ExmHTsaKv3pUkt5++22TDRw40GTx19Ci8rj88stNtuuuu5rsn//8p8mqSAMhyknopL+5c+emfb/4Xm7atGna9wo1Useb1OP/H1GZ8YQAAABQEAAAAAoCAAAgCgIAAKAKcFLhhRdeGBmPHj06petCJ1ANGTLEZKGTDyuKUFNh6ITDkKlTp5qsR48eaa2DkwrzT/v27SPjt956y8z57LPPTBY60TDUjFtFcFJhjg0ePNhk99xzT2RcvXr1tO9/0UUXmWzcuHFp36+i4KRCAABQIgoCAABAQQAAAPLsYKLQW/9GjhyZ1r1Ch/089thjad0rX61evTrta0MHGKFiCv0M9fHHH4+MQ2///Pvf/26yUL9AzZo1k37PjRs3JlsmsFOhw9KGDRtmstCBWumqCv0CpcETAgAAQEEAAAAoCAAAgCgIAACA8qypsGvXriarVatWWvcKNUeF3rpVkcXfBCmFD2QKmTNnTqaXgxw566yzTHbIIYckva5FixYm++KLL0xWUGA/JqpVqxYZ//zzz2bOhAkTTHbLLbeY7JdfftnpOlH5nHnmmSYbNGiQyTLZQBhyww03pHXd5MmTTbZkyZKyLifneEIAAAAoCAAAAAUBAAAQBQEAAFCeNRW2bdvWZKV5G2Nxjz76aFmXk3dOP/30yLhfv35mTqr/vtL994r8E3pDYSp69eplsi1btpgs9Hsp3kQYfyupJF1//fUme+mll0xGg2vl1rx5c5NNnDgxByux7rrrLpNt27Yt6XV33HGHyZ5++mmTDR06NDJetmxZKVaXfTwhAAAAFAQAAICCAAAAiIIAAAAoz5oKMyl0SlpFd+qpp2bsXvne3IKw0Mmdp512Wlr3WrFihcluvPFGk40fPz7pvZ599lmTvfXWWyYbNWqUyY466qjI+Keffkr6/VCx5UtTc6iBMN219ezZ02Tt27ePjEOnii5evNhkW7duTWsNZcUTAgAAQEEAAAAoCAAAgCgIAACA8qypsF27dmld9/7775vsm2++Ketycurmm282WehkwlQsXbrUZJWx6bIqOOOMM0zWsmXLpNetWrXKZN26dTNZus2m8+fPT2leaK21a9eOjGkqrFzWrFljsptuuslkffr0MVmoiXaPPfaIjGvUqGHmbNq0yWTr1q0zWeh18XvvvXdkXLduXTMnVfvvv39kHPp90rFjR5O99957aX/PsuAJAQAAoCAAAAAUBAAAQHnWQ3DccceZLJVDIir629JatWplsksvvdRkBQXR/1yhn3+F3lYXeqvdv/71r9IsEXmiYcOGaV03ffp0k3E4FbJh48aNJrvnnntSyho0aGCyZs2aRcb16tUzc1avXm2yBQsW7GyZO7Rp0yYy/u1vf2vmDBkyxGSp9PKEhA4DO+ecc0z2yy+/pHX/0uAJAQAAoCAAAAAUBAAAQBQEAABAedZUGGogTKWpMF/enJWKUAPh1KlTTbbffvuZLP7PGWogDDW7hA5uQtUyceLEcr1/qPkrJPRmtx9++CHTy0ElEWoODGWZFG8+DDUjhj6zX3/9dZMdeOCBSb9f9+7dTbbXXnuZ7Ntvv016r7LiCQEAAKAgAAAAFAQAAEAUBAAAQHnWVPjpp5+arHnz5jlYSebE31oYOoEw1ECYisGDB5vsscceS+teqBi+++67tK6bOXNmRtcRPzVz7NixKV3397//3WSbN2/OyJqQH+JvHzzrrLPMnMsuu8xkX375pckeeOABk2X7TYBHHnmkya699lqTpdJAGLJy5UqThRrGs4EnBAAAgIIAAABQEAAAAFEQAAAA5VlTYej0pyuuuCIHK0nu9NNPN9mf/vQnk7Vt2zYyjjdjSamftDhgwIDImAbCqmfGjBlpXbfHHnuY7Pvvv0/p2l133dVk8Uax448/3sxZtWqVyUJNYqhcrrnmmsj41ltvTem6Tp06mSz0Ofv5559HxgsXLjRzpk2bltL3vOGGG0wW/zxu2rSpmRM6STBd559/vsnWr1+fsfuXBk8IAAAABQEAAKAgAAAAyrMegh9//NFkzrmk14V+PpqqWrVqRcb169c3c4YOHWqyfv36pfX9Qv88oUMoOHQIIaGf+8+ePdtkxx13XGQc/7muJN14440mS6VfQJLGjx8fGYd+75522mkmKywsNBkql3333Tdj96pTp47JWrduvdOxJPXu3Tul+4c+jzP59tz4oUMjR440c+bNm5ex71dWPCEAAAAUBAAAgIIAAACIggAAAEhypWmgcM5lrtsiINSMsmjRosg41QMhnn322ZTmNWnSJDLu0KGDmZPJxpNXX33VZPfcc4/JZs2aldb9c8F7n7zzM4+V974ub126dDHZ9OnTI+PQGwXjv7ckaffddzfZUUcdZbJ4E2H37t3NnNdff91kFcx87/3RuV5EWeRib8cPnxo4cGC2l5CyTH62P//88yaLv+029HsuF0r6zOYJAQAAoCAAAAAUBAAAQBQEAABAedZUGNKiRYvIuH///mbOxRdfbLL4CYRS+s0iqTaezJw502TxJsJhw4altYZ8RlNh/mnUqFFk/MQTT5g5Xbt2NdmGDRtM9swzz5hsxIgRkXG+NEtlGE2FaahRo0ZkHHrDa8gf/vAHkx144IFJr7vssstMtueee6b0PefMmWOyN998MzIO/Z54+OGHTRY6hXPr1q0prSPbaCoEAAAloiAAAAAUBAAAgIIAAACoAjQVpqJhw4YmCzVMtWnTJq37b9q0yWShVxGvWbPGZKFXG1c2NBWikqKpEJUSTYUAAKBEFAQAAICCAAAAUBAAAABVkqZC5BZNhaikaCpEpURTIQAAKBEFAQAAoCAAAAAUBAAAQBQEAABAFAQAAEAUBAAAQBQEAABAFAQAAEAUBAAAQBQEAABAFAQAAEAUBAAAQFJBKeevk7SiPBaCCmv/XC8gA9jXCGFvozIqcV+X6vXHAACgcuJHBgAAgIIAAABQEAAAAFEQRDjnTnHOfeKcW+acu34n8+53znVJ/PoA59w7iWuecs5VT+SDnHN9s7V2oCTOuXrOuYnOuSXOuY+dc/+vhHlDnHMXFBsPTlyz2Dk3LJEd4Zx7PEtLB0rknKvpnHvXOfdhYo/eupO5xT+zRyeuWZj4fVE7kVf5z2yaChOcc9UkLZXUTdJKSfMknee9/yg2r76kqd77jonx05Imee8nOOcelvSh9/4h51wtSW9679tm9R8EiHHOjZX0hvf+sUTBWst7vyE2p0DS+5Laee+3OudOkHSTpNO894XOuX2992sSc1+V1Nd7/2WW/1GAHZxzTtLu3vsfnXO7Spor6Qrv/duxefHP7D289xsTv75P0hrv/d18ZvOEoLj2kpZ57z/33m+RNEFSj8C830t6SdqxIbtKmpj42lhJv5Mk7/1PkpY759qX98KBkjjn6krqImm0JHnvt8SLgYSukt733m9NjPtLutt7X5i4bk2xuS9IOrf8Vg0k54v8mBjumvhf6E+4Oz6zE9dtLwacpN22X8NnNgVBcY0lfVVsvDKRxXWSND/x6/qSNhT7EI1f856kzhleJ1AaB0haK2mMc+4D59xjzrndA/OK72tJaiGpc+LHYbOdc78t9jX2NfKCc66ac26BpDWSXvHevxOYFt/bcs6NkbRa0iGSRhT7UpXe2xQEpddQRR+wqVgjqVE5rgVIpkBSO0kPJR6FbpIU6o+J7+sCSXtJ6ijpWklPJ/5EJbGvkSe89//23reR1ERSe+dcq8A085ntve+joj38saRzin2pSu9tCoJfrZLUtNi4SSKL2yypZuLX30mql/j5a+iamon5QK6slLSy2J+cJqqoQIgrvq+3Xzcp8Vj2XUnbJO2d+Br7Gnkl8WOwWZJOCXw5vre3X/NvFf1o+PfF4iq9tykIfjVP0sGJvzVQXUU/I30+MO9jSc2lop9hqWgTnp342oWSphSb20LSonJbMZCE9361pK+ccy0T0YmSPgpM3bGvE56TdIIkOedaSKquomNwJfY18oBzbh/nXL3Er3dTUUP4ksDUHXvbFdnxa0ndY9dU6b1NQZCQ6AMYJOllFW2gp733iwNTp0o6vtj4OklXOeeWqainYHSxr3WS9Eq5LBhI3WBJ/3DOLZTURtJdgTnTVdR8uN3/SjrQObdIRX+KutD/+leSTlDR7wMglxpKmpXY1/NU1EPwYmBe8c9sJ2msc+7/JP1f4h63FZtbpT+z+WuHaXDOzZV0egnd2tvntJV0lfe+d/ZWBqTPOTdZ0h+995/uZE4NSbMlHVusmRbIa3xmp4aCIA3OuQ6SNnvvF+5kTjdJn3rvl2dtYUAZJH6ssJ/3fs5O5hwsqbH3/vWsLQwoIz6zU0NBAAAA6CEAAAAUBAAAQBQEAABAFAQAAEAUBAAAQNL/BwbOhv+SEbocAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R-cp8bEmHSo",
        "colab_type": "text"
      },
      "source": [
        "###Auxiliary Functions\n",
        "\n",
        "Simple functions for plotting graphs and other functionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAwmvr9Lmf9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  def plot_loss_accuracy(history):\n",
        "    Plots the graphs for loss and acccuracy, like the ones in ML9\n",
        "\"\"\"\n",
        "def plot_loss_accuracy(history):\n",
        "  fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "  loss_ax.set_title('Loss')\n",
        "  loss_ax.plot(history['loss'], '-r', label='Train')\n",
        "  loss_ax.plot(history['val_loss'], '-g', label='Validation')\n",
        "\n",
        "  acc_ax.set_title('Accuracy')\n",
        "  acc_ax.plot(history['accuracy'], '-r', label='Train')\n",
        "  acc_ax.plot(history['val_accuracy'], '-g', label='Validation')\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "def multiple_line_chart(ax: plt.Axes, xvalues: list, yvalues: dict, title: str, xlabel: str, ylabel: str, percentage=False):\n",
        "    legend: list = []\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel(ylabel)\n",
        "    if percentage:\n",
        "        ax.set_ylim(0.0, 1.0)\n",
        "\n",
        "    for name, y in yvalues.items():\n",
        "        if xvalues == None:\n",
        "            ax.plot(list(range(len(y))), y)\n",
        "        else:\n",
        "            ax.plot(xvalues, y)\n",
        "        legend.append(name)\n",
        "    ax.legend(legend, loc='best', fancybox=True, shadow=True, borderaxespad=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNBP_bLBHgj6",
        "colab_type": "text"
      },
      "source": [
        "###Test Functions\n",
        "\n",
        "This section contains all functions used for testing, in order to clean-up the model code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw720tNwKmpF",
        "colab_type": "text"
      },
      "source": [
        "####Test Model\n",
        "\n",
        "In order to properly validate the trainning of a model, multiple testruns should be conducted, with different batches and validation sets. The higher the number of runs, the higher the validity of the conclusions, but for simplicity we will only consider 3 sets in this report. \n",
        "The accuracy history will be the average off all tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3auxRdzIIXF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, epochs=10,tests=3, plot=False, verbose=1):\n",
        "  model.save_weights('test_model_init.h5')\n",
        "  train_hist = {'loss':         np.empty((tests, epochs)),\n",
        "                'val_loss':     np.empty((tests, epochs)),\n",
        "                'accuracy':     np.empty((tests, epochs)),\n",
        "                'val_accuracy': np.empty((tests, epochs)),}\n",
        "  for i in range(tests):\n",
        "    model.load_weights('test_model_init.h5')\n",
        "    if verbose:\n",
        "      print(\"TEST {}/{}\".format(i + 1, tests))\n",
        "    test_train_model = model.fit(mnist_train_x, mnist_train_y, validation_split=0.2, epochs=epochs, batch_size=256, verbose=verbose)\n",
        "    for key in train_hist:\n",
        "      train_hist[key][i] = test_train_model.history[key]\n",
        "  averaged_train_hist = {key: np.average(value, axis=0) for key, value in train_hist.items()}\n",
        "  if plot:\n",
        "    plot_loss_accuracy(averaged_train_hist)\n",
        "  \n",
        "  return averaged_train_hist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI1YNOdnWy3U",
        "colab_type": "text"
      },
      "source": [
        "####Test Model Parameter\n",
        "\n",
        "To test the impact of some parameter, the previous function is used with different values for the parameter. With this, we can plot the accuracy line for each model.\n",
        "(Note: for running all maybe consider using a single test, as this can take quite a while)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_StJeqdXiRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model_parameter(model_creator, parameter_values, epochs=50, verbose=1, tests=3):\n",
        "  named_parameters = parameter_values.items() if isinstance(parameter_values, dict) else zip(parameter_values, parameter_values)\n",
        "  return {name: test_model(model_creator(parameter), epochs, verbose=verbose, tests=tests)['val_accuracy'] for name, parameter in named_parameters}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "930I3lQLUPsx",
        "colab_type": "text"
      },
      "source": [
        "## Feed-Forward Networks\n",
        "\n",
        "In this section we explore feed-forward networks to classify the mnist dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FloIHp4xic5E",
        "colab_type": "text"
      },
      "source": [
        "#### Single-Layer Network\n",
        "\n",
        "First we evaluate how a simple Single-Layer network performs. Although Single-Layer networks are defined as a single input and output layer, but given how the data is an image, a flatten layer is needed in order to rearrange the shape. Given this context, we will call this a Single-layer network, since no hidden layers are added.\n",
        "This NN is very simple, so no parametrization is necessary and we can head straight to trainning and performance.\n",
        "Like stated in the introduction, we will use Adam optimizer, however we will use this case, given it's simplicity, to evaluate the impact of using it in comparison to standart gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YDXn9cu6SKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f393ea93-0813-411f-8db7-55bfafa0c9cd"
      },
      "source": [
        "single_layer_model = tf.keras.Sequential(name='single_layer')\n",
        "single_layer_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "single_layer_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "single_layer_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "\n",
        "single_layer_model.save_weights('single_layer_init.h5')\n",
        "single_layer_model_sgd = tf.keras.models.clone_model(single_layer_model)\n",
        "single_layer_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "single_layer_model_sgd.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "single_layer_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"single_layer\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcMTIrPbeYUJ",
        "colab_type": "text"
      },
      "source": [
        "##### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HXrQBwffgj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "single_layer_model.load_weights('single_layer_init.h5')\n",
        "single_layer_model_sgd.load_weights('single_layer_init.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x84V_1s7ifXi",
        "colab_type": "text"
      },
      "source": [
        "Given the simplicity of this network and the small number of params, the updates should be fast and small wich causes the NN to take longer to converge.For this reason we consider a big pacience (40), to hopefully let the NN converge.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNeTAKEsWkn2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2d5de600-4c88-4cb2-a589-cae991a66acb"
      },
      "source": [
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=40, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('single_layer_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True) #only one needed since Adam will be the best\n",
        "\n",
        "single_layer_train = single_layer_model.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "single_layer_train_sgd = single_layer_model_sgd.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 1.0027 - accuracy: 0.7492\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.86758, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.9645 - accuracy: 0.7592 - val_loss: 0.5500 - val_accuracy: 0.8676\n",
            "Epoch 2/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.4718 - accuracy: 0.8806\n",
            "Epoch 00002: val_accuracy improved from 0.86758 to 0.89242, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4694 - accuracy: 0.8811 - val_loss: 0.4190 - val_accuracy: 0.8924\n",
            "Epoch 3/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.3890 - accuracy: 0.8961\n",
            "Epoch 00003: val_accuracy improved from 0.89242 to 0.89975, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3877 - accuracy: 0.8968 - val_loss: 0.3700 - val_accuracy: 0.8997\n",
            "Epoch 4/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.3504 - accuracy: 0.9049\n",
            "Epoch 00004: val_accuracy improved from 0.89975 to 0.90558, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3502 - accuracy: 0.9050 - val_loss: 0.3448 - val_accuracy: 0.9056\n",
            "Epoch 5/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.3293 - accuracy: 0.9096\n",
            "Epoch 00005: val_accuracy improved from 0.90558 to 0.91100, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3280 - accuracy: 0.9100 - val_loss: 0.3291 - val_accuracy: 0.9110\n",
            "Epoch 6/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.3131 - accuracy: 0.9137\n",
            "Epoch 00006: val_accuracy improved from 0.91100 to 0.91250, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3132 - accuracy: 0.9136 - val_loss: 0.3184 - val_accuracy: 0.9125\n",
            "Epoch 7/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.3015 - accuracy: 0.9167\n",
            "Epoch 00007: val_accuracy improved from 0.91250 to 0.91400, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3021 - accuracy: 0.9162 - val_loss: 0.3097 - val_accuracy: 0.9140\n",
            "Epoch 8/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.2942 - accuracy: 0.9170\n",
            "Epoch 00008: val_accuracy improved from 0.91400 to 0.91683, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2937 - accuracy: 0.9172 - val_loss: 0.3046 - val_accuracy: 0.9168\n",
            "Epoch 9/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.2875 - accuracy: 0.9200\n",
            "Epoch 00009: val_accuracy improved from 0.91683 to 0.91933, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2872 - accuracy: 0.9201 - val_loss: 0.3008 - val_accuracy: 0.9193\n",
            "Epoch 10/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.2827 - accuracy: 0.9211\n",
            "Epoch 00010: val_accuracy improved from 0.91933 to 0.92075, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2818 - accuracy: 0.9212 - val_loss: 0.2966 - val_accuracy: 0.9208\n",
            "Epoch 11/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2774 - accuracy: 0.9225\n",
            "Epoch 00011: val_accuracy did not improve from 0.92075\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2774 - accuracy: 0.9225 - val_loss: 0.2942 - val_accuracy: 0.9192\n",
            "Epoch 12/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.2736 - accuracy: 0.9227\n",
            "Epoch 00012: val_accuracy did not improve from 0.92075\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2733 - accuracy: 0.9229 - val_loss: 0.2920 - val_accuracy: 0.9197\n",
            "Epoch 13/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2702 - accuracy: 0.9239\n",
            "Epoch 00013: val_accuracy did not improve from 0.92075\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2701 - accuracy: 0.9239 - val_loss: 0.2906 - val_accuracy: 0.9207\n",
            "Epoch 14/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2668 - accuracy: 0.9252\n",
            "Epoch 00014: val_accuracy improved from 0.92075 to 0.92167, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2671 - accuracy: 0.9251 - val_loss: 0.2886 - val_accuracy: 0.9217\n",
            "Epoch 15/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.2640 - accuracy: 0.9258\n",
            "Epoch 00015: val_accuracy improved from 0.92167 to 0.92225, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2645 - accuracy: 0.9255 - val_loss: 0.2868 - val_accuracy: 0.9222\n",
            "Epoch 16/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2622 - accuracy: 0.9259\n",
            "Epoch 00016: val_accuracy improved from 0.92225 to 0.92233, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2616 - accuracy: 0.9262 - val_loss: 0.2855 - val_accuracy: 0.9223\n",
            "Epoch 17/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.2605 - accuracy: 0.9273\n",
            "Epoch 00017: val_accuracy did not improve from 0.92233\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2600 - accuracy: 0.9277 - val_loss: 0.2857 - val_accuracy: 0.9214\n",
            "Epoch 18/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2577 - accuracy: 0.9275\n",
            "Epoch 00018: val_accuracy did not improve from 0.92233\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2577 - accuracy: 0.9275 - val_loss: 0.2848 - val_accuracy: 0.9221\n",
            "Epoch 19/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.2539 - accuracy: 0.9286\n",
            "Epoch 00019: val_accuracy did not improve from 0.92233\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2561 - accuracy: 0.9281 - val_loss: 0.2830 - val_accuracy: 0.9222\n",
            "Epoch 20/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.2545 - accuracy: 0.9285\n",
            "Epoch 00020: val_accuracy improved from 0.92233 to 0.92308, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2542 - accuracy: 0.9285 - val_loss: 0.2837 - val_accuracy: 0.9231\n",
            "Epoch 21/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2525 - accuracy: 0.9289\n",
            "Epoch 00021: val_accuracy improved from 0.92308 to 0.92367, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2528 - accuracy: 0.9289 - val_loss: 0.2821 - val_accuracy: 0.9237\n",
            "Epoch 22/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2517 - accuracy: 0.9298\n",
            "Epoch 00022: val_accuracy did not improve from 0.92367\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2515 - accuracy: 0.9301 - val_loss: 0.2829 - val_accuracy: 0.9236\n",
            "Epoch 23/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2492 - accuracy: 0.9303\n",
            "Epoch 00023: val_accuracy did not improve from 0.92367\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2501 - accuracy: 0.9301 - val_loss: 0.2822 - val_accuracy: 0.9231\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2490 - accuracy: 0.9307\n",
            "Epoch 00024: val_accuracy did not improve from 0.92367\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2490 - accuracy: 0.9307 - val_loss: 0.2825 - val_accuracy: 0.9234\n",
            "Epoch 25/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.2488 - accuracy: 0.9298\n",
            "Epoch 00025: val_accuracy improved from 0.92367 to 0.92433, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2478 - accuracy: 0.9302 - val_loss: 0.2819 - val_accuracy: 0.9243\n",
            "Epoch 26/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.2463 - accuracy: 0.9307\n",
            "Epoch 00026: val_accuracy did not improve from 0.92433\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2468 - accuracy: 0.9301 - val_loss: 0.2816 - val_accuracy: 0.9225\n",
            "Epoch 27/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2460 - accuracy: 0.9312\n",
            "Epoch 00027: val_accuracy did not improve from 0.92433\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2458 - accuracy: 0.9313 - val_loss: 0.2814 - val_accuracy: 0.9241\n",
            "Epoch 28/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.2446 - accuracy: 0.9314\n",
            "Epoch 00028: val_accuracy did not improve from 0.92433\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2447 - accuracy: 0.9313 - val_loss: 0.2818 - val_accuracy: 0.9227\n",
            "Epoch 29/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2428 - accuracy: 0.9325\n",
            "Epoch 00029: val_accuracy did not improve from 0.92433\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2437 - accuracy: 0.9323 - val_loss: 0.2812 - val_accuracy: 0.9240\n",
            "Epoch 30/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2427 - accuracy: 0.9327\n",
            "Epoch 00030: val_accuracy improved from 0.92433 to 0.92475, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2430 - accuracy: 0.9327 - val_loss: 0.2816 - val_accuracy: 0.9247\n",
            "Epoch 31/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2424 - accuracy: 0.9329\n",
            "Epoch 00031: val_accuracy did not improve from 0.92475\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2419 - accuracy: 0.9330 - val_loss: 0.2820 - val_accuracy: 0.9228\n",
            "Epoch 32/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2413 - accuracy: 0.9327\n",
            "Epoch 00032: val_accuracy did not improve from 0.92475\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2413 - accuracy: 0.9327 - val_loss: 0.2808 - val_accuracy: 0.9237\n",
            "Epoch 33/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.2411 - accuracy: 0.9330\n",
            "Epoch 00033: val_accuracy did not improve from 0.92475\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2407 - accuracy: 0.9330 - val_loss: 0.2835 - val_accuracy: 0.9244\n",
            "Epoch 34/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2398 - accuracy: 0.9332\n",
            "Epoch 00034: val_accuracy did not improve from 0.92475\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2399 - accuracy: 0.9332 - val_loss: 0.2816 - val_accuracy: 0.9235\n",
            "Epoch 35/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2380 - accuracy: 0.9333\n",
            "Epoch 00035: val_accuracy did not improve from 0.92475\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2389 - accuracy: 0.9329 - val_loss: 0.2816 - val_accuracy: 0.9243\n",
            "Epoch 36/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2388 - accuracy: 0.9335\n",
            "Epoch 00036: val_accuracy improved from 0.92475 to 0.92508, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2385 - accuracy: 0.9338 - val_loss: 0.2803 - val_accuracy: 0.9251\n",
            "Epoch 37/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2374 - accuracy: 0.9333\n",
            "Epoch 00037: val_accuracy did not improve from 0.92508\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2380 - accuracy: 0.9333 - val_loss: 0.2806 - val_accuracy: 0.9246\n",
            "Epoch 38/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.2370 - accuracy: 0.9340\n",
            "Epoch 00038: val_accuracy did not improve from 0.92508\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2374 - accuracy: 0.9341 - val_loss: 0.2809 - val_accuracy: 0.9250\n",
            "Epoch 39/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2367 - accuracy: 0.9343\n",
            "Epoch 00039: val_accuracy did not improve from 0.92508\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2367 - accuracy: 0.9344 - val_loss: 0.2801 - val_accuracy: 0.9244\n",
            "Epoch 40/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.2359 - accuracy: 0.9348\n",
            "Epoch 00040: val_accuracy did not improve from 0.92508\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2362 - accuracy: 0.9346 - val_loss: 0.2822 - val_accuracy: 0.9234\n",
            "Epoch 41/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.2357 - accuracy: 0.9342\n",
            "Epoch 00041: val_accuracy did not improve from 0.92508\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2353 - accuracy: 0.9342 - val_loss: 0.2835 - val_accuracy: 0.9235\n",
            "Epoch 42/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.2352 - accuracy: 0.9343\n",
            "Epoch 00042: val_accuracy did not improve from 0.92508\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2352 - accuracy: 0.9344 - val_loss: 0.2813 - val_accuracy: 0.9243\n",
            "Epoch 43/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.2333 - accuracy: 0.9352\n",
            "Epoch 00043: val_accuracy did not improve from 0.92508\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2343 - accuracy: 0.9351 - val_loss: 0.2810 - val_accuracy: 0.9242\n",
            "Epoch 44/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2346 - accuracy: 0.9349\n",
            "Epoch 00044: val_accuracy did not improve from 0.92508\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2345 - accuracy: 0.9350 - val_loss: 0.2810 - val_accuracy: 0.9243\n",
            "Epoch 45/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.2344 - accuracy: 0.9356\n",
            "Epoch 00045: val_accuracy did not improve from 0.92508\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2335 - accuracy: 0.9355 - val_loss: 0.2815 - val_accuracy: 0.9248\n",
            "Epoch 46/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2335 - accuracy: 0.9355\n",
            "Epoch 00046: val_accuracy did not improve from 0.92508\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2329 - accuracy: 0.9356 - val_loss: 0.2817 - val_accuracy: 0.9240\n",
            "Epoch 47/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2320 - accuracy: 0.9357\n",
            "Epoch 00047: val_accuracy did not improve from 0.92508\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2326 - accuracy: 0.9356 - val_loss: 0.2819 - val_accuracy: 0.9243\n",
            "Epoch 48/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.2323 - accuracy: 0.9355\n",
            "Epoch 00048: val_accuracy improved from 0.92508 to 0.92592, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2319 - accuracy: 0.9355 - val_loss: 0.2818 - val_accuracy: 0.9259\n",
            "Epoch 49/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.2313 - accuracy: 0.9363\n",
            "Epoch 00049: val_accuracy did not improve from 0.92592\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2319 - accuracy: 0.9360 - val_loss: 0.2821 - val_accuracy: 0.9248\n",
            "Epoch 50/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2304 - accuracy: 0.9363\n",
            "Epoch 00050: val_accuracy improved from 0.92592 to 0.92617, saving model to single_layer_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2312 - accuracy: 0.9361 - val_loss: 0.2821 - val_accuracy: 0.9262\n",
            "Epoch 51/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.2304 - accuracy: 0.9361\n",
            "Epoch 00051: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2309 - accuracy: 0.9357 - val_loss: 0.2823 - val_accuracy: 0.9243\n",
            "Epoch 52/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2304 - accuracy: 0.9361\n",
            "Epoch 00052: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2305 - accuracy: 0.9360 - val_loss: 0.2830 - val_accuracy: 0.9250\n",
            "Epoch 53/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2306 - accuracy: 0.9357\n",
            "Epoch 00053: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2303 - accuracy: 0.9357 - val_loss: 0.2818 - val_accuracy: 0.9248\n",
            "Epoch 54/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.2315 - accuracy: 0.9357\n",
            "Epoch 00054: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2298 - accuracy: 0.9360 - val_loss: 0.2823 - val_accuracy: 0.9241\n",
            "Epoch 55/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.2283 - accuracy: 0.9368\n",
            "Epoch 00055: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2296 - accuracy: 0.9362 - val_loss: 0.2836 - val_accuracy: 0.9237\n",
            "Epoch 56/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.2286 - accuracy: 0.9367\n",
            "Epoch 00056: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2290 - accuracy: 0.9367 - val_loss: 0.2823 - val_accuracy: 0.9247\n",
            "Epoch 57/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2285 - accuracy: 0.9367\n",
            "Epoch 00057: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2286 - accuracy: 0.9368 - val_loss: 0.2831 - val_accuracy: 0.9228\n",
            "Epoch 58/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2295 - accuracy: 0.9367\n",
            "Epoch 00058: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2286 - accuracy: 0.9369 - val_loss: 0.2833 - val_accuracy: 0.9244\n",
            "Epoch 59/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.2262 - accuracy: 0.9367\n",
            "Epoch 00059: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2282 - accuracy: 0.9365 - val_loss: 0.2826 - val_accuracy: 0.9242\n",
            "Epoch 60/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2273 - accuracy: 0.9369\n",
            "Epoch 00060: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2279 - accuracy: 0.9365 - val_loss: 0.2834 - val_accuracy: 0.9248\n",
            "Epoch 61/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2275 - accuracy: 0.9371\n",
            "Epoch 00061: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2275 - accuracy: 0.9372 - val_loss: 0.2845 - val_accuracy: 0.9241\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2269 - accuracy: 0.9372\n",
            "Epoch 00062: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2269 - accuracy: 0.9372 - val_loss: 0.2844 - val_accuracy: 0.9254\n",
            "Epoch 63/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2267 - accuracy: 0.9371\n",
            "Epoch 00063: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2270 - accuracy: 0.9371 - val_loss: 0.2843 - val_accuracy: 0.9234\n",
            "Epoch 64/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2261 - accuracy: 0.9376\n",
            "Epoch 00064: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2264 - accuracy: 0.9376 - val_loss: 0.2846 - val_accuracy: 0.9238\n",
            "Epoch 65/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2264 - accuracy: 0.9374\n",
            "Epoch 00065: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2262 - accuracy: 0.9374 - val_loss: 0.2841 - val_accuracy: 0.9240\n",
            "Epoch 66/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2269 - accuracy: 0.9373\n",
            "Epoch 00066: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2261 - accuracy: 0.9376 - val_loss: 0.2853 - val_accuracy: 0.9255\n",
            "Epoch 67/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2258 - accuracy: 0.9375\n",
            "Epoch 00067: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2258 - accuracy: 0.9375 - val_loss: 0.2843 - val_accuracy: 0.9247\n",
            "Epoch 68/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2247 - accuracy: 0.9378\n",
            "Epoch 00068: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2254 - accuracy: 0.9376 - val_loss: 0.2876 - val_accuracy: 0.9233\n",
            "Epoch 69/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2259 - accuracy: 0.9367\n",
            "Epoch 00069: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2254 - accuracy: 0.9368 - val_loss: 0.2854 - val_accuracy: 0.9214\n",
            "Epoch 70/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2241 - accuracy: 0.9372\n",
            "Epoch 00070: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2250 - accuracy: 0.9371 - val_loss: 0.2881 - val_accuracy: 0.9236\n",
            "Epoch 71/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.2246 - accuracy: 0.9378\n",
            "Epoch 00071: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2246 - accuracy: 0.9377 - val_loss: 0.2841 - val_accuracy: 0.9229\n",
            "Epoch 72/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2238 - accuracy: 0.9378\n",
            "Epoch 00072: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2243 - accuracy: 0.9376 - val_loss: 0.2852 - val_accuracy: 0.9236\n",
            "Epoch 73/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2246 - accuracy: 0.9369\n",
            "Epoch 00073: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2242 - accuracy: 0.9370 - val_loss: 0.2883 - val_accuracy: 0.9218\n",
            "Epoch 74/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2242 - accuracy: 0.9377\n",
            "Epoch 00074: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2240 - accuracy: 0.9376 - val_loss: 0.2865 - val_accuracy: 0.9233\n",
            "Epoch 75/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.2237 - accuracy: 0.9384\n",
            "Epoch 00075: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2233 - accuracy: 0.9385 - val_loss: 0.2889 - val_accuracy: 0.9222\n",
            "Epoch 76/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.2239 - accuracy: 0.9380\n",
            "Epoch 00076: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2235 - accuracy: 0.9381 - val_loss: 0.2868 - val_accuracy: 0.9240\n",
            "Epoch 77/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2234 - accuracy: 0.9375\n",
            "Epoch 00077: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2231 - accuracy: 0.9377 - val_loss: 0.2861 - val_accuracy: 0.9240\n",
            "Epoch 78/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.2233 - accuracy: 0.9379\n",
            "Epoch 00078: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2232 - accuracy: 0.9380 - val_loss: 0.2871 - val_accuracy: 0.9236\n",
            "Epoch 79/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.2235 - accuracy: 0.9376\n",
            "Epoch 00079: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2231 - accuracy: 0.9378 - val_loss: 0.2867 - val_accuracy: 0.9236\n",
            "Epoch 80/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.2221 - accuracy: 0.9383\n",
            "Epoch 00080: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2225 - accuracy: 0.9381 - val_loss: 0.2862 - val_accuracy: 0.9209\n",
            "Epoch 81/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2228 - accuracy: 0.9383\n",
            "Epoch 00081: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2223 - accuracy: 0.9384 - val_loss: 0.2879 - val_accuracy: 0.9236\n",
            "Epoch 82/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2213 - accuracy: 0.9387\n",
            "Epoch 00082: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2219 - accuracy: 0.9385 - val_loss: 0.2874 - val_accuracy: 0.9228\n",
            "Epoch 83/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.2215 - accuracy: 0.9379\n",
            "Epoch 00083: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2218 - accuracy: 0.9379 - val_loss: 0.2879 - val_accuracy: 0.9227\n",
            "Epoch 84/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2216 - accuracy: 0.9380\n",
            "Epoch 00084: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2217 - accuracy: 0.9380 - val_loss: 0.2873 - val_accuracy: 0.9229\n",
            "Epoch 85/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2209 - accuracy: 0.9388\n",
            "Epoch 00085: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2214 - accuracy: 0.9386 - val_loss: 0.2882 - val_accuracy: 0.9233\n",
            "Epoch 86/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2211 - accuracy: 0.9388\n",
            "Epoch 00086: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2211 - accuracy: 0.9387 - val_loss: 0.2879 - val_accuracy: 0.9222\n",
            "Epoch 87/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2213 - accuracy: 0.9381\n",
            "Epoch 00087: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2210 - accuracy: 0.9382 - val_loss: 0.2880 - val_accuracy: 0.9230\n",
            "Epoch 88/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.2205 - accuracy: 0.9390\n",
            "Epoch 00088: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2209 - accuracy: 0.9389 - val_loss: 0.2899 - val_accuracy: 0.9233\n",
            "Epoch 89/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2211 - accuracy: 0.9383\n",
            "Epoch 00089: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2209 - accuracy: 0.9384 - val_loss: 0.2916 - val_accuracy: 0.9211\n",
            "Epoch 90/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.2219 - accuracy: 0.9382\n",
            "Epoch 00090: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2205 - accuracy: 0.9385 - val_loss: 0.2896 - val_accuracy: 0.9223\n",
            "Epoch 00090: early stopping\n",
            "Epoch 1/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 1.7126 - accuracy: 0.5315\n",
            "Epoch 00001: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.7043 - accuracy: 0.5353 - val_loss: 1.2658 - val_accuracy: 0.7355\n",
            "Epoch 2/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 1.0744 - accuracy: 0.7777\n",
            "Epoch 00002: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0688 - accuracy: 0.7791 - val_loss: 0.9308 - val_accuracy: 0.8073\n",
            "Epoch 3/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.8465 - accuracy: 0.8182\n",
            "Epoch 00003: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.8436 - accuracy: 0.8186 - val_loss: 0.7803 - val_accuracy: 0.8315\n",
            "Epoch 4/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.7296 - accuracy: 0.8369\n",
            "Epoch 00004: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.7298 - accuracy: 0.8368 - val_loss: 0.6942 - val_accuracy: 0.8459\n",
            "Epoch 5/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.6623 - accuracy: 0.8467\n",
            "Epoch 00005: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.6601 - accuracy: 0.8474 - val_loss: 0.6379 - val_accuracy: 0.8535\n",
            "Epoch 6/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.6139 - accuracy: 0.8545\n",
            "Epoch 00006: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.6125 - accuracy: 0.8547 - val_loss: 0.5977 - val_accuracy: 0.8591\n",
            "Epoch 7/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.5789 - accuracy: 0.8602\n",
            "Epoch 00007: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.5776 - accuracy: 0.8605 - val_loss: 0.5674 - val_accuracy: 0.8623\n",
            "Epoch 8/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.5515 - accuracy: 0.8641\n",
            "Epoch 00008: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.5508 - accuracy: 0.8641 - val_loss: 0.5437 - val_accuracy: 0.8656\n",
            "Epoch 9/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.5312 - accuracy: 0.8677\n",
            "Epoch 00009: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.5292 - accuracy: 0.8678 - val_loss: 0.5243 - val_accuracy: 0.8692\n",
            "Epoch 10/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.5119 - accuracy: 0.8712\n",
            "Epoch 00010: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.5116 - accuracy: 0.8712 - val_loss: 0.5084 - val_accuracy: 0.8721\n",
            "Epoch 11/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.4956 - accuracy: 0.8742\n",
            "Epoch 00011: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4968 - accuracy: 0.8740 - val_loss: 0.4949 - val_accuracy: 0.8748\n",
            "Epoch 12/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.4855 - accuracy: 0.8760\n",
            "Epoch 00012: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4841 - accuracy: 0.8764 - val_loss: 0.4832 - val_accuracy: 0.8760\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.4732 - accuracy: 0.8789\n",
            "Epoch 00013: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4732 - accuracy: 0.8789 - val_loss: 0.4730 - val_accuracy: 0.8783\n",
            "Epoch 14/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.4639 - accuracy: 0.8801\n",
            "Epoch 00014: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4635 - accuracy: 0.8803 - val_loss: 0.4642 - val_accuracy: 0.8805\n",
            "Epoch 15/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.4553 - accuracy: 0.8818\n",
            "Epoch 00015: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4550 - accuracy: 0.8817 - val_loss: 0.4561 - val_accuracy: 0.8817\n",
            "Epoch 16/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.4471 - accuracy: 0.8833\n",
            "Epoch 00016: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4473 - accuracy: 0.8833 - val_loss: 0.4490 - val_accuracy: 0.8834\n",
            "Epoch 17/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.4404 - accuracy: 0.8843\n",
            "Epoch 00017: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4405 - accuracy: 0.8844 - val_loss: 0.4426 - val_accuracy: 0.8840\n",
            "Epoch 18/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.4345 - accuracy: 0.8852\n",
            "Epoch 00018: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4342 - accuracy: 0.8852 - val_loss: 0.4367 - val_accuracy: 0.8857\n",
            "Epoch 19/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.4282 - accuracy: 0.8862\n",
            "Epoch 00019: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4285 - accuracy: 0.8860 - val_loss: 0.4314 - val_accuracy: 0.8863\n",
            "Epoch 20/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.4240 - accuracy: 0.8872\n",
            "Epoch 00020: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4233 - accuracy: 0.8875 - val_loss: 0.4264 - val_accuracy: 0.8873\n",
            "Epoch 21/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.4184 - accuracy: 0.8881\n",
            "Epoch 00021: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4184 - accuracy: 0.8881 - val_loss: 0.4219 - val_accuracy: 0.8879\n",
            "Epoch 22/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.4134 - accuracy: 0.8888\n",
            "Epoch 00022: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4140 - accuracy: 0.8889 - val_loss: 0.4177 - val_accuracy: 0.8882\n",
            "Epoch 23/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.4102 - accuracy: 0.8896\n",
            "Epoch 00023: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4098 - accuracy: 0.8899 - val_loss: 0.4137 - val_accuracy: 0.8886\n",
            "Epoch 24/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.4051 - accuracy: 0.8905\n",
            "Epoch 00024: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4059 - accuracy: 0.8903 - val_loss: 0.4101 - val_accuracy: 0.8895\n",
            "Epoch 25/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.4034 - accuracy: 0.8902\n",
            "Epoch 00025: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4023 - accuracy: 0.8909 - val_loss: 0.4067 - val_accuracy: 0.8898\n",
            "Epoch 26/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.3991 - accuracy: 0.8918\n",
            "Epoch 00026: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3989 - accuracy: 0.8919 - val_loss: 0.4036 - val_accuracy: 0.8900\n",
            "Epoch 27/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.3945 - accuracy: 0.8929\n",
            "Epoch 00027: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3957 - accuracy: 0.8921 - val_loss: 0.4005 - val_accuracy: 0.8912\n",
            "Epoch 28/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.3926 - accuracy: 0.8932\n",
            "Epoch 00028: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3927 - accuracy: 0.8932 - val_loss: 0.3977 - val_accuracy: 0.8919\n",
            "Epoch 29/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.3900 - accuracy: 0.8936\n",
            "Epoch 00029: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3898 - accuracy: 0.8937 - val_loss: 0.3950 - val_accuracy: 0.8919\n",
            "Epoch 30/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.3876 - accuracy: 0.8941\n",
            "Epoch 00030: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3871 - accuracy: 0.8944 - val_loss: 0.3925 - val_accuracy: 0.8926\n",
            "Epoch 31/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8950\n",
            "Epoch 00031: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3845 - accuracy: 0.8950 - val_loss: 0.3900 - val_accuracy: 0.8933\n",
            "Epoch 32/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.3821 - accuracy: 0.8956\n",
            "Epoch 00032: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3821 - accuracy: 0.8955 - val_loss: 0.3878 - val_accuracy: 0.8943\n",
            "Epoch 33/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.8958\n",
            "Epoch 00033: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3797 - accuracy: 0.8958 - val_loss: 0.3856 - val_accuracy: 0.8943\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.8969\n",
            "Epoch 00034: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3775 - accuracy: 0.8969 - val_loss: 0.3836 - val_accuracy: 0.8948\n",
            "Epoch 35/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.3756 - accuracy: 0.8967\n",
            "Epoch 00035: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3754 - accuracy: 0.8968 - val_loss: 0.3816 - val_accuracy: 0.8955\n",
            "Epoch 36/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.3734 - accuracy: 0.8976\n",
            "Epoch 00036: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3734 - accuracy: 0.8975 - val_loss: 0.3797 - val_accuracy: 0.8960\n",
            "Epoch 37/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.3702 - accuracy: 0.8978\n",
            "Epoch 00037: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3714 - accuracy: 0.8976 - val_loss: 0.3778 - val_accuracy: 0.8962\n",
            "Epoch 38/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.3688 - accuracy: 0.8986\n",
            "Epoch 00038: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3695 - accuracy: 0.8986 - val_loss: 0.3761 - val_accuracy: 0.8965\n",
            "Epoch 39/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.8989\n",
            "Epoch 00039: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3677 - accuracy: 0.8989 - val_loss: 0.3744 - val_accuracy: 0.8972\n",
            "Epoch 40/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.3657 - accuracy: 0.8995\n",
            "Epoch 00040: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3660 - accuracy: 0.8994 - val_loss: 0.3729 - val_accuracy: 0.8974\n",
            "Epoch 41/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.3640 - accuracy: 0.8996\n",
            "Epoch 00041: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3643 - accuracy: 0.8996 - val_loss: 0.3714 - val_accuracy: 0.8975\n",
            "Epoch 42/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.3630 - accuracy: 0.8999\n",
            "Epoch 00042: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3628 - accuracy: 0.9001 - val_loss: 0.3698 - val_accuracy: 0.8982\n",
            "Epoch 43/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.3623 - accuracy: 0.8999\n",
            "Epoch 00043: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3612 - accuracy: 0.9004 - val_loss: 0.3684 - val_accuracy: 0.8985\n",
            "Epoch 44/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.3582 - accuracy: 0.9012\n",
            "Epoch 00044: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3597 - accuracy: 0.9008 - val_loss: 0.3671 - val_accuracy: 0.8992\n",
            "Epoch 45/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.3573 - accuracy: 0.9016\n",
            "Epoch 00045: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3583 - accuracy: 0.9011 - val_loss: 0.3657 - val_accuracy: 0.8990\n",
            "Epoch 46/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.3561 - accuracy: 0.9016\n",
            "Epoch 00046: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3569 - accuracy: 0.9013 - val_loss: 0.3645 - val_accuracy: 0.9001\n",
            "Epoch 47/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.3554 - accuracy: 0.9020\n",
            "Epoch 00047: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3555 - accuracy: 0.9019 - val_loss: 0.3633 - val_accuracy: 0.8997\n",
            "Epoch 48/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.3564 - accuracy: 0.9017\n",
            "Epoch 00048: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3543 - accuracy: 0.9021 - val_loss: 0.3620 - val_accuracy: 0.9006\n",
            "Epoch 49/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.3525 - accuracy: 0.9027\n",
            "Epoch 00049: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3530 - accuracy: 0.9025 - val_loss: 0.3609 - val_accuracy: 0.9007\n",
            "Epoch 50/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.9025\n",
            "Epoch 00050: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3518 - accuracy: 0.9025 - val_loss: 0.3598 - val_accuracy: 0.9012\n",
            "Epoch 51/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.9029\n",
            "Epoch 00051: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3506 - accuracy: 0.9029 - val_loss: 0.3588 - val_accuracy: 0.9022\n",
            "Epoch 52/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.9032\n",
            "Epoch 00052: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3494 - accuracy: 0.9032 - val_loss: 0.3576 - val_accuracy: 0.9022\n",
            "Epoch 53/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.3466 - accuracy: 0.9041\n",
            "Epoch 00053: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3483 - accuracy: 0.9035 - val_loss: 0.3566 - val_accuracy: 0.9022\n",
            "Epoch 54/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.3463 - accuracy: 0.9041\n",
            "Epoch 00054: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3472 - accuracy: 0.9037 - val_loss: 0.3556 - val_accuracy: 0.9026\n",
            "Epoch 55/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.3469 - accuracy: 0.9035\n",
            "Epoch 00055: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3461 - accuracy: 0.9038 - val_loss: 0.3547 - val_accuracy: 0.9027\n",
            "Epoch 56/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.3459 - accuracy: 0.9036\n",
            "Epoch 00056: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3451 - accuracy: 0.9042 - val_loss: 0.3538 - val_accuracy: 0.9032\n",
            "Epoch 57/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.3444 - accuracy: 0.9044\n",
            "Epoch 00057: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3441 - accuracy: 0.9044 - val_loss: 0.3528 - val_accuracy: 0.9032\n",
            "Epoch 58/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.3422 - accuracy: 0.9049\n",
            "Epoch 00058: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3431 - accuracy: 0.9047 - val_loss: 0.3520 - val_accuracy: 0.9040\n",
            "Epoch 59/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.3431 - accuracy: 0.9046\n",
            "Epoch 00059: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3422 - accuracy: 0.9048 - val_loss: 0.3511 - val_accuracy: 0.9037\n",
            "Epoch 60/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.3410 - accuracy: 0.9049\n",
            "Epoch 00060: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3412 - accuracy: 0.9051 - val_loss: 0.3503 - val_accuracy: 0.9040\n",
            "Epoch 61/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.3405 - accuracy: 0.9053\n",
            "Epoch 00061: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3403 - accuracy: 0.9053 - val_loss: 0.3494 - val_accuracy: 0.9042\n",
            "Epoch 62/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.3380 - accuracy: 0.9061\n",
            "Epoch 00062: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3394 - accuracy: 0.9056 - val_loss: 0.3486 - val_accuracy: 0.9042\n",
            "Epoch 63/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.3381 - accuracy: 0.9060\n",
            "Epoch 00063: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3386 - accuracy: 0.9058 - val_loss: 0.3479 - val_accuracy: 0.9047\n",
            "Epoch 64/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.3374 - accuracy: 0.9061\n",
            "Epoch 00064: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.9060 - val_loss: 0.3472 - val_accuracy: 0.9048\n",
            "Epoch 65/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.9063\n",
            "Epoch 00065: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3369 - accuracy: 0.9063 - val_loss: 0.3464 - val_accuracy: 0.9046\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.3361 - accuracy: 0.9065\n",
            "Epoch 00066: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3361 - accuracy: 0.9065 - val_loss: 0.3457 - val_accuracy: 0.9051\n",
            "Epoch 67/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.3353 - accuracy: 0.9066\n",
            "Epoch 00067: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3353 - accuracy: 0.9066 - val_loss: 0.3449 - val_accuracy: 0.9053\n",
            "Epoch 68/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.3319 - accuracy: 0.9077\n",
            "Epoch 00068: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3345 - accuracy: 0.9069 - val_loss: 0.3443 - val_accuracy: 0.9053\n",
            "Epoch 69/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.3329 - accuracy: 0.9074\n",
            "Epoch 00069: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.9073 - val_loss: 0.3436 - val_accuracy: 0.9053\n",
            "Epoch 70/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.3317 - accuracy: 0.9078\n",
            "Epoch 00070: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3330 - accuracy: 0.9072 - val_loss: 0.3430 - val_accuracy: 0.9055\n",
            "Epoch 71/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.3331 - accuracy: 0.9071\n",
            "Epoch 00071: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3323 - accuracy: 0.9074 - val_loss: 0.3424 - val_accuracy: 0.9056\n",
            "Epoch 72/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.3288 - accuracy: 0.9086\n",
            "Epoch 00072: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.9077 - val_loss: 0.3417 - val_accuracy: 0.9060\n",
            "Epoch 73/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.3268 - accuracy: 0.9087\n",
            "Epoch 00073: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3309 - accuracy: 0.9075 - val_loss: 0.3411 - val_accuracy: 0.9062\n",
            "Epoch 74/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.3299 - accuracy: 0.9082\n",
            "Epoch 00074: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.9081 - val_loss: 0.3405 - val_accuracy: 0.9064\n",
            "Epoch 75/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.3295 - accuracy: 0.9073\n",
            "Epoch 00075: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.9077 - val_loss: 0.3400 - val_accuracy: 0.9067\n",
            "Epoch 76/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.3290 - accuracy: 0.9083\n",
            "Epoch 00076: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3289 - accuracy: 0.9084 - val_loss: 0.3393 - val_accuracy: 0.9067\n",
            "Epoch 77/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.3261 - accuracy: 0.9088\n",
            "Epoch 00077: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3283 - accuracy: 0.9081 - val_loss: 0.3388 - val_accuracy: 0.9067\n",
            "Epoch 78/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.3257 - accuracy: 0.9092\n",
            "Epoch 00078: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3276 - accuracy: 0.9086 - val_loss: 0.3382 - val_accuracy: 0.9070\n",
            "Epoch 79/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.3277 - accuracy: 0.9081\n",
            "Epoch 00079: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.9085 - val_loss: 0.3376 - val_accuracy: 0.9071\n",
            "Epoch 80/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.3259 - accuracy: 0.9087\n",
            "Epoch 00080: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3264 - accuracy: 0.9088 - val_loss: 0.3371 - val_accuracy: 0.9071\n",
            "Epoch 81/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.3263 - accuracy: 0.9088\n",
            "Epoch 00081: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3258 - accuracy: 0.9089 - val_loss: 0.3366 - val_accuracy: 0.9072\n",
            "Epoch 82/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.3252 - accuracy: 0.9090\n",
            "Epoch 00082: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3252 - accuracy: 0.9090 - val_loss: 0.3361 - val_accuracy: 0.9071\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.3247 - accuracy: 0.9093\n",
            "Epoch 00083: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.9093 - val_loss: 0.3356 - val_accuracy: 0.9072\n",
            "Epoch 84/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.3242 - accuracy: 0.9093\n",
            "Epoch 00084: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.9095 - val_loss: 0.3352 - val_accuracy: 0.9072\n",
            "Epoch 85/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.3237 - accuracy: 0.9095\n",
            "Epoch 00085: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3235 - accuracy: 0.9096 - val_loss: 0.3346 - val_accuracy: 0.9072\n",
            "Epoch 86/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.3225 - accuracy: 0.9096\n",
            "Epoch 00086: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3230 - accuracy: 0.9096 - val_loss: 0.3342 - val_accuracy: 0.9074\n",
            "Epoch 87/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.3221 - accuracy: 0.9099\n",
            "Epoch 00087: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3225 - accuracy: 0.9099 - val_loss: 0.3337 - val_accuracy: 0.9077\n",
            "Epoch 88/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.3222 - accuracy: 0.9104\n",
            "Epoch 00088: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3219 - accuracy: 0.9103 - val_loss: 0.3332 - val_accuracy: 0.9080\n",
            "Epoch 89/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.3224 - accuracy: 0.9099\n",
            "Epoch 00089: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3214 - accuracy: 0.9101 - val_loss: 0.3327 - val_accuracy: 0.9084\n",
            "Epoch 90/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.3240 - accuracy: 0.9095\n",
            "Epoch 00090: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3209 - accuracy: 0.9103 - val_loss: 0.3323 - val_accuracy: 0.9084\n",
            "Epoch 91/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.3205 - accuracy: 0.9104\n",
            "Epoch 00091: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3204 - accuracy: 0.9104 - val_loss: 0.3319 - val_accuracy: 0.9086\n",
            "Epoch 92/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.3193 - accuracy: 0.9112\n",
            "Epoch 00092: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3199 - accuracy: 0.9107 - val_loss: 0.3316 - val_accuracy: 0.9085\n",
            "Epoch 93/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.3196 - accuracy: 0.9109\n",
            "Epoch 00093: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3194 - accuracy: 0.9108 - val_loss: 0.3310 - val_accuracy: 0.9087\n",
            "Epoch 94/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.3189 - accuracy: 0.9109\n",
            "Epoch 00094: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3190 - accuracy: 0.9110 - val_loss: 0.3306 - val_accuracy: 0.9086\n",
            "Epoch 95/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.3181 - accuracy: 0.9116\n",
            "Epoch 00095: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3185 - accuracy: 0.9112 - val_loss: 0.3303 - val_accuracy: 0.9087\n",
            "Epoch 96/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.3188 - accuracy: 0.9111\n",
            "Epoch 00096: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3180 - accuracy: 0.9113 - val_loss: 0.3299 - val_accuracy: 0.9088\n",
            "Epoch 97/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.3183 - accuracy: 0.9110\n",
            "Epoch 00097: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3176 - accuracy: 0.9115 - val_loss: 0.3295 - val_accuracy: 0.9087\n",
            "Epoch 98/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.3159 - accuracy: 0.9116\n",
            "Epoch 00098: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3171 - accuracy: 0.9114 - val_loss: 0.3291 - val_accuracy: 0.9093\n",
            "Epoch 99/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.3174 - accuracy: 0.9115\n",
            "Epoch 00099: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3167 - accuracy: 0.9116 - val_loss: 0.3287 - val_accuracy: 0.9086\n",
            "Epoch 100/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.3159 - accuracy: 0.9115\n",
            "Epoch 00100: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3162 - accuracy: 0.9118 - val_loss: 0.3284 - val_accuracy: 0.9087\n",
            "Epoch 101/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.3156 - accuracy: 0.9119\n",
            "Epoch 00101: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3158 - accuracy: 0.9118 - val_loss: 0.3280 - val_accuracy: 0.9090\n",
            "Epoch 102/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.9122\n",
            "Epoch 00102: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3154 - accuracy: 0.9122 - val_loss: 0.3276 - val_accuracy: 0.9090\n",
            "Epoch 103/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.3163 - accuracy: 0.9119\n",
            "Epoch 00103: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3149 - accuracy: 0.9120 - val_loss: 0.3273 - val_accuracy: 0.9091\n",
            "Epoch 104/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.3149 - accuracy: 0.9118\n",
            "Epoch 00104: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3145 - accuracy: 0.9121 - val_loss: 0.3270 - val_accuracy: 0.9097\n",
            "Epoch 105/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.3139 - accuracy: 0.9123\n",
            "Epoch 00105: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3141 - accuracy: 0.9122 - val_loss: 0.3266 - val_accuracy: 0.9099\n",
            "Epoch 106/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.3133 - accuracy: 0.9125\n",
            "Epoch 00106: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3138 - accuracy: 0.9122 - val_loss: 0.3263 - val_accuracy: 0.9095\n",
            "Epoch 107/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.3128 - accuracy: 0.9112\n",
            "Epoch 00107: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3134 - accuracy: 0.9124 - val_loss: 0.3259 - val_accuracy: 0.9097\n",
            "Epoch 108/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.3128 - accuracy: 0.9125\n",
            "Epoch 00108: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3130 - accuracy: 0.9125 - val_loss: 0.3256 - val_accuracy: 0.9094\n",
            "Epoch 109/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.3129 - accuracy: 0.9124\n",
            "Epoch 00109: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3126 - accuracy: 0.9127 - val_loss: 0.3253 - val_accuracy: 0.9098\n",
            "Epoch 110/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.3126 - accuracy: 0.9121\n",
            "Epoch 00110: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3122 - accuracy: 0.9126 - val_loss: 0.3250 - val_accuracy: 0.9102\n",
            "Epoch 111/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.3106 - accuracy: 0.9133\n",
            "Epoch 00111: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3118 - accuracy: 0.9128 - val_loss: 0.3246 - val_accuracy: 0.9095\n",
            "Epoch 112/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.3111 - accuracy: 0.9131\n",
            "Epoch 00112: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3114 - accuracy: 0.9129 - val_loss: 0.3243 - val_accuracy: 0.9102\n",
            "Epoch 113/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.3117 - accuracy: 0.9128\n",
            "Epoch 00113: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3111 - accuracy: 0.9129 - val_loss: 0.3241 - val_accuracy: 0.9099\n",
            "Epoch 114/10000\n",
            "167/188 [=========================>....] - ETA: 0s - loss: 0.3109 - accuracy: 0.9129\n",
            "Epoch 00114: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3107 - accuracy: 0.9129 - val_loss: 0.3238 - val_accuracy: 0.9105\n",
            "Epoch 115/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.3104 - accuracy: 0.9131\n",
            "Epoch 00115: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3104 - accuracy: 0.9130 - val_loss: 0.3235 - val_accuracy: 0.9104\n",
            "Epoch 116/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.3102 - accuracy: 0.9129\n",
            "Epoch 00116: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3100 - accuracy: 0.9129 - val_loss: 0.3232 - val_accuracy: 0.9100\n",
            "Epoch 117/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.3076 - accuracy: 0.9139\n",
            "Epoch 00117: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3097 - accuracy: 0.9131 - val_loss: 0.3229 - val_accuracy: 0.9103\n",
            "Epoch 118/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.3089 - accuracy: 0.9135\n",
            "Epoch 00118: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3093 - accuracy: 0.9133 - val_loss: 0.3226 - val_accuracy: 0.9103\n",
            "Epoch 119/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.3090 - accuracy: 0.9133\n",
            "Epoch 00119: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3090 - accuracy: 0.9133 - val_loss: 0.3223 - val_accuracy: 0.9105\n",
            "Epoch 120/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.3082 - accuracy: 0.9135\n",
            "Epoch 00120: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3087 - accuracy: 0.9134 - val_loss: 0.3220 - val_accuracy: 0.9104\n",
            "Epoch 121/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.3083 - accuracy: 0.9136\n",
            "Epoch 00121: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3083 - accuracy: 0.9136 - val_loss: 0.3217 - val_accuracy: 0.9108\n",
            "Epoch 122/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.3080 - accuracy: 0.9137\n",
            "Epoch 00122: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3080 - accuracy: 0.9137 - val_loss: 0.3215 - val_accuracy: 0.9107\n",
            "Epoch 123/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.3068 - accuracy: 0.9137\n",
            "Epoch 00123: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3077 - accuracy: 0.9136 - val_loss: 0.3213 - val_accuracy: 0.9106\n",
            "Epoch 124/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.3043 - accuracy: 0.9149\n",
            "Epoch 00124: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3074 - accuracy: 0.9139 - val_loss: 0.3210 - val_accuracy: 0.9112\n",
            "Epoch 125/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.3077 - accuracy: 0.9134\n",
            "Epoch 00125: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3070 - accuracy: 0.9138 - val_loss: 0.3207 - val_accuracy: 0.9111\n",
            "Epoch 126/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.3086 - accuracy: 0.9135\n",
            "Epoch 00126: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3067 - accuracy: 0.9140 - val_loss: 0.3204 - val_accuracy: 0.9118\n",
            "Epoch 127/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.3068 - accuracy: 0.9138\n",
            "Epoch 00127: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3064 - accuracy: 0.9140 - val_loss: 0.3202 - val_accuracy: 0.9112\n",
            "Epoch 128/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.3061 - accuracy: 0.9141\n",
            "Epoch 00128: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3061 - accuracy: 0.9141 - val_loss: 0.3200 - val_accuracy: 0.9117\n",
            "Epoch 129/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.3058 - accuracy: 0.9146\n",
            "Epoch 00129: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3058 - accuracy: 0.9142 - val_loss: 0.3197 - val_accuracy: 0.9117\n",
            "Epoch 130/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.3052 - accuracy: 0.9145\n",
            "Epoch 00130: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3055 - accuracy: 0.9143 - val_loss: 0.3195 - val_accuracy: 0.9124\n",
            "Epoch 131/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.3063 - accuracy: 0.9142\n",
            "Epoch 00131: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3052 - accuracy: 0.9144 - val_loss: 0.3192 - val_accuracy: 0.9119\n",
            "Epoch 132/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.3038 - accuracy: 0.9147\n",
            "Epoch 00132: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3049 - accuracy: 0.9145 - val_loss: 0.3190 - val_accuracy: 0.9122\n",
            "Epoch 133/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.3045 - accuracy: 0.9146\n",
            "Epoch 00133: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3046 - accuracy: 0.9145 - val_loss: 0.3188 - val_accuracy: 0.9126\n",
            "Epoch 134/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.3067 - accuracy: 0.9141\n",
            "Epoch 00134: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3044 - accuracy: 0.9147 - val_loss: 0.3184 - val_accuracy: 0.9124\n",
            "Epoch 135/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.3042 - accuracy: 0.9146\n",
            "Epoch 00135: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3041 - accuracy: 0.9146 - val_loss: 0.3183 - val_accuracy: 0.9122\n",
            "Epoch 136/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.3039 - accuracy: 0.9149\n",
            "Epoch 00136: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3038 - accuracy: 0.9149 - val_loss: 0.3181 - val_accuracy: 0.9121\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.3035 - accuracy: 0.9150\n",
            "Epoch 00137: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3035 - accuracy: 0.9150 - val_loss: 0.3179 - val_accuracy: 0.9121\n",
            "Epoch 138/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.3044 - accuracy: 0.9146\n",
            "Epoch 00138: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3033 - accuracy: 0.9149 - val_loss: 0.3176 - val_accuracy: 0.9126\n",
            "Epoch 139/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.3038 - accuracy: 0.9147\n",
            "Epoch 00139: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3030 - accuracy: 0.9151 - val_loss: 0.3174 - val_accuracy: 0.9126\n",
            "Epoch 140/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.3033 - accuracy: 0.9152\n",
            "Epoch 00140: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3027 - accuracy: 0.9152 - val_loss: 0.3171 - val_accuracy: 0.9132\n",
            "Epoch 141/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.3053 - accuracy: 0.9150\n",
            "Epoch 00141: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3025 - accuracy: 0.9155 - val_loss: 0.3170 - val_accuracy: 0.9130\n",
            "Epoch 142/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.3023 - accuracy: 0.9156\n",
            "Epoch 00142: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3022 - accuracy: 0.9154 - val_loss: 0.3168 - val_accuracy: 0.9130\n",
            "Epoch 143/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.3030 - accuracy: 0.9156\n",
            "Epoch 00143: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3019 - accuracy: 0.9154 - val_loss: 0.3166 - val_accuracy: 0.9131\n",
            "Epoch 144/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.3020 - accuracy: 0.9149\n",
            "Epoch 00144: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3017 - accuracy: 0.9155 - val_loss: 0.3164 - val_accuracy: 0.9134\n",
            "Epoch 145/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.3021 - accuracy: 0.9154\n",
            "Epoch 00145: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3014 - accuracy: 0.9154 - val_loss: 0.3162 - val_accuracy: 0.9131\n",
            "Epoch 146/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.3019 - accuracy: 0.9155\n",
            "Epoch 00146: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3012 - accuracy: 0.9155 - val_loss: 0.3159 - val_accuracy: 0.9134\n",
            "Epoch 147/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.3008 - accuracy: 0.9159\n",
            "Epoch 00147: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3009 - accuracy: 0.9158 - val_loss: 0.3158 - val_accuracy: 0.9131\n",
            "Epoch 148/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.3005 - accuracy: 0.9158\n",
            "Epoch 00148: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3007 - accuracy: 0.9157 - val_loss: 0.3156 - val_accuracy: 0.9137\n",
            "Epoch 149/10000\n",
            "167/188 [=========================>....] - ETA: 0s - loss: 0.3001 - accuracy: 0.9163\n",
            "Epoch 00149: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3004 - accuracy: 0.9157 - val_loss: 0.3154 - val_accuracy: 0.9137\n",
            "Epoch 150/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.3001 - accuracy: 0.9158\n",
            "Epoch 00150: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3002 - accuracy: 0.9157 - val_loss: 0.3151 - val_accuracy: 0.9138\n",
            "Epoch 151/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.3023 - accuracy: 0.9153\n",
            "Epoch 00151: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3000 - accuracy: 0.9158 - val_loss: 0.3150 - val_accuracy: 0.9136\n",
            "Epoch 152/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.3000 - accuracy: 0.9157\n",
            "Epoch 00152: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2997 - accuracy: 0.9159 - val_loss: 0.3149 - val_accuracy: 0.9137\n",
            "Epoch 153/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2994 - accuracy: 0.9160\n",
            "Epoch 00153: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2995 - accuracy: 0.9160 - val_loss: 0.3146 - val_accuracy: 0.9137\n",
            "Epoch 154/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.3005 - accuracy: 0.9161\n",
            "Epoch 00154: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2993 - accuracy: 0.9164 - val_loss: 0.3144 - val_accuracy: 0.9137\n",
            "Epoch 155/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.2989 - accuracy: 0.9165\n",
            "Epoch 00155: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2990 - accuracy: 0.9164 - val_loss: 0.3142 - val_accuracy: 0.9138\n",
            "Epoch 156/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2987 - accuracy: 0.9165\n",
            "Epoch 00156: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2988 - accuracy: 0.9164 - val_loss: 0.3141 - val_accuracy: 0.9142\n",
            "Epoch 157/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2986 - accuracy: 0.9162\n",
            "Epoch 00157: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2986 - accuracy: 0.9162 - val_loss: 0.3139 - val_accuracy: 0.9143\n",
            "Epoch 158/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.9166\n",
            "Epoch 00158: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2983 - accuracy: 0.9166 - val_loss: 0.3138 - val_accuracy: 0.9141\n",
            "Epoch 159/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2991 - accuracy: 0.9166\n",
            "Epoch 00159: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2981 - accuracy: 0.9166 - val_loss: 0.3135 - val_accuracy: 0.9143\n",
            "Epoch 160/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.2984 - accuracy: 0.9165\n",
            "Epoch 00160: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2979 - accuracy: 0.9167 - val_loss: 0.3133 - val_accuracy: 0.9143\n",
            "Epoch 161/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2977 - accuracy: 0.9167\n",
            "Epoch 00161: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2977 - accuracy: 0.9167 - val_loss: 0.3131 - val_accuracy: 0.9146\n",
            "Epoch 162/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.2968 - accuracy: 0.9167\n",
            "Epoch 00162: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2975 - accuracy: 0.9166 - val_loss: 0.3130 - val_accuracy: 0.9147\n",
            "Epoch 163/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.2973 - accuracy: 0.9165\n",
            "Epoch 00163: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2972 - accuracy: 0.9166 - val_loss: 0.3129 - val_accuracy: 0.9146\n",
            "Epoch 164/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2971 - accuracy: 0.9165\n",
            "Epoch 00164: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2970 - accuracy: 0.9168 - val_loss: 0.3128 - val_accuracy: 0.9147\n",
            "Epoch 165/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.2963 - accuracy: 0.9168\n",
            "Epoch 00165: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2968 - accuracy: 0.9169 - val_loss: 0.3125 - val_accuracy: 0.9146\n",
            "Epoch 166/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.2953 - accuracy: 0.9172\n",
            "Epoch 00166: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2966 - accuracy: 0.9169 - val_loss: 0.3125 - val_accuracy: 0.9151\n",
            "Epoch 167/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.2978 - accuracy: 0.9164\n",
            "Epoch 00167: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2964 - accuracy: 0.9168 - val_loss: 0.3122 - val_accuracy: 0.9147\n",
            "Epoch 168/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.2957 - accuracy: 0.9169\n",
            "Epoch 00168: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2962 - accuracy: 0.9168 - val_loss: 0.3121 - val_accuracy: 0.9151\n",
            "Epoch 169/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.2962 - accuracy: 0.9166\n",
            "Epoch 00169: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2960 - accuracy: 0.9170 - val_loss: 0.3120 - val_accuracy: 0.9153\n",
            "Epoch 170/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2958 - accuracy: 0.9170\n",
            "Epoch 00170: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2958 - accuracy: 0.9170 - val_loss: 0.3117 - val_accuracy: 0.9151\n",
            "Epoch 171/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.2960 - accuracy: 0.9164\n",
            "Epoch 00171: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2956 - accuracy: 0.9170 - val_loss: 0.3115 - val_accuracy: 0.9150\n",
            "Epoch 172/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2951 - accuracy: 0.9173\n",
            "Epoch 00172: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2954 - accuracy: 0.9172 - val_loss: 0.3114 - val_accuracy: 0.9154\n",
            "Epoch 173/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2943 - accuracy: 0.9175\n",
            "Epoch 00173: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2952 - accuracy: 0.9173 - val_loss: 0.3112 - val_accuracy: 0.9153\n",
            "Epoch 174/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2946 - accuracy: 0.9173\n",
            "Epoch 00174: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2950 - accuracy: 0.9172 - val_loss: 0.3112 - val_accuracy: 0.9157\n",
            "Epoch 175/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.2934 - accuracy: 0.9175\n",
            "Epoch 00175: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2948 - accuracy: 0.9171 - val_loss: 0.3109 - val_accuracy: 0.9156\n",
            "Epoch 176/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.2951 - accuracy: 0.9172\n",
            "Epoch 00176: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2946 - accuracy: 0.9175 - val_loss: 0.3108 - val_accuracy: 0.9157\n",
            "Epoch 177/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2945 - accuracy: 0.9173\n",
            "Epoch 00177: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2944 - accuracy: 0.9174 - val_loss: 0.3107 - val_accuracy: 0.9155\n",
            "Epoch 178/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2946 - accuracy: 0.9171\n",
            "Epoch 00178: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2943 - accuracy: 0.9172 - val_loss: 0.3106 - val_accuracy: 0.9156\n",
            "Epoch 179/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2958 - accuracy: 0.9171\n",
            "Epoch 00179: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2941 - accuracy: 0.9174 - val_loss: 0.3104 - val_accuracy: 0.9153\n",
            "Epoch 180/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.2940 - accuracy: 0.9170\n",
            "Epoch 00180: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2939 - accuracy: 0.9171 - val_loss: 0.3103 - val_accuracy: 0.9153\n",
            "Epoch 181/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.2928 - accuracy: 0.9177\n",
            "Epoch 00181: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2937 - accuracy: 0.9174 - val_loss: 0.3102 - val_accuracy: 0.9156\n",
            "Epoch 182/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2935 - accuracy: 0.9178\n",
            "Epoch 00182: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2935 - accuracy: 0.9178 - val_loss: 0.3099 - val_accuracy: 0.9156\n",
            "Epoch 183/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2933 - accuracy: 0.9175\n",
            "Epoch 00183: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2933 - accuracy: 0.9175 - val_loss: 0.3098 - val_accuracy: 0.9154\n",
            "Epoch 184/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2931 - accuracy: 0.9176\n",
            "Epoch 00184: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2931 - accuracy: 0.9176 - val_loss: 0.3098 - val_accuracy: 0.9161\n",
            "Epoch 185/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.2928 - accuracy: 0.9177\n",
            "Epoch 00185: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2930 - accuracy: 0.9176 - val_loss: 0.3096 - val_accuracy: 0.9154\n",
            "Epoch 186/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2928 - accuracy: 0.9178\n",
            "Epoch 00186: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2928 - accuracy: 0.9178 - val_loss: 0.3095 - val_accuracy: 0.9156\n",
            "Epoch 187/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.2917 - accuracy: 0.9178\n",
            "Epoch 00187: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2926 - accuracy: 0.9179 - val_loss: 0.3093 - val_accuracy: 0.9158\n",
            "Epoch 188/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.9178\n",
            "Epoch 00188: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2925 - accuracy: 0.9178 - val_loss: 0.3092 - val_accuracy: 0.9157\n",
            "Epoch 189/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2923 - accuracy: 0.9179\n",
            "Epoch 00189: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2923 - accuracy: 0.9179 - val_loss: 0.3091 - val_accuracy: 0.9158\n",
            "Epoch 190/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.2944 - accuracy: 0.9173\n",
            "Epoch 00190: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2921 - accuracy: 0.9180 - val_loss: 0.3089 - val_accuracy: 0.9158\n",
            "Epoch 191/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.2914 - accuracy: 0.9182\n",
            "Epoch 00191: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2919 - accuracy: 0.9181 - val_loss: 0.3088 - val_accuracy: 0.9160\n",
            "Epoch 192/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.2939 - accuracy: 0.9179\n",
            "Epoch 00192: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2918 - accuracy: 0.9183 - val_loss: 0.3087 - val_accuracy: 0.9158\n",
            "Epoch 193/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2923 - accuracy: 0.9181\n",
            "Epoch 00193: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2916 - accuracy: 0.9183 - val_loss: 0.3085 - val_accuracy: 0.9159\n",
            "Epoch 194/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.2919 - accuracy: 0.9178\n",
            "Epoch 00194: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2914 - accuracy: 0.9181 - val_loss: 0.3083 - val_accuracy: 0.9157\n",
            "Epoch 195/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2915 - accuracy: 0.9185\n",
            "Epoch 00195: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2912 - accuracy: 0.9185 - val_loss: 0.3083 - val_accuracy: 0.9158\n",
            "Epoch 196/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.2897 - accuracy: 0.9193\n",
            "Epoch 00196: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2911 - accuracy: 0.9185 - val_loss: 0.3081 - val_accuracy: 0.9158\n",
            "Epoch 197/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2909 - accuracy: 0.9183\n",
            "Epoch 00197: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2909 - accuracy: 0.9183 - val_loss: 0.3081 - val_accuracy: 0.9158\n",
            "Epoch 198/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.2898 - accuracy: 0.9191\n",
            "Epoch 00198: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2908 - accuracy: 0.9184 - val_loss: 0.3079 - val_accuracy: 0.9158\n",
            "Epoch 199/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2906 - accuracy: 0.9184\n",
            "Epoch 00199: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2906 - accuracy: 0.9184 - val_loss: 0.3078 - val_accuracy: 0.9159\n",
            "Epoch 200/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.2912 - accuracy: 0.9185\n",
            "Epoch 00200: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2904 - accuracy: 0.9185 - val_loss: 0.3077 - val_accuracy: 0.9158\n",
            "Epoch 201/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.2901 - accuracy: 0.9191\n",
            "Epoch 00201: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2903 - accuracy: 0.9187 - val_loss: 0.3076 - val_accuracy: 0.9157\n",
            "Epoch 202/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2899 - accuracy: 0.9190\n",
            "Epoch 00202: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2901 - accuracy: 0.9187 - val_loss: 0.3074 - val_accuracy: 0.9162\n",
            "Epoch 203/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2900 - accuracy: 0.9186\n",
            "Epoch 00203: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2900 - accuracy: 0.9186 - val_loss: 0.3074 - val_accuracy: 0.9160\n",
            "Epoch 204/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2898 - accuracy: 0.9190\n",
            "Epoch 00204: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2898 - accuracy: 0.9190 - val_loss: 0.3072 - val_accuracy: 0.9163\n",
            "Epoch 205/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2894 - accuracy: 0.9189\n",
            "Epoch 00205: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2897 - accuracy: 0.9188 - val_loss: 0.3071 - val_accuracy: 0.9159\n",
            "Epoch 206/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2882 - accuracy: 0.9192\n",
            "Epoch 00206: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2895 - accuracy: 0.9188 - val_loss: 0.3070 - val_accuracy: 0.9162\n",
            "Epoch 207/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2893 - accuracy: 0.9189\n",
            "Epoch 00207: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2893 - accuracy: 0.9189 - val_loss: 0.3069 - val_accuracy: 0.9162\n",
            "Epoch 208/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.2901 - accuracy: 0.9191\n",
            "Epoch 00208: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2892 - accuracy: 0.9193 - val_loss: 0.3068 - val_accuracy: 0.9166\n",
            "Epoch 209/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2893 - accuracy: 0.9187\n",
            "Epoch 00209: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2891 - accuracy: 0.9188 - val_loss: 0.3067 - val_accuracy: 0.9162\n",
            "Epoch 210/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2883 - accuracy: 0.9191\n",
            "Epoch 00210: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2889 - accuracy: 0.9190 - val_loss: 0.3066 - val_accuracy: 0.9163\n",
            "Epoch 211/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.2880 - accuracy: 0.9196\n",
            "Epoch 00211: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2887 - accuracy: 0.9193 - val_loss: 0.3065 - val_accuracy: 0.9159\n",
            "Epoch 212/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2891 - accuracy: 0.9189\n",
            "Epoch 00212: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2886 - accuracy: 0.9192 - val_loss: 0.3063 - val_accuracy: 0.9164\n",
            "Epoch 213/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.2863 - accuracy: 0.9197\n",
            "Epoch 00213: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2885 - accuracy: 0.9193 - val_loss: 0.3062 - val_accuracy: 0.9165\n",
            "Epoch 214/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.2878 - accuracy: 0.9198\n",
            "Epoch 00214: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2883 - accuracy: 0.9196 - val_loss: 0.3062 - val_accuracy: 0.9165\n",
            "Epoch 215/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2884 - accuracy: 0.9191\n",
            "Epoch 00215: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2882 - accuracy: 0.9193 - val_loss: 0.3060 - val_accuracy: 0.9163\n",
            "Epoch 216/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2880 - accuracy: 0.9195\n",
            "Epoch 00216: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2880 - accuracy: 0.9195 - val_loss: 0.3059 - val_accuracy: 0.9165\n",
            "Epoch 217/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2883 - accuracy: 0.9193\n",
            "Epoch 00217: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2879 - accuracy: 0.9194 - val_loss: 0.3058 - val_accuracy: 0.9169\n",
            "Epoch 218/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2866 - accuracy: 0.9202\n",
            "Epoch 00218: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2878 - accuracy: 0.9195 - val_loss: 0.3057 - val_accuracy: 0.9166\n",
            "Epoch 219/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2872 - accuracy: 0.9197\n",
            "Epoch 00219: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2876 - accuracy: 0.9196 - val_loss: 0.3056 - val_accuracy: 0.9162\n",
            "Epoch 220/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2875 - accuracy: 0.9196\n",
            "Epoch 00220: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2875 - accuracy: 0.9196 - val_loss: 0.3055 - val_accuracy: 0.9164\n",
            "Epoch 221/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.2886 - accuracy: 0.9194\n",
            "Epoch 00221: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2873 - accuracy: 0.9198 - val_loss: 0.3054 - val_accuracy: 0.9170\n",
            "Epoch 222/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2872 - accuracy: 0.9197\n",
            "Epoch 00222: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2872 - accuracy: 0.9197 - val_loss: 0.3053 - val_accuracy: 0.9166\n",
            "Epoch 223/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.2869 - accuracy: 0.9199\n",
            "Epoch 00223: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2870 - accuracy: 0.9197 - val_loss: 0.3052 - val_accuracy: 0.9165\n",
            "Epoch 224/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2866 - accuracy: 0.9197\n",
            "Epoch 00224: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2869 - accuracy: 0.9197 - val_loss: 0.3050 - val_accuracy: 0.9169\n",
            "Epoch 225/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.2886 - accuracy: 0.9194\n",
            "Epoch 00225: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2868 - accuracy: 0.9199 - val_loss: 0.3050 - val_accuracy: 0.9169\n",
            "Epoch 226/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2871 - accuracy: 0.9198\n",
            "Epoch 00226: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2866 - accuracy: 0.9200 - val_loss: 0.3049 - val_accuracy: 0.9169\n",
            "Epoch 227/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.2872 - accuracy: 0.9198\n",
            "Epoch 00227: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2865 - accuracy: 0.9199 - val_loss: 0.3048 - val_accuracy: 0.9167\n",
            "Epoch 228/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.2865 - accuracy: 0.9200\n",
            "Epoch 00228: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2864 - accuracy: 0.9201 - val_loss: 0.3047 - val_accuracy: 0.9172\n",
            "Epoch 229/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2866 - accuracy: 0.9200\n",
            "Epoch 00229: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2863 - accuracy: 0.9200 - val_loss: 0.3046 - val_accuracy: 0.9169\n",
            "Epoch 230/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.9200\n",
            "Epoch 00230: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2861 - accuracy: 0.9200 - val_loss: 0.3046 - val_accuracy: 0.9170\n",
            "Epoch 231/10000\n",
            "167/188 [=========================>....] - ETA: 0s - loss: 0.2829 - accuracy: 0.9208\n",
            "Epoch 00231: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2860 - accuracy: 0.9201 - val_loss: 0.3044 - val_accuracy: 0.9168\n",
            "Epoch 232/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.2860 - accuracy: 0.9204\n",
            "Epoch 00232: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2859 - accuracy: 0.9201 - val_loss: 0.3044 - val_accuracy: 0.9171\n",
            "Epoch 233/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.2863 - accuracy: 0.9199\n",
            "Epoch 00233: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2857 - accuracy: 0.9202 - val_loss: 0.3043 - val_accuracy: 0.9169\n",
            "Epoch 234/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.2857 - accuracy: 0.9203\n",
            "Epoch 00234: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2856 - accuracy: 0.9204 - val_loss: 0.3042 - val_accuracy: 0.9167\n",
            "Epoch 235/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.2857 - accuracy: 0.9202\n",
            "Epoch 00235: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2855 - accuracy: 0.9203 - val_loss: 0.3041 - val_accuracy: 0.9175\n",
            "Epoch 236/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.9204\n",
            "Epoch 00236: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2853 - accuracy: 0.9204 - val_loss: 0.3040 - val_accuracy: 0.9171\n",
            "Epoch 237/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.2874 - accuracy: 0.9197\n",
            "Epoch 00237: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2852 - accuracy: 0.9205 - val_loss: 0.3039 - val_accuracy: 0.9174\n",
            "Epoch 238/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.2856 - accuracy: 0.9203\n",
            "Epoch 00238: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2851 - accuracy: 0.9203 - val_loss: 0.3039 - val_accuracy: 0.9175\n",
            "Epoch 239/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2846 - accuracy: 0.9205\n",
            "Epoch 00239: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2850 - accuracy: 0.9204 - val_loss: 0.3037 - val_accuracy: 0.9172\n",
            "Epoch 240/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2847 - accuracy: 0.9206\n",
            "Epoch 00240: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2849 - accuracy: 0.9205 - val_loss: 0.3036 - val_accuracy: 0.9175\n",
            "Epoch 241/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2845 - accuracy: 0.9209\n",
            "Epoch 00241: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2847 - accuracy: 0.9208 - val_loss: 0.3036 - val_accuracy: 0.9174\n",
            "Epoch 242/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.2858 - accuracy: 0.9202\n",
            "Epoch 00242: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2846 - accuracy: 0.9207 - val_loss: 0.3035 - val_accuracy: 0.9174\n",
            "Epoch 243/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.2852 - accuracy: 0.9204\n",
            "Epoch 00243: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2845 - accuracy: 0.9208 - val_loss: 0.3034 - val_accuracy: 0.9175\n",
            "Epoch 244/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2843 - accuracy: 0.9209\n",
            "Epoch 00244: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2844 - accuracy: 0.9208 - val_loss: 0.3034 - val_accuracy: 0.9176\n",
            "Epoch 245/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.2834 - accuracy: 0.9210\n",
            "Epoch 00245: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.9208 - val_loss: 0.3032 - val_accuracy: 0.9173\n",
            "Epoch 246/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2840 - accuracy: 0.9209\n",
            "Epoch 00246: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2841 - accuracy: 0.9209 - val_loss: 0.3032 - val_accuracy: 0.9173\n",
            "Epoch 247/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.2852 - accuracy: 0.9210\n",
            "Epoch 00247: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2840 - accuracy: 0.9209 - val_loss: 0.3030 - val_accuracy: 0.9177\n",
            "Epoch 248/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.2853 - accuracy: 0.9207\n",
            "Epoch 00248: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2839 - accuracy: 0.9210 - val_loss: 0.3030 - val_accuracy: 0.9178\n",
            "Epoch 249/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2838 - accuracy: 0.9211\n",
            "Epoch 00249: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2838 - accuracy: 0.9211 - val_loss: 0.3030 - val_accuracy: 0.9173\n",
            "Epoch 250/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.2826 - accuracy: 0.9210\n",
            "Epoch 00250: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2837 - accuracy: 0.9209 - val_loss: 0.3027 - val_accuracy: 0.9177\n",
            "Epoch 251/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.2832 - accuracy: 0.9211\n",
            "Epoch 00251: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2835 - accuracy: 0.9210 - val_loss: 0.3027 - val_accuracy: 0.9176\n",
            "Epoch 252/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.2840 - accuracy: 0.9208\n",
            "Epoch 00252: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2834 - accuracy: 0.9211 - val_loss: 0.3026 - val_accuracy: 0.9176\n",
            "Epoch 253/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2829 - accuracy: 0.9211\n",
            "Epoch 00253: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2833 - accuracy: 0.9211 - val_loss: 0.3025 - val_accuracy: 0.9178\n",
            "Epoch 254/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2831 - accuracy: 0.9212\n",
            "Epoch 00254: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2832 - accuracy: 0.9212 - val_loss: 0.3025 - val_accuracy: 0.9178\n",
            "Epoch 255/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.2822 - accuracy: 0.9216\n",
            "Epoch 00255: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2831 - accuracy: 0.9211 - val_loss: 0.3024 - val_accuracy: 0.9177\n",
            "Epoch 256/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2825 - accuracy: 0.9212\n",
            "Epoch 00256: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2830 - accuracy: 0.9211 - val_loss: 0.3023 - val_accuracy: 0.9178\n",
            "Epoch 257/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2828 - accuracy: 0.9213\n",
            "Epoch 00257: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2828 - accuracy: 0.9213 - val_loss: 0.3022 - val_accuracy: 0.9177\n",
            "Epoch 258/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2830 - accuracy: 0.9212\n",
            "Epoch 00258: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2827 - accuracy: 0.9212 - val_loss: 0.3021 - val_accuracy: 0.9179\n",
            "Epoch 259/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2827 - accuracy: 0.9217\n",
            "Epoch 00259: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2826 - accuracy: 0.9215 - val_loss: 0.3020 - val_accuracy: 0.9174\n",
            "Epoch 260/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2797 - accuracy: 0.9222\n",
            "Epoch 00260: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2825 - accuracy: 0.9213 - val_loss: 0.3020 - val_accuracy: 0.9179\n",
            "Epoch 261/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.2810 - accuracy: 0.9220\n",
            "Epoch 00261: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2824 - accuracy: 0.9215 - val_loss: 0.3018 - val_accuracy: 0.9178\n",
            "Epoch 262/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2822 - accuracy: 0.9215\n",
            "Epoch 00262: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2823 - accuracy: 0.9215 - val_loss: 0.3019 - val_accuracy: 0.9178\n",
            "Epoch 263/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2821 - accuracy: 0.9212\n",
            "Epoch 00263: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2822 - accuracy: 0.9213 - val_loss: 0.3018 - val_accuracy: 0.9176\n",
            "Epoch 264/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2824 - accuracy: 0.9213\n",
            "Epoch 00264: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2821 - accuracy: 0.9215 - val_loss: 0.3017 - val_accuracy: 0.9179\n",
            "Epoch 265/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2821 - accuracy: 0.9215\n",
            "Epoch 00265: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2820 - accuracy: 0.9216 - val_loss: 0.3017 - val_accuracy: 0.9179\n",
            "Epoch 266/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.2815 - accuracy: 0.9217\n",
            "Epoch 00266: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2819 - accuracy: 0.9216 - val_loss: 0.3017 - val_accuracy: 0.9182\n",
            "Epoch 267/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2819 - accuracy: 0.9217\n",
            "Epoch 00267: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2818 - accuracy: 0.9217 - val_loss: 0.3016 - val_accuracy: 0.9178\n",
            "Epoch 268/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2816 - accuracy: 0.9216\n",
            "Epoch 00268: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2817 - accuracy: 0.9216 - val_loss: 0.3014 - val_accuracy: 0.9172\n",
            "Epoch 269/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2815 - accuracy: 0.9217\n",
            "Epoch 00269: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2815 - accuracy: 0.9217 - val_loss: 0.3014 - val_accuracy: 0.9175\n",
            "Epoch 270/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2821 - accuracy: 0.9215\n",
            "Epoch 00270: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2814 - accuracy: 0.9217 - val_loss: 0.3012 - val_accuracy: 0.9178\n",
            "Epoch 271/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2816 - accuracy: 0.9217\n",
            "Epoch 00271: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2813 - accuracy: 0.9218 - val_loss: 0.3012 - val_accuracy: 0.9178\n",
            "Epoch 272/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.2805 - accuracy: 0.9217\n",
            "Epoch 00272: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2812 - accuracy: 0.9218 - val_loss: 0.3011 - val_accuracy: 0.9178\n",
            "Epoch 273/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.2820 - accuracy: 0.9215\n",
            "Epoch 00273: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2811 - accuracy: 0.9219 - val_loss: 0.3011 - val_accuracy: 0.9179\n",
            "Epoch 274/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.2806 - accuracy: 0.9216\n",
            "Epoch 00274: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2810 - accuracy: 0.9217 - val_loss: 0.3010 - val_accuracy: 0.9177\n",
            "Epoch 275/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2807 - accuracy: 0.9219\n",
            "Epoch 00275: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2809 - accuracy: 0.9219 - val_loss: 0.3009 - val_accuracy: 0.9179\n",
            "Epoch 276/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2784 - accuracy: 0.9226\n",
            "Epoch 00276: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2808 - accuracy: 0.9220 - val_loss: 0.3009 - val_accuracy: 0.9178\n",
            "Epoch 277/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.2807 - accuracy: 0.9217\n",
            "Epoch 00277: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2807 - accuracy: 0.9219 - val_loss: 0.3008 - val_accuracy: 0.9179\n",
            "Epoch 278/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.2797 - accuracy: 0.9222\n",
            "Epoch 00278: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2806 - accuracy: 0.9220 - val_loss: 0.3006 - val_accuracy: 0.9183\n",
            "Epoch 279/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.2808 - accuracy: 0.9218\n",
            "Epoch 00279: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2805 - accuracy: 0.9220 - val_loss: 0.3007 - val_accuracy: 0.9181\n",
            "Epoch 280/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2827 - accuracy: 0.9212\n",
            "Epoch 00280: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2804 - accuracy: 0.9221 - val_loss: 0.3006 - val_accuracy: 0.9178\n",
            "Epoch 281/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.2808 - accuracy: 0.9218\n",
            "Epoch 00281: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2803 - accuracy: 0.9219 - val_loss: 0.3006 - val_accuracy: 0.9180\n",
            "Epoch 282/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2802 - accuracy: 0.9219\n",
            "Epoch 00282: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2802 - accuracy: 0.9219 - val_loss: 0.3004 - val_accuracy: 0.9178\n",
            "Epoch 283/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2803 - accuracy: 0.9221\n",
            "Epoch 00283: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2801 - accuracy: 0.9222 - val_loss: 0.3004 - val_accuracy: 0.9181\n",
            "Epoch 284/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.2801 - accuracy: 0.9222\n",
            "Epoch 00284: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2800 - accuracy: 0.9221 - val_loss: 0.3004 - val_accuracy: 0.9179\n",
            "Epoch 285/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.2797 - accuracy: 0.9221\n",
            "Epoch 00285: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.9220 - val_loss: 0.3003 - val_accuracy: 0.9181\n",
            "Epoch 286/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.2799 - accuracy: 0.9221\n",
            "Epoch 00286: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2798 - accuracy: 0.9222 - val_loss: 0.3002 - val_accuracy: 0.9184\n",
            "Epoch 287/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.2814 - accuracy: 0.9218\n",
            "Epoch 00287: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2798 - accuracy: 0.9222 - val_loss: 0.3001 - val_accuracy: 0.9182\n",
            "Epoch 288/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2796 - accuracy: 0.9221\n",
            "Epoch 00288: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2796 - accuracy: 0.9221 - val_loss: 0.3002 - val_accuracy: 0.9183\n",
            "Epoch 289/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2768 - accuracy: 0.9225\n",
            "Epoch 00289: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2796 - accuracy: 0.9222 - val_loss: 0.3000 - val_accuracy: 0.9179\n",
            "Epoch 290/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2795 - accuracy: 0.9222\n",
            "Epoch 00290: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2795 - accuracy: 0.9222 - val_loss: 0.2999 - val_accuracy: 0.9187\n",
            "Epoch 291/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.2799 - accuracy: 0.9222\n",
            "Epoch 00291: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2794 - accuracy: 0.9222 - val_loss: 0.2999 - val_accuracy: 0.9186\n",
            "Epoch 292/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2793 - accuracy: 0.9222\n",
            "Epoch 00292: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2793 - accuracy: 0.9222 - val_loss: 0.2998 - val_accuracy: 0.9184\n",
            "Epoch 293/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.2802 - accuracy: 0.9221\n",
            "Epoch 00293: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.9222 - val_loss: 0.2998 - val_accuracy: 0.9185\n",
            "Epoch 294/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.2790 - accuracy: 0.9223\n",
            "Epoch 00294: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2791 - accuracy: 0.9222 - val_loss: 0.2997 - val_accuracy: 0.9187\n",
            "Epoch 295/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.2789 - accuracy: 0.9220\n",
            "Epoch 00295: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2790 - accuracy: 0.9223 - val_loss: 0.2997 - val_accuracy: 0.9186\n",
            "Epoch 296/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2785 - accuracy: 0.9225\n",
            "Epoch 00296: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2789 - accuracy: 0.9224 - val_loss: 0.2996 - val_accuracy: 0.9184\n",
            "Epoch 297/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2793 - accuracy: 0.9222\n",
            "Epoch 00297: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2788 - accuracy: 0.9222 - val_loss: 0.2994 - val_accuracy: 0.9185\n",
            "Epoch 298/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.2798 - accuracy: 0.9216\n",
            "Epoch 00298: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2787 - accuracy: 0.9222 - val_loss: 0.2994 - val_accuracy: 0.9187\n",
            "Epoch 299/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2771 - accuracy: 0.9230\n",
            "Epoch 00299: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2786 - accuracy: 0.9223 - val_loss: 0.2994 - val_accuracy: 0.9190\n",
            "Epoch 300/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2802 - accuracy: 0.9221\n",
            "Epoch 00300: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2785 - accuracy: 0.9224 - val_loss: 0.2993 - val_accuracy: 0.9183\n",
            "Epoch 301/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2786 - accuracy: 0.9223\n",
            "Epoch 00301: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2784 - accuracy: 0.9224 - val_loss: 0.2993 - val_accuracy: 0.9185\n",
            "Epoch 302/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2775 - accuracy: 0.9230\n",
            "Epoch 00302: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2784 - accuracy: 0.9224 - val_loss: 0.2992 - val_accuracy: 0.9187\n",
            "Epoch 303/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.9224\n",
            "Epoch 00303: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2783 - accuracy: 0.9225 - val_loss: 0.2992 - val_accuracy: 0.9184\n",
            "Epoch 304/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.2784 - accuracy: 0.9222\n",
            "Epoch 00304: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2782 - accuracy: 0.9225 - val_loss: 0.2991 - val_accuracy: 0.9182\n",
            "Epoch 305/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.2792 - accuracy: 0.9226\n",
            "Epoch 00305: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2781 - accuracy: 0.9226 - val_loss: 0.2990 - val_accuracy: 0.9187\n",
            "Epoch 306/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2780 - accuracy: 0.9225\n",
            "Epoch 00306: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2780 - accuracy: 0.9225 - val_loss: 0.2990 - val_accuracy: 0.9187\n",
            "Epoch 307/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.2770 - accuracy: 0.9222\n",
            "Epoch 00307: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2779 - accuracy: 0.9225 - val_loss: 0.2990 - val_accuracy: 0.9183\n",
            "Epoch 308/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.2774 - accuracy: 0.9232\n",
            "Epoch 00308: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.9225 - val_loss: 0.2989 - val_accuracy: 0.9186\n",
            "Epoch 309/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.2783 - accuracy: 0.9224\n",
            "Epoch 00309: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2777 - accuracy: 0.9226 - val_loss: 0.2988 - val_accuracy: 0.9182\n",
            "Epoch 310/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2771 - accuracy: 0.9225\n",
            "Epoch 00310: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2777 - accuracy: 0.9226 - val_loss: 0.2988 - val_accuracy: 0.9187\n",
            "Epoch 311/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.2772 - accuracy: 0.9227\n",
            "Epoch 00311: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2776 - accuracy: 0.9226 - val_loss: 0.2987 - val_accuracy: 0.9183\n",
            "Epoch 312/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.2782 - accuracy: 0.9228\n",
            "Epoch 00312: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2775 - accuracy: 0.9227 - val_loss: 0.2986 - val_accuracy: 0.9187\n",
            "Epoch 313/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.9224\n",
            "Epoch 00313: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2774 - accuracy: 0.9225 - val_loss: 0.2985 - val_accuracy: 0.9183\n",
            "Epoch 314/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2750 - accuracy: 0.9226\n",
            "Epoch 00314: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2773 - accuracy: 0.9225 - val_loss: 0.2985 - val_accuracy: 0.9187\n",
            "Epoch 315/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.2767 - accuracy: 0.9228\n",
            "Epoch 00315: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2772 - accuracy: 0.9227 - val_loss: 0.2986 - val_accuracy: 0.9183\n",
            "Epoch 316/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.2777 - accuracy: 0.9226\n",
            "Epoch 00316: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2771 - accuracy: 0.9228 - val_loss: 0.2985 - val_accuracy: 0.9187\n",
            "Epoch 317/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2771 - accuracy: 0.9226\n",
            "Epoch 00317: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2771 - accuracy: 0.9226 - val_loss: 0.2984 - val_accuracy: 0.9186\n",
            "Epoch 318/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2768 - accuracy: 0.9228\n",
            "Epoch 00318: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2770 - accuracy: 0.9227 - val_loss: 0.2983 - val_accuracy: 0.9186\n",
            "Epoch 319/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2769 - accuracy: 0.9229\n",
            "Epoch 00319: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2769 - accuracy: 0.9227 - val_loss: 0.2982 - val_accuracy: 0.9186\n",
            "Epoch 320/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2768 - accuracy: 0.9229\n",
            "Epoch 00320: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2768 - accuracy: 0.9229 - val_loss: 0.2982 - val_accuracy: 0.9185\n",
            "Epoch 321/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2764 - accuracy: 0.9225\n",
            "Epoch 00321: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2767 - accuracy: 0.9227 - val_loss: 0.2983 - val_accuracy: 0.9185\n",
            "Epoch 322/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.2782 - accuracy: 0.9232\n",
            "Epoch 00322: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2766 - accuracy: 0.9230 - val_loss: 0.2981 - val_accuracy: 0.9185\n",
            "Epoch 323/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.2764 - accuracy: 0.9231\n",
            "Epoch 00323: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2766 - accuracy: 0.9229 - val_loss: 0.2980 - val_accuracy: 0.9185\n",
            "Epoch 324/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.2768 - accuracy: 0.9229\n",
            "Epoch 00324: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2765 - accuracy: 0.9229 - val_loss: 0.2980 - val_accuracy: 0.9183\n",
            "Epoch 325/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.2761 - accuracy: 0.9226\n",
            "Epoch 00325: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2764 - accuracy: 0.9228 - val_loss: 0.2979 - val_accuracy: 0.9187\n",
            "Epoch 326/10000\n",
            "167/188 [=========================>....] - ETA: 0s - loss: 0.2768 - accuracy: 0.9226\n",
            "Epoch 00326: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2763 - accuracy: 0.9229 - val_loss: 0.2979 - val_accuracy: 0.9186\n",
            "Epoch 327/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.2772 - accuracy: 0.9230\n",
            "Epoch 00327: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.9231 - val_loss: 0.2978 - val_accuracy: 0.9183\n",
            "Epoch 328/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.2763 - accuracy: 0.9229\n",
            "Epoch 00328: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.9229 - val_loss: 0.2978 - val_accuracy: 0.9187\n",
            "Epoch 329/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 0.2766 - accuracy: 0.9228\n",
            "Epoch 00329: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2761 - accuracy: 0.9228 - val_loss: 0.2978 - val_accuracy: 0.9187\n",
            "Epoch 330/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.2762 - accuracy: 0.9226\n",
            "Epoch 00330: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2760 - accuracy: 0.9229 - val_loss: 0.2977 - val_accuracy: 0.9187\n",
            "Epoch 331/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2758 - accuracy: 0.9230\n",
            "Epoch 00331: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2759 - accuracy: 0.9230 - val_loss: 0.2977 - val_accuracy: 0.9186\n",
            "Epoch 332/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.2779 - accuracy: 0.9225\n",
            "Epoch 00332: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2759 - accuracy: 0.9230 - val_loss: 0.2976 - val_accuracy: 0.9186\n",
            "Epoch 333/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.2764 - accuracy: 0.9227\n",
            "Epoch 00333: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2758 - accuracy: 0.9232 - val_loss: 0.2975 - val_accuracy: 0.9187\n",
            "Epoch 334/10000\n",
            "168/188 [=========================>....] - ETA: 0s - loss: 0.2755 - accuracy: 0.9233\n",
            "Epoch 00334: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2757 - accuracy: 0.9229 - val_loss: 0.2975 - val_accuracy: 0.9187\n",
            "Epoch 335/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2756 - accuracy: 0.9230\n",
            "Epoch 00335: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2756 - accuracy: 0.9230 - val_loss: 0.2974 - val_accuracy: 0.9187\n",
            "Epoch 336/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.2752 - accuracy: 0.9233\n",
            "Epoch 00336: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2755 - accuracy: 0.9232 - val_loss: 0.2974 - val_accuracy: 0.9187\n",
            "Epoch 337/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.2747 - accuracy: 0.9236\n",
            "Epoch 00337: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2755 - accuracy: 0.9232 - val_loss: 0.2974 - val_accuracy: 0.9187\n",
            "Epoch 338/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2754 - accuracy: 0.9231\n",
            "Epoch 00338: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2754 - accuracy: 0.9231 - val_loss: 0.2973 - val_accuracy: 0.9186\n",
            "Epoch 339/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.2760 - accuracy: 0.9228\n",
            "Epoch 00339: val_accuracy did not improve from 0.92617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2753 - accuracy: 0.9231 - val_loss: 0.2973 - val_accuracy: 0.9186\n",
            "Epoch 00339: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhDaW1llihBP",
        "colab_type": "text"
      },
      "source": [
        "##### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNFzyIrLiP5V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "275efb07-5a54-4897-b5d6-e349c1621b03"
      },
      "source": [
        "  fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "  loss_ax.set_title('Loss')\n",
        "  loss_ax.plot(single_layer_train.history['loss'], '-r', label='Train Adam')\n",
        "  loss_ax.plot(single_layer_train.history['val_loss'], '-g', label='Validation Adam')\n",
        "  loss_ax.plot(single_layer_train_sgd.history['loss'], '-b', label='Train SGD')\n",
        "  loss_ax.plot(single_layer_train_sgd.history['val_loss'], '-y', label='Validation SGD')\n",
        "\n",
        "  acc_ax.set_title('Accuracy')\n",
        "  acc_ax.plot(single_layer_train.history['accuracy'], '-r', label='Train Adam')\n",
        "  acc_ax.plot(single_layer_train.history['val_accuracy'], '-g', label='Validation Adam')\n",
        "  acc_ax.plot(single_layer_train_sgd.history['accuracy'], '-b', label='Train SGD')\n",
        "  acc_ax.plot(single_layer_train_sgd.history['val_accuracy'], '-y', label='Validation SGD')\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYvIjV_-imMr",
        "colab_type": "text"
      },
      "source": [
        "Right away, the impact of using an optimizer is very clear. Not only did the NN converged much sooner, but also with a higher accuracy, confirming the purpose for using it. Relatively to the performance of the NN itself, looking at the plots, namely the high number of epochs (this is especially clear in SGD), we confirm right away that convergence took a lot of updates. The validation line follows the train line pretty closely, so it is safe to say that the model did not overfit, already expected given the simplicity of a Single-Layer NN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS_EriMDjcZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fe0992aa-01fd-43d3-b48b-eef38cb1e06f"
      },
      "source": [
        "single_layer_model.load_weights('single_layer_best.h5')\n",
        "loss, acc = single_layer_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy: {}'.format(acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2642 - accuracy: 0.9281\n",
            "Accuracy: 0.9280999898910522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1duCPAxz7ju",
        "colab_type": "text"
      },
      "source": [
        "Testing the model yields aproximmately 93% accuracy wich is already a very good accuracy, especially when you factor in the complexity of the dataset (it's images) and by contrast the simplicity of the NN. This suggests the a big part of the data is linnearly seperable, but clearly not all. This is particullarly visible with [t-SNE](http://colah.github.io/posts/2014-10-Visualizing-MNIST/) as seen in the codeblock below (executes SVG):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN7h5vzlfrEt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "e246f625-3a11-4a79-a8fc-7262920ff8ed"
      },
      "source": [
        "from IPython.core.display import HTML\n",
        "HTML('''<svg style=\"width: 450px; height: 450px;\"><g><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"172.49447127005934\" cx=\"285.77277574679636\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"118.18281811751663\" cx=\"147.67415536071638\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"416.0208586288969\" cx=\"307.2821957316456\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"272.3185892701962\" cx=\"33.73707558630356\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"352.99402428612206\" cx=\"226.5130177612517\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"198.43359155086202\" cx=\"114.31040601288002\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"253.1997912930484\" cx=\"156.0557639424658\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"188.06692789520983\" cx=\"335.9971631507218\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"269.7777593218553\" cx=\"150.22628386903986\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"418.4463597555139\" cx=\"189.2038984172081\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"159.3034011168307\" cx=\"349.11717297095004\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.03153982808922\" cx=\"222.9087065623025\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"222.4201404610915\" cx=\"385.0987434513317\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"72.81556984574584\" cx=\"250.65347246625544\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"235.0389957582297\" cx=\"135.92590005442\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"336.197414150304\" cx=\"159.42299303869189\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"170.51663815438522\" cx=\"143.40726091351814\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"234.10141100600293\" cx=\"268.23960553570953\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"82.84146091097638\" cx=\"290.5573162056661\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"351.48686835678933\" cx=\"169.8724990657022\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"407.7698826076662\" cx=\"324.15660193328125\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"116.79483960765539\" cx=\"129.5309205983287\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"362.6806124253099\" cx=\"179.60940741441152\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"273.3250868598564\" cx=\"34.090410373370105\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"274.1545269768398\" cx=\"97.10927831110018\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"191.39653083629807\" cx=\"206.5222764925494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"389.73549091448143\" cx=\"245.3464704412162\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"190.71171393531398\" cx=\"360.81585526157755\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"310.9948292214441\" cx=\"129.75563914946372\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"353.58335146098017\" cx=\"127.1049579696264\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"241.19024339535233\" cx=\"401.7081485626674\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"227.74124645685544\" cx=\"260.8327525400708\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"59.47008329238516\" cx=\"279.35021055296\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"351.1619159479724\" cx=\"164.62659936735724\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"138.66131936068874\" cx=\"179.6315100678567\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"150.79109953976567\" cx=\"236.55647165919046\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"86.89114170999912\" cx=\"288.02135675254755\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"134.47880837216934\" cx=\"168.96211477939033\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"256.7960984868944\" cx=\"212.84760896577671\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"74.36711788043206\" cx=\"258.74806795645503\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"287.9548210882853\" cx=\"109.87684338399795\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"247.23870346124474\" cx=\"294.6195179957905\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"267.0771727349661\" cx=\"207.41781442159743\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"349.84199800755664\" cx=\"174.5336316693181\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"237.64156500228884\" cx=\"352.96532020455464\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.72752691007526\" cx=\"221.3809816841855\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"276.87876554560364\" cx=\"312.38513417090576\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"177.9372620426067\" cx=\"247.2639223272044\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"242.29247931791662\" cx=\"347.54207734176566\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"191.63097938973277\" cx=\"348.02383057815575\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"150.0318132338292\" cx=\"371.0827493086693\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"85.60305642532826\" cx=\"140.6974745023202\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"299.1083485465103\" cx=\"215.0794282432581\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"282.81000133477875\" cx=\"57.01371341965756\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"438.25875416141247\" cx=\"227.18661525123434\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"262.485018210894\" cx=\"274.88290333112224\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"69.15283656900661\" cx=\"165.59513291642426\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"363.9965416691307\" cx=\"180.56630451804057\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"392.3061344469437\" cx=\"298.541895642196\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"263.5753855634595\" cx=\"26.957258331747553\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"422.370116414103\" cx=\"322.4186729849794\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.6899935003004\" cx=\"181.60166247025307\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"94.59628163384424\" cx=\"277.9500352022714\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"119.6239682604981\" cx=\"133.66697920432776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"438.697400905401\" cx=\"273.6912609941465\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"161.34258104542286\" cx=\"220.88657628571426\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"92.76168997494955\" cx=\"264.6079467327178\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"220.54672150547074\" cx=\"74.15115383365792\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"50.39133735219427\" cx=\"149.27844649087217\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"117.91922350976257\" cx=\"192.81217444787498\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"234.91538771271107\" cx=\"183.01328472088028\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"342.665003267825\" cx=\"153.61535190323383\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"231.46084527198522\" cx=\"118.0928441400454\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"77.20457554710102\" cx=\"263.9351728385326\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"223.25219026248615\" cx=\"359.30931466835864\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"125.49510988527257\" cx=\"172.7596670998512\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"211.58422807793352\" cx=\"194.66548990566136\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"250.881127899192\" cx=\"51.91303853824458\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"243.8985532745807\" cx=\"48.926120124788746\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"350.95016340780694\" cx=\"131.2903093935997\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"100.37374932343577\" cx=\"195.5994574979423\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"123.70021839386364\" cx=\"172.53168506968402\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"156.95911886316446\" cx=\"137.58569779848509\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"79.8044914975489\" cx=\"249.22696402633918\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"277.80832414474764\" cx=\"212.90946672743215\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"238.26744973519442\" cx=\"297.8987430395966\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"234.91395444656206\" cx=\"392.86617516855534\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"372.8523271613689\" cx=\"187.28956579085036\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"70.67567258109659\" cx=\"169.9593054103292\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"436.1076929415555\" cx=\"199.4091682007234\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"78.02322530580292\" cx=\"241.87852675596923\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"347.89900829932714\" cx=\"152.50439002010916\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"401.51569425204406\" cx=\"285.680925843665\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.25662828748443\" cx=\"259.3708897439726\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"257.0993877680618\" cx=\"285.488078406782\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"124.51889012885532\" cx=\"180.513388359289\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"295.9589319523562\" cx=\"172.29189078376058\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"251.1887602446269\" cx=\"274.19454550044753\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"218.51481366851826\" cx=\"359.14093233607207\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"275.67646470808506\" cx=\"54.64405404536901\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"198.43382779597712\" cx=\"264.0594460101965\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"320.828125577124\" cx=\"201.21469896342157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"234.3704722158395\" cx=\"127.16782114653918\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"314.050593856705\" cx=\"179.60620162314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"247.8322596983673\" cx=\"163.53034511616715\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"242.07465994825407\" cx=\"56.67839919020979\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"66.63422190259608\" cx=\"276.842177470078\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"139.9857644167989\" cx=\"339.37745715122145\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"49.38749339952484\" cx=\"144.4584143240093\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"218.5409029582812\" cx=\"151.35799686378832\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"335.84279375028535\" cx=\"311.97163379649686\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"193.57054079675675\" cx=\"361.66762328897636\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"285.51331572863677\" cx=\"114.02863701347876\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"234.722904601507\" cx=\"34.553384870144015\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"81.12706856902786\" cx=\"117.27561185203423\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"422.9851009072782\" cx=\"204.57611258396489\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"355.69275662356114\" cx=\"250.46261937766982\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"181.21940993295343\" cx=\"201.81305839337892\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"100.19004951717324\" cx=\"173.65221213293495\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"116.30800984832639\" cx=\"123.3135535162312\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"291.69583390921724\" cx=\"191.46501414924202\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"63.263498576295135\" cx=\"140.5424098016397\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"195.3375114120015\" cx=\"179.69264535898563\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"344.1042854261753\" cx=\"142.54979003892166\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"223.94462744195113\" cx=\"105.4865520696907\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"243.69598545002478\" cx=\"297.0748519357824\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"80.49917300560756\" cx=\"300.4228682606692\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"423.8274520945067\" cx=\"182.66526544890402\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"258.87761299070957\" cx=\"112.77486770529778\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"104.62798542772133\" cx=\"262.66294069990107\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"216.2500443783086\" cx=\"346.94734399962186\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"419.8308220590105\" cx=\"183.1951659891636\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"224.53188506839527\" cx=\"222.29614272310855\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"333.8064267867849\" cx=\"217.71168711142914\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"246.03576256428636\" cx=\"175.88161882585402\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"147.5212034309707\" cx=\"328.0245278276868\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"232.00946858099792\" cx=\"368.3566015497309\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"241.25258463538285\" cx=\"285.11998104705646\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.4461115466249\" cx=\"303.39680418093815\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"407.47507068028114\" cx=\"198.46853355153075\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"269.8797045831038\" cx=\"177.40835013530733\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"352.26347747314406\" cx=\"129.5683901724019\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"403.13906080172796\" cx=\"233.04187368426082\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"219.4879732265838\" cx=\"160.8520507282225\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"276.7519293891442\" cx=\"343.3996346235858\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"165.9954011174299\" cx=\"229.20488937572543\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"246.97345239064862\" cx=\"274.18570553788396\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"72.57190773282133\" cx=\"269.46986570789943\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"277.29328781748734\" cx=\"171.24451180103898\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"209.97096100692113\" cx=\"370.74645713432636\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"371.0675557514032\" cx=\"260.8581873484538\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"81.46885481581555\" cx=\"254.54859951333498\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"230.47379274991476\" cx=\"95.37808509561563\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"354.297009495263\" cx=\"173.62445058487165\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"314.41151595781776\" cx=\"246.5410521069499\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"98.25804795383318\" cx=\"254.51497578997314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"90.70523668259112\" cx=\"117.47137664138543\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"145.63060519757425\" cx=\"326.4750235879501\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"290.4101055816252\" cx=\"265.895801266346\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"180.013713758664\" cx=\"202.0535202091044\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"277.22060123904333\" cx=\"331.21513348295923\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"187.5310937567099\" cx=\"207.33972716994023\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.79304662228685\" cx=\"264.94181876814883\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.6244821804693\" cx=\"182.62549660551272\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"412.4225378574999\" cx=\"307.5837433918479\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"89.9275836924719\" cx=\"262.0184585317701\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"405.8243546379672\" cx=\"216.57062457889782\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"365.3336450681536\" cx=\"194.08875789188275\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"298.41307917270007\" cx=\"153.04185864516137\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"125.27018255938465\" cx=\"183.34777483946132\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"329.84668395368266\" cx=\"279.1803722914755\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"180.605447337253\" cx=\"201.9323704176253\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"306.5498608981667\" cx=\"233.9872758148174\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"152.70167422057116\" cx=\"225.13144113346183\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"288.78924432897605\" cx=\"101.8158633760515\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"160.15833372995775\" cx=\"235.1148668817142\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"326.1068138998192\" cx=\"262.30613640608567\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"254.9665119279969\" cx=\"65.08628592046246\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"147.613943373838\" cx=\"106.40884201099033\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"192.54706652324225\" cx=\"336.0559277495908\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"184.99326082488767\" cx=\"174.22420001515752\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"192.48012949161168\" cx=\"329.0829938486019\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"169.49166949316574\" cx=\"399.92587146159167\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.6410941623745\" cx=\"208.99267929973917\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"242.37885025730236\" cx=\"149.41206233272842\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"320.67031933429354\" cx=\"181.9773279147713\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"32.880025308328925\" cx=\"252.74311270321633\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"208.17746500991313\" cx=\"176.96195674917166\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"289.59259309591937\" cx=\"316.5607555925794\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"214.06570006758133\" cx=\"163.47794265318916\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"200.11155544546563\" cx=\"174.35777739850664\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"166.0402437367239\" cx=\"228.08924465429044\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"108.81061179176203\" cx=\"177.8863728965074\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"348.44426202503354\" cx=\"151.98279926442223\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"412.09987098281994\" cx=\"279.42965484051103\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"360.0699390810152\" cx=\"168.89191152169136\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"289.80263148548204\" cx=\"253.1316644946537\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"232.13276638311316\" cx=\"269.71987347449766\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"165.8005813085392\" cx=\"382.15377777506393\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"209.92678729094723\" cx=\"120.91468765282636\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"247.15023653322135\" cx=\"151.29788621717034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"275.35153152852166\" cx=\"33.636314297666914\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"238.05355656705268\" cx=\"289.5788603617639\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"192.12629474395266\" cx=\"329.98436236203196\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"58.13434242332858\" cx=\"272.8375315828849\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"254.7667749242681\" cx=\"19.633308142263846\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"73.49527451232011\" cx=\"143.63407820032708\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"145.46627199667947\" cx=\"311.6572849474982\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"261.0224988731386\" cx=\"94.138600375791\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"58.43393419374062\" cx=\"147.2624955005764\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"90.40611740240932\" cx=\"178.416397053397\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"257.2907490583485\" cx=\"93.55558039609939\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"281.7188236065276\" cx=\"142.9487640857867\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"190.72339158629526\" cx=\"122.29919390890252\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"284.7288555827585\" cx=\"237.3162847093225\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"142.04743707797985\" cx=\"340.8581426395154\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"100.60761001111887\" cx=\"199.70373838892093\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"398.7327267958821\" cx=\"262.2049767971967\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"45.95166531475364\" cx=\"250.55898266131442\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.5455157993677\" cx=\"279.411211239314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"198.611206671892\" cx=\"213.57006987763413\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"61.696160577402715\" cx=\"229.43242329560883\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"422.01473783208706\" cx=\"314.50018174588746\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"324.5621883964134\" cx=\"180.32729588447677\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"306.8274763787997\" cx=\"148.75473502322157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"225.2889613836908\" cx=\"280.8561962448619\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"326.101462673258\" cx=\"284.4195307629308\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"340.19223114189344\" cx=\"209.73536526578377\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"247.33756242729743\" cx=\"362.9585325268838\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"57.89715232774399\" cx=\"154.77397486481664\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"322.19621005066284\" cx=\"149.85817002709695\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"236.56962682898018\" cx=\"90.82821295307828\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"111.02729421289906\" cx=\"202.36392156705148\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"178.80328169392723\" cx=\"103.26389209773379\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"107.0722872702442\" cx=\"188.62333154086303\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"142.6496258764312\" cx=\"335.14643899708744\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"183.5732189082389\" cx=\"255.64671076101138\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"411.5254437324319\" cx=\"253.56965194994893\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"58.48427088547938\" cx=\"244.2281410069431\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"154.41821474484559\" cx=\"254.08036718923145\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"239.8533171801658\" cx=\"222.66416059047341\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"45.894384115444716\" cx=\"216.38696735169674\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"129.25431907414156\" cx=\"358.0179768928005\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"313.60489821776986\" cx=\"188.29342622573714\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"193.3706582001082\" cx=\"392.2788038834875\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"234.1770008583545\" cx=\"277.8098759201335\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"55.640022545268735\" cx=\"157.70924899729187\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"339.72902589407687\" cx=\"209.91590735390872\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"248.31647153217637\" cx=\"159.82745566392924\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"55.03730082179025\" cx=\"145.79372116134272\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"242.49755381302543\" cx=\"402.7861075526165\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"258.79294109322734\" cx=\"92.87452418770371\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"213.68921737978698\" cx=\"174.88771914430959\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"157.57324078696578\" cx=\"97.17810805068797\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"145.03953640175106\" cx=\"373.76277982350643\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"145.0649904393876\" cx=\"330.5613498501793\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"123.87277622120823\" cx=\"281.4546985207028\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"417.18092103746034\" cx=\"219.90725993271536\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"285.73218858669054\" cx=\"175.80549845213207\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"149.17034267449296\" cx=\"251.80520860802872\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"69.28267248902085\" cx=\"104.54350552269484\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"80.33040608824983\" cx=\"245.95331134551012\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"128.57263654148716\" cx=\"244.0292281140811\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"314.7745752531115\" cx=\"186.96081423093784\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"344.5202416509671\" cx=\"330.16866651626344\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"241.33279328576273\" cx=\"271.1278696373113\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"179.68527810791707\" cx=\"385.8225325552026\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"341.2517300484282\" cx=\"220.48868113732556\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"226.92158304178747\" cx=\"156.69591128743792\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"226.16057846469394\" cx=\"68.49987399997731\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"221.45170580532846\" cx=\"96.68040002791837\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"403.9661934082846\" cx=\"220.3525229134455\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"438.6234726665846\" cx=\"227.2968000759421\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"153.92829731680263\" cx=\"253.44302182120614\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"118.60336738687218\" cx=\"278.979712283576\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"415.6618539590674\" cx=\"222.42905498031234\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"286.0424553398628\" cx=\"90.12658693744945\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"160.38234354574737\" cx=\"103.72537220680273\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"111.79728846603031\" cx=\"341.88560011555234\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"191.48937791357807\" cx=\"334.48869963214725\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"351.416005810397\" cx=\"205.41945819830596\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"137.89700048439292\" cx=\"337.98552290920003\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"329.50588663993506\" cx=\"327.42669582868416\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"65.39070453359702\" cx=\"144.8844576658096\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"203.1469535541739\" cx=\"410.252870661229\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"336.7330972018117\" cx=\"216.88977593397223\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"80.9380614887837\" cx=\"243.06554583098273\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"146.40517051897953\" cx=\"238.81286317568092\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"275.0226783282689\" cx=\"210.64874382157802\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"406.68891286601746\" cx=\"220.80194147322106\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"262.84414375031724\" cx=\"79.52170854170174\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"150.65607721536355\" cx=\"336.2913377657033\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"374.5566763388884\" cx=\"255.3347600746349\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"95.53047173605917\" cx=\"160.70594685969937\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"418.3506530135264\" cx=\"325.16184138035163\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"227.65826827889407\" cx=\"274.4733367125837\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"89.81030722206633\" cx=\"171.0324570868891\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"418.1257916165078\" cx=\"219.0246990027818\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"224.04484344389766\" cx=\"380.78953365816403\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"60.39720801743616\" cx=\"229.9038418383508\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"261.10243213313726\" cx=\"307.05596631058825\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"326.8461512287088\" cx=\"172.57662658228205\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"100.27842716651942\" cx=\"259.10365531322395\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"113.74675019159974\" cx=\"148.06833857640962\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"313.8793216423125\" cx=\"257.3646797441214\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"330.1378148525298\" cx=\"153.3001954255858\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"195.4402560607907\" cx=\"423.800176471775\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"313.4329777028288\" cx=\"162.5880127985891\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"169.02834337575538\" cx=\"104.02702974845398\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"222.51167170802097\" cx=\"54.65199847412411\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"286.46775698188304\" cx=\"114.88884393615272\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.48751118790247\" cx=\"243.2154598387463\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"282.5912713226085\" cx=\"326.5148446250296\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"343.1999171491904\" cx=\"212.7760363105209\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"428.3958832137625\" cx=\"274.0991684028067\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"255.8062946363575\" cx=\"46.556098141718834\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"204.75328847927915\" cx=\"408.8401578372215\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"163.64497649077038\" cx=\"99.96611906535419\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"222.1458028814308\" cx=\"154.43037557412222\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.8411745944125\" cx=\"175.7821980908939\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"113.18431100728614\" cx=\"187.78146657904585\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"143.67410007113065\" cx=\"333.44597962285883\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"352.14625594346296\" cx=\"317.06067223247186\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"53.493389547802224\" cx=\"225.07215537031448\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"261.0615974396917\" cx=\"206.0983717184482\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"172.04840203419792\" cx=\"100.372526592237\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"105.5040921960504\" cx=\"175.5849389138377\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"143.03062881232947\" cx=\"329.7178558958822\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"179.0050460103881\" cx=\"281.37896822612447\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"418.78877232656026\" cx=\"220.78417501645285\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"147.73307134665745\" cx=\"374.1842081444532\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"79.31832102691327\" cx=\"261.6690465124291\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"191.01995886982647\" cx=\"299.33994262923005\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"251.90648526603695\" cx=\"332.5400839937343\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"355.7875953021024\" cx=\"311.3766422329481\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"148.41673174539196\" cx=\"248.60125235671563\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"396.0994728138395\" cx=\"240.51694039661444\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"324.4355939791415\" cx=\"173.26156709989615\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"414.26494208741104\" cx=\"251.57625412703885\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"172.81690189962418\" cx=\"99.34662943277435\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"325.52204680509016\" cx=\"266.43893977416116\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"137.88184233851786\" cx=\"334.62586464480285\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"384.00888734758337\" cx=\"242.97051073935162\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"227.00277684803262\" cx=\"273.0196545903558\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.17496347225284\" cx=\"291.94905815515204\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"255.38181435816776\" cx=\"44.58411071912593\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"208.83375531324603\" cx=\"315.2349864650101\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"159.95203130965749\" cx=\"100.99014824018562\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"254.01721037952268\" cx=\"316.4488852894595\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"309.119010042924\" cx=\"189.1500757365031\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"346.90197699648917\" cx=\"283.8327693199043\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"257.94014842131753\" cx=\"38.7255834846846\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"176.24484599043717\" cx=\"417.6818235632767\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"314.96921925168397\" cx=\"154.50269954378484\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"328.10072267146666\" cx=\"256.7098577316494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"253.56962752670273\" cx=\"18.260822916696803\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"219.75915789542026\" cx=\"352.65468534852863\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"247.3118982413899\" cx=\"44.972497688389964\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"239.7247929699477\" cx=\"152.6191941579146\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"99.31821713720616\" cx=\"151.94449459133747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"215.92578422261963\" cx=\"186.54225656284348\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"190.1558264323907\" cx=\"333.27452061000315\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"346.6676767830105\" cx=\"258.6656678579287\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"402.8892782921\" cx=\"202.85826447044863\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"349.41388889451713\" cx=\"252.0171397055486\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"174.8014652540431\" cx=\"109.81649649226486\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"231.36237956133675\" cx=\"114.22006148559859\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.34563226108934\" cx=\"239.77631058718228\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"237.44078961886805\" cx=\"300.2958233294569\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"413.3029300023359\" cx=\"235.25509758679388\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"300.79589135642135\" cx=\"105.52698844288403\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"311.8599808093183\" cx=\"201.81455003404767\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"398.3696675005883\" cx=\"248.30393650581385\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"412.9557375882626\" cx=\"213.83145586826538\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"341.9024040362044\" cx=\"287.3698806301944\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"171.39487662282286\" cx=\"97.80376203255082\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"199.56910644374224\" cx=\"280.7691701373371\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"326.6566167175099\" cx=\"174.62304769835637\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"183.43939429162975\" cx=\"150.47967049019158\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"406.3287324646847\" cx=\"196.91371929077616\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"428.6933103196312\" cx=\"293.1131037662378\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"183.64530663278643\" cx=\"105.5289223563846\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"244.76022574107932\" cx=\"127.32589659891943\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"359.58440592278316\" cx=\"200.6356978977233\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"257.33810246874975\" cx=\"233.05381024340608\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"179.78564931741013\" cx=\"97.81615665998616\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"270.49395012353517\" cx=\"381.50936702987474\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"317.5834802252851\" cx=\"157.88398797139703\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"102.4840884783323\" cx=\"290.54172402806796\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"358.82453175109515\" cx=\"193.19114732400496\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"196.3846953551513\" cx=\"195.27205747985118\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"183.61366626957712\" cx=\"84.66543497479176\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"220.9222502849369\" cx=\"375.24186104264646\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"233.68953550351952\" cx=\"262.4592067584687\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"246.98497483408337\" cx=\"145.47212013671702\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"80.73117669680431\" cx=\"244.9598319605077\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"171.0411957091923\" cx=\"306.68345721068954\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"257.2639819373977\" cx=\"16.893216427460693\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"270.29361426590987\" cx=\"141.2949274103242\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"114.7081029879815\" cx=\"138.27114926483657\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"178.62272449710306\" cx=\"162.56592662736122\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"85.2151309581496\" cx=\"265.23823221765156\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"421.77642694572376\" cx=\"240.08229059032942\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"149.70109754301768\" cx=\"255.4527947270378\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"212.82608074298184\" cx=\"371.164116521576\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"137.28108199890215\" cx=\"335.03497525532845\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"250.46330781032333\" cx=\"152.14640175368191\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"150.3642815337506\" cx=\"255.58437226801706\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"284.38048194310954\" cx=\"104.31938033138384\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"367.4717622533308\" cx=\"176.7485889517075\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"200.43922467310654\" cx=\"176.38206839077355\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"329.8404646636752\" cx=\"152.46172305350325\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"332.0275340343351\" cx=\"225.88532788216853\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"415.43156441847344\" cx=\"214.30916340705895\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"370.48526098927425\" cx=\"269.9273626144459\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"234.85027814692745\" cx=\"255.87460213898322\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"256.4928119527633\" cx=\"72.18601202533117\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"151.7372502376928\" cx=\"226.0560231331095\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"156.0257363895989\" cx=\"220.43313057083674\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.179273420814\" cx=\"194.94922028892543\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"184.17448744955576\" cx=\"274.7388597397659\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"82.567856103228\" cx=\"252.1325262150332\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"270.3939167994974\" cx=\"189.362031557349\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"362.65649344727746\" cx=\"172.94620734156769\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"320.72860045478745\" cx=\"304.50231045012515\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"139.55852336720562\" cx=\"315.9455018898545\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"295.1409909289996\" cx=\"232.61457082635252\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"108.35362583395289\" cx=\"136.57455222353656\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"328.2418324281375\" cx=\"292.1349610844649\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"66.12441593230315\" cx=\"143.48040899404748\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"82.9442440182727\" cx=\"292.7337930046525\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"75.28092497387699\" cx=\"254.10200559355508\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"166.64778376173643\" cx=\"137.2978303786701\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"144.71344122586558\" cx=\"336.06526767274687\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.49833618397025\" cx=\"322.11587267625964\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"63.80033538301622\" cx=\"131.72468174922628\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"311.26767584719505\" cx=\"238.4042030790958\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"146.00451528594638\" cx=\"238.2761321298544\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.3032767290596\" cx=\"277.2644079256017\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"224.98749098388222\" cx=\"260.5773111358248\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"49.78392369084797\" cx=\"147.17552433377608\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"339.7748464582661\" cx=\"206.3204489942554\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"406.19848998330957\" cx=\"252.56481906423943\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"256.4807964163266\" cx=\"16.585504417975322\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"243.79418100682975\" cx=\"178.5738077230114\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"239.09384682280248\" cx=\"274.11472761597025\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"299.496719033557\" cx=\"256.37603239583416\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"256.4559412325866\" cx=\"16.814101784256344\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"193.5025983498688\" cx=\"117.24001026259225\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"79.9164057532484\" cx=\"249.80417127738426\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"271.11563463805663\" cx=\"105.70740279382463\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"126.06296622501671\" cx=\"183.05110042151748\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"119.46043170010778\" cx=\"363.0127260574788\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"99.25814494909531\" cx=\"119.02213352963962\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"289.65275318918935\" cx=\"125.22590827650882\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"239.63549575022608\" cx=\"45.720757390929776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"235.89016596187065\" cx=\"292.78592076400827\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"165.60899750831842\" cx=\"101.63430625804239\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"74.74142903609265\" cx=\"163.72737354218066\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"212.64697260776498\" cx=\"334.3928390561314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"348.19627058302257\" cx=\"299.1898225937498\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"433.7041900810073\" cx=\"214.76394486829963\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"75.00980348687364\" cx=\"115.20875278646544\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"161.5071614795777\" cx=\"227.48583960555163\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"48.66169346513914\" cx=\"152.0621501527417\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"93.47978721976772\" cx=\"240.83774340721754\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"277.2635538974164\" cx=\"67.74484560018557\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"333.00400651808474\" cx=\"136.35514094638316\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"288.6316193905363\" cx=\"271.5174982669478\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"257.3424290508\" cx=\"260.19078940415574\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"247.50527722978197\" cx=\"140.50268765786416\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"368.3009496429817\" cx=\"164.59002532709255\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"216.6041867940245\" cx=\"95.40012731426394\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"108.56904841451141\" cx=\"112.1581360970852\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"171.32726656731782\" cx=\"274.112562951427\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"276.42090053620336\" cx=\"24.426776468856378\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"210.02185672053116\" cx=\"129.17243237130901\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"154.51524555829226\" cx=\"115.8495704082758\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"254.0162901223882\" cx=\"204.04796053226087\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"198.94791639574075\" cx=\"352.75568837635285\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"194.79355978146447\" cx=\"285.10588325716316\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"433.17930837592604\" cx=\"188.14995951198745\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"345.12298535073535\" cx=\"228.43650076526615\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"334.1376534263338\" cx=\"132.68341936712432\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"280.54256467239713\" cx=\"132.15526319486594\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"246.4669387432682\" cx=\"251.79001200364658\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"236.61649950804252\" cx=\"396.06053876937995\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"373.4715420903265\" cx=\"148.11774676990524\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"16.478285147259705\" cx=\"232.61506323259542\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"95.86111600392891\" cx=\"105.19052045822288\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"141.61564693640233\" cx=\"377.3611225711932\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"301.94887739967584\" cx=\"28.357147990668995\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"252.7319147101357\" cx=\"53.08504506030282\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"171.8405887439754\" cx=\"84.46224219949525\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"50.44135538773124\" cx=\"168.42726133282181\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"129.73609428682138\" cx=\"372.12385406065897\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"160.7962285052275\" cx=\"302.6107287777611\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"339.47597990541675\" cx=\"119.05377938692135\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"71.47922462872033\" cx=\"288.473590337692\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"231.88022138518406\" cx=\"286.81530895762165\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"252.03333515767744\" cx=\"191.176231966365\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"373.6635489341255\" cx=\"146.8798058844376\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"201.50156950916764\" cx=\"278.1977354584428\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"226.78597971922437\" cx=\"264.15492749521377\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"185.81851445866818\" cx=\"398.59170189725427\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"318.9190233077337\" cx=\"179.8190227603959\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"37.964042162089434\" cx=\"202.09020413081794\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"275.0365371260108\" cx=\"26.999958262788127\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"287.98146733964234\" cx=\"21.78311671360342\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"193.88529895415252\" cx=\"320.56733539327314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"244.65596198125914\" cx=\"67.6675110364533\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"340.9023290172321\" cx=\"120.55952883370819\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"207.83347838711134\" cx=\"264.3827034976643\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"162.6199309125367\" cx=\"234.57332440194418\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"155.9110970739668\" cx=\"357.59461465835324\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"161.35757436912456\" cx=\"85.99439615845152\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"279.0294586626068\" cx=\"387.3913319773654\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"249.99124199717147\" cx=\"292.6058250692695\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"290.48170433372513\" cx=\"167.44987133897385\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"110.25832185724255\" cx=\"107.39331386421958\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"338.43875396857305\" cx=\"276.64926410432565\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"347.53127904245537\" cx=\"155.6979899448639\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"295.6569722367205\" cx=\"197.92359024091746\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"156.14701803881667\" cx=\"227.1466735162508\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"65.2065652015389\" cx=\"156.55905394283928\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"376.48868889037334\" cx=\"164.13928612965307\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"59.322787210141506\" cx=\"145.31929701759398\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"125.40614986424724\" cx=\"99.93353921575684\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"299.65999737254236\" cx=\"354.54225085393557\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"374.43448816771723\" cx=\"150.50373452749955\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"201.0603845037096\" cx=\"148.96500965789937\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"428.10217010086626\" cx=\"180.08507047149655\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"283.2180460952501\" cx=\"340.344205126744\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"305.73556793891345\" cx=\"28.379717640272013\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"29.772665838739346\" cx=\"250.52095543888814\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"299.1355387110393\" cx=\"26.6376131969122\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"46.93180783889645\" cx=\"262.2149650209013\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"152.01798085740202\" cx=\"243.10972778806527\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"246.37478941318867\" cx=\"65.03155397076787\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"266.1398729877474\" cx=\"284.7852931418674\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"223.8802616362247\" cx=\"335.03699707398806\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"421.8053037904933\" cx=\"203.69184437101916\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"124.50226506563752\" cx=\"187.91196178775348\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"170.18833436137695\" cx=\"251.66723596672384\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"142.6457580494301\" cx=\"361.83630230117495\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"244.15819077665643\" cx=\"292.118841475912\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"156.47201989428567\" cx=\"365.0011407566815\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.99694356126915\" cx=\"268.09291654847107\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"153.33905804710355\" cx=\"128.78729789293226\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"179.96525603970136\" cx=\"330.0124150959349\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"342.57053818621006\" cx=\"291.29561515486364\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"151.28853285891302\" cx=\"109.52198124479177\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"274.2269498398065\" cx=\"95.76178012701183\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"268.4658489920278\" cx=\"24.919199193934126\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"196.65110018096087\" cx=\"407.1322375126129\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"165.98390751787548\" cx=\"100.36315370464625\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"258.2379463770764\" cx=\"113.00643187069898\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"177.96609493479673\" cx=\"330.93833112504797\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"224.95131972780365\" cx=\"160.9834524588835\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"225.90791053689392\" cx=\"267.1977700720847\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"302.26803905613605\" cx=\"140.5829066096299\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"138.94546729345856\" cx=\"321.62287856764766\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"299.1142711566057\" cx=\"217.36866057778707\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"164.62048751184227\" cx=\"93.79616582845483\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"417.67189332741265\" cx=\"256.13177692308557\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"105.49723559363935\" cx=\"247.37550007096667\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.74555586007443\" cx=\"264.914680797308\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"329.77097563539405\" cx=\"132.4781718087335\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"166.76128580437245\" cx=\"146.1138332923359\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"419.9696462815443\" cx=\"186.14297210088532\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"200.99560938958604\" cx=\"142.9232496133533\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"244.92146852622398\" cx=\"274.32488138105424\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"275.0344136670109\" cx=\"115.55120931009138\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"270.844793348748\" cx=\"36.39299811125319\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"222.56847011571384\" cx=\"335.04665565334597\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"231.83805661113755\" cx=\"262.9883683459845\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"317.9210140600006\" cx=\"259.3459603902546\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"112.61465261178014\" cx=\"112.53601839983487\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"86.80564295461396\" cx=\"300.5320739386534\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"180.69600063928732\" cx=\"234.22556884544525\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"334.754824560342\" cx=\"270.1937015113861\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"174.5414692637404\" cx=\"330.1798084951814\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"98.68569556478737\" cx=\"199.6779244895393\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"372.08974990603804\" cx=\"149.04323975544014\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"164.8972184468117\" cx=\"148.54161445901744\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"433.4984260798067\" cx=\"183.97708237949996\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"320.2837344207914\" cx=\"128.58054495869155\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"295.5124506610614\" cx=\"24.257515084978625\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"222.0515781654853\" cx=\"213.5154739062326\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"377.68383644556883\" cx=\"169.01252838814332\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"362.38834974753917\" cx=\"255.5125345237658\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"162.43515426807497\" cx=\"89.29742152408829\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"25.08874931669506\" cx=\"245.65302732197003\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"281.0993339739478\" cx=\"24.455653313625966\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"245.8995027000661\" cx=\"335.3502580966427\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"372.1831821020334\" cx=\"151.4989747627205\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"50.457156340082335\" cx=\"166.72370330173433\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"111.82658286030569\" cx=\"252.074525292234\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"83.7732665857503\" cx=\"244.40539077215556\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"336.63701686289795\" cx=\"129.203353011028\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"332.3353779015591\" cx=\"229.07134701708816\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"376.0526243604338\" cx=\"151.5680627237132\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"254.79440186755656\" cx=\"348.22083702787944\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"129.11729690736956\" cx=\"110.0175575674528\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"287.0764782324712\" cx=\"78.20272459360164\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"421.37034906318763\" cx=\"170.6325050951289\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"406.29265838501254\" cx=\"325.40661329591\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"109.93695158365954\" cx=\"246.2671808366879\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"299.28038443697267\" cx=\"259.68754610339806\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"272.57744524046666\" cx=\"33.2903635439661\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"323.6356350548966\" cx=\"332.6233741319967\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"330.36626937292726\" cx=\"115.44333869171122\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"89.17048952144093\" cx=\"183.48556342933938\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"182.42823223446393\" cx=\"334.6014599750033\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"147.97568409174502\" cx=\"227.90131029169112\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"252.55623212908813\" cx=\"256.88781073813476\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"414.23023053770515\" cx=\"287.0246605881287\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"333.1699604703508\" cx=\"135.08652116038405\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"240.07595897191666\" cx=\"141.73265664421447\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"171.89929840211994\" cx=\"85.64351172769533\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"196.19684477715677\" cx=\"407.97933557843373\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.6976144814313\" cx=\"177.15133742634208\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"197.34549874428862\" cx=\"410.2478161145798\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"111.44151431079828\" cx=\"250.07306491801123\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"282.21220779428324\" cx=\"185.93948813974922\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"189.2990423168498\" cx=\"274.1437637888407\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"380.2994544550638\" cx=\"201.6314985283336\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"214.49295347883762\" cx=\"237.2658546183522\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"264.23369631193395\" cx=\"374.0820623495605\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"184.1721112632234\" cx=\"330.98692070174934\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"100.62087270200048\" cx=\"301.49399262449697\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"375.43247543916056\" cx=\"148.98402464263066\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"308.3528781227214\" cx=\"218.63468578807414\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"129.12735105994346\" cx=\"113.40460927705954\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"268.03270456159265\" cx=\"183.63393634978218\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"202.1212047346673\" cx=\"112.16778368829817\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"300.2218871496115\" cx=\"171.7471809712262\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"280.470641770023\" cx=\"20.242205203170222\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"266.1302034202447\" cx=\"145.11195621760166\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"122.56692310625107\" cx=\"149.23086232942822\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"286.9834635859816\" cx=\"253.6514751708685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"371.67711210100293\" cx=\"149.29526934069798\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"180.29398287628788\" cx=\"110.72063401820702\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"175.09996370403866\" cx=\"334.74370151059776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"263.69432673781586\" cx=\"58.25638470150013\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"190.79223506106416\" cx=\"352.80968412033985\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"202.5779681825424\" cx=\"197.1019187423709\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"424.05114874816707\" cx=\"172.83310636622014\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"219.17555211025422\" cx=\"79.1741095662675\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"112.67426329780565\" cx=\"252.07898098498669\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"225.85540574681664\" cx=\"182.8662551011502\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"337.07536692697454\" cx=\"135.42086843308155\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"165.39044330646638\" cx=\"290.48949188133577\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"174.69730862863562\" cx=\"254.8919048711536\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"278.8904806060445\" cx=\"203.50808962403218\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"430.8623701208172\" cx=\"183.86287160151858\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"129.04657720686077\" cx=\"172.18897032465316\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"176.1903832502924\" cx=\"96.62080033003775\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"34.68071854023951\" cx=\"217.38341010202404\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"190.66949473561232\" cx=\"322.71963827350265\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"77.46721418624968\" cx=\"290.8223447663283\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"419.80664814025357\" cx=\"170.48646166140261\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"100.3358621998568\" cx=\"177.84449707633354\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"433.20482284835936\" cx=\"184.4021972230571\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"225.48139745189957\" cx=\"160.75169600094677\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"114.99241024885225\" cx=\"244.52704739181766\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"129.28485512878947\" cx=\"184.63812917605188\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"122.80653059371136\" cx=\"97.72843829933333\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"77.87059997328787\" cx=\"185.09391742606806\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"120.87672665934922\" cx=\"130.0179701205555\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"151.084395103156\" cx=\"406.42250224605567\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"255.40067001479812\" cx=\"36.42097392814184\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"97.0514837160975\" cx=\"275.3657114294217\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"193.37192733084294\" cx=\"117.38418571168731\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"219.01174702707314\" cx=\"85.81039967227694\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"141.3902526143566\" cx=\"347.74912695591837\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"273.83047284886754\" cx=\"88.67709679249684\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"441.92835502870764\" cx=\"219.117894266903\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"277.1271141023235\" cx=\"121.37291527100801\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"156.40266272374316\" cx=\"297.3257112836095\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"423.93045496470086\" cx=\"196.43908087820202\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"83.12943821224022\" cx=\"232.8781729884562\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"385.45360863765393\" cx=\"311.0661337405883\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"329.38928044636776\" cx=\"141.6903962389695\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"170.31425850181054\" cx=\"129.59726701717148\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"232.1868263390718\" cx=\"268.0470190672676\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"283.7638876867081\" cx=\"245.33059119833274\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"365.94576165551257\" cx=\"214.97848015615833\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"224.08399901145228\" cx=\"184.097094897983\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"120.82678554082648\" cx=\"130.2056146708334\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"194.64039602984982\" cx=\"309.08789406355334\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"254.6184020038253\" cx=\"36.846808495189265\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"413.4106248103978\" cx=\"272.534593922354\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"205.3673527153198\" cx=\"124.70545479381798\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"279.23959045140106\" cx=\"335.15281212112336\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"143.58868372683216\" cx=\"333.101226576951\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"197.24586648753936\" cx=\"201.0693422887509\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"442.81854859878507\" cx=\"216.50132303583885\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"251.7019807809442\" cx=\"51.31318472058226\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"111.80321107612573\" cx=\"330.0225022129434\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"419.9927213858123\" cx=\"198.90137580798145\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"83.27567943257448\" cx=\"231.77735110278735\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"98.18563607901143\" cx=\"175.56038041000969\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"329.5474987446315\" cx=\"174.83346517891772\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"372.30931501721994\" cx=\"330.1881814615872\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"228.56089914131317\" cx=\"261.0019562361879\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"394.3628844192142\" cx=\"313.1873841233601\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"355.8173402103182\" cx=\"200.0772611451857\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"274.7872902884462\" cx=\"334.8106193129748\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"113.11414071402184\" cx=\"127.13239536741547\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"259.0868986923473\" cx=\"132.70463747490592\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"274.9333639395709\" cx=\"29.636915249658493\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"133.6821349032464\" cx=\"105.33613535429843\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"173.77006852806326\" cx=\"92.08205917827345\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"199.0154907397749\" cx=\"174.34805289027946\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"144.43400720725336\" cx=\"331.77268294279696\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"163.14193372365693\" cx=\"130.7218926584662\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"440.55184814211106\" cx=\"207.07788105074172\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"413.1707096548806\" cx=\"272.3715518284837\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"191.7904558305864\" cx=\"401.64947186895756\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"255.03131451248265\" cx=\"146.291907168415\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"98.64612725504031\" cx=\"243.73973032826817\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"206.62870933754695\" cx=\"404.6306434826362\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"339.03433339787335\" cx=\"142.2320843116593\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"284.6286931480184\" cx=\"229.65575287655395\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"230.28915654767994\" cx=\"265.62710266529075\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"280.44138034018226\" cx=\"342.95891112021314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"365.7746432751485\" cx=\"203.00533666924017\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"304.46874471460376\" cx=\"144.52230489246924\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"443.5614570747637\" cx=\"217.11709249461455\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"275.40759579078406\" cx=\"196.11314777745366\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"144.60678479749575\" cx=\"331.92312163447906\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"198.1503831044802\" cx=\"186.65195396031152\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"105.7924211179507\" cx=\"122.94926354870982\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"285.54689549941907\" cx=\"330.2953378505495\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"102.29660875022775\" cx=\"246.2563245495371\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"250.29058104025106\" cx=\"352.0184168187026\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"112.22933133494028\" cx=\"248.38034531833918\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"261.3442427436479\" cx=\"163.4768932853522\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"90.70882980596997\" cx=\"232.73987138956366\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"239.11980974889917\" cx=\"318.1207370284684\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"367.93695635537233\" cx=\"211.75734600058766\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"437.6412643712025\" cx=\"273.7673923560134\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"115.59197837474746\" cx=\"120.51163151013486\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"341.4180246331858\" cx=\"250.83825460478954\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"123.41926251718418\" cx=\"112.25453509220074\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"377.91200527419915\" cx=\"251.02518767268586\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"274.7504992323199\" cx=\"26.40618088924969\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"186.0426698673776\" cx=\"384.34793449917754\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"441.52346386581956\" cx=\"184.36634840035515\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"268.2398393338683\" cx=\"215.27540318088032\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.62341625256175\" cx=\"290.22810589070446\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"213.34492583596446\" cx=\"371.59920310662034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"339.9994331516624\" cx=\"143.15979140838942\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"335.32663663224633\" cx=\"228.10227882609627\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"374.22166977749754\" cx=\"191.35360260117122\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"295.5215268687401\" cx=\"326.7015222185572\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"156.48881527374925\" cx=\"285.0330758091254\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"282.6480360791076\" cx=\"310.38643456808654\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"97.16190358409202\" cx=\"232.9689831383773\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"222.68861998600798\" cx=\"399.9812187474\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"246.94002233334047\" cx=\"273.1047303021627\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"33.192352338667874\" cx=\"257.5269389326684\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"368.8383798095268\" cx=\"234.1218366371341\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"341.60473519114805\" cx=\"340.40012379608663\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"233.50391963949187\" cx=\"39.206402728759045\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"265.0377840316211\" cx=\"298.3401093494453\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"146.91969040343005\" cx=\"349.81311811567105\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"177.04849693136492\" cx=\"393.3322702984779\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"258.45980801054014\" cx=\"269.5623446823256\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"32.04024534700451\" cx=\"191.95419811861356\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"160.96789629283603\" cx=\"282.033141938048\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"374.683600400507\" cx=\"205.5121734178473\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"305.1856332634841\" cx=\"178.80569603868685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"157.4460035632179\" cx=\"101.93292008355925\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"145.151357258219\" cx=\"255.4170777620745\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"123.74612686321194\" cx=\"199.81523509511462\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"247.72397427751758\" cx=\"270.2864744186881\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"291.75210969326884\" cx=\"275.59007835992026\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"256.01776148475585\" cx=\"18.168610404784175\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"239.21843796390914\" cx=\"138.88248019983595\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"115.4488687757067\" cx=\"120.10196050421989\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"374.46368366868865\" cx=\"236.1317681843076\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"253.82907410976102\" cx=\"19.360538433527065\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"243.0183424341354\" cx=\"310.70145918799585\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"106.59947838379419\" cx=\"249.03320182639405\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"311.7729327255037\" cx=\"254.22084238053498\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"110.90329299782113\" cx=\"124.53343538557296\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"362.34944072648545\" cx=\"282.7009519377794\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"146.09720028808925\" cx=\"347.8276812037334\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"90.3609781032033\" cx=\"136.1209780847156\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"240.96967836298552\" cx=\"272.5705086739253\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"278.30644971702304\" cx=\"361.22617456804096\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.13501047494435\" cx=\"204.47558616692527\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"122.67112368423815\" cx=\"265.5770763886451\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"325.72816242692727\" cx=\"126.72313092286139\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"251.59370772175748\" cx=\"302.0764412206544\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"421.800359125293\" cx=\"213.13952826401967\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"276.99953624608406\" cx=\"213.52609394826828\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"156.53505888151668\" cx=\"294.9032538731269\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"348.6711672170016\" cx=\"260.3930948867524\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"206.79982497087482\" cx=\"125.0653934559631\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"54.15106298387306\" cx=\"263.2646542610859\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"328.2514580430607\" cx=\"127.84677861926099\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"416.0153645564522\" cx=\"313.66573103483444\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"156.63608937970312\" cx=\"295.71295378781633\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"345.3685594008706\" cx=\"262.8255267857584\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"206.1900406172686\" cx=\"126.72279029036983\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"232.21546917069324\" cx=\"344.84661947150363\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"230.87126682915755\" cx=\"40.79968373773556\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"50.65323978563534\" cx=\"275.99123904761836\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"146.44523329524662\" cx=\"333.89455964982744\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"335.2389182715935\" cx=\"286.385765891674\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"206.55249556459344\" cx=\"119.60461509023165\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"195.8918715627851\" cx=\"183.4380754141632\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.60847237551206\" cx=\"301.25919794449834\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"82.27616480899151\" cx=\"260.9083509769105\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"233.76478850055426\" cx=\"278.06445475500567\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"100.43429400177689\" cx=\"170.98540035639985\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"307.56245141416815\" cx=\"186.66886471529645\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"295.5568867189945\" cx=\"260.49973757994115\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"295.02152781776107\" cx=\"20.3793372513911\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"350.0641343446427\" cx=\"177.00195359656942\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"248.07936659471466\" cx=\"268.8928232790277\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"260.49126052623876\" cx=\"219.63917048694245\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"127.6759379896352\" cx=\"114.3397993004594\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"356.8657081260798\" cx=\"342.2873706452918\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"367.8494577576173\" cx=\"183.8418430392363\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"425.23395661665165\" cx=\"323.76568769069263\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"110.7902689394878\" cx=\"249.72747127901937\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"208.69276642616896\" cx=\"192.95490220888087\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"241.5103115737659\" cx=\"271.2121267323239\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"159.4929521102469\" cx=\"312.5024490998185\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"233.11701503964935\" cx=\"39.543914587184716\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"397.5221738615515\" cx=\"260.58383259981673\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"231.86555890765737\" cx=\"35.45010539828577\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"195.49331781246207\" cx=\"311.0792810559486\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"155.96626854945694\" cx=\"297.0796043084471\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"292.6679166290836\" cx=\"105.42063418849864\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"322.85229020572467\" cx=\"144.1558777307669\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"171.0255430967972\" cx=\"357.6749929382199\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"94.93204637723248\" cx=\"246.47852956252868\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"423.7931031535822\" cx=\"300.46771637403566\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"148.1723554030496\" cx=\"326.2295594192637\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"150.56689193736796\" cx=\"116.27591042998813\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"155.7846070440714\" cx=\"294.51641623229233\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"80.95182963433022\" cx=\"306.94359055280336\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"439.3941811491336\" cx=\"210.2549328292929\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"406.894687855363\" cx=\"320.7230593826471\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"133.73159254339404\" cx=\"154.4779542414937\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"385.33498062542697\" cx=\"224.25957742011286\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"443.30035677589956\" cx=\"216.0288039617103\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"103.80466570744136\" cx=\"279.7572828626086\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"330.6739923705575\" cx=\"150.86466761675717\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"361.17664305799514\" cx=\"292.8141548023018\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"442.23923162392117\" cx=\"216.02838915924073\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"215.69547133221775\" cx=\"340.1391553549612\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"134.9695608992239\" cx=\"330.3934839607025\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"255.69802569772511\" cx=\"286.59890843216795\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"124.77978165296656\" cx=\"114.99675850711243\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"117.3909354797655\" cx=\"144.0974592584619\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"145.66089401896215\" cx=\"334.52060920490635\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"191.10274630046013\" cx=\"161.46000280866838\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"213.5047168124656\" cx=\"133.26635144165684\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"268.36339003500575\" cx=\"179.18828676152168\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"235.26205922004073\" cx=\"268.58158132799656\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"233.84481000909153\" cx=\"200.7490625885482\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"142.56721478976002\" cx=\"333.30518852238976\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"281.4351811284227\" cx=\"193.34419020602581\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"131.03344257763405\" cx=\"138.00191224468173\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"245.87423820792895\" cx=\"170.10531038554834\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"258.81010457554476\" cx=\"17.79969442826433\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"49.72811490295424\" cx=\"164.477270478309\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"155.59685810641707\" cx=\"108.95202616937375\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"140.57901435938265\" cx=\"373.56424602164304\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"216.46927984514375\" cx=\"390.09629459295684\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"278.137517977492\" cx=\"335.76493969662727\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"423.41653942821927\" cx=\"263.5325342453469\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"219.61999235363578\" cx=\"334.6020533348273\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"153.32216377433596\" cx=\"218.23604619286917\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"317.6276141092338\" cx=\"161.49683507033797\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"75.53350946045177\" cx=\"262.0667761518854\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"424.79396931898657\" cx=\"308.55829844431446\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"312.43379272359255\" cx=\"205.09924167993634\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"272.851544514735\" cx=\"75.38500163515421\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"244.14094350973429\" cx=\"264.46564476232646\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"176.96579465885415\" cx=\"407.05728737632165\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"375.32845067149174\" cx=\"203.1229523986192\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"273.16683285012175\" cx=\"188.2817348395747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"122.50370830870182\" cx=\"105.68029504038225\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"207.63766689814435\" cx=\"349.0120274125025\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"257.72384404213165\" cx=\"17.146097593947495\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"227.21481198954945\" cx=\"119.60632924083441\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"163.8556082401571\" cx=\"90.23994064012948\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"395.0423473466009\" cx=\"201.48470515371866\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"193.4127125776365\" cx=\"371.3118631177601\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"441.2887351146902\" cx=\"190.456678792349\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"443.7376629662116\" cx=\"208.581313372475\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"260.6850144850752\" cx=\"204.7840549848899\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"146.72500794635044\" cx=\"229.49509761378135\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"333.25208586525486\" cx=\"231.34159492766383\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"100.9588570506564\" cx=\"250.41563956419478\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"110.92602746959749\" cx=\"153.5118820368819\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"129.77599224091512\" cx=\"108.94690569385524\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"281.6541144212734\" cx=\"230.27730759361395\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"279.4204717984994\" cx=\"27.827871027631883\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"383.95690243411116\" cx=\"298.79222206499594\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"153.27700799291262\" cx=\"102.41391513795193\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"287.359340552289\" cx=\"252.81151115811718\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"133.5525736868544\" cx=\"337.79216452357963\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"62.61300039883713\" cx=\"215.35284487902527\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"340.6910269910071\" cx=\"139.9469951945127\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"191.64694241722097\" cx=\"270.7200611219551\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"230.6672609311392\" cx=\"247.95558209541846\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"419.5921595520107\" cx=\"283.25315017105595\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"156.23442873141258\" cx=\"226.27669924875352\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"66.71696263361396\" cx=\"270.21906489682726\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"175.53602273990575\" cx=\"83.942426029208\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"323.28179481316516\" cx=\"115.63060964506286\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"262.97298799025526\" cx=\"17.978998976571077\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"243.74346110353798\" cx=\"94.76208969311064\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.34689958641766\" cx=\"229.6356819997747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"106.0822114631213\" cx=\"296.1906963513218\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"246.5597240122332\" cx=\"261.89529790977616\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"197.52103985297072\" cx=\"420.7628774140008\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"258.2400973064385\" cx=\"270.2267236338153\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"413.73439049956676\" cx=\"302.24384011397336\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"130.66889988278024\" cx=\"153.58851335934122\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"306.7315333916971\" cx=\"185.55546621104253\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"374.0606824667216\" cx=\"228.7587655425191\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"369.86899088314703\" cx=\"201.46494022809867\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"172.00961937681046\" cx=\"84.28451994405259\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"334.43831104680015\" cx=\"304.4120263576406\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"353.6713445252553\" cx=\"151.02294085574545\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"299.3724431148568\" cx=\"197.80941242737075\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"219.22789551195342\" cx=\"239.7121219652922\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"257.3421735764314\" cx=\"214.40246511883376\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"433.6129665021347\" cx=\"184.32492584115798\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"201.6356303708919\" cx=\"197.71667797857586\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"122.88232681715908\" cx=\"262.632292016768\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"355.7459392448263\" cx=\"310.87562128449434\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.5626784228359\" cx=\"16.404419790196478\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"311.1640906053218\" cx=\"205.90637723631218\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"146.2831471699817\" cx=\"169.66883929424787\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"48.81864812674066\" cx=\"220.91555786123985\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"411.17526254294864\" cx=\"198.33253053519726\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"208.11908362259717\" cx=\"215.45455526867673\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.69704781146623\" cx=\"219.5799237832164\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"322.970280905548\" cx=\"116.14067933083314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"126.41223539847412\" cx=\"149.32860187822027\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"249.9238626927091\" cx=\"202.58012705293334\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"275.1879894740589\" cx=\"21.746306428223615\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"114.54194026096259\" cx=\"190.31798917459002\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"199.87885126003218\" cx=\"343.46925550960566\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"317.270521376615\" cx=\"162.81139079604762\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"113.55892983100364\" cx=\"260.99441012768506\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"160.35872452830742\" cx=\"305.25044928307113\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"143.54894510083932\" cx=\"167.15403202004157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"83.47066406363854\" cx=\"281.76444883106524\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"249.42313430361304\" cx=\"24.208068432975903\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"195.81186138577226\" cx=\"291.81850800572\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.14214288866145\" cx=\"14.979059611421192\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"297.0516095623847\" cx=\"208.15708444809954\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"233.81193244944356\" cx=\"268.94395386423474\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"154.8225235360545\" cx=\"261.79873683952354\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"127.92069891704865\" cx=\"130.3104195967894\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"40.58972531230318\" cx=\"295.9163058912138\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"443.9230769230769\" cx=\"208.53759841155025\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"255.6334648524269\" cx=\"203.7998619558372\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"307.9685677552114\" cx=\"196.66339836204858\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"179.74677326079112\" cx=\"405.1846437716747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"351.3480001816759\" cx=\"145.29943594570622\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"290.4822262706074\" cx=\"298.68999935308904\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"114.11019407196461\" cx=\"257.0761255652509\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"294.38956664073163\" cx=\"346.2075341805021\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"135.16174355334113\" cx=\"352.5253988357589\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"274.55912970092453\" cx=\"302.48194771965626\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"121.89252571365844\" cx=\"256.4096698543771\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"240.2297916268515\" cx=\"157.7412629574274\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"142.633934805529\" cx=\"165.62115833759503\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"334.7845035396885\" cx=\"239.20538443445963\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"342.1860080558023\" cx=\"141.87122264534344\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"282.3463840315288\" cx=\"139.97973437221097\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"199.48386865679822\" cx=\"343.457388313125\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"55.58124695825483\" cx=\"162.56608046138967\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"152.40766992183543\" cx=\"235.88278300194318\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"38.140467816435134\" cx=\"218.72101895571183\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"432.8200839431987\" cx=\"201.63658603941747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"412.0219210829739\" cx=\"259.6672784701494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"167.87328057311674\" cx=\"90.58970428010693\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"423.9166099021401\" cx=\"304.81100589857806\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"443.77724226410356\" cx=\"219.53471031403234\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"147.28523851354126\" cx=\"370.40804424801973\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.48319842381403\" cx=\"15.98456277396894\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"300.26456510436236\" cx=\"214.98136729122803\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"352.85215634745373\" cx=\"151.6689393878712\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.24960686290005\" cx=\"296.7268024464077\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"128.85706467195172\" cx=\"110.76655347570022\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"146.43511870787586\" cx=\"375.8552962073922\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"122.62291869260795\" cx=\"258.63617842408155\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"112.28890905653111\" cx=\"186.12753650435178\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"344.92700079848635\" cx=\"149.64599993742573\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"278.27560599431825\" cx=\"144.49242263244227\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"280.12528987021864\" cx=\"15.550223382777052\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"377.9427171391653\" cx=\"293.67327389863175\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"376.8917450330648\" cx=\"194.80697875333092\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"397.307542427425\" cx=\"277.1179908949492\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"205.7497181811844\" cx=\"338.82468753441066\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"425.7139187854247\" cx=\"249.8778934884841\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"221.4974988991554\" cx=\"245.5132594924938\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"163.16565163440092\" cx=\"107.34075756721313\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"169.31534273212407\" cx=\"85.39039981016586\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"252.56898661826858\" cx=\"85.74994289909496\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"227.6600996936056\" cx=\"245.11827688925985\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"298.4674759839755\" cx=\"248.8526034240266\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"120.17922119805398\" cx=\"110.8647655147225\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"239.96578427690503\" cx=\"319.4712129998218\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.4715400020862\" cx=\"17.792200513449693\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"82.6173247315205\" cx=\"187.69896484017931\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"322.05621559069823\" cx=\"202.30262694782164\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"95.44409392908287\" cx=\"291.5538200775494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"155.803193491152\" cx=\"319.8885207664349\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"275.53100364603796\" cx=\"187.12543861767222\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"353.7074955219417\" cx=\"151.01830935267452\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"257.02570401546905\" cx=\"380.9489496642208\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"237.5125037464893\" cx=\"284.86253980044046\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"265.21323998218026\" cx=\"300.1584715183382\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"354.98176870848647\" cx=\"176.01503688110225\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"52.85860441753619\" cx=\"141.62254444427688\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"119.91151702411125\" cx=\"110.05371955228412\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"114.57761876741877\" cx=\"231.31457782641678\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"279.61655524405245\" cx=\"45.090993842878255\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"216.24687567202608\" cx=\"345.13679440174536\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"177.50240071453254\" cx=\"92.2744286308538\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"166.27151671628553\" cx=\"134.13790362392922\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"219.60519269598774\" cx=\"289.37595877230694\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"375.9074489901538\" cx=\"152.95575554180732\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"417.1641970809385\" cx=\"191.56591004265357\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"348.42135174293895\" cx=\"305.53410824339346\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"148.74933739712446\" cx=\"256.3577673519916\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"72.95545991833399\" cx=\"142.9514781575744\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"114.42213651723245\" cx=\"262.9268045172049\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"259.4347311658604\" cx=\"218.39708432381525\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"348.3036027823032\" cx=\"156.05231366497054\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"272.28754501384714\" cx=\"82.13123911892794\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"230.5189444966287\" cx=\"314.4433290842292\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"70.52501412651675\" cx=\"176.31797454163316\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"314.0540386401278\" cx=\"115.92725659264451\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"160.98806503278072\" cx=\"137.3079449660409\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"102.93120708203067\" cx=\"114.76596351185351\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"420.28786295754406\" cx=\"294.27062241925927\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"270.1195043630996\" cx=\"34.05008388162567\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"246.85748900355736\" cx=\"131.53183980641566\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"178.62583414210678\" cx=\"90.71029917026911\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"304.46293198595725\" cx=\"209.55618433410706\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"133.80003769791068\" cx=\"311.748634890037\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"344.4522470103909\" cx=\"261.11058503656545\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"343.30701859742834\" cx=\"124.67067731524274\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"207.9451426625146\" cx=\"196.3021493636254\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"237.4263285334344\" cx=\"300.67337598785986\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"283.94953788868855\" cx=\"115.63198316317404\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.18487467645286\" cx=\"170.34014901812657\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"178.8508219027916\" cx=\"283.0282558096027\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"275.24437239252313\" cx=\"307.11601102833686\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"268.610359579542\" cx=\"346.4967421539935\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"246.52104162166782\" cx=\"66.30793688113143\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"377.5151464452253\" cx=\"159.08883256445753\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"239.2406930778647\" cx=\"323.27520986726034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"224.68477239949004\" cx=\"350.74090212941536\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"299.8756122456365\" cx=\"22.10467378564955\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"118.04580693888951\" cx=\"294.47884227084273\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"149.3580092010606\" cx=\"258.5364472740283\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"292.5191151709901\" cx=\"223.85789616905066\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"421.4753737520414\" cx=\"193.24309652600624\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"200.14425616465678\" cx=\"209.24458114781268\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"158.82743863279742\" cx=\"205.0408300752219\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"93.3936291756892\" cx=\"192.49707565798766\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"148.15912018253022\" cx=\"291.41322676368833\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"80.58968235506231\" cx=\"138.07691182762497\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"218.31216205935758\" cx=\"64.28450296416591\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"213.78266193744534\" cx=\"73.52155510777973\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"276.2179495000944\" cx=\"54.66169001791664\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"325.53167242001336\" cx=\"147.91440016058027\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"375.7740638993402\" cx=\"231.73613525806593\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"236.99704437565074\" cx=\"109.08914722944975\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.25646354809174\" cx=\"19.969896996518802\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"271.1357511843131\" cx=\"334.34098600039783\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"154.78391668898524\" cx=\"285.98731927576364\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"345.35348366608224\" cx=\"176.61167117231196\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"145.36039572659675\" cx=\"234.7873350058844\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"91.39643494871979\" cx=\"143.43591250131752\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"96.21312122546382\" cx=\"250.58344227183846\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"68.87146314282136\" cx=\"264.6299779632212\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"104.48152444448927\" cx=\"123.85538992887702\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"373.7563657940071\" cx=\"280.4944884913896\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"274.91574719627675\" cx=\"50.10503818998247\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"203.16405110762196\" cx=\"165.9666256129207\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"120.44402450174587\" cx=\"354.09791225089424\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"384.2523187094652\" cx=\"260.02605238893625\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"416.907008561655\" cx=\"184.46819476829964\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"105.2366627257299\" cx=\"297.0277512527136\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"254.40551219066384\" cx=\"291.5181470651657\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"59.268868383168765\" cx=\"140.48177172406702\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"368.37515258542044\" cx=\"200.48858861394274\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"168.3476717524308\" cx=\"307.3626893870335\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"252.2119227295302\" cx=\"330.7945182847343\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"300.90897584955155\" cx=\"141.15426816759378\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"123.85293163153781\" cx=\"133.40270333159057\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"220.9876647717412\" cx=\"395.6261774018983\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"146.55475762943266\" cx=\"254.51789039540506\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"387.1516506200069\" cx=\"278.05223044381614\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"142.70986838078784\" cx=\"232.15270613221247\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.18551209134677\" cx=\"268.6506170953011\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"110.97138653170131\" cx=\"272.4839275862685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"299.3687950507535\" cx=\"205.0861822697352\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"278.00547344035493\" cx=\"14.601463000438647\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"354.3977817720446\" cx=\"300.641394992159\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"117.0289859871056\" cx=\"272.73638021510465\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"225.47221479656721\" cx=\"91.24423510673938\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"134.92892673942256\" cx=\"315.92589903937164\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"272.90962510158465\" cx=\"153.52852907638947\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"131.43731184304738\" cx=\"306.83681325483974\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"350.80238384718814\" cx=\"214.79541972257653\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"299.7950196969445\" cx=\"24.746619390299745\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"150.44526416158618\" cx=\"105.5485801475919\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"348.1292978399211\" cx=\"152.48168851276745\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"298.54779382904525\" cx=\"149.21795125918305\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"158.72897936051513\" cx=\"204.38650252926993\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"85.30635453702217\" cx=\"181.25085770354733\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"184.47801846991067\" cx=\"92.71098762731337\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"215.6182699997423\" cx=\"357.4177604663568\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"279.5309630894357\" cx=\"21.760283348523053\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"225.50834106992767\" cx=\"96.79720400809367\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"417.1422207911595\" cx=\"188.76834208896972\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"164.0980671512162\" cx=\"145.34619599628346\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"144.76415700860304\" cx=\"249.61038160707693\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"91.35143849539732\" cx=\"286.2637425426762\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"131.9516669053246\" cx=\"138.8295942584828\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"326.5064087768705\" cx=\"219.02047474783086\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"110.55155149176356\" cx=\"253.45777889979274\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"214.7297136632534\" cx=\"122.2078164960015\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"262.99787339139374\" cx=\"365.2269251578708\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"361.9479668766581\" cx=\"229.57033000804446\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"201.7268566968007\" cx=\"201.91655847712929\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"223.37947624612698\" cx=\"353.4670718646436\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"143.01578932265622\" cx=\"346.6648937352374\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"85.33095699342975\" cx=\"285.03755347816787\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"368.52302005119833\" cx=\"228.25468594092146\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"385.4747058758417\" cx=\"210.1544599794596\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"377.9309927885682\" cx=\"252.24153960048184\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"165.6026243842825\" cx=\"376.00870169819444\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"196.73669508261378\" cx=\"343.8806736305581\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"92.96339935068599\" cx=\"167.88636440656407\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"351.239118653966\" cx=\"132.3725427719108\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"293.54815493989116\" cx=\"180.97923350891529\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"279.2850319245916\" cx=\"19.023224361709403\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"273.07976279001736\" cx=\"205.01712864669526\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"349.9871184371122\" cx=\"152.21264927922067\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"235.2574067708186\" cx=\"388.0604550604111\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"113.15695052651131\" cx=\"255.67757371296977\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"417.38352045293277\" cx=\"326.07008847248244\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.91230085628223\" cx=\"197.61464755920449\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"168.71036294487075\" cx=\"412.06371693901747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"421.0132123779893\" cx=\"187.43916114241213\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"380.69030276878306\" cx=\"298.2359527240378\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"144.32568058086028\" cx=\"230.16301921185928\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"259.03073553678087\" cx=\"216.94945941645761\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"371.8178592488925\" cx=\"175.42742935091925\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"125.86690475575347\" cx=\"195.7625600266095\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"357.2825983431872\" cx=\"197.3319225911978\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"179.61623959357638\" cx=\"361.50247147128727\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"419.7714641003175\" cx=\"188.222418086425\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"403.21604374482376\" cx=\"306.43582288338746\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"369.5857165078959\" cx=\"169.5838789579623\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"261.45934081432915\" cx=\"101.90865825964326\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"180.6218856020077\" cx=\"116.4823776724617\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"435.8648769157875\" cx=\"277.5493140403689\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.51390368702386\" cx=\"227.1706015752658\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"167.5807376976513\" cx=\"349.83317148009434\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"129.76332290985755\" cx=\"157.241148530927\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"402.24153813900926\" cx=\"225.26214264888202\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"241.0032299766465\" cx=\"57.31805206866186\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"122.75380947453158\" cx=\"287.6423646471641\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"192.8591957669732\" cx=\"113.40936714379669\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"101.3389150060942\" cx=\"237.80977328445456\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"128.72062487685886\" cx=\"325.99406149799205\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"289.9517900582844\" cx=\"241.5402223775934\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"428.10981784970943\" cx=\"256.05780198465334\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"188.2144574755324\" cx=\"157.58579718945842\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"66.426710786358\" cx=\"234.55412055847262\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"33.782789316159906\" cx=\"191.9633622314514\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"300.8886422874335\" cx=\"187.6585559373482\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"247.82515860973245\" cx=\"147.75064383729216\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"249.0862968425799\" cx=\"250.0717408465521\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"350.7695073176788\" cx=\"340.63085286247616\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"136.2880174163693\" cx=\"164.96625940810878\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"416.75781153034546\" cx=\"325.000227745317\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"233.46709458879238\" cx=\"61.948357431790306\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"385.2236597295515\" cx=\"305.66241681126803\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"188.81130878260367\" cx=\"144.7350573538196\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"269.76655416110424\" cx=\"97.70637410439524\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"274.3614364921452\" cx=\"282.9809353636361\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"96.91431870344195\" cx=\"250.42975658334157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"413.62023466230977\" cx=\"227.92593764311445\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"72.25443825067408\" cx=\"275.66195730971486\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"336.04180004237895\" cx=\"150.2811861349802\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"193.8789368182615\" cx=\"407.7006322714566\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"271.2644196139329\" cx=\"279.2677994662888\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"292.28907835772856\" cx=\"219.47818935699797\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"119.09039493280919\" cx=\"116.96263652114678\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"182.88387763859654\" cx=\"307.90602018738434\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"238.85773356541702\" cx=\"42.34373785760715\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"399.64150131896764\" cx=\"299.59766956761314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"210.90167885535098\" cx=\"157.28398031970627\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"243.4212378752079\" cx=\"271.0881062879924\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"436.8966637209109\" cx=\"221.28224324434711\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"304.33271148087186\" cx=\"236.12521306912194\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"316.19623242705904\" cx=\"169.1504680650136\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"165.6647403673428\" cx=\"360.235109827878\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"240.0213884106002\" cx=\"235.5741404339375\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"420.1680042730895\" cx=\"294.2773032113521\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"365.79539988084474\" cx=\"214.24247017489313\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"115.1091812645929\" cx=\"345.93370960985584\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"292.04628430825034\" cx=\"293.2022560797987\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"59.54459390288081\" cx=\"244.7282142279002\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"288.97776243677265\" cx=\"216.13925267358516\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"216.15657509732424\" cx=\"360.3670115191315\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"395.98938259019167\" cx=\"200.35367067691712\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"111.69150559517915\" cx=\"286.36372916709814\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"300.85906769546347\" cx=\"156.274702729389\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"261.29871611233455\" cx=\"107.37947978980371\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"289.83849679040134\" cx=\"217.59938346334513\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"382.8991286663241\" cx=\"267.5270902684953\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"128.73998598815416\" cx=\"325.90466195117114\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"156.08525367639282\" cx=\"353.2231899888213\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.15818717077104\" cx=\"188.13790826407993\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"244.12808463317734\" cx=\"332.03527762936613\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"262.3301567908939\" cx=\"295.98474005758555\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"279.1749252187264\" cx=\"134.24327993341947\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"372.74542349973905\" cx=\"228.89718114341483\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"107.74588252825991\" cx=\"294.25472257360417\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"123.2560885655752\" cx=\"338.8163475324395\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"291.1704852079781\" cx=\"118.0162677583105\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"252.78941155178805\" cx=\"110.42489908665121\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"358.99877076460785\" cx=\"252.94236348153376\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"167.71623251228363\" cx=\"244.4233756183034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"197.70585495593954\" cx=\"172.54486534947895\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"275.88258857103085\" cx=\"287.9771074930776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"436.3325763148639\" cx=\"243.06985181026133\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"207.37121811975524\" cx=\"160.22451777358353\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"343.86598552795687\" cx=\"193.8173534601485\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"286.59417009476425\" cx=\"214.1274311654907\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"270.58568190410887\" cx=\"119.87509926483143\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"411.0709081309331\" cx=\"266.94530645510366\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"257.6613709443625\" cx=\"342.06642102785383\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"207.01553461671858\" cx=\"160.0236270146414\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"345.16844330614316\" cx=\"258.00962341433774\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"83.73304997545475\" cx=\"289.11315531098495\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"423.984033159182\" cx=\"276.6411933119043\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"245.39063072208876\" cx=\"78.16972719449849\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"248.0381418221255\" cx=\"361.49392269456325\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"394.3873550178831\" cx=\"244.6723779696442\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"181.3660796909384\" cx=\"201.22370649519476\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"173.15271608966444\" cx=\"249.94138024261935\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"169.32373767481963\" cx=\"141.93267933971038\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"173.37274270293165\" cx=\"247.54314207699136\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"47.175909477616536\" cx=\"235.0890777056585\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"269.663488109077\" cx=\"278.02058458653437\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"133.5746378817925\" cx=\"176.6259447725234\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.44053686849989\" cx=\"232.73422210957236\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"218.05443512097452\" cx=\"101.3564160737871\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"414.9230110966979\" cx=\"229.37110738684834\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"374.2703912119376\" cx=\"234.31691672770685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"414.98957727843845\" cx=\"232.21548895831575\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"373.8804878786788\" cx=\"161.54623227568868\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"414.9247691998802\" cx=\"231.3616805697627\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"58.50762069336956\" cx=\"116.49165166674842\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"239.0481327062669\" cx=\"59.86611496337622\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"167.3535303316988\" cx=\"316.11769710841776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"278.1401606263379\" cx=\"290.38143995856495\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"407.2249805025962\" cx=\"219.12821488199043\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"280.8449364434662\" cx=\"181.82195829307008\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"270.148180674225\" cx=\"335.14716421465016\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"157.2157359989137\" cx=\"229.95610900979486\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"351.9360966843065\" cx=\"177.23577033167294\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"156.53732243936392\" cx=\"231.82052764461255\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"345.8902765202237\" cx=\"246.42326331428885\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"245.3144979867038\" cx=\"77.53368941571506\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"206.9849642241179\" cx=\"273.4504393166759\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"231.2064557250777\" cx=\"299.43309462753075\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"236.1006610462053\" cx=\"398.47022795550095\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.07523496674554\" cx=\"211.14881154846265\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"350.92379186007213\" cx=\"190.3512695184241\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"246.89510829110463\" cx=\"93.78284819684878\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"250.66222894429407\" cx=\"174.79606153371387\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"130.54059131490564\" cx=\"326.10861290846503\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"254.3559638983209\" cx=\"330.5229462837905\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"81.41225488148977\" cx=\"235.69179736885985\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"180.8481479874997\" cx=\"281.4789823209086\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"205.9186526677517\" cx=\"125.03006657014338\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"284.3110423614804\" cx=\"180.4281670545623\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"179.1437768336904\" cx=\"188.71787353949225\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"348.4015840702828\" cx=\"120.24490528108731\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"84.59290527749226\" cx=\"244.2050411793492\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"136.14662196793128\" cx=\"163.08808876658236\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"368.12020564769443\" cx=\"220.0432165928126\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"305.2487601558742\" cx=\"213.6017308436151\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.63946791693087\" cx=\"193.6591488970658\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.7555707490009\" cx=\"292.3210453181685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"95.20887071143349\" cx=\"259.7447860971637\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"77.38737432548263\" cx=\"137.12598128667088\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"164.22500769505208\" cx=\"217.64181006428157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"142.44394428631722\" cx=\"357.5569802621067\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"174.24452563624672\" cx=\"239.5499314526508\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"290.66486572088814\" cx=\"263.07041132980186\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"157.68000709678455\" cx=\"330.5061234339647\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"361.0679263524585\" cx=\"177.18838945090945\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"158.78339814808032\" cx=\"330.37950704040304\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"56.40330304187249\" cx=\"287.4100807582726\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"285.4673413304191\" cx=\"291.3493252070835\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"213.7564662000288\" cx=\"354.823800090439\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"253.43019620916374\" cx=\"59.455949490941215\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"276.64664098481313\" cx=\"240.97041014805896\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"98.35465572370163\" cx=\"243.69036334031588\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"159.29941791430826\" cx=\"305.31864720432776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"155.51444152567345\" cx=\"227.84934855633702\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"264.18194214950444\" cx=\"214.7490442570704\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"95.21908968618071\" cx=\"237.04834016971034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"206.4248462854122\" cx=\"246.43129702172118\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"256.33235481997826\" cx=\"264.5884482696114\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"196.21893094838467\" cx=\"193.123452110377\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"238.6670349976189\" cx=\"56.41136529310532\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"309.92182039076766\" cx=\"173.2882298334705\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.09683765959824\" cx=\"209.82925072275583\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"220.06528898555965\" cx=\"195.30543122291678\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"323.181582931773\" cx=\"132.64186220315224\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"236.44873388538787\" cx=\"383.72064328372613\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"96.36121944228442\" cx=\"263.00046079943536\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"261.2955789969686\" cx=\"229.11426224709263\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"253.1288326003883\" cx=\"262.06375166500453\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"210.70295550798826\" cx=\"401.54738101478927\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"242.42751400398168\" cx=\"37.55574162716959\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"256.90507616087217\" cx=\"197.70939558555034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"304.57497809939537\" cx=\"222.32114968059986\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"280.4453580486322\" cx=\"343.6654598247525\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"416.1352671934863\" cx=\"226.17364577300154\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"115.49696388588801\" cx=\"101.96507139550592\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"321.7842040639588\" cx=\"166.67132281504612\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"218.00837556463395\" cx=\"334.384125457234\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"137.9750273012532\" cx=\"168.2698781335696\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"99.20772035219741\" cx=\"298.8236261830901\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"128.91874112921641\" cx=\"325.2200675601211\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"163.53286994253534\" cx=\"397.8957237880987\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"314.0758940603131\" cx=\"168.53523084450597\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"264.41053951578544\" cx=\"141.52103596178773\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"359.1118827281003\" cx=\"204.43598351922543\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"200.82181539594137\" cx=\"411.89880686051595\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"155.54751034771837\" cx=\"341.29888811917783\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"116.25201426196953\" cx=\"253.36898095390453\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"136.6617022477712\" cx=\"164.6984014001376\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"362.30441130872833\" cx=\"295.23423877348824\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"209.22631777756806\" cx=\"130.08127282326387\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"275.2750348108372\" cx=\"332.2551504086049\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"86.39730151423062\" cx=\"107.0006854710282\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"206.1052451031564\" cx=\"365.03772029101856\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"245.48613693043202\" cx=\"36.139325798334355\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"30.457732720019692\" cx=\"217.43536342457966\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"103.38231438232391\" cx=\"132.07264333344185\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"95.23528621174783\" cx=\"145.6793675374778\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"238.56379382203252\" cx=\"58.46097297119761\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"315.64197391661565\" cx=\"296.6204976386743\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"108.1631683185833\" cx=\"134.2978360727958\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"99.35072006978929\" cx=\"158.45234976580608\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"412.6523988604432\" cx=\"227.62190288499224\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"219.1560969129683\" cx=\"164.11630991868915\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"247.8234884117093\" cx=\"77.33980359913996\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"338.99519362577695\" cx=\"350.2682031244143\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"137.89746198647828\" cx=\"171.71268369034564\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"231.63429451258398\" cx=\"354.2305501478553\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"418.9138613679823\" cx=\"232.22285032863266\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"411.115069485244\" cx=\"323.4673925213775\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"311.55944405844576\" cx=\"173.49572446749124\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"207.16280460211811\" cx=\"287.8072967019553\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"358.47887767730634\" cx=\"211.7278332169326\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"246.7985115093811\" cx=\"309.3134532077724\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"182.91974294351584\" cx=\"142.97519057424594\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"76.3081187344366\" cx=\"151.1896584840813\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"138.83720659593484\" cx=\"171.09257872165196\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"265.2137344487003\" cx=\"294.57082952578514\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"96.90389095394183\" cx=\"263.60697343290076\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"225.94296889992287\" cx=\"183.03974966784662\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"183.77034073348398\" cx=\"113.05652682325017\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"294.6156257455432\" cx=\"189.55138201712097\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"93.0886642024262\" cx=\"258.0926113786157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"261.7357448519881\" cx=\"130.0454404827792\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"186.17804381241618\" cx=\"147.064566046682\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"340.3580532364208\" cx=\"250.93797476669795\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"187.0593754436402\" cx=\"148.014507654596\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"128.61562216429488\" cx=\"275.8577605575732\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"344.5461407084716\" cx=\"266.44102477465395\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"288.4238500528933\" cx=\"188.19050576662968\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"346.31119938650556\" cx=\"270.6062431701535\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"322.83987360199956\" cx=\"334.42442997268864\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"115.58369331350077\" cx=\"110.05118129081465\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"91.06698838864301\" cx=\"288.4250831720773\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"255.78646103483197\" cx=\"31.802810465116284\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"206.35049775005365\" cx=\"268.47736426779215\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"172.65782103198654\" cx=\"84.48722924097396\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"420.04658527206055\" cx=\"278.82467505325775\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"135.9462531458714\" cx=\"370.61273141102123\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"368.2101655899047\" cx=\"205.3257567927608\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"405.5768356861865\" cx=\"181.5026675259074\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"320.7634218859422\" cx=\"237.14732412591113\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.1698915603928\" cx=\"243.16097924286606\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"41.87010790740649\" cx=\"207.90852574310864\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"110.53996998705003\" cx=\"263.8688648781969\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"283.7077767248299\" cx=\"261.13357498271046\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"315.2557516118949\" cx=\"187.50974349110982\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"56.788778152740804\" cx=\"273.0196930488629\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"227.06989449729483\" cx=\"275.58199108528163\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"192.45058237000381\" cx=\"420.1231695948243\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"354.0823011441223\" cx=\"167.33912182663263\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"284.38515739876004\" cx=\"183.6092816996864\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"124.38153831773667\" cx=\"99.11929570315561\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"30.79909042915669\" cx=\"223.73807027734097\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.1027723655224\" cx=\"28.69956056171538\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"329.64296374743145\" cx=\"258.2194173176767\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"174.53944195100826\" cx=\"81.99485426455954\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"202.12539121787017\" cx=\"382.44831499882685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"187.62063889645063\" cx=\"338.2827961810404\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"181.57277768445465\" cx=\"241.2386458735107\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"432.8011843339888\" cx=\"207.6660009031802\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"224.60971478540662\" cx=\"361.1834966132902\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"151.73996980355295\" cx=\"222.78488819682312\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"269.4507081773644\" cx=\"319.34144300867683\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"121.35326052691677\" cx=\"260.86396711266565\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"214.8450891845931\" cx=\"335.1352091130104\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"309.75035038976716\" cx=\"197.3758641826109\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"199.00075014340564\" cx=\"210.88339977624747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"233.85673832712814\" cx=\"255.1695945217647\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"419.33349862131206\" cx=\"321.509393007229\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.2596736769704\" cx=\"165.53973618396387\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"169.61071505489852\" cx=\"240.02783059722088\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"121.75808576093549\" cx=\"108.05865702542329\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"163.3532467380268\" cx=\"157.17114305983606\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"255.54347743985443\" cx=\"63.705691443966955\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"385.2934344495998\" cx=\"298.7117668681151\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"177.97567110306792\" cx=\"80.53982609458262\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"29.66759719730601\" cx=\"215.3290665334844\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"129.63968430356095\" cx=\"318.4727202737135\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"244.63817217468306\" cx=\"125.65631391183028\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"338.5091879773147\" cx=\"139.3614973881485\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"256.9174433179453\" cx=\"164.02169649711817\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"235.54604370415535\" cx=\"253.13364785480627\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"96.76166040649223\" cx=\"198.9942366204426\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"372.9967443496515\" cx=\"147.02502520729712\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"81.9743534333118\" cx=\"255.01966677881998\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"238.08898028589923\" cx=\"264.14398330290385\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"224.15317075704976\" cx=\"88.63675931260752\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"377.05946807665805\" cx=\"162.1651395365894\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"415.0241459822608\" cx=\"321.4441893554547\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"403.8783431898931\" cx=\"179.150020546944\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"347.69346406102426\" cx=\"308.3211138428023\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"275.8402127902645\" cx=\"50.967080132853\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"253.31221100341278\" cx=\"308.8507094620412\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"372.88377523204264\" cx=\"154.432880871157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"32.63567094227637\" cx=\"215.9836406259373\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"149.07959707992308\" cx=\"237.7904492581483\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"188.01509132169366\" cx=\"267.84690022550393\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"134.32476556896353\" cx=\"323.05687542830606\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"175.44535406235008\" cx=\"358.84894436192354\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"120.7273098651419\" cx=\"120.2688814132362\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"242.5476391509499\" cx=\"148.22119465996735\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"265.70308873431765\" cx=\"12.691701442354942\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"223.1789776266056\" cx=\"364.81541913175926\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"238.22367433947278\" cx=\"258.973069452321\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"173.74575725749526\" cx=\"340.3968822933442\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"304.60410767149745\" cx=\"52.34009278937474\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"155.68180745455774\" cx=\"111.02104989948577\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"116.63094043848372\" cx=\"110.2414739840109\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"308.1666400549894\" cx=\"205.63068056048047\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"162.51042306056797\" cx=\"217.19212229495622\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"182.2657230656208\" cx=\"282.97476002620823\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"225.56246970179188\" cx=\"42.613408909485095\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"277.8788570467933\" cx=\"295.79991946054423\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"157.4227471545593\" cx=\"242.6215615956141\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"159.88796493087932\" cx=\"361.91339512571966\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"432.49309872757715\" cx=\"194.92401897862138\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"33.81296276202645\" cx=\"237.73560880052293\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"109.46212087854985\" cx=\"103.1225955425998\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"186.63217559959025\" cx=\"295.05243991629163\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"322.30921213270636\" cx=\"155.4984836921778\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"232.1286808534914\" cx=\"173.10641998812895\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"81.55123293805208\" cx=\"261.81108202030686\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"22.07896457372419\" cx=\"219.90711159275935\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"108.81099637683316\" cx=\"133.86340328237233\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"265.1749215739144\" cx=\"69.27150548669708\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"253.01816961968808\" cx=\"25.194628033734165\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"386.82591805290275\" cx=\"286.5915738454542\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"334.54568719866023\" cx=\"153.53956666793098\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"328.8187429992706\" cx=\"225.47751648832613\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"109.83770665901763\" cx=\"105.04244421769206\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"84.9285711275765\" cx=\"177.61122425440206\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"115.8089283074456\" cx=\"263.2534655825522\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"25.00101996789735\" cx=\"232.48070637771818\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"236.42626038205262\" cx=\"249.2551348827996\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"99.52646445915184\" cx=\"300.15853744720755\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"372.4888722928592\" cx=\"167.11005197012136\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"409.12651194015774\" cx=\"283.7227450251258\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"151.01282931549073\" cx=\"252.08093138070458\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"176.21845796048504\" cx=\"133.54457676433125\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.6953557150065\" cx=\"179.15673979754393\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"247.6485434098874\" cx=\"95.55264276533012\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"339.1097780006846\" cx=\"146.01207757658673\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"316.6914406468663\" cx=\"272.7888595950968\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"119.99351056127665\" cx=\"262.45769039447396\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"167.702524801534\" cx=\"289.22731664231435\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"119.74706844769509\" cx=\"115.75412738176564\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"342.5785375556896\" cx=\"351.90837054763426\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"225.7541111897733\" cx=\"264.14095057491437\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"49.65955986698869\" cx=\"277.3371439506977\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"276.4272681661668\" cx=\"46.30099736996436\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"349.8198678837492\" cx=\"359.09599082347404\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"335.36955632618464\" cx=\"148.4054603556917\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"194.5779091968995\" cx=\"272.6604411457734\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"336.88165692071766\" cx=\"157.50764950300436\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"205.87998263884936\" cx=\"417.86857807381847\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"275.92034108983495\" cx=\"25.442015127776216\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"265.741179138577\" cx=\"124.90341721214709\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"125.28619228648866\" cx=\"314.9122097088812\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"69.68659669515864\" cx=\"148.79940732626983\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"216.94869260667235\" cx=\"133.57857408461933\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"67.88114559651089\" cx=\"165.31101794808907\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"137.016102884892\" cx=\"320.80244872947367\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"278.8772783499598\" cx=\"373.98407007343593\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"305.42055430714896\" cx=\"23.80394644023012\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"70.34923677271954\" cx=\"215.96718793924248\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"405.0998622928234\" cx=\"179.70082328581964\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"17.73510915971994\" cx=\"231.75733138955778\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"177.27937983178293\" cx=\"82.04288344587151\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"47.62095132193079\" cx=\"284.47974579692516\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.8259827814528\" cx=\"179.89308560398734\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"262.2069000226322\" cx=\"299.324636143399\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"249.1931895160649\" cx=\"277.3554666823009\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"256.1584811622831\" cx=\"154.4166623693001\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"265.31062241626336\" cx=\"11.797288424639971\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"410.95981798610035\" cx=\"295.6720833828999\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"321.14951233292436\" cx=\"151.91105766643875\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"261.3289225226357\" cx=\"144.3840850179043\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"171.25095390106029\" cx=\"78.77150393751647\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"184.9338506725064\" cx=\"202.77095679171106\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"134.99370185354613\" cx=\"325.7423780392982\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"328.07647183569554\" cx=\"273.55676060662665\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"103.75982308814734\" cx=\"289.10494167268007\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"276.8117323677053\" cx=\"141.50571299373934\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"357.0237506140254\" cx=\"175.18807459079144\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"184.75819418830298\" cx=\"291.3903109875213\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"118.91245291446874\" cx=\"265.36838129979515\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"154.10570641011594\" cx=\"150.559823513088\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"122.39982638691656\" cx=\"340.5032805003092\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"346.80183104396633\" cx=\"317.7678088027628\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"176.2768324802105\" cx=\"80.31259125826791\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"45.2424355028613\" cx=\"253.8507726488017\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"176.3402011117882\" cx=\"81.50883762795236\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"266.53524292308873\" cx=\"209.40443667966503\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"425.32746572966124\" cx=\"182.9600746292529\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"194.1119514187881\" cx=\"347.225344065326\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"101.65596693873563\" cx=\"254.78043014124972\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"403.00865349817946\" cx=\"284.2875521546631\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"374.47772651785743\" cx=\"153.41463146053744\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"308.16446440230123\" cx=\"144.47450646219997\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"111.40806639775467\" cx=\"102.84006836120115\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"217.3059432938739\" cx=\"100.67542579426076\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"216.51346180222632\" cx=\"132.3829924977007\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"370.5824511308219\" cx=\"235.75460629180725\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"154.8799750516092\" cx=\"239.4079811028959\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"385.73044395999983\" cx=\"305.7857697257975\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"155.3765293191654\" cx=\"254.71231188404352\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"97.19824137924157\" cx=\"191.30175503951014\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"265.14078140774274\" cx=\"36.8955079533395\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"365.95544221116023\" cx=\"277.509833635781\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"202.342819134871\" cx=\"367.95758904435877\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"45.45753942721802\" cx=\"284.808945123742\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"133.175757234159\" cx=\"372.68361213761955\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"165.4138370669361\" cx=\"103.34039156245444\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"352.6193285453903\" cx=\"168.58458959134958\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"245.1142981073716\" cx=\"202.20397538300375\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"146.45666646000416\" cx=\"250.1776281047797\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"230.42901498642908\" cx=\"357.488941668951\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"341.47517397475605\" cx=\"138.80015152425142\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"61.11971150835501\" cx=\"143.07118300800056\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"373.9577675016866\" cx=\"163.53811922867646\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"168.79197739103748\" cx=\"295.66727606951076\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"231.00405658571478\" cx=\"250.28353733929708\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"165.8424681168579\" cx=\"350.4143344632996\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"178.64420632036203\" cx=\"81.17218284482807\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"63.31995566473736\" cx=\"170.32219438937713\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"286.86603328154763\" cx=\"31.543819890070928\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"220.3011762992158\" cx=\"280.37439356181983\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"140.03778229470575\" cx=\"324.69163668424045\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"118.4878160552143\" cx=\"204.3972049823923\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"281.32999711146806\" cx=\"25.149950236613485\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"213.88109648640162\" cx=\"199.67872113004378\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"142.0897029772973\" cx=\"332.5416662865984\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"338.98801836716416\" cx=\"313.09580342977864\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"117.80950688304098\" cx=\"154.1810820369418\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"93.43424135920075\" cx=\"176.0169707946028\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"292.4804753594862\" cx=\"92.40395688281116\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"293.99296053909023\" cx=\"261.96760265018526\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"208.6785408990914\" cx=\"183.19829211638466\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"373.2301984759737\" cx=\"152.57429110382367\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"133.296472993915\" cx=\"355.26732557075854\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"331.66091458009714\" cx=\"219.669603527732\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"405.1203661711872\" cx=\"253.44662318569368\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"225.92521686509485\" cx=\"209.93061361232517\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"183.05265554409917\" cx=\"255.9215379998787\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"273.3814890075742\" cx=\"367.01124605389606\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.33042466856227\" cx=\"281.2626806887589\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"243.37066356483592\" cx=\"202.98831328577012\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"311.41184580221767\" cx=\"185.21986354279142\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.64980776127186\" cx=\"339.1357179636526\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"250.43560669705693\" cx=\"272.77932737940523\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"355.6463097351132\" cx=\"325.5373062912256\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"346.5732336776853\" cx=\"217.84454751832425\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"175.04758321735045\" cx=\"114.12276146260214\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"115.49802973594228\" cx=\"135.39887566108524\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"81.23949926753716\" cx=\"157.70357911452888\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"273.21788102424205\" cx=\"59.97093087747711\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"390.00183255845786\" cx=\"294.7336573508301\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"188.63088893759064\" cx=\"152.2166819283951\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"413.8799834193525\" cx=\"275.12897734185003\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"143.8543605880428\" cx=\"372.9422620801733\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"338.82814085902197\" cx=\"312.4290098334496\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"406.8090242778045\" cx=\"254.52018142361453\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"178.10141393911084\" cx=\"342.8713685698786\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"173.00702427657464\" cx=\"233.6382270910168\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"281.1147942938073\" cx=\"209.3249209691722\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"84.1131518834721\" cx=\"254.73744726547827\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"176.98721055324378\" cx=\"242.02064879548803\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"294.9971066657442\" cx=\"178.80527848918106\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"276.11287536458866\" cx=\"114.39877267408133\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"259.13387301174987\" cx=\"276.09481879541914\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"110.99014329502768\" cx=\"237.21692303564117\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"356.067232601395\" cx=\"220.40832826754396\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"239.7243108650907\" cx=\"360.1351286975285\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"92.57504534585662\" cx=\"143.55423833956002\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"412.4244278184209\" cx=\"302.24814746677004\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"216.7953035980875\" cx=\"64.78933130482389\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"171.6279461640739\" cx=\"186.72488777201553\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"188.0925852135268\" cx=\"152.28448427643573\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"197.84465445514738\" cx=\"298.569481379941\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"125.12397430348506\" cx=\"348.4901674472658\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"285.5297045467394\" cx=\"260.3347121259183\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"417.3378756990618\" cx=\"253.36625589397195\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"272.14671820190716\" cx=\"146.20138683081538\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"301.55306793853896\" cx=\"204.21538552242396\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"302.92369067354724\" cx=\"104.52359500415508\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"243.6227604524812\" cx=\"294.40542498076354\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.4724272947861\" cx=\"80.61788587587759\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"354.27187960790076\" cx=\"199.2818210955266\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"197.8223183036233\" cx=\"213.78241852465982\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"121.72396757105359\" cx=\"346.9389160924916\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"233.09574473817952\" cx=\"218.27303091504908\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"401.92342035631356\" cx=\"251.62653587805315\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"80.07685464492477\" cx=\"114.65818079863249\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"217.46834258126816\" cx=\"49.215163276106864\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"276.0972447284833\" cx=\"327.7472639676903\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"399.56270533196505\" cx=\"214.06988487718627\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"206.77685974805578\" cx=\"339.9674326266282\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"83.32526893046077\" cx=\"260.9381453317784\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"186.97409645115283\" cx=\"402.002520964257\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"97.59092471315739\" cx=\"290.6597696686158\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"405.75688742834575\" cx=\"319.6886024583155\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"296.7357388553189\" cx=\"198.5618064194252\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"109.85670516153156\" cx=\"159.89863137245095\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"201.15127569119926\" cx=\"356.41387256110784\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"244.21252577961687\" cx=\"168.0806732667174\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"156.468553134573\" cx=\"350.9678292976732\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"93.72293288988243\" cx=\"109.74297481480926\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"171.81221735387072\" cx=\"116.8947627501644\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"271.5099771818508\" cx=\"64.52179195305452\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"271.17161099515994\" cx=\"63.046512632046266\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"90.46525559820458\" cx=\"181.91283574537863\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"376.2860674986111\" cx=\"222.8020293594712\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"352.7760854203838\" cx=\"303.33519365254267\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"432.75597910591335\" cx=\"254.54020731767565\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"108.15808080749947\" cx=\"294.5789827292931\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"311.4962951897659\" cx=\"181.70597292968904\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"15.076923076923073\" cx=\"229.7624117085805\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"144.22871569628293\" cx=\"350.12717028475765\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"163.30841510687765\" cx=\"253.73510594162244\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"180.34381960743417\" cx=\"254.88054312933792\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"403.3168379978951\" cx=\"283.667688925157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"406.04366702181665\" cx=\"235.12143229828567\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"52.52030141267848\" cx=\"277.6010187561464\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"371.08996057883286\" cx=\"229.15971367828945\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"251.20953195902237\" cx=\"158.89517200485264\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"277.94906030449226\" cx=\"72.02295894331597\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"212.79937817738224\" cx=\"372.1477752520834\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"219.60661772102807\" cx=\"81.65067260218595\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"277.70483230210596\" cx=\"135.04752423417125\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"95.20262944513625\" cx=\"140.34044220449834\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"207.74469829695855\" cx=\"261.58763259990656\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"273.6533933999009\" cx=\"66.64409719773568\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"368.5974537446798\" cx=\"253.06682619869702\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"400.2338941862499\" cx=\"241.82673825558695\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"71.66752846769158\" cx=\"267.5254255645445\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"86.60399950774688\" cx=\"260.015215331039\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"52.58636213975411\" cx=\"253.66528177492216\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"106.70570078044094\" cx=\"158.98799435880665\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"261.6050683388898\" cx=\"143.3125156342085\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"201.75360733553416\" cx=\"178.7158240016357\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"126.33424154604852\" cx=\"165.04401701541929\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"257.8892595752981\" cx=\"281.07360218557295\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"181.38940202846635\" cx=\"175.56094080539907\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"173.68010309178055\" cx=\"107.89242836953503\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"270.98231547611243\" cx=\"151.9432694131823\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"217.53142826811495\" cx=\"67.28525545203762\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"165.20791923170702\" cx=\"357.55047528033214\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"302.13989531043484\" cx=\"213.74588294290226\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"350.44619214245034\" cx=\"287.8122029086485\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"205.8590584639435\" cx=\"256.0309854170505\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"199.12602873032696\" cx=\"327.32015477583565\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"81.01351707973984\" cx=\"143.11706400698662\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"146.9057629297826\" cx=\"103.74979885289207\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"63.621657158968176\" cx=\"135.83295683087223\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"74.0883706208754\" cx=\"253.20863919664086\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"198.0800644712599\" cx=\"188.86571628194417\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"347.5298835480544\" cx=\"186.4533652177237\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"66.72464334689172\" cx=\"129.71987273784845\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"274.59019868059954\" cx=\"199.2431071140447\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"84.70720396063278\" cx=\"252.96127682592476\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"355.3636836604106\" cx=\"316.8267675922092\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"351.0269375761498\" cx=\"246.8976819639652\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"250.15648996112836\" cx=\"75.42014172251082\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"183.76320393337824\" cx=\"179.0571597344829\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.307293701157\" cx=\"242.07215847169377\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"150.99475931121995\" cx=\"359.612851182786\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.00837689651536\" cx=\"265.51182329021884\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"291.80857227578343\" cx=\"201.92820316367593\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"347.0296372638153\" cx=\"322.58723112758423\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"107.92147308359401\" cx=\"284.53010995902616\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"80.18917546198517\" cx=\"174.36921605733664\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.395443195225\" cx=\"253.22151730245133\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"320.26276354626975\" cx=\"308.18940444408435\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"251.17692189202657\" cx=\"272.06607041241085\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"281.07229764344714\" cx=\"202.94660228776962\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"312.03063768759705\" cx=\"182.9532976908923\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"352.048010940006\" cx=\"304.3527782803965\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"252.8740752081616\" cx=\"278.9104979589171\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"122.0221528589198\" cx=\"277.4280873318756\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"360.036249428784\" cx=\"243.02894706739204\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"182.82353074686344\" cx=\"309.4922358191969\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"203.00406646506718\" cx=\"207.81596298407766\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"203.17620399586974\" cx=\"126.33852387543935\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"200.97852831835533\" cx=\"206.10373255963614\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"216.2651242336513\" cx=\"364.88525978067685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.00255937644636\" cx=\"243.63134876115063\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"299.8420984037235\" cx=\"11.796387396759034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"249.7052384414334\" cx=\"250.26408282877023\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"248.29658848399882\" cx=\"324.22384938000494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"102.46738649810025\" cx=\"252.79549318990453\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"398.1236209602228\" cx=\"262.62825112648494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"407.898674653916\" cx=\"210.69794873439318\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"417.2730676205036\" cx=\"299.7389606286747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"402.0944837959532\" cx=\"207.29624982764875\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"154.05118323517428\" cx=\"138.80071741371322\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"409.0013679580113\" cx=\"206.16343115082077\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"53.19892924105358\" cx=\"230.731315764158\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"86.40757542970229\" cx=\"147.3352919604693\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"279.52903467000766\" cx=\"188.98837144927313\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"76.4586123668431\" cx=\"138.32172220169042\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"256.22508305549457\" cx=\"230.62610118642542\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"244.11620782206992\" cx=\"293.02918730371675\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"152.48022464254078\" cx=\"136.2665710045014\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"88.84302082744425\" cx=\"132.36546640660197\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"224.57187058426862\" cx=\"246.25593172335732\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"249.76800409856028\" cx=\"284.4796853621283\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"146.09578831147095\" cx=\"390.48738464586364\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"102.07276925068389\" cx=\"275.89230179103333\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"268.70524221066273\" cx=\"304.3851603433858\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"89.17037963999203\" cx=\"249.33388142315013\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"16.541466980374288\" cx=\"227.88658051177694\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"238.381181155355\" cx=\"276.80166417987044\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"138.58970412637146\" cx=\"270.3584165503159\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"173.24899421518617\" cx=\"231.6286354895758\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"237.39546420795793\" cx=\"152.00645674036934\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"220.81669335781504\" cx=\"62.81448696455972\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"278.9086879621264\" cx=\"312.4725448635017\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"302.2686598863223\" cx=\"198.78615412067023\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"275.79683159424076\" cx=\"364.89596223379925\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"141.23555601652987\" cx=\"336.27367981686587\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"50.15696022170138\" cx=\"276.0392792170752\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"258.5463231693276\" cx=\"282.94019681645835\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"351.286444594005\" cx=\"304.2995956591313\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"180.07541768629096\" cx=\"230.7871681612518\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"106.42407462692321\" cx=\"186.19245721139512\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"91.7786685568457\" cx=\"116.16573230118118\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"59.62830159064898\" cx=\"146.8197446844716\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"144.87198367440362\" cx=\"337.12926073054143\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"162.2102599066217\" cx=\"142.00697018730824\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"114.18185875293389\" cx=\"274.66094829842694\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"36.890104833169914\" cx=\"258.4604010702843\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"315.2253474149856\" cx=\"179.20206589521308\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"236.54633264857353\" cx=\"226.57246139313693\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"146.09938692892226\" cx=\"337.3551000724551\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"201.53717659268204\" cx=\"246.80399704063737\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"268.29619752900646\" cx=\"70.65536344222475\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"378.1386797151245\" cx=\"279.09145622302975\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"209.63622228156194\" cx=\"366.152632412231\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"169.19251724854928\" cx=\"232.0564843209333\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"360.0811140243678\" cx=\"219.0710792756013\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"250.20719612923904\" cx=\"154.50047993851715\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"174.5703900610895\" cx=\"245.0939711127643\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"374.7690991558921\" cx=\"276.01826438997404\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.2945951578945\" cx=\"15.915842915830048\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"270.5912446524591\" cx=\"123.63181414481048\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"193.20680847758854\" cx=\"242.5728538963552\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.56295955723294\" cx=\"194.44737522960494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"93.19061221071092\" cx=\"126.08629100950102\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"348.97900009608077\" cx=\"322.582088675776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"307.73861884710897\" cx=\"139.0436982616546\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"237.34000566718257\" cx=\"124.10964461347498\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"179.13690374906201\" cx=\"181.94653089168227\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"179.9475706205017\" cx=\"386.9547290283262\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"302.561675252018\" cx=\"206.70735805803182\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.76735633953524\" cx=\"337.34756220506097\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"434.65560959440893\" cx=\"241.983650338127\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"80.90969009867902\" cx=\"106.85229057429561\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"159.013374526545\" cx=\"335.2579027388465\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"54.10512155009009\" cx=\"260.70167221264785\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"228.3190240612962\" cx=\"47.69051422011012\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"265.56846198313156\" cx=\"189.38398037676578\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"315.2236442525277\" cx=\"178.48671019254485\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"191.37149160113114\" cx=\"261.94721689437904\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"115.05246046067333\" cx=\"278.64138730242854\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"222.9347750343043\" cx=\"348.45236822884596\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"106.05158750331428\" cx=\"155.24565197234304\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"244.61289120032856\" cx=\"151.55689327443307\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"255.045500207535\" cx=\"105.15873175505756\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"396.53591094070526\" cx=\"312.9080709743417\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"210.2181187234386\" cx=\"158.91050596104594\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"384.0618611940956\" cx=\"302.14242503071574\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"188.85321756721217\" cx=\"364.46940244918915\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.0032636426225\" cx=\"231.4968189564452\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"434.8664501185485\" cx=\"254.45692816755817\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"301.36125888134796\" cx=\"138.75550119749295\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"183.93307241226114\" cx=\"291.47124416870486\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"289.225264906336\" cx=\"189.56907293039308\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"55.28265510902774\" cx=\"259.17557546856193\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"352.84149784691095\" cx=\"265.7275343095807\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"295.687491809151\" cx=\"238.64860689180034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"220.6482155660197\" cx=\"149.8162337721262\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"265.5858369872381\" cx=\"295.04928082463584\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"340.5293144626685\" cx=\"229.38215527977565\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"341.5568818201543\" cx=\"299.4602957802047\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"224.57131259253597\" cx=\"303.0773018919863\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"91.16649702876227\" cx=\"150.78102585785837\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"286.8538913814447\" cx=\"242.31439624633694\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"245.30119134324266\" cx=\"89.15513603591425\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"276.9643027594959\" cx=\"12.699656859254935\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"214.73918681766628\" cx=\"152.8656692359308\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"208.35261466593357\" cx=\"348.6045100829859\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"254.32391147967823\" cx=\"361.8135678293986\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"173.71740784368038\" cx=\"284.20922316381836\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"408.0614420441641\" cx=\"244.7647319539223\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"63.681938121831934\" cx=\"288.4282312755882\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"187.6093870360838\" cx=\"233.16558096646293\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"85.83909276569948\" cx=\"149.08317616804098\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"68.43711276348458\" cx=\"263.3669538900071\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"153.848166270196\" cx=\"357.57379212378765\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"306.6682856297132\" cx=\"223.0038891354408\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"199.63854053129896\" cx=\"356.1110063235187\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"244.56756510265942\" cx=\"246.55893531275754\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"207.17795862743884\" cx=\"183.95909753335206\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"314.60498422488706\" cx=\"79.97055228414776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"55.43466510542899\" cx=\"128.01950126877892\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"121.03716456288073\" cx=\"182.71409676479294\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"338.3735503167988\" cx=\"286.5256229998275\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"259.7962850853043\" cx=\"91.1104544427098\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"204.5269931293525\" cx=\"178.57521969962974\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"215.09486207959426\" cx=\"147.1623165836189\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"354.4772150714507\" cx=\"287.25582368624146\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"194.12354940571896\" cx=\"373.86869455209626\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"347.75737111170156\" cx=\"304.37400737632294\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"423.9140826288155\" cx=\"257.9030439029822\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"30.856866094985644\" cx=\"236.63368191953364\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"186.13327536310015\" cx=\"399.3454886366735\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"233.18947704788215\" cx=\"217.8692303255413\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"129.4671154880715\" cx=\"277.0494193767663\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"109.26202676011219\" cx=\"279.8477537535562\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"310.1197333624448\" cx=\"171.3684745576098\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"29.0320648731875\" cx=\"233.42616207548107\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"241.5301135843749\" cx=\"263.2039749779699\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"187.73712696746037\" cx=\"152.74470074884238\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"349.62341084127\" cx=\"184.44020521622986\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"173.25391690409668\" cx=\"130.67622592830548\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"110.46122894077192\" cx=\"154.9838264559162\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"82.68240751370097\" cx=\"299.30758254253055\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"280.3524532835916\" cx=\"198.97931746671884\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"199.20459121925063\" cx=\"210.5922881066539\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"259.4224491669102\" cx=\"282.4905729157251\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"106.3794297942372\" cx=\"294.63776381037945\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"345.29002712934545\" cx=\"235.575555157592\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"127.88337218885904\" cx=\"196.70628234451607\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"350.30936776228634\" cx=\"211.84241209776778\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"121.13459644361585\" cx=\"285.5375360469296\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"117.72853524335031\" cx=\"158.79970150798027\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"149.47701630428625\" cx=\"359.0811458397283\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"244.80768353885705\" cx=\"48.9199887399404\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"274.50430160496217\" cx=\"110.58710608150992\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"407.1931038942718\" cx=\"246.1752595106149\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"341.5248623659463\" cx=\"337.5110877773064\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"112.23995687104842\" cx=\"329.84740612412935\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"239.77471897977122\" cx=\"320.5184601248047\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"251.97771316824685\" cx=\"24.674031705159752\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"68.0102782752522\" cx=\"103.46404115689592\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"128.1696573158099\" cx=\"276.10314780924534\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"25.973207075140152\" cx=\"239.14879686179685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"294.2467866860375\" cx=\"179.45446083628855\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"189.1741428209272\" cx=\"168.45479212984245\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"144.53455422706466\" cx=\"354.5572496717097\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"410.4427048994559\" cx=\"276.97511754102356\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"158.62282838681017\" cx=\"95.76043957333532\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"191.19324466177\" cx=\"341.3070193463961\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"357.3067942382339\" cx=\"245.7364520650073\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"73.17362953511487\" cx=\"162.37505156248582\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"119.2983016222633\" cx=\"158.19696330228447\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"330.45111982776393\" cx=\"243.58983554975813\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"157.98038451955617\" cx=\"301.4524629308872\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"91.51696391001265\" cx=\"113.72537520267362\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"122.77464299724207\" cx=\"275.2017683076704\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"405.23392864862006\" cx=\"297.11473890173124\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"317.4093455991489\" cx=\"169.46127323728535\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"398.2764440793459\" cx=\"279.51678533541224\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"121.55961788794144\" cx=\"343.0790884608695\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"288.6716876608758\" cx=\"106.38692066193579\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"333.3654066035002\" cx=\"218.2629657743303\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"172.82551660521753\" cx=\"342.10700024693074\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"339.4422572887509\" cx=\"233.79693710876438\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"319.119793197082\" cx=\"300.26273253112214\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"144.44395147837832\" cx=\"358.55306658448416\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"235.95507018669664\" cx=\"120.57759334390651\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"261.4644667839201\" cx=\"298.47394495419934\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"307.6386541989768\" cx=\"170.99398759163097\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"272.0003039182909\" cx=\"105.75278383221823\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"277.4743504689764\" cx=\"249.10658889907478\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"217.9027877333546\" cx=\"175.35720961100296\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"295.63348507701915\" cx=\"339.346481570778\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"343.72009592825907\" cx=\"238.9210634384078\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.08395965627807\" cx=\"305.5766708226229\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"100.4898170979035\" cx=\"283.6205772539433\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"154.94590392094617\" cx=\"133.65272208633363\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"290.24380550279517\" cx=\"212.20945459558396\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"195.83235152895494\" cx=\"158.53833199956637\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.96770779638425\" cx=\"295.15647567210533\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"114.7290134277062\" cx=\"103.42719790708144\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"68.90055975048872\" cx=\"275.9898435532173\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"262.2726173701801\" cx=\"220.73823220915176\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"203.32311274600605\" cx=\"359.7899690902598\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"348.90987367658096\" cx=\"298.38125995205644\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"198.4259520431276\" cx=\"410.43487829317854\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"330.52747644660104\" cx=\"320.41955583265434\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"106.59893996469461\" cx=\"134.4375997817177\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"258.47116700531967\" cx=\"345.20842611828\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"176.68048747679848\" cx=\"263.69599388872297\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"262.2804848819209\" cx=\"341.471292112494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"420.3382545900073\" cx=\"225.94618902766695\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"310.59933292243653\" cx=\"256.31704803406734\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"115.43949588811596\" cx=\"164.71025211440093\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"173.46223564898415\" cx=\"233.12114422177078\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"131.75057286570197\" cx=\"338.7709445177561\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"169.6809073244526\" cx=\"147.34252765387902\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"395.21244382949027\" cx=\"260.9203198137314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"263.5069568911602\" cx=\"383.88004830163806\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"281.52982751442835\" cx=\"197.48989915027406\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"430.4279208481765\" cx=\"266.74208895648115\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"268.93263362804214\" cx=\"79.2370716364843\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"183.50055980015713\" cx=\"284.1138955128295\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"416.90498674299533\" cx=\"281.1004627057553\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"52.91103984494886\" cx=\"229.4524103877833\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"115.74486742273986\" cx=\"351.4314740712853\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"298.38581758522923\" cx=\"244.09054196256443\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"299.2119832350355\" cx=\"221.12040469572173\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.86395312125876\" cx=\"321.5097775923001\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"75.49934731799033\" cx=\"282.3248387263569\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"95.121416066258\" cx=\"262.45331985984416\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"216.30291383744438\" cx=\"153.90067556750685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"226.00725504159888\" cx=\"182.54236579535126\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"252.05606688241764\" cx=\"92.59124981245257\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"52.37112635765872\" cx=\"277.72951961655656\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"176.01562779396988\" cx=\"263.2938607502022\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"389.78736594650474\" cx=\"214.16040384126782\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.14576159421551\" cx=\"295.81579732990957\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"235.3706821829663\" cx=\"367.85698158975055\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"83.76014674075223\" cx=\"106.86505879865719\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"189.30984915734862\" cx=\"300.4257581427751\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"182.44002251393036\" cx=\"398.0825662037996\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"180.871585700549\" cx=\"167.39762820409675\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"103.20168026848553\" cx=\"134.4378085564706\"></circle></g></svg>''')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<svg style=\"width: 450px; height: 450px;\"><g><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"172.49447127005934\" cx=\"285.77277574679636\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"118.18281811751663\" cx=\"147.67415536071638\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"416.0208586288969\" cx=\"307.2821957316456\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"272.3185892701962\" cx=\"33.73707558630356\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"352.99402428612206\" cx=\"226.5130177612517\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"198.43359155086202\" cx=\"114.31040601288002\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"253.1997912930484\" cx=\"156.0557639424658\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"188.06692789520983\" cx=\"335.9971631507218\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"269.7777593218553\" cx=\"150.22628386903986\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"418.4463597555139\" cx=\"189.2038984172081\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"159.3034011168307\" cx=\"349.11717297095004\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.03153982808922\" cx=\"222.9087065623025\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"222.4201404610915\" cx=\"385.0987434513317\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"72.81556984574584\" cx=\"250.65347246625544\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"235.0389957582297\" cx=\"135.92590005442\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"336.197414150304\" cx=\"159.42299303869189\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"170.51663815438522\" cx=\"143.40726091351814\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"234.10141100600293\" cx=\"268.23960553570953\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"82.84146091097638\" cx=\"290.5573162056661\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"351.48686835678933\" cx=\"169.8724990657022\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"407.7698826076662\" cx=\"324.15660193328125\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"116.79483960765539\" cx=\"129.5309205983287\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"362.6806124253099\" cx=\"179.60940741441152\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"273.3250868598564\" cx=\"34.090410373370105\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"274.1545269768398\" cx=\"97.10927831110018\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"191.39653083629807\" cx=\"206.5222764925494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"389.73549091448143\" cx=\"245.3464704412162\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"190.71171393531398\" cx=\"360.81585526157755\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"310.9948292214441\" cx=\"129.75563914946372\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"353.58335146098017\" cx=\"127.1049579696264\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"241.19024339535233\" cx=\"401.7081485626674\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"227.74124645685544\" cx=\"260.8327525400708\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"59.47008329238516\" cx=\"279.35021055296\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"351.1619159479724\" cx=\"164.62659936735724\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"138.66131936068874\" cx=\"179.6315100678567\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"150.79109953976567\" cx=\"236.55647165919046\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"86.89114170999912\" cx=\"288.02135675254755\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"134.47880837216934\" cx=\"168.96211477939033\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"256.7960984868944\" cx=\"212.84760896577671\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"74.36711788043206\" cx=\"258.74806795645503\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"287.9548210882853\" cx=\"109.87684338399795\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"247.23870346124474\" cx=\"294.6195179957905\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"267.0771727349661\" cx=\"207.41781442159743\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"349.84199800755664\" cx=\"174.5336316693181\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"237.64156500228884\" cx=\"352.96532020455464\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.72752691007526\" cx=\"221.3809816841855\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"276.87876554560364\" cx=\"312.38513417090576\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"177.9372620426067\" cx=\"247.2639223272044\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"242.29247931791662\" cx=\"347.54207734176566\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"191.63097938973277\" cx=\"348.02383057815575\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"150.0318132338292\" cx=\"371.0827493086693\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"85.60305642532826\" cx=\"140.6974745023202\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"299.1083485465103\" cx=\"215.0794282432581\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"282.81000133477875\" cx=\"57.01371341965756\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"438.25875416141247\" cx=\"227.18661525123434\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"262.485018210894\" cx=\"274.88290333112224\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"69.15283656900661\" cx=\"165.59513291642426\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"363.9965416691307\" cx=\"180.56630451804057\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"392.3061344469437\" cx=\"298.541895642196\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"263.5753855634595\" cx=\"26.957258331747553\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"422.370116414103\" cx=\"322.4186729849794\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.6899935003004\" cx=\"181.60166247025307\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"94.59628163384424\" cx=\"277.9500352022714\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"119.6239682604981\" cx=\"133.66697920432776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"438.697400905401\" cx=\"273.6912609941465\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"161.34258104542286\" cx=\"220.88657628571426\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"92.76168997494955\" cx=\"264.6079467327178\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"220.54672150547074\" cx=\"74.15115383365792\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"50.39133735219427\" cx=\"149.27844649087217\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"117.91922350976257\" cx=\"192.81217444787498\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"234.91538771271107\" cx=\"183.01328472088028\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"342.665003267825\" cx=\"153.61535190323383\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"231.46084527198522\" cx=\"118.0928441400454\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"77.20457554710102\" cx=\"263.9351728385326\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"223.25219026248615\" cx=\"359.30931466835864\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"125.49510988527257\" cx=\"172.7596670998512\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"211.58422807793352\" cx=\"194.66548990566136\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"250.881127899192\" cx=\"51.91303853824458\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"243.8985532745807\" cx=\"48.926120124788746\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"350.95016340780694\" cx=\"131.2903093935997\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"100.37374932343577\" cx=\"195.5994574979423\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"123.70021839386364\" cx=\"172.53168506968402\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"156.95911886316446\" cx=\"137.58569779848509\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"79.8044914975489\" cx=\"249.22696402633918\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"277.80832414474764\" cx=\"212.90946672743215\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"238.26744973519442\" cx=\"297.8987430395966\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"234.91395444656206\" cx=\"392.86617516855534\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"372.8523271613689\" cx=\"187.28956579085036\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"70.67567258109659\" cx=\"169.9593054103292\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"436.1076929415555\" cx=\"199.4091682007234\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"78.02322530580292\" cx=\"241.87852675596923\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"347.89900829932714\" cx=\"152.50439002010916\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"401.51569425204406\" cx=\"285.680925843665\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.25662828748443\" cx=\"259.3708897439726\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"257.0993877680618\" cx=\"285.488078406782\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"124.51889012885532\" cx=\"180.513388359289\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"295.9589319523562\" cx=\"172.29189078376058\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"251.1887602446269\" cx=\"274.19454550044753\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"218.51481366851826\" cx=\"359.14093233607207\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"275.67646470808506\" cx=\"54.64405404536901\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"198.43382779597712\" cx=\"264.0594460101965\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"320.828125577124\" cx=\"201.21469896342157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"234.3704722158395\" cx=\"127.16782114653918\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"314.050593856705\" cx=\"179.60620162314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"247.8322596983673\" cx=\"163.53034511616715\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"242.07465994825407\" cx=\"56.67839919020979\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"66.63422190259608\" cx=\"276.842177470078\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"139.9857644167989\" cx=\"339.37745715122145\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"49.38749339952484\" cx=\"144.4584143240093\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"218.5409029582812\" cx=\"151.35799686378832\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"335.84279375028535\" cx=\"311.97163379649686\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"193.57054079675675\" cx=\"361.66762328897636\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"285.51331572863677\" cx=\"114.02863701347876\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"234.722904601507\" cx=\"34.553384870144015\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"81.12706856902786\" cx=\"117.27561185203423\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"422.9851009072782\" cx=\"204.57611258396489\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"355.69275662356114\" cx=\"250.46261937766982\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"181.21940993295343\" cx=\"201.81305839337892\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"100.19004951717324\" cx=\"173.65221213293495\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"116.30800984832639\" cx=\"123.3135535162312\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"291.69583390921724\" cx=\"191.46501414924202\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"63.263498576295135\" cx=\"140.5424098016397\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"195.3375114120015\" cx=\"179.69264535898563\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"344.1042854261753\" cx=\"142.54979003892166\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"223.94462744195113\" cx=\"105.4865520696907\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"243.69598545002478\" cx=\"297.0748519357824\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"80.49917300560756\" cx=\"300.4228682606692\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"423.8274520945067\" cx=\"182.66526544890402\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"258.87761299070957\" cx=\"112.77486770529778\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"104.62798542772133\" cx=\"262.66294069990107\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"216.2500443783086\" cx=\"346.94734399962186\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"419.8308220590105\" cx=\"183.1951659891636\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"224.53188506839527\" cx=\"222.29614272310855\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"333.8064267867849\" cx=\"217.71168711142914\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"246.03576256428636\" cx=\"175.88161882585402\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"147.5212034309707\" cx=\"328.0245278276868\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"232.00946858099792\" cx=\"368.3566015497309\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"241.25258463538285\" cx=\"285.11998104705646\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.4461115466249\" cx=\"303.39680418093815\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"407.47507068028114\" cx=\"198.46853355153075\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"269.8797045831038\" cx=\"177.40835013530733\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"352.26347747314406\" cx=\"129.5683901724019\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"403.13906080172796\" cx=\"233.04187368426082\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"219.4879732265838\" cx=\"160.8520507282225\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"276.7519293891442\" cx=\"343.3996346235858\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"165.9954011174299\" cx=\"229.20488937572543\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"246.97345239064862\" cx=\"274.18570553788396\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"72.57190773282133\" cx=\"269.46986570789943\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"277.29328781748734\" cx=\"171.24451180103898\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"209.97096100692113\" cx=\"370.74645713432636\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"371.0675557514032\" cx=\"260.8581873484538\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"81.46885481581555\" cx=\"254.54859951333498\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"230.47379274991476\" cx=\"95.37808509561563\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"354.297009495263\" cx=\"173.62445058487165\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"314.41151595781776\" cx=\"246.5410521069499\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"98.25804795383318\" cx=\"254.51497578997314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"90.70523668259112\" cx=\"117.47137664138543\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"145.63060519757425\" cx=\"326.4750235879501\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"290.4101055816252\" cx=\"265.895801266346\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"180.013713758664\" cx=\"202.0535202091044\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"277.22060123904333\" cx=\"331.21513348295923\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"187.5310937567099\" cx=\"207.33972716994023\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.79304662228685\" cx=\"264.94181876814883\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.6244821804693\" cx=\"182.62549660551272\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"412.4225378574999\" cx=\"307.5837433918479\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"89.9275836924719\" cx=\"262.0184585317701\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"405.8243546379672\" cx=\"216.57062457889782\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"365.3336450681536\" cx=\"194.08875789188275\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"298.41307917270007\" cx=\"153.04185864516137\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"125.27018255938465\" cx=\"183.34777483946132\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"329.84668395368266\" cx=\"279.1803722914755\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"180.605447337253\" cx=\"201.9323704176253\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"306.5498608981667\" cx=\"233.9872758148174\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"152.70167422057116\" cx=\"225.13144113346183\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"288.78924432897605\" cx=\"101.8158633760515\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"160.15833372995775\" cx=\"235.1148668817142\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"326.1068138998192\" cx=\"262.30613640608567\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"254.9665119279969\" cx=\"65.08628592046246\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"147.613943373838\" cx=\"106.40884201099033\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"192.54706652324225\" cx=\"336.0559277495908\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"184.99326082488767\" cx=\"174.22420001515752\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"192.48012949161168\" cx=\"329.0829938486019\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"169.49166949316574\" cx=\"399.92587146159167\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.6410941623745\" cx=\"208.99267929973917\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"242.37885025730236\" cx=\"149.41206233272842\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"320.67031933429354\" cx=\"181.9773279147713\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"32.880025308328925\" cx=\"252.74311270321633\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"208.17746500991313\" cx=\"176.96195674917166\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"289.59259309591937\" cx=\"316.5607555925794\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"214.06570006758133\" cx=\"163.47794265318916\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"200.11155544546563\" cx=\"174.35777739850664\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"166.0402437367239\" cx=\"228.08924465429044\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"108.81061179176203\" cx=\"177.8863728965074\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"348.44426202503354\" cx=\"151.98279926442223\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"412.09987098281994\" cx=\"279.42965484051103\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"360.0699390810152\" cx=\"168.89191152169136\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"289.80263148548204\" cx=\"253.1316644946537\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"232.13276638311316\" cx=\"269.71987347449766\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"165.8005813085392\" cx=\"382.15377777506393\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"209.92678729094723\" cx=\"120.91468765282636\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"247.15023653322135\" cx=\"151.29788621717034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"275.35153152852166\" cx=\"33.636314297666914\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"238.05355656705268\" cx=\"289.5788603617639\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"192.12629474395266\" cx=\"329.98436236203196\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"58.13434242332858\" cx=\"272.8375315828849\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"254.7667749242681\" cx=\"19.633308142263846\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"73.49527451232011\" cx=\"143.63407820032708\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"145.46627199667947\" cx=\"311.6572849474982\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"261.0224988731386\" cx=\"94.138600375791\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"58.43393419374062\" cx=\"147.2624955005764\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"90.40611740240932\" cx=\"178.416397053397\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"257.2907490583485\" cx=\"93.55558039609939\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"281.7188236065276\" cx=\"142.9487640857867\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"190.72339158629526\" cx=\"122.29919390890252\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"284.7288555827585\" cx=\"237.3162847093225\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"142.04743707797985\" cx=\"340.8581426395154\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"100.60761001111887\" cx=\"199.70373838892093\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"398.7327267958821\" cx=\"262.2049767971967\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"45.95166531475364\" cx=\"250.55898266131442\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.5455157993677\" cx=\"279.411211239314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"198.611206671892\" cx=\"213.57006987763413\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"61.696160577402715\" cx=\"229.43242329560883\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"422.01473783208706\" cx=\"314.50018174588746\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"324.5621883964134\" cx=\"180.32729588447677\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"306.8274763787997\" cx=\"148.75473502322157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"225.2889613836908\" cx=\"280.8561962448619\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"326.101462673258\" cx=\"284.4195307629308\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"340.19223114189344\" cx=\"209.73536526578377\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"247.33756242729743\" cx=\"362.9585325268838\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"57.89715232774399\" cx=\"154.77397486481664\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"322.19621005066284\" cx=\"149.85817002709695\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"236.56962682898018\" cx=\"90.82821295307828\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"111.02729421289906\" cx=\"202.36392156705148\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"178.80328169392723\" cx=\"103.26389209773379\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"107.0722872702442\" cx=\"188.62333154086303\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"142.6496258764312\" cx=\"335.14643899708744\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"183.5732189082389\" cx=\"255.64671076101138\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"411.5254437324319\" cx=\"253.56965194994893\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"58.48427088547938\" cx=\"244.2281410069431\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"154.41821474484559\" cx=\"254.08036718923145\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"239.8533171801658\" cx=\"222.66416059047341\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"45.894384115444716\" cx=\"216.38696735169674\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"129.25431907414156\" cx=\"358.0179768928005\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"313.60489821776986\" cx=\"188.29342622573714\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"193.3706582001082\" cx=\"392.2788038834875\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"234.1770008583545\" cx=\"277.8098759201335\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"55.640022545268735\" cx=\"157.70924899729187\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"339.72902589407687\" cx=\"209.91590735390872\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"248.31647153217637\" cx=\"159.82745566392924\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"55.03730082179025\" cx=\"145.79372116134272\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"242.49755381302543\" cx=\"402.7861075526165\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"258.79294109322734\" cx=\"92.87452418770371\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"213.68921737978698\" cx=\"174.88771914430959\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"157.57324078696578\" cx=\"97.17810805068797\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"145.03953640175106\" cx=\"373.76277982350643\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"145.0649904393876\" cx=\"330.5613498501793\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"123.87277622120823\" cx=\"281.4546985207028\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"417.18092103746034\" cx=\"219.90725993271536\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"285.73218858669054\" cx=\"175.80549845213207\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"149.17034267449296\" cx=\"251.80520860802872\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"69.28267248902085\" cx=\"104.54350552269484\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"80.33040608824983\" cx=\"245.95331134551012\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"128.57263654148716\" cx=\"244.0292281140811\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"314.7745752531115\" cx=\"186.96081423093784\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"344.5202416509671\" cx=\"330.16866651626344\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"241.33279328576273\" cx=\"271.1278696373113\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"179.68527810791707\" cx=\"385.8225325552026\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"341.2517300484282\" cx=\"220.48868113732556\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"226.92158304178747\" cx=\"156.69591128743792\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"226.16057846469394\" cx=\"68.49987399997731\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"221.45170580532846\" cx=\"96.68040002791837\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"403.9661934082846\" cx=\"220.3525229134455\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"438.6234726665846\" cx=\"227.2968000759421\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"153.92829731680263\" cx=\"253.44302182120614\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"118.60336738687218\" cx=\"278.979712283576\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"415.6618539590674\" cx=\"222.42905498031234\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"286.0424553398628\" cx=\"90.12658693744945\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"160.38234354574737\" cx=\"103.72537220680273\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"111.79728846603031\" cx=\"341.88560011555234\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"191.48937791357807\" cx=\"334.48869963214725\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"351.416005810397\" cx=\"205.41945819830596\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"137.89700048439292\" cx=\"337.98552290920003\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"329.50588663993506\" cx=\"327.42669582868416\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"65.39070453359702\" cx=\"144.8844576658096\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"203.1469535541739\" cx=\"410.252870661229\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"336.7330972018117\" cx=\"216.88977593397223\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"80.9380614887837\" cx=\"243.06554583098273\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"146.40517051897953\" cx=\"238.81286317568092\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"275.0226783282689\" cx=\"210.64874382157802\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"406.68891286601746\" cx=\"220.80194147322106\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"262.84414375031724\" cx=\"79.52170854170174\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"150.65607721536355\" cx=\"336.2913377657033\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"374.5566763388884\" cx=\"255.3347600746349\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"95.53047173605917\" cx=\"160.70594685969937\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"418.3506530135264\" cx=\"325.16184138035163\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"227.65826827889407\" cx=\"274.4733367125837\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"89.81030722206633\" cx=\"171.0324570868891\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"418.1257916165078\" cx=\"219.0246990027818\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"224.04484344389766\" cx=\"380.78953365816403\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"60.39720801743616\" cx=\"229.9038418383508\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"261.10243213313726\" cx=\"307.05596631058825\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"326.8461512287088\" cx=\"172.57662658228205\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"100.27842716651942\" cx=\"259.10365531322395\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"113.74675019159974\" cx=\"148.06833857640962\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"313.8793216423125\" cx=\"257.3646797441214\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"330.1378148525298\" cx=\"153.3001954255858\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"195.4402560607907\" cx=\"423.800176471775\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"313.4329777028288\" cx=\"162.5880127985891\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"169.02834337575538\" cx=\"104.02702974845398\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"222.51167170802097\" cx=\"54.65199847412411\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"286.46775698188304\" cx=\"114.88884393615272\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.48751118790247\" cx=\"243.2154598387463\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"282.5912713226085\" cx=\"326.5148446250296\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"343.1999171491904\" cx=\"212.7760363105209\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"428.3958832137625\" cx=\"274.0991684028067\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"255.8062946363575\" cx=\"46.556098141718834\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"204.75328847927915\" cx=\"408.8401578372215\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"163.64497649077038\" cx=\"99.96611906535419\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"222.1458028814308\" cx=\"154.43037557412222\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.8411745944125\" cx=\"175.7821980908939\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"113.18431100728614\" cx=\"187.78146657904585\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"143.67410007113065\" cx=\"333.44597962285883\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"352.14625594346296\" cx=\"317.06067223247186\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"53.493389547802224\" cx=\"225.07215537031448\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"261.0615974396917\" cx=\"206.0983717184482\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"172.04840203419792\" cx=\"100.372526592237\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"105.5040921960504\" cx=\"175.5849389138377\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"143.03062881232947\" cx=\"329.7178558958822\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"179.0050460103881\" cx=\"281.37896822612447\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"418.78877232656026\" cx=\"220.78417501645285\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"147.73307134665745\" cx=\"374.1842081444532\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"79.31832102691327\" cx=\"261.6690465124291\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"191.01995886982647\" cx=\"299.33994262923005\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"251.90648526603695\" cx=\"332.5400839937343\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"355.7875953021024\" cx=\"311.3766422329481\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"148.41673174539196\" cx=\"248.60125235671563\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"396.0994728138395\" cx=\"240.51694039661444\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"324.4355939791415\" cx=\"173.26156709989615\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"414.26494208741104\" cx=\"251.57625412703885\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"172.81690189962418\" cx=\"99.34662943277435\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"325.52204680509016\" cx=\"266.43893977416116\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"137.88184233851786\" cx=\"334.62586464480285\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"384.00888734758337\" cx=\"242.97051073935162\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"227.00277684803262\" cx=\"273.0196545903558\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.17496347225284\" cx=\"291.94905815515204\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"255.38181435816776\" cx=\"44.58411071912593\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"208.83375531324603\" cx=\"315.2349864650101\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"159.95203130965749\" cx=\"100.99014824018562\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"254.01721037952268\" cx=\"316.4488852894595\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"309.119010042924\" cx=\"189.1500757365031\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"346.90197699648917\" cx=\"283.8327693199043\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"257.94014842131753\" cx=\"38.7255834846846\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"176.24484599043717\" cx=\"417.6818235632767\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"314.96921925168397\" cx=\"154.50269954378484\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"328.10072267146666\" cx=\"256.7098577316494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"253.56962752670273\" cx=\"18.260822916696803\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"219.75915789542026\" cx=\"352.65468534852863\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"247.3118982413899\" cx=\"44.972497688389964\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"239.7247929699477\" cx=\"152.6191941579146\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"99.31821713720616\" cx=\"151.94449459133747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"215.92578422261963\" cx=\"186.54225656284348\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"190.1558264323907\" cx=\"333.27452061000315\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"346.6676767830105\" cx=\"258.6656678579287\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"402.8892782921\" cx=\"202.85826447044863\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"349.41388889451713\" cx=\"252.0171397055486\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"174.8014652540431\" cx=\"109.81649649226486\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"231.36237956133675\" cx=\"114.22006148559859\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.34563226108934\" cx=\"239.77631058718228\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"237.44078961886805\" cx=\"300.2958233294569\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"413.3029300023359\" cx=\"235.25509758679388\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"300.79589135642135\" cx=\"105.52698844288403\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"311.8599808093183\" cx=\"201.81455003404767\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"398.3696675005883\" cx=\"248.30393650581385\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"412.9557375882626\" cx=\"213.83145586826538\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"341.9024040362044\" cx=\"287.3698806301944\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"171.39487662282286\" cx=\"97.80376203255082\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"199.56910644374224\" cx=\"280.7691701373371\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"326.6566167175099\" cx=\"174.62304769835637\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"183.43939429162975\" cx=\"150.47967049019158\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"406.3287324646847\" cx=\"196.91371929077616\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"428.6933103196312\" cx=\"293.1131037662378\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"183.64530663278643\" cx=\"105.5289223563846\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"244.76022574107932\" cx=\"127.32589659891943\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"359.58440592278316\" cx=\"200.6356978977233\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"257.33810246874975\" cx=\"233.05381024340608\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"179.78564931741013\" cx=\"97.81615665998616\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"270.49395012353517\" cx=\"381.50936702987474\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"317.5834802252851\" cx=\"157.88398797139703\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"102.4840884783323\" cx=\"290.54172402806796\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"358.82453175109515\" cx=\"193.19114732400496\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"196.3846953551513\" cx=\"195.27205747985118\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"183.61366626957712\" cx=\"84.66543497479176\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"220.9222502849369\" cx=\"375.24186104264646\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"233.68953550351952\" cx=\"262.4592067584687\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"246.98497483408337\" cx=\"145.47212013671702\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"80.73117669680431\" cx=\"244.9598319605077\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"171.0411957091923\" cx=\"306.68345721068954\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"257.2639819373977\" cx=\"16.893216427460693\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"270.29361426590987\" cx=\"141.2949274103242\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"114.7081029879815\" cx=\"138.27114926483657\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"178.62272449710306\" cx=\"162.56592662736122\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"85.2151309581496\" cx=\"265.23823221765156\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"421.77642694572376\" cx=\"240.08229059032942\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"149.70109754301768\" cx=\"255.4527947270378\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"212.82608074298184\" cx=\"371.164116521576\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"137.28108199890215\" cx=\"335.03497525532845\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"250.46330781032333\" cx=\"152.14640175368191\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"150.3642815337506\" cx=\"255.58437226801706\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"284.38048194310954\" cx=\"104.31938033138384\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"367.4717622533308\" cx=\"176.7485889517075\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"200.43922467310654\" cx=\"176.38206839077355\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"329.8404646636752\" cx=\"152.46172305350325\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"332.0275340343351\" cx=\"225.88532788216853\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"415.43156441847344\" cx=\"214.30916340705895\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"370.48526098927425\" cx=\"269.9273626144459\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"234.85027814692745\" cx=\"255.87460213898322\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"256.4928119527633\" cx=\"72.18601202533117\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"151.7372502376928\" cx=\"226.0560231331095\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"156.0257363895989\" cx=\"220.43313057083674\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.179273420814\" cx=\"194.94922028892543\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"184.17448744955576\" cx=\"274.7388597397659\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"82.567856103228\" cx=\"252.1325262150332\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"270.3939167994974\" cx=\"189.362031557349\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"362.65649344727746\" cx=\"172.94620734156769\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"320.72860045478745\" cx=\"304.50231045012515\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"139.55852336720562\" cx=\"315.9455018898545\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"295.1409909289996\" cx=\"232.61457082635252\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"108.35362583395289\" cx=\"136.57455222353656\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"328.2418324281375\" cx=\"292.1349610844649\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"66.12441593230315\" cx=\"143.48040899404748\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"82.9442440182727\" cx=\"292.7337930046525\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"75.28092497387699\" cx=\"254.10200559355508\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"166.64778376173643\" cx=\"137.2978303786701\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"144.71344122586558\" cx=\"336.06526767274687\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.49833618397025\" cx=\"322.11587267625964\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"63.80033538301622\" cx=\"131.72468174922628\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"311.26767584719505\" cx=\"238.4042030790958\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"146.00451528594638\" cx=\"238.2761321298544\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.3032767290596\" cx=\"277.2644079256017\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"224.98749098388222\" cx=\"260.5773111358248\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"49.78392369084797\" cx=\"147.17552433377608\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"339.7748464582661\" cx=\"206.3204489942554\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"406.19848998330957\" cx=\"252.56481906423943\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"256.4807964163266\" cx=\"16.585504417975322\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"243.79418100682975\" cx=\"178.5738077230114\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"239.09384682280248\" cx=\"274.11472761597025\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"299.496719033557\" cx=\"256.37603239583416\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"256.4559412325866\" cx=\"16.814101784256344\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"193.5025983498688\" cx=\"117.24001026259225\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"79.9164057532484\" cx=\"249.80417127738426\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"271.11563463805663\" cx=\"105.70740279382463\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"126.06296622501671\" cx=\"183.05110042151748\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"119.46043170010778\" cx=\"363.0127260574788\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"99.25814494909531\" cx=\"119.02213352963962\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"289.65275318918935\" cx=\"125.22590827650882\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"239.63549575022608\" cx=\"45.720757390929776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"235.89016596187065\" cx=\"292.78592076400827\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"165.60899750831842\" cx=\"101.63430625804239\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"74.74142903609265\" cx=\"163.72737354218066\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"212.64697260776498\" cx=\"334.3928390561314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"348.19627058302257\" cx=\"299.1898225937498\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"433.7041900810073\" cx=\"214.76394486829963\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"75.00980348687364\" cx=\"115.20875278646544\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"161.5071614795777\" cx=\"227.48583960555163\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"48.66169346513914\" cx=\"152.0621501527417\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"93.47978721976772\" cx=\"240.83774340721754\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"277.2635538974164\" cx=\"67.74484560018557\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"333.00400651808474\" cx=\"136.35514094638316\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"288.6316193905363\" cx=\"271.5174982669478\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"257.3424290508\" cx=\"260.19078940415574\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"247.50527722978197\" cx=\"140.50268765786416\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"368.3009496429817\" cx=\"164.59002532709255\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"216.6041867940245\" cx=\"95.40012731426394\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"108.56904841451141\" cx=\"112.1581360970852\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"171.32726656731782\" cx=\"274.112562951427\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"276.42090053620336\" cx=\"24.426776468856378\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"210.02185672053116\" cx=\"129.17243237130901\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"154.51524555829226\" cx=\"115.8495704082758\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"254.0162901223882\" cx=\"204.04796053226087\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"198.94791639574075\" cx=\"352.75568837635285\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"194.79355978146447\" cx=\"285.10588325716316\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"433.17930837592604\" cx=\"188.14995951198745\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"345.12298535073535\" cx=\"228.43650076526615\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"334.1376534263338\" cx=\"132.68341936712432\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"280.54256467239713\" cx=\"132.15526319486594\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"246.4669387432682\" cx=\"251.79001200364658\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"236.61649950804252\" cx=\"396.06053876937995\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"373.4715420903265\" cx=\"148.11774676990524\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"16.478285147259705\" cx=\"232.61506323259542\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"95.86111600392891\" cx=\"105.19052045822288\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"141.61564693640233\" cx=\"377.3611225711932\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"301.94887739967584\" cx=\"28.357147990668995\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"252.7319147101357\" cx=\"53.08504506030282\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"171.8405887439754\" cx=\"84.46224219949525\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"50.44135538773124\" cx=\"168.42726133282181\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"129.73609428682138\" cx=\"372.12385406065897\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"160.7962285052275\" cx=\"302.6107287777611\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"339.47597990541675\" cx=\"119.05377938692135\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"71.47922462872033\" cx=\"288.473590337692\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"231.88022138518406\" cx=\"286.81530895762165\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"252.03333515767744\" cx=\"191.176231966365\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"373.6635489341255\" cx=\"146.8798058844376\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"201.50156950916764\" cx=\"278.1977354584428\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"226.78597971922437\" cx=\"264.15492749521377\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"185.81851445866818\" cx=\"398.59170189725427\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"318.9190233077337\" cx=\"179.8190227603959\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"37.964042162089434\" cx=\"202.09020413081794\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"275.0365371260108\" cx=\"26.999958262788127\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"287.98146733964234\" cx=\"21.78311671360342\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"193.88529895415252\" cx=\"320.56733539327314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"244.65596198125914\" cx=\"67.6675110364533\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"340.9023290172321\" cx=\"120.55952883370819\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"207.83347838711134\" cx=\"264.3827034976643\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"162.6199309125367\" cx=\"234.57332440194418\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"155.9110970739668\" cx=\"357.59461465835324\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"161.35757436912456\" cx=\"85.99439615845152\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"279.0294586626068\" cx=\"387.3913319773654\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"249.99124199717147\" cx=\"292.6058250692695\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"290.48170433372513\" cx=\"167.44987133897385\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"110.25832185724255\" cx=\"107.39331386421958\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"338.43875396857305\" cx=\"276.64926410432565\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"347.53127904245537\" cx=\"155.6979899448639\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"295.6569722367205\" cx=\"197.92359024091746\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"156.14701803881667\" cx=\"227.1466735162508\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"65.2065652015389\" cx=\"156.55905394283928\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"376.48868889037334\" cx=\"164.13928612965307\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"59.322787210141506\" cx=\"145.31929701759398\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"125.40614986424724\" cx=\"99.93353921575684\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"299.65999737254236\" cx=\"354.54225085393557\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"374.43448816771723\" cx=\"150.50373452749955\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"201.0603845037096\" cx=\"148.96500965789937\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"428.10217010086626\" cx=\"180.08507047149655\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"283.2180460952501\" cx=\"340.344205126744\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"305.73556793891345\" cx=\"28.379717640272013\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"29.772665838739346\" cx=\"250.52095543888814\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"299.1355387110393\" cx=\"26.6376131969122\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"46.93180783889645\" cx=\"262.2149650209013\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"152.01798085740202\" cx=\"243.10972778806527\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"246.37478941318867\" cx=\"65.03155397076787\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"266.1398729877474\" cx=\"284.7852931418674\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"223.8802616362247\" cx=\"335.03699707398806\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"421.8053037904933\" cx=\"203.69184437101916\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"124.50226506563752\" cx=\"187.91196178775348\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"170.18833436137695\" cx=\"251.66723596672384\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"142.6457580494301\" cx=\"361.83630230117495\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"244.15819077665643\" cx=\"292.118841475912\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"156.47201989428567\" cx=\"365.0011407566815\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.99694356126915\" cx=\"268.09291654847107\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"153.33905804710355\" cx=\"128.78729789293226\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"179.96525603970136\" cx=\"330.0124150959349\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"342.57053818621006\" cx=\"291.29561515486364\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"151.28853285891302\" cx=\"109.52198124479177\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"274.2269498398065\" cx=\"95.76178012701183\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"268.4658489920278\" cx=\"24.919199193934126\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"196.65110018096087\" cx=\"407.1322375126129\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"165.98390751787548\" cx=\"100.36315370464625\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"258.2379463770764\" cx=\"113.00643187069898\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"177.96609493479673\" cx=\"330.93833112504797\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"224.95131972780365\" cx=\"160.9834524588835\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"225.90791053689392\" cx=\"267.1977700720847\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"302.26803905613605\" cx=\"140.5829066096299\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"138.94546729345856\" cx=\"321.62287856764766\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"299.1142711566057\" cx=\"217.36866057778707\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"164.62048751184227\" cx=\"93.79616582845483\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"417.67189332741265\" cx=\"256.13177692308557\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"105.49723559363935\" cx=\"247.37550007096667\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.74555586007443\" cx=\"264.914680797308\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"329.77097563539405\" cx=\"132.4781718087335\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"166.76128580437245\" cx=\"146.1138332923359\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"419.9696462815443\" cx=\"186.14297210088532\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"200.99560938958604\" cx=\"142.9232496133533\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"244.92146852622398\" cx=\"274.32488138105424\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"275.0344136670109\" cx=\"115.55120931009138\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"270.844793348748\" cx=\"36.39299811125319\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"222.56847011571384\" cx=\"335.04665565334597\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"231.83805661113755\" cx=\"262.9883683459845\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"317.9210140600006\" cx=\"259.3459603902546\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"112.61465261178014\" cx=\"112.53601839983487\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"86.80564295461396\" cx=\"300.5320739386534\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"180.69600063928732\" cx=\"234.22556884544525\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"334.754824560342\" cx=\"270.1937015113861\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"174.5414692637404\" cx=\"330.1798084951814\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"98.68569556478737\" cx=\"199.6779244895393\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"372.08974990603804\" cx=\"149.04323975544014\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"164.8972184468117\" cx=\"148.54161445901744\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"433.4984260798067\" cx=\"183.97708237949996\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"320.2837344207914\" cx=\"128.58054495869155\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"295.5124506610614\" cx=\"24.257515084978625\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"222.0515781654853\" cx=\"213.5154739062326\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"377.68383644556883\" cx=\"169.01252838814332\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"362.38834974753917\" cx=\"255.5125345237658\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"162.43515426807497\" cx=\"89.29742152408829\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"25.08874931669506\" cx=\"245.65302732197003\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"281.0993339739478\" cx=\"24.455653313625966\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"245.8995027000661\" cx=\"335.3502580966427\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"372.1831821020334\" cx=\"151.4989747627205\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"50.457156340082335\" cx=\"166.72370330173433\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"111.82658286030569\" cx=\"252.074525292234\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"83.7732665857503\" cx=\"244.40539077215556\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"336.63701686289795\" cx=\"129.203353011028\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"332.3353779015591\" cx=\"229.07134701708816\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"376.0526243604338\" cx=\"151.5680627237132\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"254.79440186755656\" cx=\"348.22083702787944\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"129.11729690736956\" cx=\"110.0175575674528\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"287.0764782324712\" cx=\"78.20272459360164\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"421.37034906318763\" cx=\"170.6325050951289\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"406.29265838501254\" cx=\"325.40661329591\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"109.93695158365954\" cx=\"246.2671808366879\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"299.28038443697267\" cx=\"259.68754610339806\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"272.57744524046666\" cx=\"33.2903635439661\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"323.6356350548966\" cx=\"332.6233741319967\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"330.36626937292726\" cx=\"115.44333869171122\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"89.17048952144093\" cx=\"183.48556342933938\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"182.42823223446393\" cx=\"334.6014599750033\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"147.97568409174502\" cx=\"227.90131029169112\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"252.55623212908813\" cx=\"256.88781073813476\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"414.23023053770515\" cx=\"287.0246605881287\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"333.1699604703508\" cx=\"135.08652116038405\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"240.07595897191666\" cx=\"141.73265664421447\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"171.89929840211994\" cx=\"85.64351172769533\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"196.19684477715677\" cx=\"407.97933557843373\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.6976144814313\" cx=\"177.15133742634208\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"197.34549874428862\" cx=\"410.2478161145798\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"111.44151431079828\" cx=\"250.07306491801123\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"282.21220779428324\" cx=\"185.93948813974922\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"189.2990423168498\" cx=\"274.1437637888407\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"380.2994544550638\" cx=\"201.6314985283336\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"214.49295347883762\" cx=\"237.2658546183522\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"264.23369631193395\" cx=\"374.0820623495605\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"184.1721112632234\" cx=\"330.98692070174934\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"100.62087270200048\" cx=\"301.49399262449697\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"375.43247543916056\" cx=\"148.98402464263066\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"308.3528781227214\" cx=\"218.63468578807414\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"129.12735105994346\" cx=\"113.40460927705954\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"268.03270456159265\" cx=\"183.63393634978218\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"202.1212047346673\" cx=\"112.16778368829817\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"300.2218871496115\" cx=\"171.7471809712262\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"280.470641770023\" cx=\"20.242205203170222\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"266.1302034202447\" cx=\"145.11195621760166\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"122.56692310625107\" cx=\"149.23086232942822\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"286.9834635859816\" cx=\"253.6514751708685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"371.67711210100293\" cx=\"149.29526934069798\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"180.29398287628788\" cx=\"110.72063401820702\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"175.09996370403866\" cx=\"334.74370151059776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"263.69432673781586\" cx=\"58.25638470150013\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"190.79223506106416\" cx=\"352.80968412033985\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"202.5779681825424\" cx=\"197.1019187423709\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"424.05114874816707\" cx=\"172.83310636622014\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"219.17555211025422\" cx=\"79.1741095662675\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"112.67426329780565\" cx=\"252.07898098498669\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"225.85540574681664\" cx=\"182.8662551011502\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"337.07536692697454\" cx=\"135.42086843308155\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"165.39044330646638\" cx=\"290.48949188133577\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"174.69730862863562\" cx=\"254.8919048711536\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"278.8904806060445\" cx=\"203.50808962403218\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"430.8623701208172\" cx=\"183.86287160151858\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"129.04657720686077\" cx=\"172.18897032465316\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"176.1903832502924\" cx=\"96.62080033003775\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"34.68071854023951\" cx=\"217.38341010202404\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"190.66949473561232\" cx=\"322.71963827350265\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"77.46721418624968\" cx=\"290.8223447663283\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"419.80664814025357\" cx=\"170.48646166140261\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"100.3358621998568\" cx=\"177.84449707633354\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"433.20482284835936\" cx=\"184.4021972230571\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"225.48139745189957\" cx=\"160.75169600094677\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"114.99241024885225\" cx=\"244.52704739181766\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"129.28485512878947\" cx=\"184.63812917605188\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"122.80653059371136\" cx=\"97.72843829933333\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"77.87059997328787\" cx=\"185.09391742606806\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"120.87672665934922\" cx=\"130.0179701205555\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"151.084395103156\" cx=\"406.42250224605567\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"255.40067001479812\" cx=\"36.42097392814184\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"97.0514837160975\" cx=\"275.3657114294217\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"193.37192733084294\" cx=\"117.38418571168731\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"219.01174702707314\" cx=\"85.81039967227694\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"141.3902526143566\" cx=\"347.74912695591837\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"273.83047284886754\" cx=\"88.67709679249684\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"441.92835502870764\" cx=\"219.117894266903\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"277.1271141023235\" cx=\"121.37291527100801\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"156.40266272374316\" cx=\"297.3257112836095\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"423.93045496470086\" cx=\"196.43908087820202\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"83.12943821224022\" cx=\"232.8781729884562\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"385.45360863765393\" cx=\"311.0661337405883\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"329.38928044636776\" cx=\"141.6903962389695\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"170.31425850181054\" cx=\"129.59726701717148\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"232.1868263390718\" cx=\"268.0470190672676\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"283.7638876867081\" cx=\"245.33059119833274\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"365.94576165551257\" cx=\"214.97848015615833\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"224.08399901145228\" cx=\"184.097094897983\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"120.82678554082648\" cx=\"130.2056146708334\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"194.64039602984982\" cx=\"309.08789406355334\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"254.6184020038253\" cx=\"36.846808495189265\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"413.4106248103978\" cx=\"272.534593922354\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"205.3673527153198\" cx=\"124.70545479381798\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"279.23959045140106\" cx=\"335.15281212112336\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"143.58868372683216\" cx=\"333.101226576951\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"197.24586648753936\" cx=\"201.0693422887509\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"442.81854859878507\" cx=\"216.50132303583885\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"251.7019807809442\" cx=\"51.31318472058226\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"111.80321107612573\" cx=\"330.0225022129434\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"419.9927213858123\" cx=\"198.90137580798145\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"83.27567943257448\" cx=\"231.77735110278735\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"98.18563607901143\" cx=\"175.56038041000969\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"329.5474987446315\" cx=\"174.83346517891772\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"372.30931501721994\" cx=\"330.1881814615872\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"228.56089914131317\" cx=\"261.0019562361879\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"394.3628844192142\" cx=\"313.1873841233601\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"355.8173402103182\" cx=\"200.0772611451857\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"274.7872902884462\" cx=\"334.8106193129748\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"113.11414071402184\" cx=\"127.13239536741547\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"259.0868986923473\" cx=\"132.70463747490592\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"274.9333639395709\" cx=\"29.636915249658493\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"133.6821349032464\" cx=\"105.33613535429843\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"173.77006852806326\" cx=\"92.08205917827345\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"199.0154907397749\" cx=\"174.34805289027946\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"144.43400720725336\" cx=\"331.77268294279696\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"163.14193372365693\" cx=\"130.7218926584662\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"440.55184814211106\" cx=\"207.07788105074172\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"413.1707096548806\" cx=\"272.3715518284837\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"191.7904558305864\" cx=\"401.64947186895756\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"255.03131451248265\" cx=\"146.291907168415\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"98.64612725504031\" cx=\"243.73973032826817\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"206.62870933754695\" cx=\"404.6306434826362\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"339.03433339787335\" cx=\"142.2320843116593\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"284.6286931480184\" cx=\"229.65575287655395\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"230.28915654767994\" cx=\"265.62710266529075\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"280.44138034018226\" cx=\"342.95891112021314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"365.7746432751485\" cx=\"203.00533666924017\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"304.46874471460376\" cx=\"144.52230489246924\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"443.5614570747637\" cx=\"217.11709249461455\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"275.40759579078406\" cx=\"196.11314777745366\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"144.60678479749575\" cx=\"331.92312163447906\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"198.1503831044802\" cx=\"186.65195396031152\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"105.7924211179507\" cx=\"122.94926354870982\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"285.54689549941907\" cx=\"330.2953378505495\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"102.29660875022775\" cx=\"246.2563245495371\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"250.29058104025106\" cx=\"352.0184168187026\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"112.22933133494028\" cx=\"248.38034531833918\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"261.3442427436479\" cx=\"163.4768932853522\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"90.70882980596997\" cx=\"232.73987138956366\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"239.11980974889917\" cx=\"318.1207370284684\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"367.93695635537233\" cx=\"211.75734600058766\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"437.6412643712025\" cx=\"273.7673923560134\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"115.59197837474746\" cx=\"120.51163151013486\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"341.4180246331858\" cx=\"250.83825460478954\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"123.41926251718418\" cx=\"112.25453509220074\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"377.91200527419915\" cx=\"251.02518767268586\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"274.7504992323199\" cx=\"26.40618088924969\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"186.0426698673776\" cx=\"384.34793449917754\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"441.52346386581956\" cx=\"184.36634840035515\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"268.2398393338683\" cx=\"215.27540318088032\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.62341625256175\" cx=\"290.22810589070446\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"213.34492583596446\" cx=\"371.59920310662034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"339.9994331516624\" cx=\"143.15979140838942\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"335.32663663224633\" cx=\"228.10227882609627\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"374.22166977749754\" cx=\"191.35360260117122\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"295.5215268687401\" cx=\"326.7015222185572\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"156.48881527374925\" cx=\"285.0330758091254\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"282.6480360791076\" cx=\"310.38643456808654\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"97.16190358409202\" cx=\"232.9689831383773\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"222.68861998600798\" cx=\"399.9812187474\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"246.94002233334047\" cx=\"273.1047303021627\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"33.192352338667874\" cx=\"257.5269389326684\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"368.8383798095268\" cx=\"234.1218366371341\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"341.60473519114805\" cx=\"340.40012379608663\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"233.50391963949187\" cx=\"39.206402728759045\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"265.0377840316211\" cx=\"298.3401093494453\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"146.91969040343005\" cx=\"349.81311811567105\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"177.04849693136492\" cx=\"393.3322702984779\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"258.45980801054014\" cx=\"269.5623446823256\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"32.04024534700451\" cx=\"191.95419811861356\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"160.96789629283603\" cx=\"282.033141938048\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"374.683600400507\" cx=\"205.5121734178473\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"305.1856332634841\" cx=\"178.80569603868685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"157.4460035632179\" cx=\"101.93292008355925\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"145.151357258219\" cx=\"255.4170777620745\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"123.74612686321194\" cx=\"199.81523509511462\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"247.72397427751758\" cx=\"270.2864744186881\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"291.75210969326884\" cx=\"275.59007835992026\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"256.01776148475585\" cx=\"18.168610404784175\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"239.21843796390914\" cx=\"138.88248019983595\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"115.4488687757067\" cx=\"120.10196050421989\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"374.46368366868865\" cx=\"236.1317681843076\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"253.82907410976102\" cx=\"19.360538433527065\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"243.0183424341354\" cx=\"310.70145918799585\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"106.59947838379419\" cx=\"249.03320182639405\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"311.7729327255037\" cx=\"254.22084238053498\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"110.90329299782113\" cx=\"124.53343538557296\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"362.34944072648545\" cx=\"282.7009519377794\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"146.09720028808925\" cx=\"347.8276812037334\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"90.3609781032033\" cx=\"136.1209780847156\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"240.96967836298552\" cx=\"272.5705086739253\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"278.30644971702304\" cx=\"361.22617456804096\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.13501047494435\" cx=\"204.47558616692527\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"122.67112368423815\" cx=\"265.5770763886451\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"325.72816242692727\" cx=\"126.72313092286139\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"251.59370772175748\" cx=\"302.0764412206544\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"421.800359125293\" cx=\"213.13952826401967\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"276.99953624608406\" cx=\"213.52609394826828\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"156.53505888151668\" cx=\"294.9032538731269\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"348.6711672170016\" cx=\"260.3930948867524\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"206.79982497087482\" cx=\"125.0653934559631\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"54.15106298387306\" cx=\"263.2646542610859\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"328.2514580430607\" cx=\"127.84677861926099\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"416.0153645564522\" cx=\"313.66573103483444\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"156.63608937970312\" cx=\"295.71295378781633\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"345.3685594008706\" cx=\"262.8255267857584\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"206.1900406172686\" cx=\"126.72279029036983\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"232.21546917069324\" cx=\"344.84661947150363\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"230.87126682915755\" cx=\"40.79968373773556\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"50.65323978563534\" cx=\"275.99123904761836\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"146.44523329524662\" cx=\"333.89455964982744\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"335.2389182715935\" cx=\"286.385765891674\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"206.55249556459344\" cx=\"119.60461509023165\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"195.8918715627851\" cx=\"183.4380754141632\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.60847237551206\" cx=\"301.25919794449834\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"82.27616480899151\" cx=\"260.9083509769105\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"233.76478850055426\" cx=\"278.06445475500567\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"100.43429400177689\" cx=\"170.98540035639985\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"307.56245141416815\" cx=\"186.66886471529645\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"295.5568867189945\" cx=\"260.49973757994115\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"295.02152781776107\" cx=\"20.3793372513911\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"350.0641343446427\" cx=\"177.00195359656942\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"248.07936659471466\" cx=\"268.8928232790277\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"260.49126052623876\" cx=\"219.63917048694245\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"127.6759379896352\" cx=\"114.3397993004594\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"356.8657081260798\" cx=\"342.2873706452918\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"367.8494577576173\" cx=\"183.8418430392363\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"425.23395661665165\" cx=\"323.76568769069263\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"110.7902689394878\" cx=\"249.72747127901937\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"208.69276642616896\" cx=\"192.95490220888087\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"241.5103115737659\" cx=\"271.2121267323239\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"159.4929521102469\" cx=\"312.5024490998185\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"233.11701503964935\" cx=\"39.543914587184716\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"397.5221738615515\" cx=\"260.58383259981673\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"231.86555890765737\" cx=\"35.45010539828577\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"195.49331781246207\" cx=\"311.0792810559486\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"155.96626854945694\" cx=\"297.0796043084471\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"292.6679166290836\" cx=\"105.42063418849864\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"322.85229020572467\" cx=\"144.1558777307669\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"171.0255430967972\" cx=\"357.6749929382199\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"94.93204637723248\" cx=\"246.47852956252868\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"423.7931031535822\" cx=\"300.46771637403566\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"148.1723554030496\" cx=\"326.2295594192637\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"150.56689193736796\" cx=\"116.27591042998813\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"155.7846070440714\" cx=\"294.51641623229233\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"80.95182963433022\" cx=\"306.94359055280336\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"439.3941811491336\" cx=\"210.2549328292929\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"406.894687855363\" cx=\"320.7230593826471\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"133.73159254339404\" cx=\"154.4779542414937\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"385.33498062542697\" cx=\"224.25957742011286\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"443.30035677589956\" cx=\"216.0288039617103\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"103.80466570744136\" cx=\"279.7572828626086\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"330.6739923705575\" cx=\"150.86466761675717\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"361.17664305799514\" cx=\"292.8141548023018\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"442.23923162392117\" cx=\"216.02838915924073\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"215.69547133221775\" cx=\"340.1391553549612\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"134.9695608992239\" cx=\"330.3934839607025\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"255.69802569772511\" cx=\"286.59890843216795\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"124.77978165296656\" cx=\"114.99675850711243\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"117.3909354797655\" cx=\"144.0974592584619\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"145.66089401896215\" cx=\"334.52060920490635\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"191.10274630046013\" cx=\"161.46000280866838\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"213.5047168124656\" cx=\"133.26635144165684\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"268.36339003500575\" cx=\"179.18828676152168\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"235.26205922004073\" cx=\"268.58158132799656\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"233.84481000909153\" cx=\"200.7490625885482\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"142.56721478976002\" cx=\"333.30518852238976\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"281.4351811284227\" cx=\"193.34419020602581\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"131.03344257763405\" cx=\"138.00191224468173\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"245.87423820792895\" cx=\"170.10531038554834\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"258.81010457554476\" cx=\"17.79969442826433\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"49.72811490295424\" cx=\"164.477270478309\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"155.59685810641707\" cx=\"108.95202616937375\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"140.57901435938265\" cx=\"373.56424602164304\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"216.46927984514375\" cx=\"390.09629459295684\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"278.137517977492\" cx=\"335.76493969662727\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"423.41653942821927\" cx=\"263.5325342453469\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"219.61999235363578\" cx=\"334.6020533348273\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"153.32216377433596\" cx=\"218.23604619286917\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"317.6276141092338\" cx=\"161.49683507033797\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"75.53350946045177\" cx=\"262.0667761518854\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"424.79396931898657\" cx=\"308.55829844431446\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"312.43379272359255\" cx=\"205.09924167993634\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"272.851544514735\" cx=\"75.38500163515421\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"244.14094350973429\" cx=\"264.46564476232646\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"176.96579465885415\" cx=\"407.05728737632165\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"375.32845067149174\" cx=\"203.1229523986192\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"273.16683285012175\" cx=\"188.2817348395747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"122.50370830870182\" cx=\"105.68029504038225\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"207.63766689814435\" cx=\"349.0120274125025\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"257.72384404213165\" cx=\"17.146097593947495\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"227.21481198954945\" cx=\"119.60632924083441\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"163.8556082401571\" cx=\"90.23994064012948\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"395.0423473466009\" cx=\"201.48470515371866\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"193.4127125776365\" cx=\"371.3118631177601\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"441.2887351146902\" cx=\"190.456678792349\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"443.7376629662116\" cx=\"208.581313372475\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"260.6850144850752\" cx=\"204.7840549848899\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"146.72500794635044\" cx=\"229.49509761378135\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"333.25208586525486\" cx=\"231.34159492766383\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"100.9588570506564\" cx=\"250.41563956419478\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"110.92602746959749\" cx=\"153.5118820368819\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"129.77599224091512\" cx=\"108.94690569385524\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"281.6541144212734\" cx=\"230.27730759361395\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"279.4204717984994\" cx=\"27.827871027631883\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"383.95690243411116\" cx=\"298.79222206499594\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"153.27700799291262\" cx=\"102.41391513795193\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"287.359340552289\" cx=\"252.81151115811718\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"133.5525736868544\" cx=\"337.79216452357963\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"62.61300039883713\" cx=\"215.35284487902527\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"340.6910269910071\" cx=\"139.9469951945127\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"191.64694241722097\" cx=\"270.7200611219551\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"230.6672609311392\" cx=\"247.95558209541846\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"419.5921595520107\" cx=\"283.25315017105595\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"156.23442873141258\" cx=\"226.27669924875352\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"66.71696263361396\" cx=\"270.21906489682726\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"175.53602273990575\" cx=\"83.942426029208\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"323.28179481316516\" cx=\"115.63060964506286\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"262.97298799025526\" cx=\"17.978998976571077\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"243.74346110353798\" cx=\"94.76208969311064\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.34689958641766\" cx=\"229.6356819997747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"106.0822114631213\" cx=\"296.1906963513218\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"246.5597240122332\" cx=\"261.89529790977616\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"197.52103985297072\" cx=\"420.7628774140008\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"258.2400973064385\" cx=\"270.2267236338153\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"413.73439049956676\" cx=\"302.24384011397336\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"130.66889988278024\" cx=\"153.58851335934122\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"306.7315333916971\" cx=\"185.55546621104253\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"374.0606824667216\" cx=\"228.7587655425191\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"369.86899088314703\" cx=\"201.46494022809867\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"172.00961937681046\" cx=\"84.28451994405259\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"334.43831104680015\" cx=\"304.4120263576406\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"353.6713445252553\" cx=\"151.02294085574545\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"299.3724431148568\" cx=\"197.80941242737075\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"219.22789551195342\" cx=\"239.7121219652922\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"257.3421735764314\" cx=\"214.40246511883376\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"433.6129665021347\" cx=\"184.32492584115798\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"201.6356303708919\" cx=\"197.71667797857586\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"122.88232681715908\" cx=\"262.632292016768\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"355.7459392448263\" cx=\"310.87562128449434\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.5626784228359\" cx=\"16.404419790196478\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"311.1640906053218\" cx=\"205.90637723631218\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"146.2831471699817\" cx=\"169.66883929424787\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"48.81864812674066\" cx=\"220.91555786123985\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"411.17526254294864\" cx=\"198.33253053519726\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"208.11908362259717\" cx=\"215.45455526867673\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.69704781146623\" cx=\"219.5799237832164\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"322.970280905548\" cx=\"116.14067933083314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"126.41223539847412\" cx=\"149.32860187822027\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"249.9238626927091\" cx=\"202.58012705293334\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"275.1879894740589\" cx=\"21.746306428223615\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"114.54194026096259\" cx=\"190.31798917459002\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"199.87885126003218\" cx=\"343.46925550960566\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"317.270521376615\" cx=\"162.81139079604762\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"113.55892983100364\" cx=\"260.99441012768506\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"160.35872452830742\" cx=\"305.25044928307113\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"143.54894510083932\" cx=\"167.15403202004157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"83.47066406363854\" cx=\"281.76444883106524\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"249.42313430361304\" cx=\"24.208068432975903\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"195.81186138577226\" cx=\"291.81850800572\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.14214288866145\" cx=\"14.979059611421192\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"297.0516095623847\" cx=\"208.15708444809954\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"233.81193244944356\" cx=\"268.94395386423474\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"154.8225235360545\" cx=\"261.79873683952354\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"127.92069891704865\" cx=\"130.3104195967894\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"40.58972531230318\" cx=\"295.9163058912138\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"443.9230769230769\" cx=\"208.53759841155025\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"255.6334648524269\" cx=\"203.7998619558372\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"307.9685677552114\" cx=\"196.66339836204858\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"179.74677326079112\" cx=\"405.1846437716747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"351.3480001816759\" cx=\"145.29943594570622\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"290.4822262706074\" cx=\"298.68999935308904\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"114.11019407196461\" cx=\"257.0761255652509\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"294.38956664073163\" cx=\"346.2075341805021\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"135.16174355334113\" cx=\"352.5253988357589\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"274.55912970092453\" cx=\"302.48194771965626\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"121.89252571365844\" cx=\"256.4096698543771\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"240.2297916268515\" cx=\"157.7412629574274\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"142.633934805529\" cx=\"165.62115833759503\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"334.7845035396885\" cx=\"239.20538443445963\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"342.1860080558023\" cx=\"141.87122264534344\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"282.3463840315288\" cx=\"139.97973437221097\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"199.48386865679822\" cx=\"343.457388313125\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"55.58124695825483\" cx=\"162.56608046138967\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"152.40766992183543\" cx=\"235.88278300194318\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"38.140467816435134\" cx=\"218.72101895571183\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"432.8200839431987\" cx=\"201.63658603941747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"412.0219210829739\" cx=\"259.6672784701494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"167.87328057311674\" cx=\"90.58970428010693\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"423.9166099021401\" cx=\"304.81100589857806\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"443.77724226410356\" cx=\"219.53471031403234\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"147.28523851354126\" cx=\"370.40804424801973\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.48319842381403\" cx=\"15.98456277396894\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"300.26456510436236\" cx=\"214.98136729122803\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"352.85215634745373\" cx=\"151.6689393878712\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.24960686290005\" cx=\"296.7268024464077\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"128.85706467195172\" cx=\"110.76655347570022\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"146.43511870787586\" cx=\"375.8552962073922\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"122.62291869260795\" cx=\"258.63617842408155\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"112.28890905653111\" cx=\"186.12753650435178\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"344.92700079848635\" cx=\"149.64599993742573\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"278.27560599431825\" cx=\"144.49242263244227\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"280.12528987021864\" cx=\"15.550223382777052\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"377.9427171391653\" cx=\"293.67327389863175\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"376.8917450330648\" cx=\"194.80697875333092\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"397.307542427425\" cx=\"277.1179908949492\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"205.7497181811844\" cx=\"338.82468753441066\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"425.7139187854247\" cx=\"249.8778934884841\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"221.4974988991554\" cx=\"245.5132594924938\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"163.16565163440092\" cx=\"107.34075756721313\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"169.31534273212407\" cx=\"85.39039981016586\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"252.56898661826858\" cx=\"85.74994289909496\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"227.6600996936056\" cx=\"245.11827688925985\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"298.4674759839755\" cx=\"248.8526034240266\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"120.17922119805398\" cx=\"110.8647655147225\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"239.96578427690503\" cx=\"319.4712129998218\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.4715400020862\" cx=\"17.792200513449693\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"82.6173247315205\" cx=\"187.69896484017931\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"322.05621559069823\" cx=\"202.30262694782164\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"95.44409392908287\" cx=\"291.5538200775494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"155.803193491152\" cx=\"319.8885207664349\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"275.53100364603796\" cx=\"187.12543861767222\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"353.7074955219417\" cx=\"151.01830935267452\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"257.02570401546905\" cx=\"380.9489496642208\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"237.5125037464893\" cx=\"284.86253980044046\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"265.21323998218026\" cx=\"300.1584715183382\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"354.98176870848647\" cx=\"176.01503688110225\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"52.85860441753619\" cx=\"141.62254444427688\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"119.91151702411125\" cx=\"110.05371955228412\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"114.57761876741877\" cx=\"231.31457782641678\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"279.61655524405245\" cx=\"45.090993842878255\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"216.24687567202608\" cx=\"345.13679440174536\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"177.50240071453254\" cx=\"92.2744286308538\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"166.27151671628553\" cx=\"134.13790362392922\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"219.60519269598774\" cx=\"289.37595877230694\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"375.9074489901538\" cx=\"152.95575554180732\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"417.1641970809385\" cx=\"191.56591004265357\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"348.42135174293895\" cx=\"305.53410824339346\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"148.74933739712446\" cx=\"256.3577673519916\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"72.95545991833399\" cx=\"142.9514781575744\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"114.42213651723245\" cx=\"262.9268045172049\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"259.4347311658604\" cx=\"218.39708432381525\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"348.3036027823032\" cx=\"156.05231366497054\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"272.28754501384714\" cx=\"82.13123911892794\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"230.5189444966287\" cx=\"314.4433290842292\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"70.52501412651675\" cx=\"176.31797454163316\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"314.0540386401278\" cx=\"115.92725659264451\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"160.98806503278072\" cx=\"137.3079449660409\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"102.93120708203067\" cx=\"114.76596351185351\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"420.28786295754406\" cx=\"294.27062241925927\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"270.1195043630996\" cx=\"34.05008388162567\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"246.85748900355736\" cx=\"131.53183980641566\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"178.62583414210678\" cx=\"90.71029917026911\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"304.46293198595725\" cx=\"209.55618433410706\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"133.80003769791068\" cx=\"311.748634890037\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"344.4522470103909\" cx=\"261.11058503656545\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"343.30701859742834\" cx=\"124.67067731524274\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"207.9451426625146\" cx=\"196.3021493636254\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"237.4263285334344\" cx=\"300.67337598785986\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"283.94953788868855\" cx=\"115.63198316317404\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.18487467645286\" cx=\"170.34014901812657\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"178.8508219027916\" cx=\"283.0282558096027\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"275.24437239252313\" cx=\"307.11601102833686\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"268.610359579542\" cx=\"346.4967421539935\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"246.52104162166782\" cx=\"66.30793688113143\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"377.5151464452253\" cx=\"159.08883256445753\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"239.2406930778647\" cx=\"323.27520986726034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"224.68477239949004\" cx=\"350.74090212941536\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"299.8756122456365\" cx=\"22.10467378564955\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"118.04580693888951\" cx=\"294.47884227084273\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"149.3580092010606\" cx=\"258.5364472740283\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"292.5191151709901\" cx=\"223.85789616905066\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"421.4753737520414\" cx=\"193.24309652600624\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"200.14425616465678\" cx=\"209.24458114781268\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"158.82743863279742\" cx=\"205.0408300752219\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"93.3936291756892\" cx=\"192.49707565798766\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"148.15912018253022\" cx=\"291.41322676368833\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"80.58968235506231\" cx=\"138.07691182762497\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"218.31216205935758\" cx=\"64.28450296416591\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"213.78266193744534\" cx=\"73.52155510777973\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"276.2179495000944\" cx=\"54.66169001791664\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"325.53167242001336\" cx=\"147.91440016058027\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"375.7740638993402\" cx=\"231.73613525806593\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"236.99704437565074\" cx=\"109.08914722944975\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.25646354809174\" cx=\"19.969896996518802\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"271.1357511843131\" cx=\"334.34098600039783\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"154.78391668898524\" cx=\"285.98731927576364\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"345.35348366608224\" cx=\"176.61167117231196\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"145.36039572659675\" cx=\"234.7873350058844\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"91.39643494871979\" cx=\"143.43591250131752\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"96.21312122546382\" cx=\"250.58344227183846\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"68.87146314282136\" cx=\"264.6299779632212\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"104.48152444448927\" cx=\"123.85538992887702\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"373.7563657940071\" cx=\"280.4944884913896\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"274.91574719627675\" cx=\"50.10503818998247\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"203.16405110762196\" cx=\"165.9666256129207\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"120.44402450174587\" cx=\"354.09791225089424\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"384.2523187094652\" cx=\"260.02605238893625\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"416.907008561655\" cx=\"184.46819476829964\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"105.2366627257299\" cx=\"297.0277512527136\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"254.40551219066384\" cx=\"291.5181470651657\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"59.268868383168765\" cx=\"140.48177172406702\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"368.37515258542044\" cx=\"200.48858861394274\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"168.3476717524308\" cx=\"307.3626893870335\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"252.2119227295302\" cx=\"330.7945182847343\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"300.90897584955155\" cx=\"141.15426816759378\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"123.85293163153781\" cx=\"133.40270333159057\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"220.9876647717412\" cx=\"395.6261774018983\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"146.55475762943266\" cx=\"254.51789039540506\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"387.1516506200069\" cx=\"278.05223044381614\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"142.70986838078784\" cx=\"232.15270613221247\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.18551209134677\" cx=\"268.6506170953011\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"110.97138653170131\" cx=\"272.4839275862685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"299.3687950507535\" cx=\"205.0861822697352\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"278.00547344035493\" cx=\"14.601463000438647\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"354.3977817720446\" cx=\"300.641394992159\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"117.0289859871056\" cx=\"272.73638021510465\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"225.47221479656721\" cx=\"91.24423510673938\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"134.92892673942256\" cx=\"315.92589903937164\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"272.90962510158465\" cx=\"153.52852907638947\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"131.43731184304738\" cx=\"306.83681325483974\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"350.80238384718814\" cx=\"214.79541972257653\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"299.7950196969445\" cx=\"24.746619390299745\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"150.44526416158618\" cx=\"105.5485801475919\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"348.1292978399211\" cx=\"152.48168851276745\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"298.54779382904525\" cx=\"149.21795125918305\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"158.72897936051513\" cx=\"204.38650252926993\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"85.30635453702217\" cx=\"181.25085770354733\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"184.47801846991067\" cx=\"92.71098762731337\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"215.6182699997423\" cx=\"357.4177604663568\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"279.5309630894357\" cx=\"21.760283348523053\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"225.50834106992767\" cx=\"96.79720400809367\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"417.1422207911595\" cx=\"188.76834208896972\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"164.0980671512162\" cx=\"145.34619599628346\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"144.76415700860304\" cx=\"249.61038160707693\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"91.35143849539732\" cx=\"286.2637425426762\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"131.9516669053246\" cx=\"138.8295942584828\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"326.5064087768705\" cx=\"219.02047474783086\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"110.55155149176356\" cx=\"253.45777889979274\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"214.7297136632534\" cx=\"122.2078164960015\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"262.99787339139374\" cx=\"365.2269251578708\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"361.9479668766581\" cx=\"229.57033000804446\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"201.7268566968007\" cx=\"201.91655847712929\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"223.37947624612698\" cx=\"353.4670718646436\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"143.01578932265622\" cx=\"346.6648937352374\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"85.33095699342975\" cx=\"285.03755347816787\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"368.52302005119833\" cx=\"228.25468594092146\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"385.4747058758417\" cx=\"210.1544599794596\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"377.9309927885682\" cx=\"252.24153960048184\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"165.6026243842825\" cx=\"376.00870169819444\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"196.73669508261378\" cx=\"343.8806736305581\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"92.96339935068599\" cx=\"167.88636440656407\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"351.239118653966\" cx=\"132.3725427719108\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"293.54815493989116\" cx=\"180.97923350891529\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"279.2850319245916\" cx=\"19.023224361709403\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"273.07976279001736\" cx=\"205.01712864669526\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"349.9871184371122\" cx=\"152.21264927922067\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"235.2574067708186\" cx=\"388.0604550604111\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"113.15695052651131\" cx=\"255.67757371296977\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"417.38352045293277\" cx=\"326.07008847248244\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.91230085628223\" cx=\"197.61464755920449\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"168.71036294487075\" cx=\"412.06371693901747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"421.0132123779893\" cx=\"187.43916114241213\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"380.69030276878306\" cx=\"298.2359527240378\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"144.32568058086028\" cx=\"230.16301921185928\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"259.03073553678087\" cx=\"216.94945941645761\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"371.8178592488925\" cx=\"175.42742935091925\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"125.86690475575347\" cx=\"195.7625600266095\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"357.2825983431872\" cx=\"197.3319225911978\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"179.61623959357638\" cx=\"361.50247147128727\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"419.7714641003175\" cx=\"188.222418086425\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"403.21604374482376\" cx=\"306.43582288338746\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"369.5857165078959\" cx=\"169.5838789579623\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"261.45934081432915\" cx=\"101.90865825964326\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"180.6218856020077\" cx=\"116.4823776724617\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"435.8648769157875\" cx=\"277.5493140403689\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.51390368702386\" cx=\"227.1706015752658\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"167.5807376976513\" cx=\"349.83317148009434\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"129.76332290985755\" cx=\"157.241148530927\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"402.24153813900926\" cx=\"225.26214264888202\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"241.0032299766465\" cx=\"57.31805206866186\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"122.75380947453158\" cx=\"287.6423646471641\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"192.8591957669732\" cx=\"113.40936714379669\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"101.3389150060942\" cx=\"237.80977328445456\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"128.72062487685886\" cx=\"325.99406149799205\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"289.9517900582844\" cx=\"241.5402223775934\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"428.10981784970943\" cx=\"256.05780198465334\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"188.2144574755324\" cx=\"157.58579718945842\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"66.426710786358\" cx=\"234.55412055847262\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"33.782789316159906\" cx=\"191.9633622314514\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"300.8886422874335\" cx=\"187.6585559373482\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"247.82515860973245\" cx=\"147.75064383729216\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"249.0862968425799\" cx=\"250.0717408465521\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"350.7695073176788\" cx=\"340.63085286247616\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"136.2880174163693\" cx=\"164.96625940810878\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"416.75781153034546\" cx=\"325.000227745317\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"233.46709458879238\" cx=\"61.948357431790306\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"385.2236597295515\" cx=\"305.66241681126803\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"188.81130878260367\" cx=\"144.7350573538196\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"269.76655416110424\" cx=\"97.70637410439524\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"274.3614364921452\" cx=\"282.9809353636361\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"96.91431870344195\" cx=\"250.42975658334157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"413.62023466230977\" cx=\"227.92593764311445\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"72.25443825067408\" cx=\"275.66195730971486\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"336.04180004237895\" cx=\"150.2811861349802\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"193.8789368182615\" cx=\"407.7006322714566\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"271.2644196139329\" cx=\"279.2677994662888\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"292.28907835772856\" cx=\"219.47818935699797\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"119.09039493280919\" cx=\"116.96263652114678\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"182.88387763859654\" cx=\"307.90602018738434\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"238.85773356541702\" cx=\"42.34373785760715\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"399.64150131896764\" cx=\"299.59766956761314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"210.90167885535098\" cx=\"157.28398031970627\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"243.4212378752079\" cx=\"271.0881062879924\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"436.8966637209109\" cx=\"221.28224324434711\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"304.33271148087186\" cx=\"236.12521306912194\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"316.19623242705904\" cx=\"169.1504680650136\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"165.6647403673428\" cx=\"360.235109827878\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"240.0213884106002\" cx=\"235.5741404339375\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"420.1680042730895\" cx=\"294.2773032113521\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"365.79539988084474\" cx=\"214.24247017489313\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"115.1091812645929\" cx=\"345.93370960985584\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"292.04628430825034\" cx=\"293.2022560797987\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"59.54459390288081\" cx=\"244.7282142279002\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"288.97776243677265\" cx=\"216.13925267358516\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"216.15657509732424\" cx=\"360.3670115191315\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"395.98938259019167\" cx=\"200.35367067691712\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"111.69150559517915\" cx=\"286.36372916709814\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"300.85906769546347\" cx=\"156.274702729389\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"261.29871611233455\" cx=\"107.37947978980371\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"289.83849679040134\" cx=\"217.59938346334513\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"382.8991286663241\" cx=\"267.5270902684953\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"128.73998598815416\" cx=\"325.90466195117114\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"156.08525367639282\" cx=\"353.2231899888213\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.15818717077104\" cx=\"188.13790826407993\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"244.12808463317734\" cx=\"332.03527762936613\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"262.3301567908939\" cx=\"295.98474005758555\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"279.1749252187264\" cx=\"134.24327993341947\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"372.74542349973905\" cx=\"228.89718114341483\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"107.74588252825991\" cx=\"294.25472257360417\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"123.2560885655752\" cx=\"338.8163475324395\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"291.1704852079781\" cx=\"118.0162677583105\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"252.78941155178805\" cx=\"110.42489908665121\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"358.99877076460785\" cx=\"252.94236348153376\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"167.71623251228363\" cx=\"244.4233756183034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"197.70585495593954\" cx=\"172.54486534947895\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"275.88258857103085\" cx=\"287.9771074930776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"436.3325763148639\" cx=\"243.06985181026133\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"207.37121811975524\" cx=\"160.22451777358353\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"343.86598552795687\" cx=\"193.8173534601485\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"286.59417009476425\" cx=\"214.1274311654907\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"270.58568190410887\" cx=\"119.87509926483143\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"411.0709081309331\" cx=\"266.94530645510366\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"257.6613709443625\" cx=\"342.06642102785383\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"207.01553461671858\" cx=\"160.0236270146414\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"345.16844330614316\" cx=\"258.00962341433774\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"83.73304997545475\" cx=\"289.11315531098495\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"423.984033159182\" cx=\"276.6411933119043\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"245.39063072208876\" cx=\"78.16972719449849\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"248.0381418221255\" cx=\"361.49392269456325\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"394.3873550178831\" cx=\"244.6723779696442\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"181.3660796909384\" cx=\"201.22370649519476\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"173.15271608966444\" cx=\"249.94138024261935\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"169.32373767481963\" cx=\"141.93267933971038\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"173.37274270293165\" cx=\"247.54314207699136\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"47.175909477616536\" cx=\"235.0890777056585\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"269.663488109077\" cx=\"278.02058458653437\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"133.5746378817925\" cx=\"176.6259447725234\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.44053686849989\" cx=\"232.73422210957236\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"218.05443512097452\" cx=\"101.3564160737871\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"414.9230110966979\" cx=\"229.37110738684834\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"374.2703912119376\" cx=\"234.31691672770685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"414.98957727843845\" cx=\"232.21548895831575\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"373.8804878786788\" cx=\"161.54623227568868\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"414.9247691998802\" cx=\"231.3616805697627\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"58.50762069336956\" cx=\"116.49165166674842\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"239.0481327062669\" cx=\"59.86611496337622\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"167.3535303316988\" cx=\"316.11769710841776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"278.1401606263379\" cx=\"290.38143995856495\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"407.2249805025962\" cx=\"219.12821488199043\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"280.8449364434662\" cx=\"181.82195829307008\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"270.148180674225\" cx=\"335.14716421465016\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"157.2157359989137\" cx=\"229.95610900979486\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"351.9360966843065\" cx=\"177.23577033167294\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"156.53732243936392\" cx=\"231.82052764461255\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"345.8902765202237\" cx=\"246.42326331428885\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"245.3144979867038\" cx=\"77.53368941571506\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"206.9849642241179\" cx=\"273.4504393166759\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"231.2064557250777\" cx=\"299.43309462753075\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"236.1006610462053\" cx=\"398.47022795550095\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.07523496674554\" cx=\"211.14881154846265\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"350.92379186007213\" cx=\"190.3512695184241\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"246.89510829110463\" cx=\"93.78284819684878\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"250.66222894429407\" cx=\"174.79606153371387\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"130.54059131490564\" cx=\"326.10861290846503\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"254.3559638983209\" cx=\"330.5229462837905\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"81.41225488148977\" cx=\"235.69179736885985\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"180.8481479874997\" cx=\"281.4789823209086\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"205.9186526677517\" cx=\"125.03006657014338\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"284.3110423614804\" cx=\"180.4281670545623\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"179.1437768336904\" cx=\"188.71787353949225\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"348.4015840702828\" cx=\"120.24490528108731\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"84.59290527749226\" cx=\"244.2050411793492\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"136.14662196793128\" cx=\"163.08808876658236\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"368.12020564769443\" cx=\"220.0432165928126\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"305.2487601558742\" cx=\"213.6017308436151\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.63946791693087\" cx=\"193.6591488970658\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.7555707490009\" cx=\"292.3210453181685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"95.20887071143349\" cx=\"259.7447860971637\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"77.38737432548263\" cx=\"137.12598128667088\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"164.22500769505208\" cx=\"217.64181006428157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"142.44394428631722\" cx=\"357.5569802621067\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"174.24452563624672\" cx=\"239.5499314526508\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"290.66486572088814\" cx=\"263.07041132980186\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"157.68000709678455\" cx=\"330.5061234339647\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"361.0679263524585\" cx=\"177.18838945090945\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"158.78339814808032\" cx=\"330.37950704040304\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"56.40330304187249\" cx=\"287.4100807582726\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"285.4673413304191\" cx=\"291.3493252070835\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"213.7564662000288\" cx=\"354.823800090439\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"253.43019620916374\" cx=\"59.455949490941215\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"276.64664098481313\" cx=\"240.97041014805896\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"98.35465572370163\" cx=\"243.69036334031588\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"159.29941791430826\" cx=\"305.31864720432776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"155.51444152567345\" cx=\"227.84934855633702\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"264.18194214950444\" cx=\"214.7490442570704\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"95.21908968618071\" cx=\"237.04834016971034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"206.4248462854122\" cx=\"246.43129702172118\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"256.33235481997826\" cx=\"264.5884482696114\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"196.21893094838467\" cx=\"193.123452110377\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"238.6670349976189\" cx=\"56.41136529310532\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"309.92182039076766\" cx=\"173.2882298334705\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.09683765959824\" cx=\"209.82925072275583\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"220.06528898555965\" cx=\"195.30543122291678\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"323.181582931773\" cx=\"132.64186220315224\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"236.44873388538787\" cx=\"383.72064328372613\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"96.36121944228442\" cx=\"263.00046079943536\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"261.2955789969686\" cx=\"229.11426224709263\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"253.1288326003883\" cx=\"262.06375166500453\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"210.70295550798826\" cx=\"401.54738101478927\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"242.42751400398168\" cx=\"37.55574162716959\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"256.90507616087217\" cx=\"197.70939558555034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"304.57497809939537\" cx=\"222.32114968059986\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"280.4453580486322\" cx=\"343.6654598247525\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"416.1352671934863\" cx=\"226.17364577300154\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"115.49696388588801\" cx=\"101.96507139550592\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"321.7842040639588\" cx=\"166.67132281504612\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"218.00837556463395\" cx=\"334.384125457234\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"137.9750273012532\" cx=\"168.2698781335696\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"99.20772035219741\" cx=\"298.8236261830901\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"128.91874112921641\" cx=\"325.2200675601211\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"163.53286994253534\" cx=\"397.8957237880987\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"314.0758940603131\" cx=\"168.53523084450597\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"264.41053951578544\" cx=\"141.52103596178773\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"359.1118827281003\" cx=\"204.43598351922543\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"200.82181539594137\" cx=\"411.89880686051595\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"155.54751034771837\" cx=\"341.29888811917783\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"116.25201426196953\" cx=\"253.36898095390453\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"136.6617022477712\" cx=\"164.6984014001376\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"362.30441130872833\" cx=\"295.23423877348824\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"209.22631777756806\" cx=\"130.08127282326387\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"275.2750348108372\" cx=\"332.2551504086049\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"86.39730151423062\" cx=\"107.0006854710282\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"206.1052451031564\" cx=\"365.03772029101856\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"245.48613693043202\" cx=\"36.139325798334355\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"30.457732720019692\" cx=\"217.43536342457966\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"103.38231438232391\" cx=\"132.07264333344185\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"95.23528621174783\" cx=\"145.6793675374778\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"238.56379382203252\" cx=\"58.46097297119761\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"315.64197391661565\" cx=\"296.6204976386743\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"108.1631683185833\" cx=\"134.2978360727958\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"99.35072006978929\" cx=\"158.45234976580608\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"412.6523988604432\" cx=\"227.62190288499224\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"219.1560969129683\" cx=\"164.11630991868915\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"247.8234884117093\" cx=\"77.33980359913996\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"338.99519362577695\" cx=\"350.2682031244143\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"137.89746198647828\" cx=\"171.71268369034564\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"231.63429451258398\" cx=\"354.2305501478553\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"418.9138613679823\" cx=\"232.22285032863266\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"411.115069485244\" cx=\"323.4673925213775\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"311.55944405844576\" cx=\"173.49572446749124\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"207.16280460211811\" cx=\"287.8072967019553\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"358.47887767730634\" cx=\"211.7278332169326\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"246.7985115093811\" cx=\"309.3134532077724\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"182.91974294351584\" cx=\"142.97519057424594\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"76.3081187344366\" cx=\"151.1896584840813\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"138.83720659593484\" cx=\"171.09257872165196\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"265.2137344487003\" cx=\"294.57082952578514\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"96.90389095394183\" cx=\"263.60697343290076\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"225.94296889992287\" cx=\"183.03974966784662\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"183.77034073348398\" cx=\"113.05652682325017\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"294.6156257455432\" cx=\"189.55138201712097\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"93.0886642024262\" cx=\"258.0926113786157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"261.7357448519881\" cx=\"130.0454404827792\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"186.17804381241618\" cx=\"147.064566046682\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"340.3580532364208\" cx=\"250.93797476669795\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"187.0593754436402\" cx=\"148.014507654596\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"128.61562216429488\" cx=\"275.8577605575732\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"344.5461407084716\" cx=\"266.44102477465395\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"288.4238500528933\" cx=\"188.19050576662968\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"346.31119938650556\" cx=\"270.6062431701535\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"322.83987360199956\" cx=\"334.42442997268864\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"115.58369331350077\" cx=\"110.05118129081465\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"91.06698838864301\" cx=\"288.4250831720773\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"255.78646103483197\" cx=\"31.802810465116284\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"206.35049775005365\" cx=\"268.47736426779215\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"172.65782103198654\" cx=\"84.48722924097396\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"420.04658527206055\" cx=\"278.82467505325775\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"135.9462531458714\" cx=\"370.61273141102123\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"368.2101655899047\" cx=\"205.3257567927608\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"405.5768356861865\" cx=\"181.5026675259074\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"320.7634218859422\" cx=\"237.14732412591113\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.1698915603928\" cx=\"243.16097924286606\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"41.87010790740649\" cx=\"207.90852574310864\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"110.53996998705003\" cx=\"263.8688648781969\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"283.7077767248299\" cx=\"261.13357498271046\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"315.2557516118949\" cx=\"187.50974349110982\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"56.788778152740804\" cx=\"273.0196930488629\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"227.06989449729483\" cx=\"275.58199108528163\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"192.45058237000381\" cx=\"420.1231695948243\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"354.0823011441223\" cx=\"167.33912182663263\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"284.38515739876004\" cx=\"183.6092816996864\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"124.38153831773667\" cx=\"99.11929570315561\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"30.79909042915669\" cx=\"223.73807027734097\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.1027723655224\" cx=\"28.69956056171538\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"329.64296374743145\" cx=\"258.2194173176767\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"174.53944195100826\" cx=\"81.99485426455954\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"202.12539121787017\" cx=\"382.44831499882685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"187.62063889645063\" cx=\"338.2827961810404\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"181.57277768445465\" cx=\"241.2386458735107\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"432.8011843339888\" cx=\"207.6660009031802\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"224.60971478540662\" cx=\"361.1834966132902\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"151.73996980355295\" cx=\"222.78488819682312\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"269.4507081773644\" cx=\"319.34144300867683\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"121.35326052691677\" cx=\"260.86396711266565\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"214.8450891845931\" cx=\"335.1352091130104\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"309.75035038976716\" cx=\"197.3758641826109\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"199.00075014340564\" cx=\"210.88339977624747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"233.85673832712814\" cx=\"255.1695945217647\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"419.33349862131206\" cx=\"321.509393007229\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.2596736769704\" cx=\"165.53973618396387\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"169.61071505489852\" cx=\"240.02783059722088\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"121.75808576093549\" cx=\"108.05865702542329\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"163.3532467380268\" cx=\"157.17114305983606\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"255.54347743985443\" cx=\"63.705691443966955\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"385.2934344495998\" cx=\"298.7117668681151\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"177.97567110306792\" cx=\"80.53982609458262\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"29.66759719730601\" cx=\"215.3290665334844\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"129.63968430356095\" cx=\"318.4727202737135\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"244.63817217468306\" cx=\"125.65631391183028\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"338.5091879773147\" cx=\"139.3614973881485\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"256.9174433179453\" cx=\"164.02169649711817\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"235.54604370415535\" cx=\"253.13364785480627\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"96.76166040649223\" cx=\"198.9942366204426\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"372.9967443496515\" cx=\"147.02502520729712\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"81.9743534333118\" cx=\"255.01966677881998\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"238.08898028589923\" cx=\"264.14398330290385\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"224.15317075704976\" cx=\"88.63675931260752\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"377.05946807665805\" cx=\"162.1651395365894\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"415.0241459822608\" cx=\"321.4441893554547\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"403.8783431898931\" cx=\"179.150020546944\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"347.69346406102426\" cx=\"308.3211138428023\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"275.8402127902645\" cx=\"50.967080132853\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"253.31221100341278\" cx=\"308.8507094620412\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"372.88377523204264\" cx=\"154.432880871157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"32.63567094227637\" cx=\"215.9836406259373\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"149.07959707992308\" cx=\"237.7904492581483\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"188.01509132169366\" cx=\"267.84690022550393\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"134.32476556896353\" cx=\"323.05687542830606\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"175.44535406235008\" cx=\"358.84894436192354\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"120.7273098651419\" cx=\"120.2688814132362\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"242.5476391509499\" cx=\"148.22119465996735\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"265.70308873431765\" cx=\"12.691701442354942\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"223.1789776266056\" cx=\"364.81541913175926\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"238.22367433947278\" cx=\"258.973069452321\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"173.74575725749526\" cx=\"340.3968822933442\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"304.60410767149745\" cx=\"52.34009278937474\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"155.68180745455774\" cx=\"111.02104989948577\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"116.63094043848372\" cx=\"110.2414739840109\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"308.1666400549894\" cx=\"205.63068056048047\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"162.51042306056797\" cx=\"217.19212229495622\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"182.2657230656208\" cx=\"282.97476002620823\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"225.56246970179188\" cx=\"42.613408909485095\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"277.8788570467933\" cx=\"295.79991946054423\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"157.4227471545593\" cx=\"242.6215615956141\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"159.88796493087932\" cx=\"361.91339512571966\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"432.49309872757715\" cx=\"194.92401897862138\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"33.81296276202645\" cx=\"237.73560880052293\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"109.46212087854985\" cx=\"103.1225955425998\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"186.63217559959025\" cx=\"295.05243991629163\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"322.30921213270636\" cx=\"155.4984836921778\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"232.1286808534914\" cx=\"173.10641998812895\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"81.55123293805208\" cx=\"261.81108202030686\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"22.07896457372419\" cx=\"219.90711159275935\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"108.81099637683316\" cx=\"133.86340328237233\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"265.1749215739144\" cx=\"69.27150548669708\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"253.01816961968808\" cx=\"25.194628033734165\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"386.82591805290275\" cx=\"286.5915738454542\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"334.54568719866023\" cx=\"153.53956666793098\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"328.8187429992706\" cx=\"225.47751648832613\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"109.83770665901763\" cx=\"105.04244421769206\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"84.9285711275765\" cx=\"177.61122425440206\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"115.8089283074456\" cx=\"263.2534655825522\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"25.00101996789735\" cx=\"232.48070637771818\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"236.42626038205262\" cx=\"249.2551348827996\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"99.52646445915184\" cx=\"300.15853744720755\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"372.4888722928592\" cx=\"167.11005197012136\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"409.12651194015774\" cx=\"283.7227450251258\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"151.01282931549073\" cx=\"252.08093138070458\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"176.21845796048504\" cx=\"133.54457676433125\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.6953557150065\" cx=\"179.15673979754393\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"247.6485434098874\" cx=\"95.55264276533012\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"339.1097780006846\" cx=\"146.01207757658673\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"316.6914406468663\" cx=\"272.7888595950968\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"119.99351056127665\" cx=\"262.45769039447396\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"167.702524801534\" cx=\"289.22731664231435\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"119.74706844769509\" cx=\"115.75412738176564\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"342.5785375556896\" cx=\"351.90837054763426\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"225.7541111897733\" cx=\"264.14095057491437\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"49.65955986698869\" cx=\"277.3371439506977\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"276.4272681661668\" cx=\"46.30099736996436\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"349.8198678837492\" cx=\"359.09599082347404\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"335.36955632618464\" cx=\"148.4054603556917\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"194.5779091968995\" cx=\"272.6604411457734\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"336.88165692071766\" cx=\"157.50764950300436\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"205.87998263884936\" cx=\"417.86857807381847\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"275.92034108983495\" cx=\"25.442015127776216\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"265.741179138577\" cx=\"124.90341721214709\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"125.28619228648866\" cx=\"314.9122097088812\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"69.68659669515864\" cx=\"148.79940732626983\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"216.94869260667235\" cx=\"133.57857408461933\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"67.88114559651089\" cx=\"165.31101794808907\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"137.016102884892\" cx=\"320.80244872947367\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"278.8772783499598\" cx=\"373.98407007343593\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"305.42055430714896\" cx=\"23.80394644023012\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"70.34923677271954\" cx=\"215.96718793924248\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"405.0998622928234\" cx=\"179.70082328581964\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"17.73510915971994\" cx=\"231.75733138955778\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"177.27937983178293\" cx=\"82.04288344587151\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"47.62095132193079\" cx=\"284.47974579692516\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.8259827814528\" cx=\"179.89308560398734\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"262.2069000226322\" cx=\"299.324636143399\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"249.1931895160649\" cx=\"277.3554666823009\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"256.1584811622831\" cx=\"154.4166623693001\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"265.31062241626336\" cx=\"11.797288424639971\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"410.95981798610035\" cx=\"295.6720833828999\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"321.14951233292436\" cx=\"151.91105766643875\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"261.3289225226357\" cx=\"144.3840850179043\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"171.25095390106029\" cx=\"78.77150393751647\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"184.9338506725064\" cx=\"202.77095679171106\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"134.99370185354613\" cx=\"325.7423780392982\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"328.07647183569554\" cx=\"273.55676060662665\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"103.75982308814734\" cx=\"289.10494167268007\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"276.8117323677053\" cx=\"141.50571299373934\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"357.0237506140254\" cx=\"175.18807459079144\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"184.75819418830298\" cx=\"291.3903109875213\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"118.91245291446874\" cx=\"265.36838129979515\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"154.10570641011594\" cx=\"150.559823513088\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"122.39982638691656\" cx=\"340.5032805003092\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"346.80183104396633\" cx=\"317.7678088027628\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"176.2768324802105\" cx=\"80.31259125826791\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"45.2424355028613\" cx=\"253.8507726488017\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"176.3402011117882\" cx=\"81.50883762795236\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"266.53524292308873\" cx=\"209.40443667966503\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"425.32746572966124\" cx=\"182.9600746292529\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"194.1119514187881\" cx=\"347.225344065326\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"101.65596693873563\" cx=\"254.78043014124972\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"403.00865349817946\" cx=\"284.2875521546631\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"374.47772651785743\" cx=\"153.41463146053744\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"308.16446440230123\" cx=\"144.47450646219997\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"111.40806639775467\" cx=\"102.84006836120115\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"217.3059432938739\" cx=\"100.67542579426076\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"216.51346180222632\" cx=\"132.3829924977007\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"370.5824511308219\" cx=\"235.75460629180725\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"154.8799750516092\" cx=\"239.4079811028959\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"385.73044395999983\" cx=\"305.7857697257975\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"155.3765293191654\" cx=\"254.71231188404352\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"97.19824137924157\" cx=\"191.30175503951014\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"265.14078140774274\" cx=\"36.8955079533395\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"365.95544221116023\" cx=\"277.509833635781\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"202.342819134871\" cx=\"367.95758904435877\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"45.45753942721802\" cx=\"284.808945123742\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"133.175757234159\" cx=\"372.68361213761955\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"165.4138370669361\" cx=\"103.34039156245444\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"352.6193285453903\" cx=\"168.58458959134958\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"245.1142981073716\" cx=\"202.20397538300375\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"146.45666646000416\" cx=\"250.1776281047797\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"230.42901498642908\" cx=\"357.488941668951\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"341.47517397475605\" cx=\"138.80015152425142\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"61.11971150835501\" cx=\"143.07118300800056\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"373.9577675016866\" cx=\"163.53811922867646\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"168.79197739103748\" cx=\"295.66727606951076\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"231.00405658571478\" cx=\"250.28353733929708\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"165.8424681168579\" cx=\"350.4143344632996\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"178.64420632036203\" cx=\"81.17218284482807\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"63.31995566473736\" cx=\"170.32219438937713\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"286.86603328154763\" cx=\"31.543819890070928\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"220.3011762992158\" cx=\"280.37439356181983\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"140.03778229470575\" cx=\"324.69163668424045\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"118.4878160552143\" cx=\"204.3972049823923\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"281.32999711146806\" cx=\"25.149950236613485\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"213.88109648640162\" cx=\"199.67872113004378\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"142.0897029772973\" cx=\"332.5416662865984\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"338.98801836716416\" cx=\"313.09580342977864\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"117.80950688304098\" cx=\"154.1810820369418\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"93.43424135920075\" cx=\"176.0169707946028\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"292.4804753594862\" cx=\"92.40395688281116\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"293.99296053909023\" cx=\"261.96760265018526\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"208.6785408990914\" cx=\"183.19829211638466\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"373.2301984759737\" cx=\"152.57429110382367\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"133.296472993915\" cx=\"355.26732557075854\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"331.66091458009714\" cx=\"219.669603527732\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"405.1203661711872\" cx=\"253.44662318569368\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"225.92521686509485\" cx=\"209.93061361232517\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"183.05265554409917\" cx=\"255.9215379998787\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"273.3814890075742\" cx=\"367.01124605389606\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.33042466856227\" cx=\"281.2626806887589\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"243.37066356483592\" cx=\"202.98831328577012\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"311.41184580221767\" cx=\"185.21986354279142\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.64980776127186\" cx=\"339.1357179636526\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"250.43560669705693\" cx=\"272.77932737940523\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"355.6463097351132\" cx=\"325.5373062912256\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"346.5732336776853\" cx=\"217.84454751832425\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"175.04758321735045\" cx=\"114.12276146260214\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"115.49802973594228\" cx=\"135.39887566108524\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"81.23949926753716\" cx=\"157.70357911452888\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"273.21788102424205\" cx=\"59.97093087747711\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"390.00183255845786\" cx=\"294.7336573508301\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"188.63088893759064\" cx=\"152.2166819283951\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"413.8799834193525\" cx=\"275.12897734185003\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"143.8543605880428\" cx=\"372.9422620801733\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"338.82814085902197\" cx=\"312.4290098334496\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"406.8090242778045\" cx=\"254.52018142361453\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"178.10141393911084\" cx=\"342.8713685698786\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"173.00702427657464\" cx=\"233.6382270910168\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"281.1147942938073\" cx=\"209.3249209691722\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"84.1131518834721\" cx=\"254.73744726547827\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"176.98721055324378\" cx=\"242.02064879548803\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"294.9971066657442\" cx=\"178.80527848918106\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"276.11287536458866\" cx=\"114.39877267408133\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"259.13387301174987\" cx=\"276.09481879541914\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"110.99014329502768\" cx=\"237.21692303564117\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"356.067232601395\" cx=\"220.40832826754396\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"239.7243108650907\" cx=\"360.1351286975285\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"92.57504534585662\" cx=\"143.55423833956002\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"412.4244278184209\" cx=\"302.24814746677004\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"216.7953035980875\" cx=\"64.78933130482389\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"171.6279461640739\" cx=\"186.72488777201553\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"188.0925852135268\" cx=\"152.28448427643573\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"197.84465445514738\" cx=\"298.569481379941\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"125.12397430348506\" cx=\"348.4901674472658\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"285.5297045467394\" cx=\"260.3347121259183\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"417.3378756990618\" cx=\"253.36625589397195\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"272.14671820190716\" cx=\"146.20138683081538\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"301.55306793853896\" cx=\"204.21538552242396\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"302.92369067354724\" cx=\"104.52359500415508\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"243.6227604524812\" cx=\"294.40542498076354\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.4724272947861\" cx=\"80.61788587587759\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"354.27187960790076\" cx=\"199.2818210955266\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"197.8223183036233\" cx=\"213.78241852465982\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"121.72396757105359\" cx=\"346.9389160924916\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"233.09574473817952\" cx=\"218.27303091504908\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"401.92342035631356\" cx=\"251.62653587805315\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"80.07685464492477\" cx=\"114.65818079863249\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"217.46834258126816\" cx=\"49.215163276106864\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"276.0972447284833\" cx=\"327.7472639676903\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"399.56270533196505\" cx=\"214.06988487718627\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"206.77685974805578\" cx=\"339.9674326266282\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"83.32526893046077\" cx=\"260.9381453317784\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"186.97409645115283\" cx=\"402.002520964257\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"97.59092471315739\" cx=\"290.6597696686158\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"405.75688742834575\" cx=\"319.6886024583155\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"296.7357388553189\" cx=\"198.5618064194252\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"109.85670516153156\" cx=\"159.89863137245095\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"201.15127569119926\" cx=\"356.41387256110784\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"244.21252577961687\" cx=\"168.0806732667174\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"156.468553134573\" cx=\"350.9678292976732\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"93.72293288988243\" cx=\"109.74297481480926\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"171.81221735387072\" cx=\"116.8947627501644\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"271.5099771818508\" cx=\"64.52179195305452\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"271.17161099515994\" cx=\"63.046512632046266\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"90.46525559820458\" cx=\"181.91283574537863\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"376.2860674986111\" cx=\"222.8020293594712\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"352.7760854203838\" cx=\"303.33519365254267\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"432.75597910591335\" cx=\"254.54020731767565\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"108.15808080749947\" cx=\"294.5789827292931\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"311.4962951897659\" cx=\"181.70597292968904\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"15.076923076923073\" cx=\"229.7624117085805\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"144.22871569628293\" cx=\"350.12717028475765\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"163.30841510687765\" cx=\"253.73510594162244\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"180.34381960743417\" cx=\"254.88054312933792\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"403.3168379978951\" cx=\"283.667688925157\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"406.04366702181665\" cx=\"235.12143229828567\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"52.52030141267848\" cx=\"277.6010187561464\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"371.08996057883286\" cx=\"229.15971367828945\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"251.20953195902237\" cx=\"158.89517200485264\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"277.94906030449226\" cx=\"72.02295894331597\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"212.79937817738224\" cx=\"372.1477752520834\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"219.60661772102807\" cx=\"81.65067260218595\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"277.70483230210596\" cx=\"135.04752423417125\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"95.20262944513625\" cx=\"140.34044220449834\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"207.74469829695855\" cx=\"261.58763259990656\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"273.6533933999009\" cx=\"66.64409719773568\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"368.5974537446798\" cx=\"253.06682619869702\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"400.2338941862499\" cx=\"241.82673825558695\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"71.66752846769158\" cx=\"267.5254255645445\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"86.60399950774688\" cx=\"260.015215331039\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"52.58636213975411\" cx=\"253.66528177492216\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"106.70570078044094\" cx=\"158.98799435880665\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"261.6050683388898\" cx=\"143.3125156342085\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"201.75360733553416\" cx=\"178.7158240016357\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"126.33424154604852\" cx=\"165.04401701541929\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"257.8892595752981\" cx=\"281.07360218557295\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"181.38940202846635\" cx=\"175.56094080539907\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"173.68010309178055\" cx=\"107.89242836953503\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"270.98231547611243\" cx=\"151.9432694131823\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"217.53142826811495\" cx=\"67.28525545203762\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"165.20791923170702\" cx=\"357.55047528033214\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"302.13989531043484\" cx=\"213.74588294290226\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"350.44619214245034\" cx=\"287.8122029086485\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"205.8590584639435\" cx=\"256.0309854170505\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"199.12602873032696\" cx=\"327.32015477583565\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"81.01351707973984\" cx=\"143.11706400698662\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"146.9057629297826\" cx=\"103.74979885289207\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"63.621657158968176\" cx=\"135.83295683087223\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"74.0883706208754\" cx=\"253.20863919664086\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"198.0800644712599\" cx=\"188.86571628194417\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"347.5298835480544\" cx=\"186.4533652177237\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"66.72464334689172\" cx=\"129.71987273784845\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"274.59019868059954\" cx=\"199.2431071140447\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"84.70720396063278\" cx=\"252.96127682592476\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"355.3636836604106\" cx=\"316.8267675922092\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"351.0269375761498\" cx=\"246.8976819639652\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"250.15648996112836\" cx=\"75.42014172251082\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"183.76320393337824\" cx=\"179.0571597344829\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.307293701157\" cx=\"242.07215847169377\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"150.99475931121995\" cx=\"359.612851182786\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.00837689651536\" cx=\"265.51182329021884\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"291.80857227578343\" cx=\"201.92820316367593\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"347.0296372638153\" cx=\"322.58723112758423\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"107.92147308359401\" cx=\"284.53010995902616\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"80.18917546198517\" cx=\"174.36921605733664\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"353.395443195225\" cx=\"253.22151730245133\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"320.26276354626975\" cx=\"308.18940444408435\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"251.17692189202657\" cx=\"272.06607041241085\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"281.07229764344714\" cx=\"202.94660228776962\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"312.03063768759705\" cx=\"182.9532976908923\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"352.048010940006\" cx=\"304.3527782803965\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"252.8740752081616\" cx=\"278.9104979589171\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"122.0221528589198\" cx=\"277.4280873318756\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"360.036249428784\" cx=\"243.02894706739204\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"182.82353074686344\" cx=\"309.4922358191969\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"203.00406646506718\" cx=\"207.81596298407766\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"203.17620399586974\" cx=\"126.33852387543935\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"200.97852831835533\" cx=\"206.10373255963614\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"216.2651242336513\" cx=\"364.88525978067685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"366.00255937644636\" cx=\"243.63134876115063\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"299.8420984037235\" cx=\"11.796387396759034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"249.7052384414334\" cx=\"250.26408282877023\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"248.29658848399882\" cx=\"324.22384938000494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"102.46738649810025\" cx=\"252.79549318990453\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"398.1236209602228\" cx=\"262.62825112648494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"407.898674653916\" cx=\"210.69794873439318\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"417.2730676205036\" cx=\"299.7389606286747\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"402.0944837959532\" cx=\"207.29624982764875\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"154.05118323517428\" cx=\"138.80071741371322\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"409.0013679580113\" cx=\"206.16343115082077\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"53.19892924105358\" cx=\"230.731315764158\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"86.40757542970229\" cx=\"147.3352919604693\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"279.52903467000766\" cx=\"188.98837144927313\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"76.4586123668431\" cx=\"138.32172220169042\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"256.22508305549457\" cx=\"230.62610118642542\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"244.11620782206992\" cx=\"293.02918730371675\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"152.48022464254078\" cx=\"136.2665710045014\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"88.84302082744425\" cx=\"132.36546640660197\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"224.57187058426862\" cx=\"246.25593172335732\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"249.76800409856028\" cx=\"284.4796853621283\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"146.09578831147095\" cx=\"390.48738464586364\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"102.07276925068389\" cx=\"275.89230179103333\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"268.70524221066273\" cx=\"304.3851603433858\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"89.17037963999203\" cx=\"249.33388142315013\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"16.541466980374288\" cx=\"227.88658051177694\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"238.381181155355\" cx=\"276.80166417987044\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"138.58970412637146\" cx=\"270.3584165503159\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"173.24899421518617\" cx=\"231.6286354895758\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"237.39546420795793\" cx=\"152.00645674036934\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"220.81669335781504\" cx=\"62.81448696455972\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"278.9086879621264\" cx=\"312.4725448635017\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"302.2686598863223\" cx=\"198.78615412067023\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"275.79683159424076\" cx=\"364.89596223379925\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"141.23555601652987\" cx=\"336.27367981686587\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"50.15696022170138\" cx=\"276.0392792170752\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"258.5463231693276\" cx=\"282.94019681645835\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"351.286444594005\" cx=\"304.2995956591313\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"180.07541768629096\" cx=\"230.7871681612518\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"106.42407462692321\" cx=\"186.19245721139512\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"91.7786685568457\" cx=\"116.16573230118118\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"59.62830159064898\" cx=\"146.8197446844716\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"144.87198367440362\" cx=\"337.12926073054143\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"162.2102599066217\" cx=\"142.00697018730824\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"114.18185875293389\" cx=\"274.66094829842694\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"36.890104833169914\" cx=\"258.4604010702843\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"315.2253474149856\" cx=\"179.20206589521308\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"236.54633264857353\" cx=\"226.57246139313693\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"146.09938692892226\" cx=\"337.3551000724551\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"201.53717659268204\" cx=\"246.80399704063737\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"268.29619752900646\" cx=\"70.65536344222475\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"378.1386797151245\" cx=\"279.09145622302975\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"209.63622228156194\" cx=\"366.152632412231\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"169.19251724854928\" cx=\"232.0564843209333\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"360.0811140243678\" cx=\"219.0710792756013\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"250.20719612923904\" cx=\"154.50047993851715\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"174.5703900610895\" cx=\"245.0939711127643\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"374.7690991558921\" cx=\"276.01826438997404\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"267.2945951578945\" cx=\"15.915842915830048\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"270.5912446524591\" cx=\"123.63181414481048\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"193.20680847758854\" cx=\"242.5728538963552\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"404.56295955723294\" cx=\"194.44737522960494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"93.19061221071092\" cx=\"126.08629100950102\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"348.97900009608077\" cx=\"322.582088675776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"307.73861884710897\" cx=\"139.0436982616546\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"237.34000566718257\" cx=\"124.10964461347498\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"179.13690374906201\" cx=\"181.94653089168227\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"179.9475706205017\" cx=\"386.9547290283262\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"302.561675252018\" cx=\"206.70735805803182\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.76735633953524\" cx=\"337.34756220506097\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"434.65560959440893\" cx=\"241.983650338127\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"80.90969009867902\" cx=\"106.85229057429561\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"159.013374526545\" cx=\"335.2579027388465\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"54.10512155009009\" cx=\"260.70167221264785\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"228.3190240612962\" cx=\"47.69051422011012\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"265.56846198313156\" cx=\"189.38398037676578\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"315.2236442525277\" cx=\"178.48671019254485\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"191.37149160113114\" cx=\"261.94721689437904\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"115.05246046067333\" cx=\"278.64138730242854\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"222.9347750343043\" cx=\"348.45236822884596\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"106.05158750331428\" cx=\"155.24565197234304\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"244.61289120032856\" cx=\"151.55689327443307\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"255.045500207535\" cx=\"105.15873175505756\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"396.53591094070526\" cx=\"312.9080709743417\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"210.2181187234386\" cx=\"158.91050596104594\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"384.0618611940956\" cx=\"302.14242503071574\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"188.85321756721217\" cx=\"364.46940244918915\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"76.0032636426225\" cx=\"231.4968189564452\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"434.8664501185485\" cx=\"254.45692816755817\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"301.36125888134796\" cx=\"138.75550119749295\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"183.93307241226114\" cx=\"291.47124416870486\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"289.225264906336\" cx=\"189.56907293039308\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"55.28265510902774\" cx=\"259.17557546856193\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"352.84149784691095\" cx=\"265.7275343095807\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"295.687491809151\" cx=\"238.64860689180034\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"220.6482155660197\" cx=\"149.8162337721262\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"265.5858369872381\" cx=\"295.04928082463584\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"340.5293144626685\" cx=\"229.38215527977565\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"341.5568818201543\" cx=\"299.4602957802047\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"224.57131259253597\" cx=\"303.0773018919863\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"91.16649702876227\" cx=\"150.78102585785837\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"286.8538913814447\" cx=\"242.31439624633694\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"245.30119134324266\" cx=\"89.15513603591425\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"276.9643027594959\" cx=\"12.699656859254935\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"214.73918681766628\" cx=\"152.8656692359308\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"208.35261466593357\" cx=\"348.6045100829859\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"254.32391147967823\" cx=\"361.8135678293986\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"173.71740784368038\" cx=\"284.20922316381836\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"408.0614420441641\" cx=\"244.7647319539223\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"63.681938121831934\" cx=\"288.4282312755882\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"187.6093870360838\" cx=\"233.16558096646293\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"85.83909276569948\" cx=\"149.08317616804098\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"68.43711276348458\" cx=\"263.3669538900071\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"153.848166270196\" cx=\"357.57379212378765\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"306.6682856297132\" cx=\"223.0038891354408\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"199.63854053129896\" cx=\"356.1110063235187\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"244.56756510265942\" cx=\"246.55893531275754\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"207.17795862743884\" cx=\"183.95909753335206\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"314.60498422488706\" cx=\"79.97055228414776\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"55.43466510542899\" cx=\"128.01950126877892\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"121.03716456288073\" cx=\"182.71409676479294\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"338.3735503167988\" cx=\"286.5256229998275\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"259.7962850853043\" cx=\"91.1104544427098\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"204.5269931293525\" cx=\"178.57521969962974\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"215.09486207959426\" cx=\"147.1623165836189\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"354.4772150714507\" cx=\"287.25582368624146\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"194.12354940571896\" cx=\"373.86869455209626\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"347.75737111170156\" cx=\"304.37400737632294\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"423.9140826288155\" cx=\"257.9030439029822\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"30.856866094985644\" cx=\"236.63368191953364\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"186.13327536310015\" cx=\"399.3454886366735\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"233.18947704788215\" cx=\"217.8692303255413\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"129.4671154880715\" cx=\"277.0494193767663\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"109.26202676011219\" cx=\"279.8477537535562\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"310.1197333624448\" cx=\"171.3684745576098\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"29.0320648731875\" cx=\"233.42616207548107\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"241.5301135843749\" cx=\"263.2039749779699\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"187.73712696746037\" cx=\"152.74470074884238\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"349.62341084127\" cx=\"184.44020521622986\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"173.25391690409668\" cx=\"130.67622592830548\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"110.46122894077192\" cx=\"154.9838264559162\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"82.68240751370097\" cx=\"299.30758254253055\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"280.3524532835916\" cx=\"198.97931746671884\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"199.20459121925063\" cx=\"210.5922881066539\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"259.4224491669102\" cx=\"282.4905729157251\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"106.3794297942372\" cx=\"294.63776381037945\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"345.29002712934545\" cx=\"235.575555157592\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"127.88337218885904\" cx=\"196.70628234451607\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"350.30936776228634\" cx=\"211.84241209776778\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"121.13459644361585\" cx=\"285.5375360469296\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"117.72853524335031\" cx=\"158.79970150798027\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"149.47701630428625\" cx=\"359.0811458397283\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"244.80768353885705\" cx=\"48.9199887399404\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"274.50430160496217\" cx=\"110.58710608150992\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"407.1931038942718\" cx=\"246.1752595106149\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"341.5248623659463\" cx=\"337.5110877773064\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"112.23995687104842\" cx=\"329.84740612412935\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"239.77471897977122\" cx=\"320.5184601248047\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"251.97771316824685\" cx=\"24.674031705159752\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"68.0102782752522\" cx=\"103.46404115689592\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"128.1696573158099\" cx=\"276.10314780924534\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"25.973207075140152\" cx=\"239.14879686179685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"294.2467866860375\" cx=\"179.45446083628855\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"189.1741428209272\" cx=\"168.45479212984245\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"144.53455422706466\" cx=\"354.5572496717097\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"410.4427048994559\" cx=\"276.97511754102356\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"158.62282838681017\" cx=\"95.76043957333532\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"191.19324466177\" cx=\"341.3070193463961\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"357.3067942382339\" cx=\"245.7364520650073\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"73.17362953511487\" cx=\"162.37505156248582\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"119.2983016222633\" cx=\"158.19696330228447\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"330.45111982776393\" cx=\"243.58983554975813\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"157.98038451955617\" cx=\"301.4524629308872\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"91.51696391001265\" cx=\"113.72537520267362\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"122.77464299724207\" cx=\"275.2017683076704\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"405.23392864862006\" cx=\"297.11473890173124\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"317.4093455991489\" cx=\"169.46127323728535\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"398.2764440793459\" cx=\"279.51678533541224\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"121.55961788794144\" cx=\"343.0790884608695\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"288.6716876608758\" cx=\"106.38692066193579\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"333.3654066035002\" cx=\"218.2629657743303\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"172.82551660521753\" cx=\"342.10700024693074\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"339.4422572887509\" cx=\"233.79693710876438\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"319.119793197082\" cx=\"300.26273253112214\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"144.44395147837832\" cx=\"358.55306658448416\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"235.95507018669664\" cx=\"120.57759334390651\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"261.4644667839201\" cx=\"298.47394495419934\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"307.6386541989768\" cx=\"170.99398759163097\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"272.0003039182909\" cx=\"105.75278383221823\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"277.4743504689764\" cx=\"249.10658889907478\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"217.9027877333546\" cx=\"175.35720961100296\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"295.63348507701915\" cx=\"339.346481570778\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"343.72009592825907\" cx=\"238.9210634384078\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.08395965627807\" cx=\"305.5766708226229\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"100.4898170979035\" cx=\"283.6205772539433\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"154.94590392094617\" cx=\"133.65272208633363\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"290.24380550279517\" cx=\"212.20945459558396\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"195.83235152895494\" cx=\"158.53833199956637\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.96770779638425\" cx=\"295.15647567210533\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"114.7290134277062\" cx=\"103.42719790708144\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"68.90055975048872\" cx=\"275.9898435532173\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"262.2726173701801\" cx=\"220.73823220915176\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"203.32311274600605\" cx=\"359.7899690902598\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"348.90987367658096\" cx=\"298.38125995205644\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"198.4259520431276\" cx=\"410.43487829317854\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"330.52747644660104\" cx=\"320.41955583265434\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"106.59893996469461\" cx=\"134.4375997817177\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"258.47116700531967\" cx=\"345.20842611828\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"176.68048747679848\" cx=\"263.69599388872297\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"262.2804848819209\" cx=\"341.471292112494\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"420.3382545900073\" cx=\"225.94618902766695\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"310.59933292243653\" cx=\"256.31704803406734\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"115.43949588811596\" cx=\"164.71025211440093\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"173.46223564898415\" cx=\"233.12114422177078\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"131.75057286570197\" cx=\"338.7709445177561\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"169.6809073244526\" cx=\"147.34252765387902\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"395.21244382949027\" cx=\"260.9203198137314\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a640bf\" cy=\"263.5069568911602\" cx=\"383.88004830163806\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"281.52982751442835\" cx=\"197.48989915027406\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"430.4279208481765\" cx=\"266.74208895648115\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"268.93263362804214\" cx=\"79.2370716364843\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"183.50055980015713\" cx=\"284.1138955128295\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"416.90498674299533\" cx=\"281.1004627057553\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"52.91103984494886\" cx=\"229.4524103877833\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"115.74486742273986\" cx=\"351.4314740712853\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"298.38581758522923\" cx=\"244.09054196256443\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#5940bf\" cy=\"299.2119832350355\" cx=\"221.12040469572173\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf408c\" cy=\"337.86395312125876\" cx=\"321.5097775923001\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"75.49934731799033\" cx=\"282.3248387263569\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"95.121416066258\" cx=\"262.45331985984416\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"216.30291383744438\" cx=\"153.90067556750685\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"226.00725504159888\" cx=\"182.54236579535126\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf8c40\" cy=\"252.05606688241764\" cx=\"92.59124981245257\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#4073bf\" cy=\"52.37112635765872\" cx=\"277.72951961655656\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"176.01562779396988\" cx=\"263.2938607502022\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bf73\" cy=\"389.78736594650474\" cx=\"214.16040384126782\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"158.14576159421551\" cx=\"295.81579732990957\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#59bf40\" cy=\"235.3706821829663\" cx=\"367.85698158975055\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"83.76014674075223\" cx=\"106.86505879865719\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"189.30984915734862\" cx=\"300.4257581427751\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#40bfbf\" cy=\"182.44002251393036\" cx=\"398.0825662037996\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#a6bf40\" cy=\"180.871585700549\" cx=\"167.39762820409675\"></circle><circle r=\"3.1\" class=\"highlight\" fill=\"#bf4040\" cy=\"103.20168026848553\" cx=\"134.4378085564706\"></circle></g></svg>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMcAWquml1GM",
        "colab_type": "text"
      },
      "source": [
        "It's clear that in order to improve the accuracy, we will need to add some hidden layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx6JTUhGJA07",
        "colab_type": "text"
      },
      "source": [
        "#### Multi-Layer Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVl2dGLwkDuO",
        "colab_type": "text"
      },
      "source": [
        "##### Single Hidden Layer\n",
        "\n",
        "Let us start by adding a simple hidden layer, with ReLU activation. Here we will evaluate the impact of its size, by comparing the performances of the same NN, with a differently sized hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8RMyfkXkGdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_multi_layer_single_hidden_model(size, name='multi_layer_single_hidden_model'):\n",
        "  multi_layer_model = tf.keras.Sequential(name=name)\n",
        "  multi_layer_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  multi_layer_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "  multi_layer_model.add(tf.keras.layers.Dense(size, activation='relu', name='hidden'))\n",
        "  multi_layer_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "\n",
        "  multi_layer_model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "  multi_layer_model.summary()\n",
        "  return multi_layer_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8GUe5IS72K_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fc204768-65bf-452d-afdc-1e48ebd9babe"
      },
      "source": [
        "hidden_layer_sizes = (8, 16, 32, 64, 128, 256, 512)\n",
        "accuracy_lines = test_model_parameter(create_multi_layer_single_hidden_model, hidden_layer_sizes, 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 8)                 6280      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                90        \n",
            "=================================================================\n",
            "Total params: 6,370\n",
            "Trainable params: 6,370\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.3069 - accuracy: 0.5908 - val_loss: 0.7748 - val_accuracy: 0.7745\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.5769 - accuracy: 0.8334 - val_loss: 0.4728 - val_accuracy: 0.8623\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4207 - accuracy: 0.8814 - val_loss: 0.3863 - val_accuracy: 0.8901\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3607 - accuracy: 0.8988 - val_loss: 0.3499 - val_accuracy: 0.9031\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3329 - accuracy: 0.9057 - val_loss: 0.3325 - val_accuracy: 0.9063\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3162 - accuracy: 0.9107 - val_loss: 0.3229 - val_accuracy: 0.9103\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3044 - accuracy: 0.9131 - val_loss: 0.3139 - val_accuracy: 0.9126\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2957 - accuracy: 0.9165 - val_loss: 0.3089 - val_accuracy: 0.9134\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2888 - accuracy: 0.9188 - val_loss: 0.3067 - val_accuracy: 0.9132\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2827 - accuracy: 0.9204 - val_loss: 0.3015 - val_accuracy: 0.9158\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2776 - accuracy: 0.9221 - val_loss: 0.3034 - val_accuracy: 0.9141\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2731 - accuracy: 0.9229 - val_loss: 0.2957 - val_accuracy: 0.9178\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2688 - accuracy: 0.9243 - val_loss: 0.2957 - val_accuracy: 0.9172\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2651 - accuracy: 0.9254 - val_loss: 0.2933 - val_accuracy: 0.9180\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2623 - accuracy: 0.9258 - val_loss: 0.2904 - val_accuracy: 0.9190\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2595 - accuracy: 0.9267 - val_loss: 0.2931 - val_accuracy: 0.9176\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2564 - accuracy: 0.9275 - val_loss: 0.2872 - val_accuracy: 0.9194\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2543 - accuracy: 0.9284 - val_loss: 0.2853 - val_accuracy: 0.9188\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2524 - accuracy: 0.9290 - val_loss: 0.2837 - val_accuracy: 0.9212\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2494 - accuracy: 0.9294 - val_loss: 0.2849 - val_accuracy: 0.9196\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2472 - accuracy: 0.9297 - val_loss: 0.2868 - val_accuracy: 0.9206\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2457 - accuracy: 0.9303 - val_loss: 0.2811 - val_accuracy: 0.9216\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2436 - accuracy: 0.9309 - val_loss: 0.2827 - val_accuracy: 0.9197\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2418 - accuracy: 0.9318 - val_loss: 0.2804 - val_accuracy: 0.9210\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2406 - accuracy: 0.9322 - val_loss: 0.2812 - val_accuracy: 0.9205\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2383 - accuracy: 0.9321 - val_loss: 0.2805 - val_accuracy: 0.9208\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2372 - accuracy: 0.9328 - val_loss: 0.2803 - val_accuracy: 0.9215\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2362 - accuracy: 0.9326 - val_loss: 0.2770 - val_accuracy: 0.9208\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2346 - accuracy: 0.9336 - val_loss: 0.2772 - val_accuracy: 0.9214\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2335 - accuracy: 0.9334 - val_loss: 0.2769 - val_accuracy: 0.9220\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2327 - accuracy: 0.9339 - val_loss: 0.2760 - val_accuracy: 0.9226\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2308 - accuracy: 0.9345 - val_loss: 0.2774 - val_accuracy: 0.9211\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2297 - accuracy: 0.9345 - val_loss: 0.2772 - val_accuracy: 0.9201\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2287 - accuracy: 0.9350 - val_loss: 0.2751 - val_accuracy: 0.9214\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2275 - accuracy: 0.9350 - val_loss: 0.2761 - val_accuracy: 0.9215\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2264 - accuracy: 0.9358 - val_loss: 0.2740 - val_accuracy: 0.9233\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2255 - accuracy: 0.9360 - val_loss: 0.2740 - val_accuracy: 0.9212\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2244 - accuracy: 0.9369 - val_loss: 0.2757 - val_accuracy: 0.9224\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2239 - accuracy: 0.9359 - val_loss: 0.2736 - val_accuracy: 0.9227\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2228 - accuracy: 0.9365 - val_loss: 0.2730 - val_accuracy: 0.9230\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2225 - accuracy: 0.9370 - val_loss: 0.2735 - val_accuracy: 0.9219\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2216 - accuracy: 0.9370 - val_loss: 0.2739 - val_accuracy: 0.9233\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2206 - accuracy: 0.9369 - val_loss: 0.2736 - val_accuracy: 0.9224\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2199 - accuracy: 0.9383 - val_loss: 0.2734 - val_accuracy: 0.9226\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2196 - accuracy: 0.9379 - val_loss: 0.2730 - val_accuracy: 0.9228\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2189 - accuracy: 0.9374 - val_loss: 0.2730 - val_accuracy: 0.9220\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2172 - accuracy: 0.9385 - val_loss: 0.2730 - val_accuracy: 0.9231\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2162 - accuracy: 0.9389 - val_loss: 0.2720 - val_accuracy: 0.9230\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2165 - accuracy: 0.9387 - val_loss: 0.2705 - val_accuracy: 0.9225\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2148 - accuracy: 0.9391 - val_loss: 0.2715 - val_accuracy: 0.9237\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2227 - accuracy: 0.6395 - val_loss: 0.7274 - val_accuracy: 0.8028\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.5777 - accuracy: 0.8409 - val_loss: 0.4898 - val_accuracy: 0.8665\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4367 - accuracy: 0.8785 - val_loss: 0.4052 - val_accuracy: 0.8883\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3740 - accuracy: 0.8955 - val_loss: 0.3681 - val_accuracy: 0.8979\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3419 - accuracy: 0.9043 - val_loss: 0.3427 - val_accuracy: 0.9046\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3213 - accuracy: 0.9090 - val_loss: 0.3285 - val_accuracy: 0.9080\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3085 - accuracy: 0.9128 - val_loss: 0.3199 - val_accuracy: 0.9120\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2984 - accuracy: 0.9155 - val_loss: 0.3129 - val_accuracy: 0.9127\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2905 - accuracy: 0.9178 - val_loss: 0.3074 - val_accuracy: 0.9147\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2840 - accuracy: 0.9199 - val_loss: 0.3065 - val_accuracy: 0.9134\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2786 - accuracy: 0.9214 - val_loss: 0.3019 - val_accuracy: 0.9158\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2732 - accuracy: 0.9228 - val_loss: 0.2969 - val_accuracy: 0.9178\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2695 - accuracy: 0.9238 - val_loss: 0.2941 - val_accuracy: 0.9184\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2653 - accuracy: 0.9257 - val_loss: 0.2930 - val_accuracy: 0.9197\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2621 - accuracy: 0.9257 - val_loss: 0.2917 - val_accuracy: 0.9192\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2590 - accuracy: 0.9276 - val_loss: 0.2895 - val_accuracy: 0.9212\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2567 - accuracy: 0.9271 - val_loss: 0.2868 - val_accuracy: 0.9218\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2538 - accuracy: 0.9287 - val_loss: 0.2913 - val_accuracy: 0.9190\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2520 - accuracy: 0.9286 - val_loss: 0.2869 - val_accuracy: 0.9206\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2495 - accuracy: 0.9298 - val_loss: 0.2868 - val_accuracy: 0.9189\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2476 - accuracy: 0.9300 - val_loss: 0.2861 - val_accuracy: 0.9205\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2459 - accuracy: 0.9308 - val_loss: 0.2858 - val_accuracy: 0.9205\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2447 - accuracy: 0.9308 - val_loss: 0.2818 - val_accuracy: 0.9224\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2423 - accuracy: 0.9313 - val_loss: 0.2808 - val_accuracy: 0.9222\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2406 - accuracy: 0.9321 - val_loss: 0.2809 - val_accuracy: 0.9227\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2396 - accuracy: 0.9324 - val_loss: 0.2812 - val_accuracy: 0.9233\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2381 - accuracy: 0.9327 - val_loss: 0.2800 - val_accuracy: 0.9229\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2369 - accuracy: 0.9332 - val_loss: 0.2792 - val_accuracy: 0.9233\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2354 - accuracy: 0.9332 - val_loss: 0.2803 - val_accuracy: 0.9225\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2343 - accuracy: 0.9334 - val_loss: 0.2778 - val_accuracy: 0.9223\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2325 - accuracy: 0.9341 - val_loss: 0.2789 - val_accuracy: 0.9217\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2325 - accuracy: 0.9341 - val_loss: 0.2814 - val_accuracy: 0.9225\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2309 - accuracy: 0.9342 - val_loss: 0.2779 - val_accuracy: 0.9236\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2301 - accuracy: 0.9353 - val_loss: 0.2773 - val_accuracy: 0.9218\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2285 - accuracy: 0.9354 - val_loss: 0.2785 - val_accuracy: 0.9227\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2279 - accuracy: 0.9352 - val_loss: 0.2780 - val_accuracy: 0.9237\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2266 - accuracy: 0.9363 - val_loss: 0.2783 - val_accuracy: 0.9238\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2263 - accuracy: 0.9361 - val_loss: 0.2777 - val_accuracy: 0.9215\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2252 - accuracy: 0.9367 - val_loss: 0.2772 - val_accuracy: 0.9240\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2248 - accuracy: 0.9363 - val_loss: 0.2764 - val_accuracy: 0.9233\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2236 - accuracy: 0.9366 - val_loss: 0.2771 - val_accuracy: 0.9227\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2230 - accuracy: 0.9370 - val_loss: 0.2766 - val_accuracy: 0.9236\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2219 - accuracy: 0.9376 - val_loss: 0.2780 - val_accuracy: 0.9228\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2216 - accuracy: 0.9377 - val_loss: 0.2790 - val_accuracy: 0.9208\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2208 - accuracy: 0.9375 - val_loss: 0.2763 - val_accuracy: 0.9227\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2196 - accuracy: 0.9379 - val_loss: 0.2759 - val_accuracy: 0.9226\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2194 - accuracy: 0.9377 - val_loss: 0.2783 - val_accuracy: 0.9230\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2186 - accuracy: 0.9385 - val_loss: 0.2768 - val_accuracy: 0.9227\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2177 - accuracy: 0.9382 - val_loss: 0.2780 - val_accuracy: 0.9219\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2173 - accuracy: 0.9385 - val_loss: 0.2757 - val_accuracy: 0.9225\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2074 - accuracy: 0.6413 - val_loss: 0.7301 - val_accuracy: 0.8095\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.5825 - accuracy: 0.8382 - val_loss: 0.4947 - val_accuracy: 0.8594\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4528 - accuracy: 0.8697 - val_loss: 0.4256 - val_accuracy: 0.8810\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3969 - accuracy: 0.8867 - val_loss: 0.3847 - val_accuracy: 0.8932\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3598 - accuracy: 0.8982 - val_loss: 0.3593 - val_accuracy: 0.9007\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3326 - accuracy: 0.9072 - val_loss: 0.3377 - val_accuracy: 0.9086\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3138 - accuracy: 0.9131 - val_loss: 0.3224 - val_accuracy: 0.9117\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3003 - accuracy: 0.9167 - val_loss: 0.3143 - val_accuracy: 0.9143\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2906 - accuracy: 0.9196 - val_loss: 0.3099 - val_accuracy: 0.9149\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2838 - accuracy: 0.9213 - val_loss: 0.3023 - val_accuracy: 0.9175\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.9232 - val_loss: 0.3000 - val_accuracy: 0.9175\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2730 - accuracy: 0.9245 - val_loss: 0.2957 - val_accuracy: 0.9194\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2690 - accuracy: 0.9255 - val_loss: 0.2943 - val_accuracy: 0.9192\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2652 - accuracy: 0.9262 - val_loss: 0.2926 - val_accuracy: 0.9194\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2626 - accuracy: 0.9275 - val_loss: 0.2904 - val_accuracy: 0.9218\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2595 - accuracy: 0.9284 - val_loss: 0.2889 - val_accuracy: 0.9213\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2570 - accuracy: 0.9292 - val_loss: 0.2902 - val_accuracy: 0.9202\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2551 - accuracy: 0.9288 - val_loss: 0.2883 - val_accuracy: 0.9198\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2526 - accuracy: 0.9300 - val_loss: 0.2858 - val_accuracy: 0.9217\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2509 - accuracy: 0.9311 - val_loss: 0.2896 - val_accuracy: 0.9203\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2491 - accuracy: 0.9305 - val_loss: 0.2865 - val_accuracy: 0.9214\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2475 - accuracy: 0.9317 - val_loss: 0.2837 - val_accuracy: 0.9217\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2452 - accuracy: 0.9321 - val_loss: 0.2860 - val_accuracy: 0.9214\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2436 - accuracy: 0.9314 - val_loss: 0.2845 - val_accuracy: 0.9219\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2423 - accuracy: 0.9323 - val_loss: 0.2828 - val_accuracy: 0.9218\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2410 - accuracy: 0.9323 - val_loss: 0.2827 - val_accuracy: 0.9234\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2394 - accuracy: 0.9336 - val_loss: 0.2829 - val_accuracy: 0.9227\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2384 - accuracy: 0.9329 - val_loss: 0.2809 - val_accuracy: 0.9237\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2369 - accuracy: 0.9343 - val_loss: 0.2827 - val_accuracy: 0.9217\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2361 - accuracy: 0.9334 - val_loss: 0.2812 - val_accuracy: 0.9219\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2356 - accuracy: 0.9337 - val_loss: 0.2814 - val_accuracy: 0.9231\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2341 - accuracy: 0.9346 - val_loss: 0.2783 - val_accuracy: 0.9236\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2327 - accuracy: 0.9349 - val_loss: 0.2808 - val_accuracy: 0.9228\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2325 - accuracy: 0.9356 - val_loss: 0.2803 - val_accuracy: 0.9237\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2313 - accuracy: 0.9354 - val_loss: 0.2800 - val_accuracy: 0.9215\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2307 - accuracy: 0.9350 - val_loss: 0.2805 - val_accuracy: 0.9220\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2293 - accuracy: 0.9360 - val_loss: 0.2782 - val_accuracy: 0.9233\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2286 - accuracy: 0.9364 - val_loss: 0.2790 - val_accuracy: 0.9236\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2272 - accuracy: 0.9367 - val_loss: 0.2795 - val_accuracy: 0.9216\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2265 - accuracy: 0.9367 - val_loss: 0.2777 - val_accuracy: 0.9233\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2264 - accuracy: 0.9367 - val_loss: 0.2789 - val_accuracy: 0.9220\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2249 - accuracy: 0.9370 - val_loss: 0.2772 - val_accuracy: 0.9237\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2245 - accuracy: 0.9366 - val_loss: 0.2775 - val_accuracy: 0.9223\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2239 - accuracy: 0.9373 - val_loss: 0.2810 - val_accuracy: 0.9227\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2232 - accuracy: 0.9370 - val_loss: 0.2778 - val_accuracy: 0.9239\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2223 - accuracy: 0.9375 - val_loss: 0.2772 - val_accuracy: 0.9228\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2210 - accuracy: 0.9380 - val_loss: 0.2778 - val_accuracy: 0.9236\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2212 - accuracy: 0.9382 - val_loss: 0.2777 - val_accuracy: 0.9233\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2210 - accuracy: 0.9381 - val_loss: 0.2771 - val_accuracy: 0.9234\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2203 - accuracy: 0.9380 - val_loss: 0.2778 - val_accuracy: 0.9235\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 16)                12560     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 12,730\n",
            "Trainable params: 12,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.9972 - accuracy: 0.7194 - val_loss: 0.4706 - val_accuracy: 0.8763\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3888 - accuracy: 0.8945 - val_loss: 0.3470 - val_accuracy: 0.9057\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3185 - accuracy: 0.9107 - val_loss: 0.3091 - val_accuracy: 0.9135\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2884 - accuracy: 0.9192 - val_loss: 0.2913 - val_accuracy: 0.9202\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2698 - accuracy: 0.9242 - val_loss: 0.2785 - val_accuracy: 0.9239\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2557 - accuracy: 0.9287 - val_loss: 0.2677 - val_accuracy: 0.9259\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2446 - accuracy: 0.9316 - val_loss: 0.2602 - val_accuracy: 0.9278\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2348 - accuracy: 0.9341 - val_loss: 0.2542 - val_accuracy: 0.9295\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2271 - accuracy: 0.9365 - val_loss: 0.2480 - val_accuracy: 0.9299\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2199 - accuracy: 0.9384 - val_loss: 0.2434 - val_accuracy: 0.9332\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2131 - accuracy: 0.9411 - val_loss: 0.2405 - val_accuracy: 0.9329\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2076 - accuracy: 0.9426 - val_loss: 0.2391 - val_accuracy: 0.9342\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2024 - accuracy: 0.9433 - val_loss: 0.2335 - val_accuracy: 0.9362\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1978 - accuracy: 0.9445 - val_loss: 0.2285 - val_accuracy: 0.9371\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1926 - accuracy: 0.9465 - val_loss: 0.2279 - val_accuracy: 0.9374\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1887 - accuracy: 0.9471 - val_loss: 0.2262 - val_accuracy: 0.9377\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1844 - accuracy: 0.9480 - val_loss: 0.2258 - val_accuracy: 0.9381\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1814 - accuracy: 0.9494 - val_loss: 0.2212 - val_accuracy: 0.9399\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1778 - accuracy: 0.9503 - val_loss: 0.2192 - val_accuracy: 0.9402\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1748 - accuracy: 0.9508 - val_loss: 0.2168 - val_accuracy: 0.9395\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1713 - accuracy: 0.9519 - val_loss: 0.2199 - val_accuracy: 0.9406\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1684 - accuracy: 0.9527 - val_loss: 0.2161 - val_accuracy: 0.9421\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1655 - accuracy: 0.9533 - val_loss: 0.2125 - val_accuracy: 0.9414\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1627 - accuracy: 0.9542 - val_loss: 0.2117 - val_accuracy: 0.9422\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1609 - accuracy: 0.9547 - val_loss: 0.2175 - val_accuracy: 0.9402\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1586 - accuracy: 0.9552 - val_loss: 0.2130 - val_accuracy: 0.9427\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1559 - accuracy: 0.9557 - val_loss: 0.2087 - val_accuracy: 0.9432\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1534 - accuracy: 0.9565 - val_loss: 0.2070 - val_accuracy: 0.9445\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1512 - accuracy: 0.9574 - val_loss: 0.2044 - val_accuracy: 0.9445\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1493 - accuracy: 0.9580 - val_loss: 0.2066 - val_accuracy: 0.9441\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1472 - accuracy: 0.9587 - val_loss: 0.2051 - val_accuracy: 0.9446\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1452 - accuracy: 0.9591 - val_loss: 0.2030 - val_accuracy: 0.9457\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1440 - accuracy: 0.9597 - val_loss: 0.2072 - val_accuracy: 0.9439\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1421 - accuracy: 0.9597 - val_loss: 0.2022 - val_accuracy: 0.9439\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1402 - accuracy: 0.9603 - val_loss: 0.2051 - val_accuracy: 0.9441\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1381 - accuracy: 0.9607 - val_loss: 0.2014 - val_accuracy: 0.9444\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1367 - accuracy: 0.9615 - val_loss: 0.2001 - val_accuracy: 0.9457\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1355 - accuracy: 0.9621 - val_loss: 0.1990 - val_accuracy: 0.9455\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1346 - accuracy: 0.9623 - val_loss: 0.2000 - val_accuracy: 0.9459\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1327 - accuracy: 0.9622 - val_loss: 0.2018 - val_accuracy: 0.9445\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1307 - accuracy: 0.9628 - val_loss: 0.2009 - val_accuracy: 0.9446\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1297 - accuracy: 0.9635 - val_loss: 0.1990 - val_accuracy: 0.9461\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1285 - accuracy: 0.9631 - val_loss: 0.1994 - val_accuracy: 0.9455\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1273 - accuracy: 0.9632 - val_loss: 0.1968 - val_accuracy: 0.9474\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1263 - accuracy: 0.9644 - val_loss: 0.1969 - val_accuracy: 0.9457\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1253 - accuracy: 0.9646 - val_loss: 0.1959 - val_accuracy: 0.9469\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1240 - accuracy: 0.9652 - val_loss: 0.2061 - val_accuracy: 0.9440\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1234 - accuracy: 0.9650 - val_loss: 0.1984 - val_accuracy: 0.9458\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1213 - accuracy: 0.9655 - val_loss: 0.2007 - val_accuracy: 0.9465\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1211 - accuracy: 0.9653 - val_loss: 0.1974 - val_accuracy: 0.9460\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.8098 - accuracy: 0.7596 - val_loss: 0.3819 - val_accuracy: 0.8967\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3346 - accuracy: 0.9058 - val_loss: 0.3104 - val_accuracy: 0.9150\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2872 - accuracy: 0.9179 - val_loss: 0.2868 - val_accuracy: 0.9196\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2640 - accuracy: 0.9246 - val_loss: 0.2714 - val_accuracy: 0.9258\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2483 - accuracy: 0.9299 - val_loss: 0.2596 - val_accuracy: 0.9286\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2351 - accuracy: 0.9334 - val_loss: 0.2526 - val_accuracy: 0.9308\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2260 - accuracy: 0.9364 - val_loss: 0.2436 - val_accuracy: 0.9331\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2175 - accuracy: 0.9391 - val_loss: 0.2403 - val_accuracy: 0.9347\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2108 - accuracy: 0.9406 - val_loss: 0.2356 - val_accuracy: 0.9356\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2044 - accuracy: 0.9430 - val_loss: 0.2330 - val_accuracy: 0.9361\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1983 - accuracy: 0.9440 - val_loss: 0.2288 - val_accuracy: 0.9373\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1940 - accuracy: 0.9451 - val_loss: 0.2281 - val_accuracy: 0.9361\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1896 - accuracy: 0.9468 - val_loss: 0.2234 - val_accuracy: 0.9378\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1854 - accuracy: 0.9482 - val_loss: 0.2228 - val_accuracy: 0.9392\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1825 - accuracy: 0.9485 - val_loss: 0.2205 - val_accuracy: 0.9393\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1792 - accuracy: 0.9500 - val_loss: 0.2210 - val_accuracy: 0.9392\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1761 - accuracy: 0.9504 - val_loss: 0.2165 - val_accuracy: 0.9408\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1731 - accuracy: 0.9516 - val_loss: 0.2161 - val_accuracy: 0.9403\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1701 - accuracy: 0.9531 - val_loss: 0.2153 - val_accuracy: 0.9402\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1678 - accuracy: 0.9531 - val_loss: 0.2137 - val_accuracy: 0.9408\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1651 - accuracy: 0.9538 - val_loss: 0.2138 - val_accuracy: 0.9400\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1631 - accuracy: 0.9543 - val_loss: 0.2109 - val_accuracy: 0.9421\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1604 - accuracy: 0.9548 - val_loss: 0.2139 - val_accuracy: 0.9409\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1587 - accuracy: 0.9558 - val_loss: 0.2096 - val_accuracy: 0.9424\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1567 - accuracy: 0.9554 - val_loss: 0.2112 - val_accuracy: 0.9412\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1552 - accuracy: 0.9559 - val_loss: 0.2086 - val_accuracy: 0.9433\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1534 - accuracy: 0.9564 - val_loss: 0.2089 - val_accuracy: 0.9416\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1508 - accuracy: 0.9577 - val_loss: 0.2076 - val_accuracy: 0.9430\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1495 - accuracy: 0.9577 - val_loss: 0.2077 - val_accuracy: 0.9430\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1479 - accuracy: 0.9586 - val_loss: 0.2101 - val_accuracy: 0.9428\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1467 - accuracy: 0.9592 - val_loss: 0.2090 - val_accuracy: 0.9433\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1447 - accuracy: 0.9593 - val_loss: 0.2076 - val_accuracy: 0.9415\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1441 - accuracy: 0.9591 - val_loss: 0.2065 - val_accuracy: 0.9425\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1417 - accuracy: 0.9599 - val_loss: 0.2073 - val_accuracy: 0.9430\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1401 - accuracy: 0.9605 - val_loss: 0.2073 - val_accuracy: 0.9442\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1392 - accuracy: 0.9615 - val_loss: 0.2061 - val_accuracy: 0.9445\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1375 - accuracy: 0.9612 - val_loss: 0.2055 - val_accuracy: 0.9433\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1373 - accuracy: 0.9611 - val_loss: 0.2058 - val_accuracy: 0.9430\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1354 - accuracy: 0.9616 - val_loss: 0.2054 - val_accuracy: 0.9433\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1344 - accuracy: 0.9618 - val_loss: 0.2111 - val_accuracy: 0.9418\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1334 - accuracy: 0.9627 - val_loss: 0.2074 - val_accuracy: 0.9423\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1319 - accuracy: 0.9627 - val_loss: 0.2060 - val_accuracy: 0.9430\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1306 - accuracy: 0.9631 - val_loss: 0.2096 - val_accuracy: 0.9420\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1297 - accuracy: 0.9642 - val_loss: 0.2047 - val_accuracy: 0.9443\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1284 - accuracy: 0.9641 - val_loss: 0.2070 - val_accuracy: 0.9429\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1272 - accuracy: 0.9637 - val_loss: 0.2078 - val_accuracy: 0.9430\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1266 - accuracy: 0.9642 - val_loss: 0.2087 - val_accuracy: 0.9431\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1260 - accuracy: 0.9649 - val_loss: 0.2065 - val_accuracy: 0.9423\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1245 - accuracy: 0.9646 - val_loss: 0.2082 - val_accuracy: 0.9428\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1248 - accuracy: 0.9651 - val_loss: 0.2078 - val_accuracy: 0.9417\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.8063 - accuracy: 0.7632 - val_loss: 0.3851 - val_accuracy: 0.8942\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3353 - accuracy: 0.9061 - val_loss: 0.3134 - val_accuracy: 0.9143\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2882 - accuracy: 0.9178 - val_loss: 0.2878 - val_accuracy: 0.9211\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2666 - accuracy: 0.9236 - val_loss: 0.2742 - val_accuracy: 0.9235\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2502 - accuracy: 0.9287 - val_loss: 0.2638 - val_accuracy: 0.9258\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2384 - accuracy: 0.9319 - val_loss: 0.2565 - val_accuracy: 0.9284\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2279 - accuracy: 0.9356 - val_loss: 0.2521 - val_accuracy: 0.9302\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2202 - accuracy: 0.9378 - val_loss: 0.2447 - val_accuracy: 0.9337\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2128 - accuracy: 0.9402 - val_loss: 0.2377 - val_accuracy: 0.9351\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2066 - accuracy: 0.9411 - val_loss: 0.2349 - val_accuracy: 0.9349\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2007 - accuracy: 0.9442 - val_loss: 0.2323 - val_accuracy: 0.9372\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1964 - accuracy: 0.9445 - val_loss: 0.2282 - val_accuracy: 0.9371\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1922 - accuracy: 0.9460 - val_loss: 0.2258 - val_accuracy: 0.9377\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1876 - accuracy: 0.9472 - val_loss: 0.2238 - val_accuracy: 0.9382\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1840 - accuracy: 0.9488 - val_loss: 0.2267 - val_accuracy: 0.9367\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1807 - accuracy: 0.9495 - val_loss: 0.2212 - val_accuracy: 0.9398\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1771 - accuracy: 0.9500 - val_loss: 0.2214 - val_accuracy: 0.9382\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1744 - accuracy: 0.9508 - val_loss: 0.2184 - val_accuracy: 0.9401\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1718 - accuracy: 0.9511 - val_loss: 0.2175 - val_accuracy: 0.9407\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1686 - accuracy: 0.9521 - val_loss: 0.2159 - val_accuracy: 0.9402\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1666 - accuracy: 0.9525 - val_loss: 0.2178 - val_accuracy: 0.9388\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1642 - accuracy: 0.9531 - val_loss: 0.2160 - val_accuracy: 0.9399\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1619 - accuracy: 0.9548 - val_loss: 0.2116 - val_accuracy: 0.9405\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1592 - accuracy: 0.9553 - val_loss: 0.2113 - val_accuracy: 0.9423\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1575 - accuracy: 0.9560 - val_loss: 0.2093 - val_accuracy: 0.9423\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1547 - accuracy: 0.9569 - val_loss: 0.2102 - val_accuracy: 0.9433\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1532 - accuracy: 0.9564 - val_loss: 0.2091 - val_accuracy: 0.9427\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1512 - accuracy: 0.9580 - val_loss: 0.2134 - val_accuracy: 0.9409\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1500 - accuracy: 0.9575 - val_loss: 0.2071 - val_accuracy: 0.9438\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1477 - accuracy: 0.9585 - val_loss: 0.2068 - val_accuracy: 0.9419\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1458 - accuracy: 0.9590 - val_loss: 0.2078 - val_accuracy: 0.9422\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1442 - accuracy: 0.9599 - val_loss: 0.2057 - val_accuracy: 0.9432\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1430 - accuracy: 0.9597 - val_loss: 0.2065 - val_accuracy: 0.9438\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1414 - accuracy: 0.9605 - val_loss: 0.2066 - val_accuracy: 0.9441\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1403 - accuracy: 0.9608 - val_loss: 0.2045 - val_accuracy: 0.9426\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1383 - accuracy: 0.9606 - val_loss: 0.2054 - val_accuracy: 0.9448\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1366 - accuracy: 0.9615 - val_loss: 0.2041 - val_accuracy: 0.9436\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1353 - accuracy: 0.9622 - val_loss: 0.2011 - val_accuracy: 0.9450\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1339 - accuracy: 0.9623 - val_loss: 0.2038 - val_accuracy: 0.9439\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1328 - accuracy: 0.9624 - val_loss: 0.2041 - val_accuracy: 0.9439\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1317 - accuracy: 0.9620 - val_loss: 0.2019 - val_accuracy: 0.9472\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1306 - accuracy: 0.9626 - val_loss: 0.2022 - val_accuracy: 0.9448\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1291 - accuracy: 0.9633 - val_loss: 0.2019 - val_accuracy: 0.9454\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1278 - accuracy: 0.9639 - val_loss: 0.2050 - val_accuracy: 0.9449\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1268 - accuracy: 0.9640 - val_loss: 0.2012 - val_accuracy: 0.9457\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1264 - accuracy: 0.9641 - val_loss: 0.2019 - val_accuracy: 0.9455\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1249 - accuracy: 0.9642 - val_loss: 0.2015 - val_accuracy: 0.9453\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1242 - accuracy: 0.9646 - val_loss: 0.2019 - val_accuracy: 0.9455\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1224 - accuracy: 0.9647 - val_loss: 0.2017 - val_accuracy: 0.9452\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1216 - accuracy: 0.9654 - val_loss: 0.1999 - val_accuracy: 0.9457\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 32)                25120     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 25,450\n",
            "Trainable params: 25,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7451 - accuracy: 0.7979 - val_loss: 0.3667 - val_accuracy: 0.9009\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3161 - accuracy: 0.9114 - val_loss: 0.2920 - val_accuracy: 0.9188\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2645 - accuracy: 0.9247 - val_loss: 0.2610 - val_accuracy: 0.9261\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2336 - accuracy: 0.9337 - val_loss: 0.2381 - val_accuracy: 0.9336\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2097 - accuracy: 0.9415 - val_loss: 0.2206 - val_accuracy: 0.9389\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1922 - accuracy: 0.9460 - val_loss: 0.2028 - val_accuracy: 0.9431\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1759 - accuracy: 0.9503 - val_loss: 0.1897 - val_accuracy: 0.9455\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1629 - accuracy: 0.9545 - val_loss: 0.1831 - val_accuracy: 0.9478\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1520 - accuracy: 0.9571 - val_loss: 0.1745 - val_accuracy: 0.9503\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1424 - accuracy: 0.9603 - val_loss: 0.1679 - val_accuracy: 0.9512\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1336 - accuracy: 0.9626 - val_loss: 0.1618 - val_accuracy: 0.9537\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1270 - accuracy: 0.9644 - val_loss: 0.1554 - val_accuracy: 0.9549\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1201 - accuracy: 0.9662 - val_loss: 0.1534 - val_accuracy: 0.9547\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1149 - accuracy: 0.9676 - val_loss: 0.1504 - val_accuracy: 0.9560\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1087 - accuracy: 0.9699 - val_loss: 0.1461 - val_accuracy: 0.9571\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1033 - accuracy: 0.9710 - val_loss: 0.1444 - val_accuracy: 0.9584\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0994 - accuracy: 0.9727 - val_loss: 0.1435 - val_accuracy: 0.9577\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0954 - accuracy: 0.9733 - val_loss: 0.1391 - val_accuracy: 0.9599\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0916 - accuracy: 0.9742 - val_loss: 0.1367 - val_accuracy: 0.9603\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0883 - accuracy: 0.9756 - val_loss: 0.1354 - val_accuracy: 0.9615\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0849 - accuracy: 0.9765 - val_loss: 0.1349 - val_accuracy: 0.9614\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0819 - accuracy: 0.9774 - val_loss: 0.1334 - val_accuracy: 0.9617\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0786 - accuracy: 0.9781 - val_loss: 0.1332 - val_accuracy: 0.9613\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0761 - accuracy: 0.9783 - val_loss: 0.1317 - val_accuracy: 0.9621\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0736 - accuracy: 0.9792 - val_loss: 0.1333 - val_accuracy: 0.9610\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0713 - accuracy: 0.9799 - val_loss: 0.1309 - val_accuracy: 0.9629\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0689 - accuracy: 0.9808 - val_loss: 0.1306 - val_accuracy: 0.9631\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0658 - accuracy: 0.9815 - val_loss: 0.1327 - val_accuracy: 0.9626\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0642 - accuracy: 0.9823 - val_loss: 0.1323 - val_accuracy: 0.9628\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0622 - accuracy: 0.9826 - val_loss: 0.1309 - val_accuracy: 0.9629\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0599 - accuracy: 0.9836 - val_loss: 0.1319 - val_accuracy: 0.9627\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0576 - accuracy: 0.9844 - val_loss: 0.1295 - val_accuracy: 0.9642\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0560 - accuracy: 0.9847 - val_loss: 0.1336 - val_accuracy: 0.9621\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0544 - accuracy: 0.9853 - val_loss: 0.1320 - val_accuracy: 0.9632\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0520 - accuracy: 0.9862 - val_loss: 0.1333 - val_accuracy: 0.9637\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9859 - val_loss: 0.1336 - val_accuracy: 0.9622\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0494 - accuracy: 0.9864 - val_loss: 0.1321 - val_accuracy: 0.9638\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0479 - accuracy: 0.9869 - val_loss: 0.1319 - val_accuracy: 0.9630\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0466 - accuracy: 0.9877 - val_loss: 0.1316 - val_accuracy: 0.9646\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0446 - accuracy: 0.9886 - val_loss: 0.1342 - val_accuracy: 0.9621\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0429 - accuracy: 0.9888 - val_loss: 0.1374 - val_accuracy: 0.9628\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.9891 - val_loss: 0.1367 - val_accuracy: 0.9614\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0407 - accuracy: 0.9891 - val_loss: 0.1332 - val_accuracy: 0.9640\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0394 - accuracy: 0.9897 - val_loss: 0.1359 - val_accuracy: 0.9636\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0384 - accuracy: 0.9902 - val_loss: 0.1378 - val_accuracy: 0.9629\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0370 - accuracy: 0.9905 - val_loss: 0.1357 - val_accuracy: 0.9630\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0355 - accuracy: 0.9913 - val_loss: 0.1384 - val_accuracy: 0.9637\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0351 - accuracy: 0.9914 - val_loss: 0.1382 - val_accuracy: 0.9628\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9916 - val_loss: 0.1369 - val_accuracy: 0.9638\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0325 - accuracy: 0.9918 - val_loss: 0.1420 - val_accuracy: 0.9625\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.5192 - accuracy: 0.8491 - val_loss: 0.2991 - val_accuracy: 0.9159\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2610 - accuracy: 0.9266 - val_loss: 0.2486 - val_accuracy: 0.9297\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2177 - accuracy: 0.9393 - val_loss: 0.2242 - val_accuracy: 0.9347\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1907 - accuracy: 0.9469 - val_loss: 0.1999 - val_accuracy: 0.9426\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1701 - accuracy: 0.9527 - val_loss: 0.1843 - val_accuracy: 0.9479\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1544 - accuracy: 0.9562 - val_loss: 0.1744 - val_accuracy: 0.9487\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1428 - accuracy: 0.9596 - val_loss: 0.1630 - val_accuracy: 0.9536\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1330 - accuracy: 0.9624 - val_loss: 0.1596 - val_accuracy: 0.9528\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1245 - accuracy: 0.9651 - val_loss: 0.1505 - val_accuracy: 0.9570\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1162 - accuracy: 0.9671 - val_loss: 0.1459 - val_accuracy: 0.9581\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1100 - accuracy: 0.9693 - val_loss: 0.1434 - val_accuracy: 0.9587\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1045 - accuracy: 0.9705 - val_loss: 0.1388 - val_accuracy: 0.9601\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9723 - val_loss: 0.1359 - val_accuracy: 0.9614\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9737 - val_loss: 0.1335 - val_accuracy: 0.9616\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0897 - accuracy: 0.9753 - val_loss: 0.1309 - val_accuracy: 0.9636\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0857 - accuracy: 0.9753 - val_loss: 0.1317 - val_accuracy: 0.9632\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0818 - accuracy: 0.9769 - val_loss: 0.1316 - val_accuracy: 0.9639\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0784 - accuracy: 0.9781 - val_loss: 0.1275 - val_accuracy: 0.9635\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0762 - accuracy: 0.9789 - val_loss: 0.1289 - val_accuracy: 0.9636\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0720 - accuracy: 0.9800 - val_loss: 0.1252 - val_accuracy: 0.9637\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0696 - accuracy: 0.9803 - val_loss: 0.1248 - val_accuracy: 0.9638\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0663 - accuracy: 0.9816 - val_loss: 0.1233 - val_accuracy: 0.9642\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0637 - accuracy: 0.9827 - val_loss: 0.1241 - val_accuracy: 0.9643\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0623 - accuracy: 0.9824 - val_loss: 0.1233 - val_accuracy: 0.9647\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0587 - accuracy: 0.9841 - val_loss: 0.1237 - val_accuracy: 0.9648\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0568 - accuracy: 0.9846 - val_loss: 0.1246 - val_accuracy: 0.9646\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0550 - accuracy: 0.9848 - val_loss: 0.1235 - val_accuracy: 0.9643\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0533 - accuracy: 0.9857 - val_loss: 0.1227 - val_accuracy: 0.9656\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0510 - accuracy: 0.9864 - val_loss: 0.1222 - val_accuracy: 0.9657\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0492 - accuracy: 0.9863 - val_loss: 0.1220 - val_accuracy: 0.9661\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0476 - accuracy: 0.9875 - val_loss: 0.1230 - val_accuracy: 0.9647\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0452 - accuracy: 0.9885 - val_loss: 0.1234 - val_accuracy: 0.9657\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0446 - accuracy: 0.9884 - val_loss: 0.1242 - val_accuracy: 0.9652\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0427 - accuracy: 0.9885 - val_loss: 0.1246 - val_accuracy: 0.9658\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0413 - accuracy: 0.9891 - val_loss: 0.1241 - val_accuracy: 0.9648\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0401 - accuracy: 0.9898 - val_loss: 0.1242 - val_accuracy: 0.9660\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0390 - accuracy: 0.9900 - val_loss: 0.1269 - val_accuracy: 0.9661\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0373 - accuracy: 0.9901 - val_loss: 0.1255 - val_accuracy: 0.9665\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0353 - accuracy: 0.9913 - val_loss: 0.1266 - val_accuracy: 0.9662\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.9907 - val_loss: 0.1295 - val_accuracy: 0.9661\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0335 - accuracy: 0.9913 - val_loss: 0.1290 - val_accuracy: 0.9660\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0325 - accuracy: 0.9919 - val_loss: 0.1310 - val_accuracy: 0.9650\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.9924 - val_loss: 0.1321 - val_accuracy: 0.9657\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.9925 - val_loss: 0.1318 - val_accuracy: 0.9660\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0300 - accuracy: 0.9924 - val_loss: 0.1322 - val_accuracy: 0.9653\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9932 - val_loss: 0.1322 - val_accuracy: 0.9661\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0275 - accuracy: 0.9934 - val_loss: 0.1312 - val_accuracy: 0.9667\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0267 - accuracy: 0.9936 - val_loss: 0.1337 - val_accuracy: 0.9655\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0254 - accuracy: 0.9939 - val_loss: 0.1343 - val_accuracy: 0.9653\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0244 - accuracy: 0.9941 - val_loss: 0.1351 - val_accuracy: 0.9649\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.5281 - accuracy: 0.8456 - val_loss: 0.3063 - val_accuracy: 0.9158\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2686 - accuracy: 0.9234 - val_loss: 0.2611 - val_accuracy: 0.9265\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2260 - accuracy: 0.9366 - val_loss: 0.2238 - val_accuracy: 0.9383\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1983 - accuracy: 0.9449 - val_loss: 0.2070 - val_accuracy: 0.9419\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1771 - accuracy: 0.9503 - val_loss: 0.1908 - val_accuracy: 0.9472\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1606 - accuracy: 0.9550 - val_loss: 0.1823 - val_accuracy: 0.9474\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1482 - accuracy: 0.9581 - val_loss: 0.1671 - val_accuracy: 0.9532\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1369 - accuracy: 0.9611 - val_loss: 0.1598 - val_accuracy: 0.9548\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1272 - accuracy: 0.9632 - val_loss: 0.1534 - val_accuracy: 0.9554\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1193 - accuracy: 0.9664 - val_loss: 0.1504 - val_accuracy: 0.9578\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1129 - accuracy: 0.9682 - val_loss: 0.1452 - val_accuracy: 0.9588\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1068 - accuracy: 0.9698 - val_loss: 0.1407 - val_accuracy: 0.9589\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1012 - accuracy: 0.9717 - val_loss: 0.1371 - val_accuracy: 0.9602\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9724 - val_loss: 0.1354 - val_accuracy: 0.9603\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0925 - accuracy: 0.9740 - val_loss: 0.1338 - val_accuracy: 0.9612\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0878 - accuracy: 0.9753 - val_loss: 0.1341 - val_accuracy: 0.9607\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0845 - accuracy: 0.9761 - val_loss: 0.1325 - val_accuracy: 0.9622\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0814 - accuracy: 0.9770 - val_loss: 0.1280 - val_accuracy: 0.9624\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0778 - accuracy: 0.9783 - val_loss: 0.1284 - val_accuracy: 0.9622\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0747 - accuracy: 0.9790 - val_loss: 0.1256 - val_accuracy: 0.9635\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0721 - accuracy: 0.9801 - val_loss: 0.1274 - val_accuracy: 0.9640\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0694 - accuracy: 0.9808 - val_loss: 0.1266 - val_accuracy: 0.9623\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0673 - accuracy: 0.9811 - val_loss: 0.1256 - val_accuracy: 0.9623\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0657 - accuracy: 0.9815 - val_loss: 0.1230 - val_accuracy: 0.9634\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0630 - accuracy: 0.9821 - val_loss: 0.1254 - val_accuracy: 0.9642\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0611 - accuracy: 0.9830 - val_loss: 0.1238 - val_accuracy: 0.9628\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0587 - accuracy: 0.9836 - val_loss: 0.1245 - val_accuracy: 0.9643\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0566 - accuracy: 0.9839 - val_loss: 0.1240 - val_accuracy: 0.9639\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0554 - accuracy: 0.9842 - val_loss: 0.1239 - val_accuracy: 0.9633\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0530 - accuracy: 0.9855 - val_loss: 0.1239 - val_accuracy: 0.9634\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0515 - accuracy: 0.9863 - val_loss: 0.1217 - val_accuracy: 0.9646\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0497 - accuracy: 0.9864 - val_loss: 0.1227 - val_accuracy: 0.9652\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0487 - accuracy: 0.9871 - val_loss: 0.1254 - val_accuracy: 0.9634\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0472 - accuracy: 0.9871 - val_loss: 0.1255 - val_accuracy: 0.9638\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0463 - accuracy: 0.9876 - val_loss: 0.1238 - val_accuracy: 0.9644\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0447 - accuracy: 0.9880 - val_loss: 0.1227 - val_accuracy: 0.9643\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0431 - accuracy: 0.9882 - val_loss: 0.1252 - val_accuracy: 0.9636\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0415 - accuracy: 0.9890 - val_loss: 0.1243 - val_accuracy: 0.9648\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0407 - accuracy: 0.9891 - val_loss: 0.1263 - val_accuracy: 0.9645\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0390 - accuracy: 0.9897 - val_loss: 0.1266 - val_accuracy: 0.9653\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0383 - accuracy: 0.9902 - val_loss: 0.1265 - val_accuracy: 0.9643\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0371 - accuracy: 0.9902 - val_loss: 0.1282 - val_accuracy: 0.9644\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0359 - accuracy: 0.9906 - val_loss: 0.1312 - val_accuracy: 0.9644\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.9910 - val_loss: 0.1306 - val_accuracy: 0.9638\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0341 - accuracy: 0.9914 - val_loss: 0.1288 - val_accuracy: 0.9642\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0327 - accuracy: 0.9917 - val_loss: 0.1287 - val_accuracy: 0.9638\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9919 - val_loss: 0.1311 - val_accuracy: 0.9639\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9920 - val_loss: 0.1310 - val_accuracy: 0.9637\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0300 - accuracy: 0.9927 - val_loss: 0.1326 - val_accuracy: 0.9639\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9930 - val_loss: 0.1324 - val_accuracy: 0.9637\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6032 - accuracy: 0.8348 - val_loss: 0.3137 - val_accuracy: 0.9124\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2707 - accuracy: 0.9236 - val_loss: 0.2480 - val_accuracy: 0.9311\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2169 - accuracy: 0.9392 - val_loss: 0.2117 - val_accuracy: 0.9414\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1846 - accuracy: 0.9484 - val_loss: 0.1884 - val_accuracy: 0.9467\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1602 - accuracy: 0.9549 - val_loss: 0.1732 - val_accuracy: 0.9501\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1437 - accuracy: 0.9595 - val_loss: 0.1631 - val_accuracy: 0.9549\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1306 - accuracy: 0.9634 - val_loss: 0.1539 - val_accuracy: 0.9554\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1184 - accuracy: 0.9666 - val_loss: 0.1466 - val_accuracy: 0.9581\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1096 - accuracy: 0.9689 - val_loss: 0.1407 - val_accuracy: 0.9594\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1007 - accuracy: 0.9713 - val_loss: 0.1375 - val_accuracy: 0.9613\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0935 - accuracy: 0.9739 - val_loss: 0.1303 - val_accuracy: 0.9625\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0866 - accuracy: 0.9756 - val_loss: 0.1268 - val_accuracy: 0.9626\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0799 - accuracy: 0.9778 - val_loss: 0.1235 - val_accuracy: 0.9629\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0755 - accuracy: 0.9791 - val_loss: 0.1198 - val_accuracy: 0.9650\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0706 - accuracy: 0.9796 - val_loss: 0.1203 - val_accuracy: 0.9641\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0651 - accuracy: 0.9821 - val_loss: 0.1152 - val_accuracy: 0.9653\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0609 - accuracy: 0.9830 - val_loss: 0.1162 - val_accuracy: 0.9652\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0563 - accuracy: 0.9842 - val_loss: 0.1142 - val_accuracy: 0.9668\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0529 - accuracy: 0.9852 - val_loss: 0.1113 - val_accuracy: 0.9663\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0500 - accuracy: 0.9860 - val_loss: 0.1147 - val_accuracy: 0.9666\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.9870 - val_loss: 0.1109 - val_accuracy: 0.9684\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0435 - accuracy: 0.9880 - val_loss: 0.1112 - val_accuracy: 0.9672\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0407 - accuracy: 0.9888 - val_loss: 0.1103 - val_accuracy: 0.9686\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0377 - accuracy: 0.9899 - val_loss: 0.1087 - val_accuracy: 0.9679\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0350 - accuracy: 0.9907 - val_loss: 0.1094 - val_accuracy: 0.9688\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0328 - accuracy: 0.9916 - val_loss: 0.1090 - val_accuracy: 0.9682\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9923 - val_loss: 0.1076 - val_accuracy: 0.9682\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0282 - accuracy: 0.9929 - val_loss: 0.1079 - val_accuracy: 0.9693\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0261 - accuracy: 0.9939 - val_loss: 0.1101 - val_accuracy: 0.9678\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0243 - accuracy: 0.9945 - val_loss: 0.1093 - val_accuracy: 0.9693\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0233 - accuracy: 0.9947 - val_loss: 0.1095 - val_accuracy: 0.9693\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0217 - accuracy: 0.9952 - val_loss: 0.1107 - val_accuracy: 0.9693\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0202 - accuracy: 0.9954 - val_loss: 0.1072 - val_accuracy: 0.9702\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0183 - accuracy: 0.9963 - val_loss: 0.1112 - val_accuracy: 0.9698\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0170 - accuracy: 0.9970 - val_loss: 0.1103 - val_accuracy: 0.9705\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.9966 - val_loss: 0.1107 - val_accuracy: 0.9695\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0151 - accuracy: 0.9973 - val_loss: 0.1130 - val_accuracy: 0.9697\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0134 - accuracy: 0.9978 - val_loss: 0.1155 - val_accuracy: 0.9692\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0131 - accuracy: 0.9980 - val_loss: 0.1123 - val_accuracy: 0.9710\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0119 - accuracy: 0.9983 - val_loss: 0.1134 - val_accuracy: 0.9697\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0110 - accuracy: 0.9985 - val_loss: 0.1167 - val_accuracy: 0.9700\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9986 - val_loss: 0.1187 - val_accuracy: 0.9695\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.1175 - val_accuracy: 0.9700\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0091 - accuracy: 0.9989 - val_loss: 0.1187 - val_accuracy: 0.9698\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.9991 - val_loss: 0.1189 - val_accuracy: 0.9697\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.1211 - val_accuracy: 0.9702\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.1228 - val_accuracy: 0.9699\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.1232 - val_accuracy: 0.9693\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 0.1233 - val_accuracy: 0.9694\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.1262 - val_accuracy: 0.9698\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3877 - accuracy: 0.8874 - val_loss: 0.2383 - val_accuracy: 0.9333\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1982 - accuracy: 0.9429 - val_loss: 0.1911 - val_accuracy: 0.9453\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1584 - accuracy: 0.9547 - val_loss: 0.1665 - val_accuracy: 0.9515\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1333 - accuracy: 0.9619 - val_loss: 0.1475 - val_accuracy: 0.9571\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1160 - accuracy: 0.9667 - val_loss: 0.1386 - val_accuracy: 0.9603\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1038 - accuracy: 0.9702 - val_loss: 0.1289 - val_accuracy: 0.9617\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0940 - accuracy: 0.9732 - val_loss: 0.1249 - val_accuracy: 0.9628\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0862 - accuracy: 0.9752 - val_loss: 0.1187 - val_accuracy: 0.9645\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0786 - accuracy: 0.9775 - val_loss: 0.1174 - val_accuracy: 0.9663\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0724 - accuracy: 0.9793 - val_loss: 0.1144 - val_accuracy: 0.9663\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0678 - accuracy: 0.9811 - val_loss: 0.1132 - val_accuracy: 0.9658\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0630 - accuracy: 0.9826 - val_loss: 0.1128 - val_accuracy: 0.9649\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0580 - accuracy: 0.9839 - val_loss: 0.1082 - val_accuracy: 0.9678\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0542 - accuracy: 0.9852 - val_loss: 0.1059 - val_accuracy: 0.9687\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0514 - accuracy: 0.9858 - val_loss: 0.1074 - val_accuracy: 0.9688\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0472 - accuracy: 0.9872 - val_loss: 0.1085 - val_accuracy: 0.9677\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0446 - accuracy: 0.9883 - val_loss: 0.1055 - val_accuracy: 0.9679\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0421 - accuracy: 0.9893 - val_loss: 0.1073 - val_accuracy: 0.9693\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.9902 - val_loss: 0.1059 - val_accuracy: 0.9691\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0366 - accuracy: 0.9905 - val_loss: 0.1050 - val_accuracy: 0.9699\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9913 - val_loss: 0.1067 - val_accuracy: 0.9691\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9922 - val_loss: 0.1043 - val_accuracy: 0.9708\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0301 - accuracy: 0.9929 - val_loss: 0.1053 - val_accuracy: 0.9703\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0283 - accuracy: 0.9930 - val_loss: 0.1070 - val_accuracy: 0.9707\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0273 - accuracy: 0.9939 - val_loss: 0.1069 - val_accuracy: 0.9703\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0251 - accuracy: 0.9941 - val_loss: 0.1084 - val_accuracy: 0.9697\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0232 - accuracy: 0.9950 - val_loss: 0.1081 - val_accuracy: 0.9709\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0216 - accuracy: 0.9955 - val_loss: 0.1104 - val_accuracy: 0.9693\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0202 - accuracy: 0.9959 - val_loss: 0.1120 - val_accuracy: 0.9689\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0191 - accuracy: 0.9960 - val_loss: 0.1124 - val_accuracy: 0.9693\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0175 - accuracy: 0.9968 - val_loss: 0.1101 - val_accuracy: 0.9707\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9970 - val_loss: 0.1099 - val_accuracy: 0.9713\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0154 - accuracy: 0.9971 - val_loss: 0.1120 - val_accuracy: 0.9705\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0140 - accuracy: 0.9978 - val_loss: 0.1135 - val_accuracy: 0.9714\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0135 - accuracy: 0.9978 - val_loss: 0.1115 - val_accuracy: 0.9712\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0121 - accuracy: 0.9981 - val_loss: 0.1165 - val_accuracy: 0.9696\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0116 - accuracy: 0.9985 - val_loss: 0.1156 - val_accuracy: 0.9707\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.1185 - val_accuracy: 0.9697\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9987 - val_loss: 0.1164 - val_accuracy: 0.9707\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9989 - val_loss: 0.1194 - val_accuracy: 0.9711\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0085 - accuracy: 0.9992 - val_loss: 0.1174 - val_accuracy: 0.9719\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.1184 - val_accuracy: 0.9714\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.1210 - val_accuracy: 0.9713\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.1222 - val_accuracy: 0.9708\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 0.1238 - val_accuracy: 0.9712\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9996 - val_loss: 0.1253 - val_accuracy: 0.9703\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.1257 - val_accuracy: 0.9705\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.1276 - val_accuracy: 0.9705\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.9997 - val_loss: 0.1295 - val_accuracy: 0.9707\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.1306 - val_accuracy: 0.9702\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3761 - accuracy: 0.8891 - val_loss: 0.2289 - val_accuracy: 0.9355\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1885 - accuracy: 0.9460 - val_loss: 0.1786 - val_accuracy: 0.9506\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1469 - accuracy: 0.9578 - val_loss: 0.1559 - val_accuracy: 0.9558\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1242 - accuracy: 0.9647 - val_loss: 0.1425 - val_accuracy: 0.9593\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1071 - accuracy: 0.9695 - val_loss: 0.1378 - val_accuracy: 0.9600\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9718 - val_loss: 0.1234 - val_accuracy: 0.9647\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0861 - accuracy: 0.9753 - val_loss: 0.1180 - val_accuracy: 0.9652\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0791 - accuracy: 0.9776 - val_loss: 0.1190 - val_accuracy: 0.9663\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0719 - accuracy: 0.9799 - val_loss: 0.1106 - val_accuracy: 0.9671\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0662 - accuracy: 0.9810 - val_loss: 0.1080 - val_accuracy: 0.9691\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0608 - accuracy: 0.9834 - val_loss: 0.1080 - val_accuracy: 0.9664\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0565 - accuracy: 0.9842 - val_loss: 0.1091 - val_accuracy: 0.9671\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0526 - accuracy: 0.9856 - val_loss: 0.1039 - val_accuracy: 0.9700\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0490 - accuracy: 0.9870 - val_loss: 0.1034 - val_accuracy: 0.9693\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.9880 - val_loss: 0.1044 - val_accuracy: 0.9698\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0420 - accuracy: 0.9891 - val_loss: 0.1037 - val_accuracy: 0.9693\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0397 - accuracy: 0.9898 - val_loss: 0.1030 - val_accuracy: 0.9701\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0367 - accuracy: 0.9905 - val_loss: 0.1030 - val_accuracy: 0.9702\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9915 - val_loss: 0.1042 - val_accuracy: 0.9701\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0320 - accuracy: 0.9919 - val_loss: 0.1028 - val_accuracy: 0.9702\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.9929 - val_loss: 0.1045 - val_accuracy: 0.9699\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9933 - val_loss: 0.1029 - val_accuracy: 0.9703\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0259 - accuracy: 0.9939 - val_loss: 0.1034 - val_accuracy: 0.9709\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0241 - accuracy: 0.9945 - val_loss: 0.1069 - val_accuracy: 0.9702\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0229 - accuracy: 0.9947 - val_loss: 0.1055 - val_accuracy: 0.9704\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0211 - accuracy: 0.9956 - val_loss: 0.1067 - val_accuracy: 0.9703\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0196 - accuracy: 0.9961 - val_loss: 0.1083 - val_accuracy: 0.9697\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0185 - accuracy: 0.9961 - val_loss: 0.1047 - val_accuracy: 0.9699\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0170 - accuracy: 0.9965 - val_loss: 0.1104 - val_accuracy: 0.9701\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0158 - accuracy: 0.9970 - val_loss: 0.1098 - val_accuracy: 0.9698\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9972 - val_loss: 0.1121 - val_accuracy: 0.9691\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0139 - accuracy: 0.9976 - val_loss: 0.1112 - val_accuracy: 0.9707\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0126 - accuracy: 0.9980 - val_loss: 0.1124 - val_accuracy: 0.9706\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0117 - accuracy: 0.9984 - val_loss: 0.1143 - val_accuracy: 0.9700\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.1150 - val_accuracy: 0.9698\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0098 - accuracy: 0.9988 - val_loss: 0.1159 - val_accuracy: 0.9701\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 0.1193 - val_accuracy: 0.9694\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.9989 - val_loss: 0.1217 - val_accuracy: 0.9693\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9994 - val_loss: 0.1205 - val_accuracy: 0.9707\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.1246 - val_accuracy: 0.9697\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9996 - val_loss: 0.1214 - val_accuracy: 0.9714\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 0.1224 - val_accuracy: 0.9697\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9997 - val_loss: 0.1263 - val_accuracy: 0.9689\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.1267 - val_accuracy: 0.9696\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.1295 - val_accuracy: 0.9700\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 0.1278 - val_accuracy: 0.9707\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.1290 - val_accuracy: 0.9707\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.1318 - val_accuracy: 0.9700\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.1296 - val_accuracy: 0.9713\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.1336 - val_accuracy: 0.9710\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4897 - accuracy: 0.8670 - val_loss: 0.2694 - val_accuracy: 0.9261\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2268 - accuracy: 0.9367 - val_loss: 0.2049 - val_accuracy: 0.9439\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1706 - accuracy: 0.9515 - val_loss: 0.1709 - val_accuracy: 0.9527\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1376 - accuracy: 0.9606 - val_loss: 0.1442 - val_accuracy: 0.9607\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1155 - accuracy: 0.9672 - val_loss: 0.1338 - val_accuracy: 0.9615\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9719 - val_loss: 0.1201 - val_accuracy: 0.9666\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0844 - accuracy: 0.9764 - val_loss: 0.1132 - val_accuracy: 0.9674\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0740 - accuracy: 0.9795 - val_loss: 0.1075 - val_accuracy: 0.9701\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0661 - accuracy: 0.9821 - val_loss: 0.1049 - val_accuracy: 0.9696\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0586 - accuracy: 0.9839 - val_loss: 0.1004 - val_accuracy: 0.9718\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0516 - accuracy: 0.9860 - val_loss: 0.0935 - val_accuracy: 0.9733\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.9872 - val_loss: 0.0967 - val_accuracy: 0.9723\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0416 - accuracy: 0.9891 - val_loss: 0.0892 - val_accuracy: 0.9746\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0367 - accuracy: 0.9906 - val_loss: 0.0924 - val_accuracy: 0.9730\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.9917 - val_loss: 0.0887 - val_accuracy: 0.9746\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9929 - val_loss: 0.0853 - val_accuracy: 0.9750\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0270 - accuracy: 0.9934 - val_loss: 0.0849 - val_accuracy: 0.9753\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0237 - accuracy: 0.9944 - val_loss: 0.0909 - val_accuracy: 0.9739\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0209 - accuracy: 0.9957 - val_loss: 0.0838 - val_accuracy: 0.9762\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0187 - accuracy: 0.9962 - val_loss: 0.0863 - val_accuracy: 0.9752\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0167 - accuracy: 0.9968 - val_loss: 0.0840 - val_accuracy: 0.9756\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0150 - accuracy: 0.9973 - val_loss: 0.0862 - val_accuracy: 0.9764\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0132 - accuracy: 0.9978 - val_loss: 0.0849 - val_accuracy: 0.9757\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0123 - accuracy: 0.9981 - val_loss: 0.0842 - val_accuracy: 0.9769\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0105 - accuracy: 0.9985 - val_loss: 0.0864 - val_accuracy: 0.9762\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0095 - accuracy: 0.9989 - val_loss: 0.0862 - val_accuracy: 0.9764\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.0891 - val_accuracy: 0.9768\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.0870 - val_accuracy: 0.9762\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9995 - val_loss: 0.0868 - val_accuracy: 0.9773\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 0.0880 - val_accuracy: 0.9771\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9996 - val_loss: 0.0909 - val_accuracy: 0.9764\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.0908 - val_accuracy: 0.9771\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.0920 - val_accuracy: 0.9768\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0921 - val_accuracy: 0.9775\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.0940 - val_accuracy: 0.9773\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0942 - val_accuracy: 0.9768\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0947 - val_accuracy: 0.9766\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.0966 - val_accuracy: 0.9770\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9777\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9772\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9983 - val_loss: 0.1117 - val_accuracy: 0.9747\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.1054 - val_accuracy: 0.9745\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.1040 - val_accuracy: 0.9768\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9781\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9779\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9777\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.0997e-04 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9779\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.5180e-04 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9783\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.9229e-04 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9780\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.2315e-04 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9775\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3150 - accuracy: 0.9067 - val_loss: 0.1843 - val_accuracy: 0.9474\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1413 - accuracy: 0.9594 - val_loss: 0.1408 - val_accuracy: 0.9607\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1057 - accuracy: 0.9690 - val_loss: 0.1180 - val_accuracy: 0.9662\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0831 - accuracy: 0.9762 - val_loss: 0.1085 - val_accuracy: 0.9686\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0697 - accuracy: 0.9803 - val_loss: 0.1011 - val_accuracy: 0.9711\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0589 - accuracy: 0.9832 - val_loss: 0.0956 - val_accuracy: 0.9718\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0505 - accuracy: 0.9863 - val_loss: 0.0932 - val_accuracy: 0.9722\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0436 - accuracy: 0.9885 - val_loss: 0.0884 - val_accuracy: 0.9747\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0381 - accuracy: 0.9901 - val_loss: 0.0863 - val_accuracy: 0.9751\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.9916 - val_loss: 0.0832 - val_accuracy: 0.9756\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9933 - val_loss: 0.0825 - val_accuracy: 0.9750\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0256 - accuracy: 0.9944 - val_loss: 0.0825 - val_accuracy: 0.9758\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0226 - accuracy: 0.9954 - val_loss: 0.0823 - val_accuracy: 0.9763\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0195 - accuracy: 0.9963 - val_loss: 0.0840 - val_accuracy: 0.9754\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0177 - accuracy: 0.9970 - val_loss: 0.0847 - val_accuracy: 0.9747\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0151 - accuracy: 0.9974 - val_loss: 0.0808 - val_accuracy: 0.9764\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0134 - accuracy: 0.9980 - val_loss: 0.0849 - val_accuracy: 0.9755\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0115 - accuracy: 0.9986 - val_loss: 0.0827 - val_accuracy: 0.9763\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0105 - accuracy: 0.9985 - val_loss: 0.0817 - val_accuracy: 0.9758\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0092 - accuracy: 0.9989 - val_loss: 0.0871 - val_accuracy: 0.9759\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.9991 - val_loss: 0.0850 - val_accuracy: 0.9757\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.0874 - val_accuracy: 0.9758\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9995 - val_loss: 0.0878 - val_accuracy: 0.9767\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9996 - val_loss: 0.0882 - val_accuracy: 0.9763\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 0.9998 - val_loss: 0.0904 - val_accuracy: 0.9759\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.0889 - val_accuracy: 0.9764\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.0901 - val_accuracy: 0.9774\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.0901 - val_accuracy: 0.9762\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.0924 - val_accuracy: 0.9773\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0934 - val_accuracy: 0.9762\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9765\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9762\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9772\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9762\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9758\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9770\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9762\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9770\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.6771e-04 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9768\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.9832e-04 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9774\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.9336e-04 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9768\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.9605e-04 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9765\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.1723e-04 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9772\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.7233e-04 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9770\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.1284e-04 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9765\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.9232e-04 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9776\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.6089e-04 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9768\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.9461e-04 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 0.9764\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.4447e-04 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 0.9768\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.0558e-04 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9766\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3100 - accuracy: 0.9086 - val_loss: 0.1771 - val_accuracy: 0.9513\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1399 - accuracy: 0.9597 - val_loss: 0.1396 - val_accuracy: 0.9607\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1046 - accuracy: 0.9696 - val_loss: 0.1188 - val_accuracy: 0.9657\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0830 - accuracy: 0.9764 - val_loss: 0.1104 - val_accuracy: 0.9687\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0700 - accuracy: 0.9804 - val_loss: 0.1013 - val_accuracy: 0.9708\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0595 - accuracy: 0.9834 - val_loss: 0.0945 - val_accuracy: 0.9728\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9858 - val_loss: 0.0906 - val_accuracy: 0.9733\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0440 - accuracy: 0.9878 - val_loss: 0.0874 - val_accuracy: 0.9747\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0393 - accuracy: 0.9893 - val_loss: 0.0890 - val_accuracy: 0.9746\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0346 - accuracy: 0.9912 - val_loss: 0.0880 - val_accuracy: 0.9747\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9929 - val_loss: 0.0842 - val_accuracy: 0.9743\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0262 - accuracy: 0.9940 - val_loss: 0.0812 - val_accuracy: 0.9773\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0232 - accuracy: 0.9950 - val_loss: 0.0834 - val_accuracy: 0.9751\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0205 - accuracy: 0.9960 - val_loss: 0.0814 - val_accuracy: 0.9762\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.9968 - val_loss: 0.0835 - val_accuracy: 0.9757\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.9972 - val_loss: 0.0795 - val_accuracy: 0.9770\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.0811 - val_accuracy: 0.9772\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0123 - accuracy: 0.9981 - val_loss: 0.0821 - val_accuracy: 0.9773\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0106 - accuracy: 0.9987 - val_loss: 0.0826 - val_accuracy: 0.9780\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.9989 - val_loss: 0.0840 - val_accuracy: 0.9773\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9993 - val_loss: 0.0846 - val_accuracy: 0.9771\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.0856 - val_accuracy: 0.9778\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.0857 - val_accuracy: 0.9786\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9996 - val_loss: 0.0885 - val_accuracy: 0.9778\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.9996 - val_loss: 0.0872 - val_accuracy: 0.9784\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.0875 - val_accuracy: 0.9778\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.0891 - val_accuracy: 0.9784\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0870 - val_accuracy: 0.9787\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.0895 - val_accuracy: 0.9791\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0917 - val_accuracy: 0.9782\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0925 - val_accuracy: 0.9787\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9781\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9783\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9787\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0964 - val_accuracy: 0.9787\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9790\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9792\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9793\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9792\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.6572e-04 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9788\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.0295e-04 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9787\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.7227e-04 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9782\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.9538e-04 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9787\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.1715e-04 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9788\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.0200e-04 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9793\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.7097e-04 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9794\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.6841e-04 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9796\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.9643e-04 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 0.9796\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.0261e-04 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9797\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.3176e-04 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9788\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 203,530\n",
            "Trainable params: 203,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4186 - accuracy: 0.8845 - val_loss: 0.2360 - val_accuracy: 0.9346\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1853 - accuracy: 0.9480 - val_loss: 0.1698 - val_accuracy: 0.9526\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.1330 - accuracy: 0.9617 - val_loss: 0.1480 - val_accuracy: 0.9563\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1041 - accuracy: 0.9699 - val_loss: 0.1156 - val_accuracy: 0.9680\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0816 - accuracy: 0.9768 - val_loss: 0.1112 - val_accuracy: 0.9678\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0678 - accuracy: 0.9810 - val_loss: 0.0971 - val_accuracy: 0.9712\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0562 - accuracy: 0.9845 - val_loss: 0.0959 - val_accuracy: 0.9718\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0468 - accuracy: 0.9872 - val_loss: 0.0859 - val_accuracy: 0.9757\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0401 - accuracy: 0.9890 - val_loss: 0.0826 - val_accuracy: 0.9762\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0333 - accuracy: 0.9915 - val_loss: 0.0835 - val_accuracy: 0.9753\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.9933 - val_loss: 0.0785 - val_accuracy: 0.9777\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0236 - accuracy: 0.9944 - val_loss: 0.0789 - val_accuracy: 0.9781\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0199 - accuracy: 0.9960 - val_loss: 0.0798 - val_accuracy: 0.9761\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9967 - val_loss: 0.0819 - val_accuracy: 0.9767\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 0.0822 - val_accuracy: 0.9770\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 0.0772 - val_accuracy: 0.9779\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0098 - accuracy: 0.9987 - val_loss: 0.0783 - val_accuracy: 0.9787\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9990 - val_loss: 0.0802 - val_accuracy: 0.9781\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9996 - val_loss: 0.0801 - val_accuracy: 0.9783\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 0.0796 - val_accuracy: 0.9794\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.0806 - val_accuracy: 0.9791\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0042 - accuracy: 0.9997 - val_loss: 0.0811 - val_accuracy: 0.9795\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.0806 - val_accuracy: 0.9796\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9797\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 0.9795\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9783\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9802\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9799\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9799\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9796\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9799\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.9900e-04 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9797\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.3834e-04 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 0.9782\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.8756e-04 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9800\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.4004e-04 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9804\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.4751e-04 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9803\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.1479e-04 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9800\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.0122e-04 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9806\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.0960e-04 - accuracy: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9794\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.3297e-04 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9801\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.4291e-04 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9803\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.0217e-04 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9805\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.7228e-04 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9807\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.4813e-04 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9802\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.1706e-04 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9804\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.0880e-04 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9803\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.9006e-04 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9807\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.6061e-04 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9805\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.4272e-04 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9797\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.3127e-04 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9803\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2684 - accuracy: 0.9214 - val_loss: 0.1530 - val_accuracy: 0.9567\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1103 - accuracy: 0.9683 - val_loss: 0.1154 - val_accuracy: 0.9685\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0764 - accuracy: 0.9778 - val_loss: 0.1005 - val_accuracy: 0.9717\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0596 - accuracy: 0.9826 - val_loss: 0.0920 - val_accuracy: 0.9735\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0469 - accuracy: 0.9871 - val_loss: 0.0846 - val_accuracy: 0.9754\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0378 - accuracy: 0.9899 - val_loss: 0.0810 - val_accuracy: 0.9760\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9919 - val_loss: 0.0788 - val_accuracy: 0.9771\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9939 - val_loss: 0.0806 - val_accuracy: 0.9758\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0216 - accuracy: 0.9952 - val_loss: 0.0759 - val_accuracy: 0.9783\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9965 - val_loss: 0.0776 - val_accuracy: 0.9777\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0145 - accuracy: 0.9976 - val_loss: 0.0772 - val_accuracy: 0.9776\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0120 - accuracy: 0.9985 - val_loss: 0.0773 - val_accuracy: 0.9784\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.9986 - val_loss: 0.0775 - val_accuracy: 0.9797\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9990 - val_loss: 0.0760 - val_accuracy: 0.9798\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.0758 - val_accuracy: 0.9797\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 0.0783 - val_accuracy: 0.9801\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0049 - accuracy: 0.9997 - val_loss: 0.0782 - val_accuracy: 0.9797\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.0795 - val_accuracy: 0.9803\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.0829 - val_accuracy: 0.9798\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.0809 - val_accuracy: 0.9800\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9797\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9795\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9803\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9803\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9796\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9807\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9807\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.6773e-04 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9803\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.4539e-04 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9808\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.5193e-04 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9808\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.5583e-04 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9807\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.8209e-04 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9801\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.1585e-04 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9803\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.7148e-04 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9803\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.1282e-04 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9803\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.6500e-04 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9812\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.3677e-04 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9803\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.1191 - val_accuracy: 0.9733\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.1029 - val_accuracy: 0.9789\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0991 - val_accuracy: 0.9803\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.5581e-04 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9799\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.4137e-04 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9804\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.9751e-04 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9801\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.6752e-04 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9804\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.4237e-04 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9804\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.2197e-04 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9805\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.0609e-04 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9808\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.8915e-04 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9804\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.7647e-04 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9804\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.6414e-04 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9805\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2756 - accuracy: 0.9193 - val_loss: 0.1504 - val_accuracy: 0.9567\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1135 - accuracy: 0.9665 - val_loss: 0.1216 - val_accuracy: 0.9645\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0796 - accuracy: 0.9765 - val_loss: 0.1015 - val_accuracy: 0.9707\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.9826 - val_loss: 0.0904 - val_accuracy: 0.9739\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.9870 - val_loss: 0.0858 - val_accuracy: 0.9740\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0379 - accuracy: 0.9900 - val_loss: 0.0814 - val_accuracy: 0.9756\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9920 - val_loss: 0.0799 - val_accuracy: 0.9769\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0254 - accuracy: 0.9940 - val_loss: 0.0762 - val_accuracy: 0.9783\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0206 - accuracy: 0.9955 - val_loss: 0.0767 - val_accuracy: 0.9774\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9966 - val_loss: 0.0773 - val_accuracy: 0.9789\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0142 - accuracy: 0.9976 - val_loss: 0.0743 - val_accuracy: 0.9780\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0117 - accuracy: 0.9983 - val_loss: 0.0775 - val_accuracy: 0.9782\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0097 - accuracy: 0.9989 - val_loss: 0.0745 - val_accuracy: 0.9783\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9991 - val_loss: 0.0776 - val_accuracy: 0.9777\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 0.0768 - val_accuracy: 0.9774\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9996 - val_loss: 0.0801 - val_accuracy: 0.9784\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.0784 - val_accuracy: 0.9791\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.0792 - val_accuracy: 0.9783\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.0817 - val_accuracy: 0.9785\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9787\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 0.9797\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9786\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9797\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9790\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9797\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9793\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9796\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.0660e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9792\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.9670e-04 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9796\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.1985e-04 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9793\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.2424e-04 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9793\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.6255e-04 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9792\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.2811e-04 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9795\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.6326e-04 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9787\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.9800e-04 - accuracy: 1.0000 - val_loss: 0.0944 - val_accuracy: 0.9796\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.5264e-04 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9793\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.1459e-04 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9794\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.7528e-04 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9791\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.5024e-04 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9792\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.2464e-04 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9790\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.9863e-04 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9795\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.8189e-04 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9790\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.6028e-04 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9793\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.4360e-04 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9785\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.3262e-04 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9793\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.1691e-04 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9794\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0547e-04 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9799\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.5198e-05 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9790\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.3446e-05 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9792\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.5341e-05 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9795\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3587 - accuracy: 0.9015 - val_loss: 0.2004 - val_accuracy: 0.9455\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1538 - accuracy: 0.9566 - val_loss: 0.1412 - val_accuracy: 0.9597\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1052 - accuracy: 0.9711 - val_loss: 0.1148 - val_accuracy: 0.9681\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0774 - accuracy: 0.9781 - val_loss: 0.0958 - val_accuracy: 0.9716\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0595 - accuracy: 0.9836 - val_loss: 0.0923 - val_accuracy: 0.9715\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0482 - accuracy: 0.9868 - val_loss: 0.0817 - val_accuracy: 0.9755\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.9900 - val_loss: 0.0812 - val_accuracy: 0.9761\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0301 - accuracy: 0.9922 - val_loss: 0.0773 - val_accuracy: 0.9780\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0241 - accuracy: 0.9944 - val_loss: 0.0741 - val_accuracy: 0.9783\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0191 - accuracy: 0.9959 - val_loss: 0.0758 - val_accuracy: 0.9774\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0155 - accuracy: 0.9968 - val_loss: 0.0766 - val_accuracy: 0.9772\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0118 - accuracy: 0.9982 - val_loss: 0.0715 - val_accuracy: 0.9793\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9981 - val_loss: 0.0738 - val_accuracy: 0.9783\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.0747 - val_accuracy: 0.9791\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.0750 - val_accuracy: 0.9797\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 0.0720 - val_accuracy: 0.9799\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 0.0710 - val_accuracy: 0.9815\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.0729 - val_accuracy: 0.9818\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0736 - val_accuracy: 0.9808\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9808\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9809\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9816\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9802\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9815\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9819\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.2599e-04 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9812\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.2909e-04 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9815\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.2237e-04 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9815\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.5409e-04 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9808\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.9301e-04 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9818\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.3358e-04 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9818\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.8518e-04 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9818\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.9552e-04 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9765\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0326 - accuracy: 0.9898 - val_loss: 0.1040 - val_accuracy: 0.9758\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0886 - val_accuracy: 0.9805\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0868 - val_accuracy: 0.9812\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.2500e-04 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 0.9814\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.3938e-04 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9818\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.6875e-04 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9819\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.2077e-04 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9821\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.8470e-04 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9823\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.5941e-04 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9819\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.3563e-04 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9822\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.1441e-04 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9822\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.9668e-04 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9823\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.7971e-04 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9820\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.6560e-04 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9823\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.5204e-04 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9821\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.4062e-04 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9822\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.2898e-04 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9824\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2437 - accuracy: 0.9260 - val_loss: 0.1300 - val_accuracy: 0.9638\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0911 - accuracy: 0.9733 - val_loss: 0.0997 - val_accuracy: 0.9714\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0603 - accuracy: 0.9829 - val_loss: 0.0872 - val_accuracy: 0.9741\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0441 - accuracy: 0.9873 - val_loss: 0.0806 - val_accuracy: 0.9764\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0329 - accuracy: 0.9909 - val_loss: 0.0780 - val_accuracy: 0.9776\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0241 - accuracy: 0.9941 - val_loss: 0.0744 - val_accuracy: 0.9778\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0183 - accuracy: 0.9958 - val_loss: 0.0714 - val_accuracy: 0.9792\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0135 - accuracy: 0.9977 - val_loss: 0.0710 - val_accuracy: 0.9783\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.0703 - val_accuracy: 0.9803\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9990 - val_loss: 0.0701 - val_accuracy: 0.9803\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9995 - val_loss: 0.0717 - val_accuracy: 0.9808\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.9998 - val_loss: 0.0714 - val_accuracy: 0.9804\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0723 - val_accuracy: 0.9811\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0741 - val_accuracy: 0.9803\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.0735 - val_accuracy: 0.9808\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 0.9815\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0738 - val_accuracy: 0.9818\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9811\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 0.9813\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0759 - val_accuracy: 0.9823\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.7900e-04 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9816\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.8996e-04 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9809\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.8364e-04 - accuracy: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9821\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.8057e-04 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9823\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.1783e-04 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9819\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.5741e-04 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9820\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.9442e-04 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9815\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.5361e-04 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9819\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.0889e-04 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9822\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.7707e-04 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9818\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.4643e-04 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9820\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.2327e-04 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9820\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.0317e-04 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 0.9820\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.7667e-04 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9819\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.5603e-04 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9821\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.3829e-04 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9821\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2399e-04 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9822\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0919e-04 - accuracy: 1.0000 - val_loss: 0.0910 - val_accuracy: 0.9820\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.9643e-05 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9820\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.9539e-05 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9822\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.9968e-05 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9827\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.0028e-05 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9822\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.3451e-05 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9822\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.7321e-05 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9827\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.1378e-05 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9827\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.5949e-05 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9824\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.1724e-05 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9822\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.8575e-05 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9827\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.3190e-05 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9823\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.9794e-05 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9822\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2365 - accuracy: 0.9275 - val_loss: 0.1295 - val_accuracy: 0.9637\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0900 - accuracy: 0.9731 - val_loss: 0.0971 - val_accuracy: 0.9727\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0580 - accuracy: 0.9831 - val_loss: 0.0870 - val_accuracy: 0.9741\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0429 - accuracy: 0.9878 - val_loss: 0.0772 - val_accuracy: 0.9770\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9916 - val_loss: 0.0762 - val_accuracy: 0.9774\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0228 - accuracy: 0.9946 - val_loss: 0.0762 - val_accuracy: 0.9779\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9965 - val_loss: 0.0722 - val_accuracy: 0.9790\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0130 - accuracy: 0.9975 - val_loss: 0.0714 - val_accuracy: 0.9796\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0102 - accuracy: 0.9985 - val_loss: 0.0690 - val_accuracy: 0.9807\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 0.0707 - val_accuracy: 0.9804\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.0707 - val_accuracy: 0.9808\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0043 - accuracy: 0.9997 - val_loss: 0.0720 - val_accuracy: 0.9811\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.0731 - val_accuracy: 0.9804\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0745 - val_accuracy: 0.9808\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0732 - val_accuracy: 0.9811\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 0.9809\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9809\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9808\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9817\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.9203e-04 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9818\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.5552e-04 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9814\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.5823e-04 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9816\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.4284e-04 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9812\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.6466e-04 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9810\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.0254e-04 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9814\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.3835e-04 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 0.9815\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.9697e-04 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 0.9814\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.4100e-04 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9812\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.0447e-04 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9813\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.6576e-04 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9818\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.3789e-04 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9818\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.1005e-04 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9816\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.9119e-04 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9817\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.6870e-04 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9816\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.5154e-04 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9816\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.3500e-04 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9818\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2031e-04 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9818\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0704e-04 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9821\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.6383e-05 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9818\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.5132e-05 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9818\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.5856e-05 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9818\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.0314e-05 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9816\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.0678e-05 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9818\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.5060e-05 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9819\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.9297e-05 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9815\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.4420e-05 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9823\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.9858e-05 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9822\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.6278e-05 - accuracy: 1.0000 - val_loss: 0.0987 - val_accuracy: 0.9825\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.2232e-05 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9821\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.9634e-05 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs3foSzo7mJf",
        "colab_type": "text"
      },
      "source": [
        "With the accuracy values retrieved, we plot the graph:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eA37HV57ktR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "74df247a-fc17-4c84-ed9f-bff51df7ad91"
      },
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "multiple_line_chart(plt.gca(), \n",
        "                    None, \n",
        "                    accuracy_lines, \n",
        "                    \"Validation accuracy variation per size of the hidden layer\", \n",
        "                    \"Epochs\", \n",
        "                    \"Validation accuracy\")\n",
        "plt.show()\n",
        "plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6pTilFmC1Bh",
        "colab_type": "text"
      },
      "source": [
        "Looking at the graphs it becomes clear how much impact the hidden layer has, especially with a big size. Clearly having an hidden layer in this dataset allows the model to learn behaviour that a single-layer just can't reproduce.\n",
        "From the graph we can choose the most appropriate size wich appears to be 128. Even though higher values manage to get higher accuracy, the increase is pretty small considering we're doubling the size and, in this case (single hidden layer) doubling the number of params. Let us now run the model with size 128 until convergence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t43uumncDk2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87047fe4-f3fc-4636-9a7a-f5c4162dfdd2"
      },
      "source": [
        "multi_layer_single_hidden_model = create_multi_layer_single_hidden_model(128)\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=25, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('multi_layer_single_hidden_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "multi_layer_single_hidden_train = multi_layer_single_hidden_model.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.5281 - accuracy: 0.8577\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.92508, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5097 - accuracy: 0.8621 - val_loss: 0.2740 - val_accuracy: 0.9251\n",
            "Epoch 2/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.2272 - accuracy: 0.9366\n",
            "Epoch 00002: val_accuracy improved from 0.92508 to 0.94400, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2271 - accuracy: 0.9366 - val_loss: 0.2099 - val_accuracy: 0.9440\n",
            "Epoch 3/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.1742 - accuracy: 0.9506\n",
            "Epoch 00003: val_accuracy improved from 0.94400 to 0.95075, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1737 - accuracy: 0.9507 - val_loss: 0.1722 - val_accuracy: 0.9507\n",
            "Epoch 4/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.1403 - accuracy: 0.9595\n",
            "Epoch 00004: val_accuracy improved from 0.95075 to 0.95767, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1398 - accuracy: 0.9597 - val_loss: 0.1521 - val_accuracy: 0.9577\n",
            "Epoch 5/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.1168 - accuracy: 0.9672\n",
            "Epoch 00005: val_accuracy improved from 0.95767 to 0.96283, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1161 - accuracy: 0.9674 - val_loss: 0.1355 - val_accuracy: 0.9628\n",
            "Epoch 6/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.0989 - accuracy: 0.9720\n",
            "Epoch 00006: val_accuracy improved from 0.96283 to 0.96475, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.9721 - val_loss: 0.1247 - val_accuracy: 0.9647\n",
            "Epoch 7/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.0851 - accuracy: 0.9761\n",
            "Epoch 00007: val_accuracy improved from 0.96475 to 0.96650, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0850 - accuracy: 0.9762 - val_loss: 0.1170 - val_accuracy: 0.9665\n",
            "Epoch 8/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.0739 - accuracy: 0.9795\n",
            "Epoch 00008: val_accuracy improved from 0.96650 to 0.96825, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0739 - accuracy: 0.9794 - val_loss: 0.1095 - val_accuracy: 0.9682\n",
            "Epoch 9/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.0647 - accuracy: 0.9822\n",
            "Epoch 00009: val_accuracy did not improve from 0.96825\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0647 - accuracy: 0.9820 - val_loss: 0.1086 - val_accuracy: 0.9682\n",
            "Epoch 10/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0570 - accuracy: 0.9843\n",
            "Epoch 00010: val_accuracy improved from 0.96825 to 0.97008, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0571 - accuracy: 0.9842 - val_loss: 0.1026 - val_accuracy: 0.9701\n",
            "Epoch 11/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.9866\n",
            "Epoch 00011: val_accuracy improved from 0.97008 to 0.97225, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0501 - accuracy: 0.9866 - val_loss: 0.0965 - val_accuracy: 0.9722\n",
            "Epoch 12/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0450 - accuracy: 0.9879\n",
            "Epoch 00012: val_accuracy did not improve from 0.97225\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0453 - accuracy: 0.9878 - val_loss: 0.0971 - val_accuracy: 0.9719\n",
            "Epoch 13/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.0395 - accuracy: 0.9898\n",
            "Epoch 00013: val_accuracy improved from 0.97225 to 0.97358, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0395 - accuracy: 0.9898 - val_loss: 0.0925 - val_accuracy: 0.9736\n",
            "Epoch 14/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.0354 - accuracy: 0.9910\n",
            "Epoch 00014: val_accuracy improved from 0.97358 to 0.97442, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0355 - accuracy: 0.9909 - val_loss: 0.0923 - val_accuracy: 0.9744\n",
            "Epoch 15/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0310 - accuracy: 0.9926\n",
            "Epoch 00015: val_accuracy did not improve from 0.97442\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9924 - val_loss: 0.0970 - val_accuracy: 0.9714\n",
            "Epoch 16/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9933\n",
            "Epoch 00016: val_accuracy did not improve from 0.97442\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9933 - val_loss: 0.0921 - val_accuracy: 0.9727\n",
            "Epoch 17/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.0245 - accuracy: 0.9941\n",
            "Epoch 00017: val_accuracy did not improve from 0.97442\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0246 - accuracy: 0.9941 - val_loss: 0.0897 - val_accuracy: 0.9737\n",
            "Epoch 18/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0214 - accuracy: 0.9954\n",
            "Epoch 00018: val_accuracy did not improve from 0.97442\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0216 - accuracy: 0.9954 - val_loss: 0.0902 - val_accuracy: 0.9744\n",
            "Epoch 19/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0191 - accuracy: 0.9964\n",
            "Epoch 00019: val_accuracy did not improve from 0.97442\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0192 - accuracy: 0.9964 - val_loss: 0.0892 - val_accuracy: 0.9744\n",
            "Epoch 20/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.0171 - accuracy: 0.9969\n",
            "Epoch 00020: val_accuracy did not improve from 0.97442\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9967 - val_loss: 0.0935 - val_accuracy: 0.9735\n",
            "Epoch 21/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0152 - accuracy: 0.9974\n",
            "Epoch 00021: val_accuracy did not improve from 0.97442\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0151 - accuracy: 0.9975 - val_loss: 0.0933 - val_accuracy: 0.9741\n",
            "Epoch 22/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.0136 - accuracy: 0.9979\n",
            "Epoch 00022: val_accuracy improved from 0.97442 to 0.97475, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0135 - accuracy: 0.9979 - val_loss: 0.0879 - val_accuracy: 0.9747\n",
            "Epoch 23/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0121 - accuracy: 0.9983\n",
            "Epoch 00023: val_accuracy improved from 0.97475 to 0.97542, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.0900 - val_accuracy: 0.9754\n",
            "Epoch 24/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9986\n",
            "Epoch 00024: val_accuracy improved from 0.97542 to 0.97617, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.9986 - val_loss: 0.0911 - val_accuracy: 0.9762\n",
            "Epoch 25/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 0.0092 - accuracy: 0.9991\n",
            "Epoch 00025: val_accuracy did not improve from 0.97617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9990 - val_loss: 0.0917 - val_accuracy: 0.9749\n",
            "Epoch 26/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.0081 - accuracy: 0.9992\n",
            "Epoch 00026: val_accuracy did not improve from 0.97617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.0959 - val_accuracy: 0.9747\n",
            "Epoch 27/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.0076 - accuracy: 0.9993\n",
            "Epoch 00027: val_accuracy did not improve from 0.97617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.0927 - val_accuracy: 0.9758\n",
            "Epoch 28/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9995\n",
            "Epoch 00028: val_accuracy did not improve from 0.97617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9995 - val_loss: 0.0947 - val_accuracy: 0.9751\n",
            "Epoch 29/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0057 - accuracy: 0.9996\n",
            "Epoch 00029: val_accuracy did not improve from 0.97617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.0929 - val_accuracy: 0.9759\n",
            "Epoch 30/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0049 - accuracy: 0.9998\n",
            "Epoch 00030: val_accuracy improved from 0.97617 to 0.97708, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0049 - accuracy: 0.9998 - val_loss: 0.0960 - val_accuracy: 0.9771\n",
            "Epoch 31/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.0043 - accuracy: 0.9998\n",
            "Epoch 00031: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.0973 - val_accuracy: 0.9758\n",
            "Epoch 32/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9998\n",
            "Epoch 00032: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 0.0979 - val_accuracy: 0.9766\n",
            "Epoch 33/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 00033: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9753\n",
            "Epoch 34/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 00034: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9763\n",
            "Epoch 35/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 00035: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.1009 - val_accuracy: 0.9751\n",
            "Epoch 36/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.0029 - accuracy: 0.9999\n",
            "Epoch 00036: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.0985 - val_accuracy: 0.9759\n",
            "Epoch 37/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 00037: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9745\n",
            "Epoch 38/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 00038: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9762\n",
            "Epoch 39/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 00039: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9753\n",
            "Epoch 40/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 00040: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9753\n",
            "Epoch 41/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 00041: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9762\n",
            "Epoch 42/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 00042: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9753\n",
            "Epoch 43/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 00043: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9751\n",
            "Epoch 44/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000    \n",
            "Epoch 00044: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9757\n",
            "Epoch 45/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 00045: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9759\n",
            "Epoch 46/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 8.2413e-04 - accuracy: 1.0000\n",
            "Epoch 00046: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.3047e-04 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9760\n",
            "Epoch 47/10000\n",
            "169/188 [=========================>....] - ETA: 0s - loss: 7.5440e-04 - accuracy: 1.0000\n",
            "Epoch 00047: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.4563e-04 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 0.9768\n",
            "Epoch 48/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 6.8357e-04 - accuracy: 1.0000\n",
            "Epoch 00048: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.8657e-04 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9753\n",
            "Epoch 49/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 6.0652e-04 - accuracy: 1.0000\n",
            "Epoch 00049: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.0917e-04 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9760\n",
            "Epoch 50/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 5.8478e-04 - accuracy: 1.0000\n",
            "Epoch 00050: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.8380e-04 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9765\n",
            "Epoch 51/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 5.3220e-04 - accuracy: 1.0000\n",
            "Epoch 00051: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.3176e-04 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9762\n",
            "Epoch 52/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 6.3251e-04 - accuracy: 1.0000\n",
            "Epoch 00052: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.4602e-04 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9764\n",
            "Epoch 53/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9950\n",
            "Epoch 00053: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.1292 - val_accuracy: 0.9740\n",
            "Epoch 54/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9995\n",
            "Epoch 00054: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1258 - val_accuracy: 0.9769\n",
            "Epoch 55/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 6.7213e-04 - accuracy: 1.0000\n",
            "Epoch 00055: val_accuracy did not improve from 0.97708\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.6531e-04 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9769\n",
            "Epoch 00055: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMUrVD1hGQJ5",
        "colab_type": "text"
      },
      "source": [
        "and plot the loss and accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaCy31EukUZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "e5f4dfd2-242d-4c62-bcbe-f8229e0e1056"
      },
      "source": [
        "plot_loss_accuracy(multi_layer_single_hidden_train.history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF74iJI2GY7b",
        "colab_type": "text"
      },
      "source": [
        "And evaluate the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBI3iSYaklMM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "429056f4-15f4-47fe-d257-4f31f07f75ce"
      },
      "source": [
        "multi_layer_single_hidden_model.load_weights('multi_layer_single_hidden_best.h5')\n",
        "loss, acc = multi_layer_single_hidden_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy: {}'.format(acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9770\n",
            "Accuracy: 0.9769999980926514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHyxzdNKCPsi",
        "colab_type": "text"
      },
      "source": [
        "Already simply from including a single hidden-layer, the accuracy reaches almost 98%, obviously outperforming the single-layer. Although this is already a very good value without using CNN's, it makes uses of a single, \"fat\" hidden layer, that suffers greatly with the curse of dimensionality. On the contrary, a deep NN manages this curse effectively while simultaneously distributing the data through a hierarchy of conditions, great for its representability. As such we will try to divide this layer, into multiple."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQCzSs6UJFua",
        "colab_type": "text"
      },
      "source": [
        "##### Multiple Hidden Layers\n",
        "\n",
        "Usually, replacing a \"fat\" NN with a \"deep\", involves a tradeoff between individual size and depth, in order to maintain the number of params. In this case however, given how much bigger the flatten layer is in comparison with the hidden layers (784 >> 128), the great majority of params come from this transition alone (100480), whilst each transition between layers contributes with less than 20% (16512), being relatively cheap to expand. Given this fact, increasing the depth is just a matter of adding more hidden-layers of the same size. Let us now plot the impact of hte number of hidden layers.\n",
        "Note: The values were retrieved from the networks' summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd7HjISMLGwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_multi_layer_multi_hidden_model(layers, name='multi_layer_multi_hidden_model'):\n",
        "  multi_layer_model = tf.keras.Sequential(name=name)\n",
        "  multi_layer_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  multi_layer_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "  for i in range(layers):\n",
        "    multi_layer_model.add(tf.keras.layers.Dense(128, activation='relu', name='hidden{}'.format(i)))\n",
        "  multi_layer_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "\n",
        "  multi_layer_model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "  multi_layer_model.summary()\n",
        "  return multi_layer_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WrC7j2X3NsC8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d92f228e-3868-4a43-a014-c2c450ba115b"
      },
      "source": [
        "hidden_layer_count = (1, 2, 3, 4, 5)\n",
        "accuracy_lines = test_model_parameter(create_multi_layer_multi_hidden_model, hidden_layer_count, 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"multi_layer_multi_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4867 - accuracy: 0.8665 - val_loss: 0.2699 - val_accuracy: 0.9249\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.2218 - accuracy: 0.9368 - val_loss: 0.2089 - val_accuracy: 0.9413\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1682 - accuracy: 0.9526 - val_loss: 0.1707 - val_accuracy: 0.9524\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1325 - accuracy: 0.9631 - val_loss: 0.1454 - val_accuracy: 0.9588\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1098 - accuracy: 0.9695 - val_loss: 0.1296 - val_accuracy: 0.9636\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0922 - accuracy: 0.9746 - val_loss: 0.1185 - val_accuracy: 0.9680\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0797 - accuracy: 0.9780 - val_loss: 0.1101 - val_accuracy: 0.9688\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0687 - accuracy: 0.9814 - val_loss: 0.1026 - val_accuracy: 0.9696\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0608 - accuracy: 0.9836 - val_loss: 0.0963 - val_accuracy: 0.9717\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0522 - accuracy: 0.9862 - val_loss: 0.0930 - val_accuracy: 0.9722\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.9879 - val_loss: 0.0885 - val_accuracy: 0.9743\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0409 - accuracy: 0.9896 - val_loss: 0.0864 - val_accuracy: 0.9743\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9907 - val_loss: 0.0862 - val_accuracy: 0.9754\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0326 - accuracy: 0.9915 - val_loss: 0.0837 - val_accuracy: 0.9750\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9936 - val_loss: 0.0846 - val_accuracy: 0.9758\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9943 - val_loss: 0.0839 - val_accuracy: 0.9760\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0223 - accuracy: 0.9953 - val_loss: 0.0823 - val_accuracy: 0.9767\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0201 - accuracy: 0.9960 - val_loss: 0.0854 - val_accuracy: 0.9762\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0175 - accuracy: 0.9966 - val_loss: 0.0857 - val_accuracy: 0.9743\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0154 - accuracy: 0.9974 - val_loss: 0.0808 - val_accuracy: 0.9770\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.0828 - val_accuracy: 0.9766\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0119 - accuracy: 0.9983 - val_loss: 0.0850 - val_accuracy: 0.9774\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0110 - accuracy: 0.9985 - val_loss: 0.0854 - val_accuracy: 0.9768\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 0.0866 - val_accuracy: 0.9766\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9993 - val_loss: 0.0868 - val_accuracy: 0.9768\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.0856 - val_accuracy: 0.9763\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.0857 - val_accuracy: 0.9772\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 0.0879 - val_accuracy: 0.9772\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.0923 - val_accuracy: 0.9767\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.0923 - val_accuracy: 0.9761\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.0901 - val_accuracy: 0.9773\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9769\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.0934 - val_accuracy: 0.9776\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9778\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9771\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9768\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9767\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9757\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9762\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9765\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9776\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9770\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.8807e-04 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9769\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.8512e-04 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9770\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.7808e-04 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9776\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.1098e-04 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9770\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.7159e-04 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9759\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.1310 - val_accuracy: 0.9745\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.1166 - val_accuracy: 0.9768\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9778\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3325 - accuracy: 0.9018 - val_loss: 0.1952 - val_accuracy: 0.9450\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1561 - accuracy: 0.9552 - val_loss: 0.1502 - val_accuracy: 0.9580\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1155 - accuracy: 0.9673 - val_loss: 0.1335 - val_accuracy: 0.9610\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0923 - accuracy: 0.9742 - val_loss: 0.1121 - val_accuracy: 0.9680\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0769 - accuracy: 0.9786 - val_loss: 0.1067 - val_accuracy: 0.9680\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0653 - accuracy: 0.9820 - val_loss: 0.0979 - val_accuracy: 0.9707\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0557 - accuracy: 0.9849 - val_loss: 0.0919 - val_accuracy: 0.9736\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0490 - accuracy: 0.9866 - val_loss: 0.0889 - val_accuracy: 0.9736\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0426 - accuracy: 0.9887 - val_loss: 0.0875 - val_accuracy: 0.9732\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.9904 - val_loss: 0.0846 - val_accuracy: 0.9746\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0328 - accuracy: 0.9918 - val_loss: 0.0832 - val_accuracy: 0.9749\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.9930 - val_loss: 0.0797 - val_accuracy: 0.9760\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0246 - accuracy: 0.9947 - val_loss: 0.0783 - val_accuracy: 0.9767\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0223 - accuracy: 0.9949 - val_loss: 0.0799 - val_accuracy: 0.9753\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9964 - val_loss: 0.0784 - val_accuracy: 0.9772\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9968 - val_loss: 0.0762 - val_accuracy: 0.9772\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0154 - accuracy: 0.9973 - val_loss: 0.0776 - val_accuracy: 0.9777\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.0796 - val_accuracy: 0.9763\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.0789 - val_accuracy: 0.9769\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.9988 - val_loss: 0.0768 - val_accuracy: 0.9774\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.9991 - val_loss: 0.0804 - val_accuracy: 0.9773\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9993 - val_loss: 0.0771 - val_accuracy: 0.9778\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.0799 - val_accuracy: 0.9778\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 0.0800 - val_accuracy: 0.9775\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.0801 - val_accuracy: 0.9782\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.0828 - val_accuracy: 0.9779\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.0813 - val_accuracy: 0.9786\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.0828 - val_accuracy: 0.9781\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9773\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9787\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0864 - val_accuracy: 0.9783\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9780\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9767\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9786\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9774\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9782\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9781\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9774\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9787\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.5597e-04 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9779\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.4990e-04 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9783\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.8078e-04 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9783\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.8230e-04 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9777\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.1815e-04 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9785\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.8398e-04 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9780\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.0947e-04 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9779\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.9571e-04 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9783\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.2258e-04 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9783\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.9347e-04 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9785\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.2642e-04 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9787\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3098 - accuracy: 0.9081 - val_loss: 0.1791 - val_accuracy: 0.9490\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1407 - accuracy: 0.9595 - val_loss: 0.1481 - val_accuracy: 0.9580\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1055 - accuracy: 0.9696 - val_loss: 0.1219 - val_accuracy: 0.9651\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0844 - accuracy: 0.9762 - val_loss: 0.1097 - val_accuracy: 0.9678\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0698 - accuracy: 0.9805 - val_loss: 0.0980 - val_accuracy: 0.9707\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0595 - accuracy: 0.9837 - val_loss: 0.0978 - val_accuracy: 0.9699\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0517 - accuracy: 0.9859 - val_loss: 0.0948 - val_accuracy: 0.9714\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0449 - accuracy: 0.9884 - val_loss: 0.0898 - val_accuracy: 0.9737\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0396 - accuracy: 0.9894 - val_loss: 0.0850 - val_accuracy: 0.9744\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0347 - accuracy: 0.9914 - val_loss: 0.0844 - val_accuracy: 0.9744\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9931 - val_loss: 0.0835 - val_accuracy: 0.9753\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9936 - val_loss: 0.0853 - val_accuracy: 0.9753\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0238 - accuracy: 0.9948 - val_loss: 0.0853 - val_accuracy: 0.9750\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0211 - accuracy: 0.9954 - val_loss: 0.0801 - val_accuracy: 0.9761\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9959 - val_loss: 0.0782 - val_accuracy: 0.9761\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0166 - accuracy: 0.9966 - val_loss: 0.0837 - val_accuracy: 0.9762\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9974 - val_loss: 0.0814 - val_accuracy: 0.9758\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0130 - accuracy: 0.9978 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0118 - accuracy: 0.9980 - val_loss: 0.0792 - val_accuracy: 0.9772\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9987 - val_loss: 0.0818 - val_accuracy: 0.9770\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0086 - accuracy: 0.9992 - val_loss: 0.0807 - val_accuracy: 0.9778\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9993 - val_loss: 0.0830 - val_accuracy: 0.9768\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.0818 - val_accuracy: 0.9777\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9997 - val_loss: 0.0820 - val_accuracy: 0.9774\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0855 - val_accuracy: 0.9777\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9997 - val_loss: 0.0847 - val_accuracy: 0.9772\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0042 - accuracy: 0.9998 - val_loss: 0.0882 - val_accuracy: 0.9772\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.0850 - val_accuracy: 0.9789\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.0865 - val_accuracy: 0.9784\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0849 - val_accuracy: 0.9781\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0877 - val_accuracy: 0.9786\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9786\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9789\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9783\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9784\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9783\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9779\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9787\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9791\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.2616e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9785\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.2842e-04 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9783\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.3054e-04 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9786\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.0979e-04 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9787\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.0423e-04 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9790\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.5219e-04 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9785\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.9626e-04 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9787\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.8639e-04 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9780\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.1875e-04 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9783\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.1229 - val_accuracy: 0.9747\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.1151 - val_accuracy: 0.9771\n",
            "Model: \"multi_layer_multi_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4413 - accuracy: 0.8801 - val_loss: 0.2188 - val_accuracy: 0.9352\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1723 - accuracy: 0.9491 - val_loss: 0.1598 - val_accuracy: 0.9553\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1212 - accuracy: 0.9643 - val_loss: 0.1325 - val_accuracy: 0.9613\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0929 - accuracy: 0.9727 - val_loss: 0.1093 - val_accuracy: 0.9688\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0752 - accuracy: 0.9770 - val_loss: 0.1044 - val_accuracy: 0.9688\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0599 - accuracy: 0.9823 - val_loss: 0.0998 - val_accuracy: 0.9714\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9853 - val_loss: 0.0927 - val_accuracy: 0.9722\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.9875 - val_loss: 0.0898 - val_accuracy: 0.9740\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.9908 - val_loss: 0.0901 - val_accuracy: 0.9737\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.9904 - val_loss: 0.0863 - val_accuracy: 0.9751\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.0896 - val_accuracy: 0.9752\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9949 - val_loss: 0.0827 - val_accuracy: 0.9774\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 0.0958 - val_accuracy: 0.9736\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 0.0948 - val_accuracy: 0.9764\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.0918 - val_accuracy: 0.9763\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.0977 - val_accuracy: 0.9751\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.1221 - val_accuracy: 0.9698\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0949 - val_accuracy: 0.9768\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.0939 - val_accuracy: 0.9775\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0974 - val_accuracy: 0.9784\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0989 - val_accuracy: 0.9773\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 0.1108 - val_accuracy: 0.9741\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.1212 - val_accuracy: 0.9721\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.1079 - val_accuracy: 0.9765\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.1097 - val_accuracy: 0.9759\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.1017 - val_accuracy: 0.9789\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.3224e-04 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9796\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.3594e-04 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9793\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.1880e-04 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9793\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.6956e-04 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9794\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.3893e-04 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9791\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.9883e-04 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9799\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.6314e-04 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9798\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.4174e-04 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9797\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.1997e-04 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9803\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.0306e-04 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9802\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.8598e-04 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9803\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.6719e-04 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9803\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5262e-04 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9799\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.4239e-04 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9797\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2946e-04 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9796\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1349e-04 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9802\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0348e-04 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9793\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.4205e-05 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9797\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.3023e-05 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9793\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.9781e-05 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9799\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.0578e-05 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9795\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.4312e-05 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9799\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.8099e-05 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9801\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.4010e-05 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9797\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2877 - accuracy: 0.9150 - val_loss: 0.1515 - val_accuracy: 0.9563\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1081 - accuracy: 0.9666 - val_loss: 0.1234 - val_accuracy: 0.9642\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0738 - accuracy: 0.9772 - val_loss: 0.0991 - val_accuracy: 0.9699\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0522 - accuracy: 0.9840 - val_loss: 0.0878 - val_accuracy: 0.9727\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0414 - accuracy: 0.9881 - val_loss: 0.0864 - val_accuracy: 0.9741\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0314 - accuracy: 0.9909 - val_loss: 0.0843 - val_accuracy: 0.9752\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9929 - val_loss: 0.0786 - val_accuracy: 0.9765\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.0879 - val_accuracy: 0.9767\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 0.0807 - val_accuracy: 0.9777\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9972 - val_loss: 0.0797 - val_accuracy: 0.9774\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0845 - val_accuracy: 0.9793\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.0887 - val_accuracy: 0.9774\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0856 - val_accuracy: 0.9787\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.0895 - val_accuracy: 0.9792\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9996 - val_loss: 0.0935 - val_accuracy: 0.9784\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0930 - val_accuracy: 0.9793\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0980 - val_accuracy: 0.9780\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9793\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.0342e-04 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9795\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.7091e-04 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9793\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.6420e-04 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9791\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.7760e-04 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9792\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.1051e-04 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9794\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.5385e-04 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9796\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.1489e-04 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9784\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.7692e-04 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9792\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.5117e-04 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9789\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.1321e-04 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9790\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.8516e-04 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9796\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.7000e-04 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9794\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.4725e-04 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9789\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2883e-04 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9786\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1286e-04 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9792\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0133e-04 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9788\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.8974e-05 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9788\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.9744e-05 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9789\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.0568e-05 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9788\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.3017e-05 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9787\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.5496e-05 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9791\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.9456e-05 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9789\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9927 - val_loss: 0.1955 - val_accuracy: 0.9581\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0285 - accuracy: 0.9909 - val_loss: 0.1220 - val_accuracy: 0.9746\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.1142 - val_accuracy: 0.9783\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.1159 - val_accuracy: 0.9783\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.6502e-04 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9794\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.0110e-04 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9792\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.3597e-04 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9787\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.9705e-04 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9791\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.6767e-04 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9793\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.4715e-04 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9790\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3199 - accuracy: 0.9066 - val_loss: 0.1625 - val_accuracy: 0.9538\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1164 - accuracy: 0.9651 - val_loss: 0.1238 - val_accuracy: 0.9633\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0781 - accuracy: 0.9766 - val_loss: 0.1046 - val_accuracy: 0.9694\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0612 - accuracy: 0.9815 - val_loss: 0.0894 - val_accuracy: 0.9746\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0447 - accuracy: 0.9869 - val_loss: 0.0910 - val_accuracy: 0.9726\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0348 - accuracy: 0.9898 - val_loss: 0.0901 - val_accuracy: 0.9744\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.0855 - val_accuracy: 0.9755\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0221 - accuracy: 0.9938 - val_loss: 0.0846 - val_accuracy: 0.9770\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0168 - accuracy: 0.9960 - val_loss: 0.0891 - val_accuracy: 0.9748\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.0866 - val_accuracy: 0.9767\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9977 - val_loss: 0.0828 - val_accuracy: 0.9783\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.0852 - val_accuracy: 0.9773\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.0934 - val_accuracy: 0.9770\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0904 - val_accuracy: 0.9779\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.0910 - val_accuracy: 0.9775\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0903 - val_accuracy: 0.9793\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9787\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9793\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.1044 - val_accuracy: 0.9762\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9929 - val_loss: 0.1059 - val_accuracy: 0.9759\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.1059 - val_accuracy: 0.9763\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0990 - val_accuracy: 0.9787\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9793\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.1550e-04 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9797\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.8483e-04 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9802\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.1716e-04 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9802\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.7578e-04 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9800\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.4486e-04 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9797\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.1843e-04 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9804\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.9241e-04 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9799\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.7354e-04 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9802\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5890e-04 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 0.9801\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.4544e-04 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9803\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2948e-04 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9800\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.1662e-04 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 0.9801\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0541e-04 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9801\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.6106e-05 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9802\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.5503e-05 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9802\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.9141e-05 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9802\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.1375e-05 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9800\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.3816e-05 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9799\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.8057e-05 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9802\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.2352e-05 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9800\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.7864e-05 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9796\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.3031e-05 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 0.9794\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.9233e-05 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9795\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.5550e-05 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9803\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.1701e-05 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9802\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.8615e-05 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9795\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.5799e-05 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.9796\n",
            "Model: \"multi_layer_multi_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4280 - accuracy: 0.8793 - val_loss: 0.1948 - val_accuracy: 0.9420\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1582 - accuracy: 0.9529 - val_loss: 0.1622 - val_accuracy: 0.9515\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1139 - accuracy: 0.9664 - val_loss: 0.1333 - val_accuracy: 0.9592\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0866 - accuracy: 0.9739 - val_loss: 0.1062 - val_accuracy: 0.9693\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0705 - accuracy: 0.9791 - val_loss: 0.0969 - val_accuracy: 0.9726\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0542 - accuracy: 0.9831 - val_loss: 0.0948 - val_accuracy: 0.9718\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0424 - accuracy: 0.9874 - val_loss: 0.0945 - val_accuracy: 0.9724\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0344 - accuracy: 0.9896 - val_loss: 0.0961 - val_accuracy: 0.9741\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0284 - accuracy: 0.9910 - val_loss: 0.0861 - val_accuracy: 0.9764\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 0.0937 - val_accuracy: 0.9756\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.1003 - val_accuracy: 0.9750\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.0960 - val_accuracy: 0.9765\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.1018 - val_accuracy: 0.9752\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.1022 - val_accuracy: 0.9756\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.1076 - val_accuracy: 0.9753\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.1271 - val_accuracy: 0.9709\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.1181 - val_accuracy: 0.9752\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.1101 - val_accuracy: 0.9762\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.1305 - val_accuracy: 0.9753\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.1201 - val_accuracy: 0.9744\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0102 - accuracy: 0.9962 - val_loss: 0.1173 - val_accuracy: 0.9767\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1182 - val_accuracy: 0.9793\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.1229 - val_accuracy: 0.9777\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.1236 - val_accuracy: 0.9772\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.1406 - val_accuracy: 0.9753\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.1343 - val_accuracy: 0.9744\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.1371 - val_accuracy: 0.9750\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1344 - val_accuracy: 0.9771\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1407 - val_accuracy: 0.9764\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.1405 - val_accuracy: 0.9782\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.1679 - val_accuracy: 0.9737\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.1524 - val_accuracy: 0.9747\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.1297 - val_accuracy: 0.9768\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.1402 - val_accuracy: 0.9758\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.1380 - val_accuracy: 0.9780\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1396 - val_accuracy: 0.9778\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.1328 - val_accuracy: 0.9791\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.4269e-04 - accuracy: 0.9998 - val_loss: 0.1302 - val_accuracy: 0.9793\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.3707e-04 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9803\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.3487e-05 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9806\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.6260e-05 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9805\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.9153e-05 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9805\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.3820e-05 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9804\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.9898e-05 - accuracy: 1.0000 - val_loss: 0.1381 - val_accuracy: 0.9805\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.6606e-05 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9806\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.3819e-05 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9806\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.1424e-05 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9807\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.9295e-05 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9804\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.7374e-05 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9805\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.5699e-05 - accuracy: 1.0000 - val_loss: 0.1439 - val_accuracy: 0.9804\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3100 - accuracy: 0.9040 - val_loss: 0.1552 - val_accuracy: 0.9539\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1024 - accuracy: 0.9692 - val_loss: 0.1086 - val_accuracy: 0.9678\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0673 - accuracy: 0.9793 - val_loss: 0.0910 - val_accuracy: 0.9727\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0476 - accuracy: 0.9848 - val_loss: 0.0894 - val_accuracy: 0.9735\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0348 - accuracy: 0.9894 - val_loss: 0.0834 - val_accuracy: 0.9762\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0259 - accuracy: 0.9926 - val_loss: 0.0828 - val_accuracy: 0.9753\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0213 - accuracy: 0.9938 - val_loss: 0.0853 - val_accuracy: 0.9760\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 0.0864 - val_accuracy: 0.9772\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.1004 - val_accuracy: 0.9762\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.1061 - val_accuracy: 0.9754\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.1102 - val_accuracy: 0.9743\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1043 - val_accuracy: 0.9763\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.1040 - val_accuracy: 0.9782\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.1106 - val_accuracy: 0.9767\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1059 - val_accuracy: 0.9776\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.1164 - val_accuracy: 0.9772\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.1434 - val_accuracy: 0.9689\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 0.1224 - val_accuracy: 0.9749\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1068 - val_accuracy: 0.9783\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.1059e-04 - accuracy: 0.9999 - val_loss: 0.1103 - val_accuracy: 0.9803\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.8873e-04 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9799\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.9658e-04 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9801\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.3979e-04 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9798\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.1677e-04 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9800\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0077e-04 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9800\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.5953e-05 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9800\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.3889e-05 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9801\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.4937e-05 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9798\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.6930e-05 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9800\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.0475e-05 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9799\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.5162e-05 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9799\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.0284e-05 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9803\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.6247e-05 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9802\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.2551e-05 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.9805\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.9298e-05 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9799\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.6419e-05 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9805\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.3736e-05 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9800\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.1350e-05 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9803\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.9337e-05 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9803\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.7254e-05 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9804\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5675e-05 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9801\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.4200e-05 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9804\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2825e-05 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9801\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.1663e-05 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9803\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0472e-05 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9801\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.4354e-06 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9803\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.5578e-06 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9803\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.7664e-06 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9803\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.0150e-06 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 0.9804\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.3291e-06 - accuracy: 1.0000 - val_loss: 0.1531 - val_accuracy: 0.9802\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2845 - accuracy: 0.9129 - val_loss: 0.1383 - val_accuracy: 0.9597\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1000 - accuracy: 0.9686 - val_loss: 0.1027 - val_accuracy: 0.9691\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0656 - accuracy: 0.9794 - val_loss: 0.1001 - val_accuracy: 0.9716\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0478 - accuracy: 0.9853 - val_loss: 0.0892 - val_accuracy: 0.9726\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0365 - accuracy: 0.9887 - val_loss: 0.0967 - val_accuracy: 0.9729\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 0.0884 - val_accuracy: 0.9749\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0216 - accuracy: 0.9937 - val_loss: 0.0928 - val_accuracy: 0.9753\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.0866 - val_accuracy: 0.9766\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0937 - val_accuracy: 0.9781\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0929 - val_accuracy: 0.9788\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.1157 - val_accuracy: 0.9759\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.1308 - val_accuracy: 0.9726\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.1021 - val_accuracy: 0.9774\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.1300 - val_accuracy: 0.9720\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.1162 - val_accuracy: 0.9756\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.1320 - val_accuracy: 0.9741\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.1085 - val_accuracy: 0.9793\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1140 - val_accuracy: 0.9778\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1099 - val_accuracy: 0.9786\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.1128 - val_accuracy: 0.9798\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1115 - val_accuracy: 0.9803\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.1194 - val_accuracy: 0.9785\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.5137e-04 - accuracy: 0.9998 - val_loss: 0.1210 - val_accuracy: 0.9775\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.1524 - val_accuracy: 0.9743\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9908 - val_loss: 0.1220 - val_accuracy: 0.9733\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.1046 - val_accuracy: 0.9791\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1112 - val_accuracy: 0.9793\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.8357e-04 - accuracy: 0.9999 - val_loss: 0.1070 - val_accuracy: 0.9800\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.7740e-04 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9802\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.1616e-04 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9807\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.3395e-05 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9808\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.8597e-05 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 0.9808\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.6926e-05 - accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 0.9808\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.8546e-05 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9809\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.1163e-05 - accuracy: 1.0000 - val_loss: 0.1191 - val_accuracy: 0.9810\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.5247e-05 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9810\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.9853e-05 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9810\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.5800e-05 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9809\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.2016e-05 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9811\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.8769e-05 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9808\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.5705e-05 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9811\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.3326e-05 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9808\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.0801e-05 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9812\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.8931e-05 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9811\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.6889e-05 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9811\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5330e-05 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 0.9808\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.3827e-05 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9810\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2652e-05 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9808\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.1557e-05 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9807\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0237e-05 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9807\n",
            "Model: \"multi_layer_multi_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 151,306\n",
            "Trainable params: 151,306\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4372 - accuracy: 0.8727 - val_loss: 0.1985 - val_accuracy: 0.9433\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1508 - accuracy: 0.9548 - val_loss: 0.1399 - val_accuracy: 0.9582\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1078 - accuracy: 0.9672 - val_loss: 0.1316 - val_accuracy: 0.9613\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0817 - accuracy: 0.9756 - val_loss: 0.1172 - val_accuracy: 0.9654\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0657 - accuracy: 0.9797 - val_loss: 0.0968 - val_accuracy: 0.9716\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0513 - accuracy: 0.9836 - val_loss: 0.1102 - val_accuracy: 0.9664\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0434 - accuracy: 0.9863 - val_loss: 0.0912 - val_accuracy: 0.9734\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0318 - accuracy: 0.9904 - val_loss: 0.0874 - val_accuracy: 0.9752\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.0921 - val_accuracy: 0.9743\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.1024 - val_accuracy: 0.9731\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.0988 - val_accuracy: 0.9753\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.1198 - val_accuracy: 0.9721\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.0946 - val_accuracy: 0.9775\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.1091 - val_accuracy: 0.9749\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.1306 - val_accuracy: 0.9695\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.1359 - val_accuracy: 0.9701\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.1169 - val_accuracy: 0.9753\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.1243 - val_accuracy: 0.9723\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.1372 - val_accuracy: 0.9725\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.1219 - val_accuracy: 0.9751\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.1113 - val_accuracy: 0.9761\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.1268 - val_accuracy: 0.9753\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.1320 - val_accuracy: 0.9738\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.1337 - val_accuracy: 0.9753\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.1181 - val_accuracy: 0.9775\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.1273 - val_accuracy: 0.9766\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.1522 - val_accuracy: 0.9700\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.1265 - val_accuracy: 0.9758\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.1258 - val_accuracy: 0.9777\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.1593 - val_accuracy: 0.9716\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.1319 - val_accuracy: 0.9765\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.1368 - val_accuracy: 0.9777\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.1211 - val_accuracy: 0.9791\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.1398 - val_accuracy: 0.9768\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.1285 - val_accuracy: 0.9783\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.1727 - val_accuracy: 0.9701\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1429 - val_accuracy: 0.9772\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.1288 - val_accuracy: 0.9789\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.1664 - val_accuracy: 0.9711\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.1299 - val_accuracy: 0.9769\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.1329 - val_accuracy: 0.9776\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.1536 - val_accuracy: 0.9762\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.1360 - val_accuracy: 0.9763\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.1488 - val_accuracy: 0.9753\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.1360 - val_accuracy: 0.9793\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1407 - val_accuracy: 0.9783\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1609 - val_accuracy: 0.9745\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.1531 - val_accuracy: 0.9750\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1743 - val_accuracy: 0.9747\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1391 - val_accuracy: 0.9776\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3963 - accuracy: 0.8781 - val_loss: 0.1604 - val_accuracy: 0.9526\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1196 - accuracy: 0.9632 - val_loss: 0.1240 - val_accuracy: 0.9617\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0807 - accuracy: 0.9754 - val_loss: 0.1097 - val_accuracy: 0.9678\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0594 - accuracy: 0.9818 - val_loss: 0.1000 - val_accuracy: 0.9697\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0424 - accuracy: 0.9864 - val_loss: 0.0958 - val_accuracy: 0.9715\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9894 - val_loss: 0.0972 - val_accuracy: 0.9727\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.0982 - val_accuracy: 0.9740\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.0939 - val_accuracy: 0.9777\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.1013 - val_accuracy: 0.9761\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0152 - accuracy: 0.9949 - val_loss: 0.1124 - val_accuracy: 0.9737\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.1022 - val_accuracy: 0.9758\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.1037 - val_accuracy: 0.9769\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.1234 - val_accuracy: 0.9743\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.1206 - val_accuracy: 0.9751\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.1216 - val_accuracy: 0.9769\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.1418 - val_accuracy: 0.9727\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.1215 - val_accuracy: 0.9770\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1576 - val_accuracy: 0.9712\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.1353 - val_accuracy: 0.9759\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9951 - val_loss: 0.1258 - val_accuracy: 0.9761\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1224 - val_accuracy: 0.9779\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1215 - val_accuracy: 0.9787\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.1261 - val_accuracy: 0.9783\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.1558 - val_accuracy: 0.9752\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1570 - val_accuracy: 0.9737\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.1725 - val_accuracy: 0.9708\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.1267 - val_accuracy: 0.9774\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1274 - val_accuracy: 0.9789\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.1470 - val_accuracy: 0.9769\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.1490 - val_accuracy: 0.9762\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.1553 - val_accuracy: 0.9747\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.1278 - val_accuracy: 0.9771\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.1408 - val_accuracy: 0.9767\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.1271 - val_accuracy: 0.9808\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.6100e-04 - accuracy: 0.9998 - val_loss: 0.1271 - val_accuracy: 0.9814\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.2943e-05 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 0.9821\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.8279e-05 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9820\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.6813e-05 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9821\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.9859e-05 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9821\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.5118e-05 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.9819\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.1494e-05 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 0.9818\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.8509e-05 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9819\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.6142e-05 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9818\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.3996e-05 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9818\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.2432e-05 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9819\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0923e-05 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 0.9819\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.7164e-06 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9819\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.6377e-06 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9819\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.6834e-06 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9822\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.8735e-06 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9821\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3383 - accuracy: 0.8945 - val_loss: 0.1448 - val_accuracy: 0.9579\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1060 - accuracy: 0.9668 - val_loss: 0.1074 - val_accuracy: 0.9690\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0683 - accuracy: 0.9787 - val_loss: 0.1023 - val_accuracy: 0.9715\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0505 - accuracy: 0.9841 - val_loss: 0.0946 - val_accuracy: 0.9750\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0378 - accuracy: 0.9880 - val_loss: 0.0937 - val_accuracy: 0.9738\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 0.0950 - val_accuracy: 0.9743\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.0957 - val_accuracy: 0.9762\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.0951 - val_accuracy: 0.9772\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.1080 - val_accuracy: 0.9770\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.1191 - val_accuracy: 0.9754\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 0.1237 - val_accuracy: 0.9753\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.1219 - val_accuracy: 0.9752\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.1284 - val_accuracy: 0.9768\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.1261 - val_accuracy: 0.9762\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.1219 - val_accuracy: 0.9773\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.1240 - val_accuracy: 0.9749\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1260 - val_accuracy: 0.9778\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.1408 - val_accuracy: 0.9767\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.1248 - val_accuracy: 0.9762\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.1353 - val_accuracy: 0.9765\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.1356 - val_accuracy: 0.9756\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1339 - val_accuracy: 0.9762\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1421 - val_accuracy: 0.9764\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.1518 - val_accuracy: 0.9747\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0106 - accuracy: 0.9968 - val_loss: 0.1378 - val_accuracy: 0.9763\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.1359 - val_accuracy: 0.9776\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1576 - val_accuracy: 0.9758\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.1357 - val_accuracy: 0.9789\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1387 - val_accuracy: 0.9791\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.7605e-04 - accuracy: 0.9999 - val_loss: 0.1364 - val_accuracy: 0.9800\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.0449e-04 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9804\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.3147e-04 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9809\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.2775e-05 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9808\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.2261e-05 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.9808\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.6270e-05 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9806\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.1888e-05 - accuracy: 1.0000 - val_loss: 0.1471 - val_accuracy: 0.9807\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.8592e-05 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9808\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5953e-05 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9810\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.3806e-05 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9809\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1937e-05 - accuracy: 1.0000 - val_loss: 0.1539 - val_accuracy: 0.9811\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0425e-05 - accuracy: 1.0000 - val_loss: 0.1559 - val_accuracy: 0.9812\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.1441e-06 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 0.9811\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.0473e-06 - accuracy: 1.0000 - val_loss: 0.1589 - val_accuracy: 0.9809\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.1050e-06 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9809\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.2773e-06 - accuracy: 1.0000 - val_loss: 0.1622 - val_accuracy: 0.9810\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.5553e-06 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9807\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.9431e-06 - accuracy: 1.0000 - val_loss: 0.1650 - val_accuracy: 0.9808\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.3893e-06 - accuracy: 1.0000 - val_loss: 0.1667 - val_accuracy: 0.9810\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.8846e-06 - accuracy: 1.0000 - val_loss: 0.1686 - val_accuracy: 0.9809\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.4324e-06 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9809\n",
            "Model: \"multi_layer_multi_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden4 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 167,818\n",
            "Trainable params: 167,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4399 - accuracy: 0.8683 - val_loss: 0.1943 - val_accuracy: 0.9442\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1522 - accuracy: 0.9548 - val_loss: 0.1301 - val_accuracy: 0.9606\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1043 - accuracy: 0.9684 - val_loss: 0.1253 - val_accuracy: 0.9618\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0773 - accuracy: 0.9768 - val_loss: 0.0990 - val_accuracy: 0.9709\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0630 - accuracy: 0.9807 - val_loss: 0.0952 - val_accuracy: 0.9712\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0540 - accuracy: 0.9830 - val_loss: 0.1052 - val_accuracy: 0.9690\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0423 - accuracy: 0.9866 - val_loss: 0.1082 - val_accuracy: 0.9699\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0396 - accuracy: 0.9868 - val_loss: 0.1017 - val_accuracy: 0.9713\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: 0.1037 - val_accuracy: 0.9719\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0233 - accuracy: 0.9921 - val_loss: 0.1231 - val_accuracy: 0.9694\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9936 - val_loss: 0.1176 - val_accuracy: 0.9731\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.1095 - val_accuracy: 0.9727\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.1053 - val_accuracy: 0.9755\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.1164 - val_accuracy: 0.9746\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 0.1499 - val_accuracy: 0.9687\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.1220 - val_accuracy: 0.9735\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.1147 - val_accuracy: 0.9762\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.1150 - val_accuracy: 0.9748\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.1106 - val_accuracy: 0.9756\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.1170 - val_accuracy: 0.9743\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.1368 - val_accuracy: 0.9728\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.1208 - val_accuracy: 0.9767\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1428 - val_accuracy: 0.9729\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.1357 - val_accuracy: 0.9739\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9957 - val_loss: 0.1212 - val_accuracy: 0.9748\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.1494 - val_accuracy: 0.9705\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.1300 - val_accuracy: 0.9768\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.1053 - val_accuracy: 0.9772\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.1287 - val_accuracy: 0.9746\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.1282 - val_accuracy: 0.9760\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.1358 - val_accuracy: 0.9762\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.1479 - val_accuracy: 0.9722\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.1285 - val_accuracy: 0.9774\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.1285 - val_accuracy: 0.9761\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.1176 - val_accuracy: 0.9778\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.1178 - val_accuracy: 0.9793\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.1307 - val_accuracy: 0.9758\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.1415 - val_accuracy: 0.9746\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.1184 - val_accuracy: 0.9769\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1372 - val_accuracy: 0.9742\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.1261 - val_accuracy: 0.9777\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.1430 - val_accuracy: 0.9760\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1429 - val_accuracy: 0.9761\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1279 - val_accuracy: 0.9766\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1281 - val_accuracy: 0.9773\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1318 - val_accuracy: 0.9779\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1564 - val_accuracy: 0.9742\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1296 - val_accuracy: 0.9791\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.1409 - val_accuracy: 0.9772\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.1322 - val_accuracy: 0.9758\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4158 - accuracy: 0.8709 - val_loss: 0.1747 - val_accuracy: 0.9478\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1287 - accuracy: 0.9600 - val_loss: 0.1247 - val_accuracy: 0.9622\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0842 - accuracy: 0.9741 - val_loss: 0.1105 - val_accuracy: 0.9671\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0621 - accuracy: 0.9803 - val_loss: 0.1108 - val_accuracy: 0.9661\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0519 - accuracy: 0.9829 - val_loss: 0.1057 - val_accuracy: 0.9689\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0356 - accuracy: 0.9886 - val_loss: 0.1036 - val_accuracy: 0.9723\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0291 - accuracy: 0.9906 - val_loss: 0.1073 - val_accuracy: 0.9728\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.0991 - val_accuracy: 0.9758\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.1146 - val_accuracy: 0.9712\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9934 - val_loss: 0.1219 - val_accuracy: 0.9728\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.1230 - val_accuracy: 0.9720\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.1216 - val_accuracy: 0.9722\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 0.1146 - val_accuracy: 0.9755\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.1264 - val_accuracy: 0.9742\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.1503 - val_accuracy: 0.9700\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 0.1410 - val_accuracy: 0.9715\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.1227 - val_accuracy: 0.9760\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.1421 - val_accuracy: 0.9722\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.1297 - val_accuracy: 0.9757\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.1302 - val_accuracy: 0.9759\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.1250 - val_accuracy: 0.9757\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.1351 - val_accuracy: 0.9728\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.1204 - val_accuracy: 0.9760\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.1157 - val_accuracy: 0.9788\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.1299 - val_accuracy: 0.9749\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.1509 - val_accuracy: 0.9714\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.1726 - val_accuracy: 0.9732\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.1393 - val_accuracy: 0.9743\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.1324 - val_accuracy: 0.9777\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.1567 - val_accuracy: 0.9738\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.1397 - val_accuracy: 0.9755\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1354 - val_accuracy: 0.9765\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1457 - val_accuracy: 0.9759\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9959 - val_loss: 0.1253 - val_accuracy: 0.9746\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1353 - val_accuracy: 0.9766\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.1327 - val_accuracy: 0.9764\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.1461 - val_accuracy: 0.9723\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1667 - val_accuracy: 0.9749\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1344 - val_accuracy: 0.9770\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1509 - val_accuracy: 0.9750\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1761 - val_accuracy: 0.9711\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.1397 - val_accuracy: 0.9753\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.1290 - val_accuracy: 0.9780\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1515 - val_accuracy: 0.9747\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.1253 - val_accuracy: 0.9802\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1531 - val_accuracy: 0.9770\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.1473 - val_accuracy: 0.9746\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.1254 - val_accuracy: 0.9773\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.1464 - val_accuracy: 0.9761\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.1452 - val_accuracy: 0.9743\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4223 - accuracy: 0.8709 - val_loss: 0.1639 - val_accuracy: 0.9523\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1236 - accuracy: 0.9620 - val_loss: 0.1132 - val_accuracy: 0.9659\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0797 - accuracy: 0.9754 - val_loss: 0.1108 - val_accuracy: 0.9678\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0603 - accuracy: 0.9810 - val_loss: 0.1173 - val_accuracy: 0.9672\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0433 - accuracy: 0.9868 - val_loss: 0.0975 - val_accuracy: 0.9745\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9888 - val_loss: 0.0912 - val_accuracy: 0.9745\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 0.0965 - val_accuracy: 0.9763\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.1022 - val_accuracy: 0.9751\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.1145 - val_accuracy: 0.9726\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.1129 - val_accuracy: 0.9763\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.1048 - val_accuracy: 0.9754\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.1305 - val_accuracy: 0.9728\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.1164 - val_accuracy: 0.9747\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.1220 - val_accuracy: 0.9755\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.1283 - val_accuracy: 0.9747\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.1455 - val_accuracy: 0.9728\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.1267 - val_accuracy: 0.9753\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.1174 - val_accuracy: 0.9772\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.1266 - val_accuracy: 0.9783\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.1284 - val_accuracy: 0.9729\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.1292 - val_accuracy: 0.9762\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.1381 - val_accuracy: 0.9743\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.1251 - val_accuracy: 0.9780\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.1179 - val_accuracy: 0.9769\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.1266 - val_accuracy: 0.9787\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1652 - val_accuracy: 0.9724\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.1143 - val_accuracy: 0.9780\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.1366 - val_accuracy: 0.9775\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.1462 - val_accuracy: 0.9754\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.1578 - val_accuracy: 0.9712\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.1330 - val_accuracy: 0.9768\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.1163 - val_accuracy: 0.9789\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1338 - val_accuracy: 0.9778\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.1343 - val_accuracy: 0.9780\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1380 - val_accuracy: 0.9777\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.1150 - val_accuracy: 0.9774\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.1333 - val_accuracy: 0.9771\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.1799 - val_accuracy: 0.9712\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.1404 - val_accuracy: 0.9769\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.1308 - val_accuracy: 0.9770\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.1379 - val_accuracy: 0.9765\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.1470 - val_accuracy: 0.9782\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.1527 - val_accuracy: 0.9772\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1492 - val_accuracy: 0.9754\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.1501 - val_accuracy: 0.9730\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.1380 - val_accuracy: 0.9783\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1365 - val_accuracy: 0.9792\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.1421 - val_accuracy: 0.9782\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.1557 - val_accuracy: 0.9793\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.1342 - val_accuracy: 0.9770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JGi9myXzNsC-"
      },
      "source": [
        "With the accuracy values retrieved, we plot the graph:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aJ8fdoTTNsC-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "927be51e-a88a-435f-f27d-53574441dcd8"
      },
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "multiple_line_chart(plt.gca(), \n",
        "                    None, \n",
        "                    accuracy_lines, \n",
        "                    \"Validation accuracy variation per number of hidden layers\", \n",
        "                    \"Epochs\", \n",
        "                    \"Validation accuracy\")\n",
        "plt.show()\n",
        "plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jwATQhDVgY6",
        "colab_type": "text"
      },
      "source": [
        "Looking at the plot we can retrieve some conclussions: first of all, the model is already pretty optimized, as the variations are of less than 0.1%, resulting in some noise and fluctuations. This could be atenuated with a bigger number of tests, but would be pretty expensive. The accuracy appears to increase with the number of hidden layers. This is true for the first 4 (4 appears to reach right in the end) except for 5 hidden layers, performing worse than every other. This appears to sugest some overfitting since it is expected for accuracy to increase with the number of hidden layers, aswell as the high variations in accuracy during runtime. 3 is a safe bet as it appears to converge right at the end whilst having the highest value, but 4 appears to be catching up right in the end, perhaps even surpass it. For this reason we've decided to plot both, while running for convergence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mQr5SMxZCrw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "caec420e-d5b5-4133-8735-d2cefe860366"
      },
      "source": [
        "multi_layer_3_hidden_model = create_multi_layer_multi_hidden_model(3, \"multi_layer_3_hidden_model\")\n",
        "multi_layer_4_hidden_model = create_multi_layer_multi_hidden_model(4, \"multi_layer_4_hidden_model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"multi_layer_3_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"multi_layer_4_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 151,306\n",
            "Trainable params: 151,306\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfR-QeYbZ0GG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8d07388-d9fc-4786-a64b-01cb6f310ad7"
      },
      "source": [
        "earlystop3 = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=25, verbose=1)\n",
        "earlystop4 = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=25, verbose=1)\n",
        "checkpoint3 = tf.keras.callbacks.ModelCheckpoint('multi_layer_3_hidden_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "checkpoint4 = tf.keras.callbacks.ModelCheckpoint('multi_layer_4_hidden_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "multi_layer_3_hidden_train = multi_layer_3_hidden_model.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop3,checkpoint3], epochs=10000, batch_size=256)\n",
        "multi_layer_4_hidden_train = multi_layer_4_hidden_model.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop4,checkpoint4], epochs=10000, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.4226 - accuracy: 0.8819\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.94325, saving model to multi_layer_3_hidden_model.h5\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.4157 - accuracy: 0.8838 - val_loss: 0.1956 - val_accuracy: 0.9433\n",
            "Epoch 2/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.1545 - accuracy: 0.9536\n",
            "Epoch 00002: val_accuracy improved from 0.94325 to 0.95775, saving model to multi_layer_3_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1537 - accuracy: 0.9538 - val_loss: 0.1435 - val_accuracy: 0.9578\n",
            "Epoch 3/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.1092 - accuracy: 0.9665\n",
            "Epoch 00003: val_accuracy improved from 0.95775 to 0.96467, saving model to multi_layer_3_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1091 - accuracy: 0.9663 - val_loss: 0.1215 - val_accuracy: 0.9647\n",
            "Epoch 4/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0801 - accuracy: 0.9751\n",
            "Epoch 00004: val_accuracy improved from 0.96467 to 0.97117, saving model to multi_layer_3_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0809 - accuracy: 0.9749 - val_loss: 0.1010 - val_accuracy: 0.9712\n",
            "Epoch 5/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.0628 - accuracy: 0.9813\n",
            "Epoch 00005: val_accuracy did not improve from 0.97117\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0620 - accuracy: 0.9815 - val_loss: 0.1048 - val_accuracy: 0.9693\n",
            "Epoch 6/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0500 - accuracy: 0.9845\n",
            "Epoch 00006: val_accuracy improved from 0.97117 to 0.97325, saving model to multi_layer_3_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0504 - accuracy: 0.9845 - val_loss: 0.0926 - val_accuracy: 0.9732\n",
            "Epoch 7/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9875\n",
            "Epoch 00007: val_accuracy improved from 0.97325 to 0.97383, saving model to multi_layer_3_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0418 - accuracy: 0.9875 - val_loss: 0.0917 - val_accuracy: 0.9738\n",
            "Epoch 8/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0329 - accuracy: 0.9897\n",
            "Epoch 00008: val_accuracy did not improve from 0.97383\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0328 - accuracy: 0.9898 - val_loss: 0.1018 - val_accuracy: 0.9708\n",
            "Epoch 9/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0259 - accuracy: 0.9924\n",
            "Epoch 00009: val_accuracy improved from 0.97383 to 0.97400, saving model to multi_layer_3_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 0.0966 - val_accuracy: 0.9740\n",
            "Epoch 10/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9923\n",
            "Epoch 00010: val_accuracy improved from 0.97400 to 0.97425, saving model to multi_layer_3_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.0964 - val_accuracy: 0.9743\n",
            "Epoch 11/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0203 - accuracy: 0.9936\n",
            "Epoch 00011: val_accuracy did not improve from 0.97425\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.1019 - val_accuracy: 0.9730\n",
            "Epoch 12/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9955\n",
            "Epoch 00012: val_accuracy did not improve from 0.97425\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.1107 - val_accuracy: 0.9714\n",
            "Epoch 13/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0136 - accuracy: 0.9957\n",
            "Epoch 00013: val_accuracy improved from 0.97425 to 0.97467, saving model to multi_layer_3_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.1018 - val_accuracy: 0.9747\n",
            "Epoch 14/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9959\n",
            "Epoch 00014: val_accuracy improved from 0.97467 to 0.97533, saving model to multi_layer_3_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.1054 - val_accuracy: 0.9753\n",
            "Epoch 15/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.0141 - accuracy: 0.9954\n",
            "Epoch 00015: val_accuracy did not improve from 0.97533\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0142 - accuracy: 0.9953 - val_loss: 0.1264 - val_accuracy: 0.9704\n",
            "Epoch 16/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9965\n",
            "Epoch 00016: val_accuracy did not improve from 0.97533\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.1367 - val_accuracy: 0.9696\n",
            "Epoch 17/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9944\n",
            "Epoch 00017: val_accuracy did not improve from 0.97533\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.1222 - val_accuracy: 0.9717\n",
            "Epoch 18/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9962\n",
            "Epoch 00018: val_accuracy did not improve from 0.97533\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.1153 - val_accuracy: 0.9748\n",
            "Epoch 19/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0129 - accuracy: 0.9955\n",
            "Epoch 00019: val_accuracy did not improve from 0.97533\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.1292 - val_accuracy: 0.9739\n",
            "Epoch 20/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.0080 - accuracy: 0.9975\n",
            "Epoch 00020: val_accuracy did not improve from 0.97533\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.1367 - val_accuracy: 0.9722\n",
            "Epoch 21/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9981\n",
            "Epoch 00021: val_accuracy did not improve from 0.97533\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.1286 - val_accuracy: 0.9744\n",
            "Epoch 22/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987\n",
            "Epoch 00022: val_accuracy improved from 0.97533 to 0.97800, saving model to multi_layer_3_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1119 - val_accuracy: 0.9780\n",
            "Epoch 23/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 9.5251e-04 - accuracy: 0.9998\n",
            "Epoch 00023: val_accuracy improved from 0.97800 to 0.97867, saving model to multi_layer_3_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.5183e-04 - accuracy: 0.9998 - val_loss: 0.1166 - val_accuracy: 0.9787\n",
            "Epoch 24/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 9.9079e-04 - accuracy: 0.9996\n",
            "Epoch 00024: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.9079e-04 - accuracy: 0.9996 - val_loss: 0.1434 - val_accuracy: 0.9741\n",
            "Epoch 25/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.0123 - accuracy: 0.9957\n",
            "Epoch 00025: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 0.1784 - val_accuracy: 0.9655\n",
            "Epoch 26/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0115 - accuracy: 0.9961\n",
            "Epoch 00026: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.1259 - val_accuracy: 0.9754\n",
            "Epoch 27/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0071 - accuracy: 0.9974\n",
            "Epoch 00027: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.1484 - val_accuracy: 0.9735\n",
            "Epoch 28/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0092 - accuracy: 0.9968\n",
            "Epoch 00028: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.1544 - val_accuracy: 0.9719\n",
            "Epoch 29/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.0094 - accuracy: 0.9971\n",
            "Epoch 00029: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.1444 - val_accuracy: 0.9753\n",
            "Epoch 30/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9978\n",
            "Epoch 00030: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.1320 - val_accuracy: 0.9754\n",
            "Epoch 31/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.0081 - accuracy: 0.9972\n",
            "Epoch 00031: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.1568 - val_accuracy: 0.9719\n",
            "Epoch 32/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9971\n",
            "Epoch 00032: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.1340 - val_accuracy: 0.9743\n",
            "Epoch 33/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
            "Epoch 00033: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1317 - val_accuracy: 0.9778\n",
            "Epoch 34/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 9.3766e-04 - accuracy: 0.9998\n",
            "Epoch 00034: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.3525e-04 - accuracy: 0.9998 - val_loss: 0.1325 - val_accuracy: 0.9780\n",
            "Epoch 35/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 1.6738e-04 - accuracy: 1.0000\n",
            "Epoch 00035: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.7299e-04 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9783\n",
            "Epoch 36/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 7.7030e-05 - accuracy: 1.0000\n",
            "Epoch 00036: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.6243e-05 - accuracy: 1.0000 - val_loss: 0.1327 - val_accuracy: 0.9785\n",
            "Epoch 37/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 5.4754e-05 - accuracy: 1.0000\n",
            "Epoch 00037: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.4549e-05 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.9786\n",
            "Epoch 38/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 4.6432e-05 - accuracy: 1.0000\n",
            "Epoch 00038: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.6126e-05 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9785\n",
            "Epoch 39/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 3.9861e-05 - accuracy: 1.0000\n",
            "Epoch 00039: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.9701e-05 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9786\n",
            "Epoch 40/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 3.4554e-05 - accuracy: 1.0000\n",
            "Epoch 00040: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.4741e-05 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9786\n",
            "Epoch 41/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 3.1114e-05 - accuracy: 1.0000\n",
            "Epoch 00041: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.0960e-05 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9786\n",
            "Epoch 42/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 2.7236e-05 - accuracy: 1.0000\n",
            "Epoch 00042: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.7609e-05 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9787\n",
            "Epoch 43/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 2.4786e-05 - accuracy: 1.0000\n",
            "Epoch 00043: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.4742e-05 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9786\n",
            "Epoch 44/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 2.1964e-05 - accuracy: 1.0000\n",
            "Epoch 00044: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.2343e-05 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9787\n",
            "Epoch 45/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 2.0016e-05 - accuracy: 1.0000\n",
            "Epoch 00045: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.0168e-05 - accuracy: 1.0000 - val_loss: 0.1432 - val_accuracy: 0.9786\n",
            "Epoch 46/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 1.7848e-05 - accuracy: 1.0000\n",
            "Epoch 00046: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.8208e-05 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9784\n",
            "Epoch 47/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 1.6756e-05 - accuracy: 1.0000\n",
            "Epoch 00047: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.6556e-05 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9783\n",
            "Epoch 48/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 1.5014e-05 - accuracy: 1.0000\n",
            "Epoch 00048: val_accuracy did not improve from 0.97867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5043e-05 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9785\n",
            "Epoch 00048: early stopping\n",
            "Epoch 1/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.4248 - accuracy: 0.8744\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.94333, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4242 - accuracy: 0.8746 - val_loss: 0.2033 - val_accuracy: 0.9433\n",
            "Epoch 2/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.1529 - accuracy: 0.9544\n",
            "Epoch 00002: val_accuracy improved from 0.94333 to 0.95850, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1520 - accuracy: 0.9545 - val_loss: 0.1433 - val_accuracy: 0.9585\n",
            "Epoch 3/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9679\n",
            "Epoch 00003: val_accuracy improved from 0.95850 to 0.96267, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1068 - accuracy: 0.9679 - val_loss: 0.1339 - val_accuracy: 0.9627\n",
            "Epoch 4/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.0790 - accuracy: 0.9756\n",
            "Epoch 00004: val_accuracy improved from 0.96267 to 0.96792, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0800 - accuracy: 0.9756 - val_loss: 0.1064 - val_accuracy: 0.9679\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9807\n",
            "Epoch 00005: val_accuracy improved from 0.96792 to 0.97117, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0620 - accuracy: 0.9807 - val_loss: 0.0970 - val_accuracy: 0.9712\n",
            "Epoch 6/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.0496 - accuracy: 0.9844\n",
            "Epoch 00006: val_accuracy improved from 0.97117 to 0.97292, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0491 - accuracy: 0.9845 - val_loss: 0.0956 - val_accuracy: 0.9729\n",
            "Epoch 7/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9867\n",
            "Epoch 00007: val_accuracy did not improve from 0.97292\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0420 - accuracy: 0.9867 - val_loss: 0.0920 - val_accuracy: 0.9727\n",
            "Epoch 8/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0312 - accuracy: 0.9906\n",
            "Epoch 00008: val_accuracy improved from 0.97292 to 0.97517, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0314 - accuracy: 0.9904 - val_loss: 0.0928 - val_accuracy: 0.9752\n",
            "Epoch 9/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9918\n",
            "Epoch 00009: val_accuracy did not improve from 0.97517\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.1030 - val_accuracy: 0.9728\n",
            "Epoch 10/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0211 - accuracy: 0.9931\n",
            "Epoch 00010: val_accuracy did not improve from 0.97517\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.1068 - val_accuracy: 0.9749\n",
            "Epoch 11/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.0172 - accuracy: 0.9942\n",
            "Epoch 00011: val_accuracy did not improve from 0.97517\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.1144 - val_accuracy: 0.9706\n",
            "Epoch 12/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9927\n",
            "Epoch 00012: val_accuracy did not improve from 0.97517\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.1265 - val_accuracy: 0.9688\n",
            "Epoch 13/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9946\n",
            "Epoch 00013: val_accuracy did not improve from 0.97517\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.1115 - val_accuracy: 0.9733\n",
            "Epoch 14/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0159 - accuracy: 0.9944\n",
            "Epoch 00014: val_accuracy did not improve from 0.97517\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.1184 - val_accuracy: 0.9736\n",
            "Epoch 15/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.0145 - accuracy: 0.9950\n",
            "Epoch 00015: val_accuracy improved from 0.97517 to 0.97558, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.1098 - val_accuracy: 0.9756\n",
            "Epoch 16/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.0115 - accuracy: 0.9962\n",
            "Epoch 00016: val_accuracy did not improve from 0.97558\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.1169 - val_accuracy: 0.9741\n",
            "Epoch 17/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.0109 - accuracy: 0.9967\n",
            "Epoch 00017: val_accuracy improved from 0.97558 to 0.97667, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.1079 - val_accuracy: 0.9767\n",
            "Epoch 18/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9971\n",
            "Epoch 00018: val_accuracy did not improve from 0.97667\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.1520 - val_accuracy: 0.9701\n",
            "Epoch 19/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9956\n",
            "Epoch 00019: val_accuracy did not improve from 0.97667\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.1385 - val_accuracy: 0.9711\n",
            "Epoch 20/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.0112 - accuracy: 0.9967\n",
            "Epoch 00020: val_accuracy did not improve from 0.97667\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.1248 - val_accuracy: 0.9756\n",
            "Epoch 21/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0152 - accuracy: 0.9953\n",
            "Epoch 00021: val_accuracy did not improve from 0.97667\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.1289 - val_accuracy: 0.9732\n",
            "Epoch 22/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.0097 - accuracy: 0.9969\n",
            "Epoch 00022: val_accuracy did not improve from 0.97667\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.1500 - val_accuracy: 0.9709\n",
            "Epoch 23/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9979\n",
            "Epoch 00023: val_accuracy improved from 0.97667 to 0.97833, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.1251 - val_accuracy: 0.9783\n",
            "Epoch 24/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.0075 - accuracy: 0.9980\n",
            "Epoch 00024: val_accuracy did not improve from 0.97833\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.1225 - val_accuracy: 0.9759\n",
            "Epoch 25/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.0092 - accuracy: 0.9970\n",
            "Epoch 00025: val_accuracy did not improve from 0.97833\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.1284 - val_accuracy: 0.9771\n",
            "Epoch 26/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9971\n",
            "Epoch 00026: val_accuracy did not improve from 0.97833\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.1323 - val_accuracy: 0.9760\n",
            "Epoch 27/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.0102 - accuracy: 0.9964\n",
            "Epoch 00027: val_accuracy did not improve from 0.97833\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.1465 - val_accuracy: 0.9748\n",
            "Epoch 28/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9975\n",
            "Epoch 00028: val_accuracy did not improve from 0.97833\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.1206 - val_accuracy: 0.9778\n",
            "Epoch 29/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9988\n",
            "Epoch 00029: val_accuracy did not improve from 0.97833\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.1401 - val_accuracy: 0.9772\n",
            "Epoch 30/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.0062 - accuracy: 0.9979\n",
            "Epoch 00030: val_accuracy improved from 0.97833 to 0.97850, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.1242 - val_accuracy: 0.9785\n",
            "Epoch 31/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0050 - accuracy: 0.9986\n",
            "Epoch 00031: val_accuracy did not improve from 0.97850\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.1409 - val_accuracy: 0.9770\n",
            "Epoch 32/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9958\n",
            "Epoch 00032: val_accuracy did not improve from 0.97850\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.1261 - val_accuracy: 0.9749\n",
            "Epoch 33/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9983\n",
            "Epoch 00033: val_accuracy did not improve from 0.97850\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.1352 - val_accuracy: 0.9774\n",
            "Epoch 34/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0044 - accuracy: 0.9988\n",
            "Epoch 00034: val_accuracy did not improve from 0.97850\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.1448 - val_accuracy: 0.9748\n",
            "Epoch 35/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9972\n",
            "Epoch 00035: val_accuracy did not improve from 0.97850\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.1353 - val_accuracy: 0.9776\n",
            "Epoch 36/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0033 - accuracy: 0.9990\n",
            "Epoch 00036: val_accuracy did not improve from 0.97850\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1472 - val_accuracy: 0.9778\n",
            "Epoch 37/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0050 - accuracy: 0.9985\n",
            "Epoch 00037: val_accuracy did not improve from 0.97850\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.1486 - val_accuracy: 0.9753\n",
            "Epoch 38/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.0051 - accuracy: 0.9983\n",
            "Epoch 00038: val_accuracy did not improve from 0.97850\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1688 - val_accuracy: 0.9718\n",
            "Epoch 39/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9969\n",
            "Epoch 00039: val_accuracy did not improve from 0.97850\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.1385 - val_accuracy: 0.9765\n",
            "Epoch 40/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9964\n",
            "Epoch 00040: val_accuracy did not improve from 0.97850\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.1237 - val_accuracy: 0.9777\n",
            "Epoch 41/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9984\n",
            "Epoch 00041: val_accuracy did not improve from 0.97850\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.1357 - val_accuracy: 0.9774\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9984\n",
            "Epoch 00042: val_accuracy did not improve from 0.97850\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.1490 - val_accuracy: 0.9761\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9980\n",
            "Epoch 00043: val_accuracy did not improve from 0.97850\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.1428 - val_accuracy: 0.9764\n",
            "Epoch 44/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n",
            "Epoch 00044: val_accuracy did not improve from 0.97850\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1456 - val_accuracy: 0.9781\n",
            "Epoch 45/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
            "Epoch 00045: val_accuracy did not improve from 0.97850\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.1441 - val_accuracy: 0.9785\n",
            "Epoch 46/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
            "Epoch 00046: val_accuracy improved from 0.97850 to 0.97858, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1357 - val_accuracy: 0.9786\n",
            "Epoch 47/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
            "Epoch 00047: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.1537 - val_accuracy: 0.9747\n",
            "Epoch 48/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0110 - accuracy: 0.9964\n",
            "Epoch 00048: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.1532 - val_accuracy: 0.9752\n",
            "Epoch 49/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989\n",
            "Epoch 00049: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.1456 - val_accuracy: 0.9772\n",
            "Epoch 50/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9986\n",
            "Epoch 00050: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1420 - val_accuracy: 0.9782\n",
            "Epoch 51/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9981\n",
            "Epoch 00051: val_accuracy improved from 0.97858 to 0.97967, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.1399 - val_accuracy: 0.9797\n",
            "Epoch 52/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n",
            "Epoch 00052: val_accuracy did not improve from 0.97967\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1493 - val_accuracy: 0.9770\n",
            "Epoch 53/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9977\n",
            "Epoch 00053: val_accuracy did not improve from 0.97967\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1371 - val_accuracy: 0.9769\n",
            "Epoch 54/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
            "Epoch 00054: val_accuracy did not improve from 0.97967\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1613 - val_accuracy: 0.9748\n",
            "Epoch 55/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9973\n",
            "Epoch 00055: val_accuracy did not improve from 0.97967\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.1423 - val_accuracy: 0.9750\n",
            "Epoch 56/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 00056: val_accuracy improved from 0.97967 to 0.98025, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.1268 - val_accuracy: 0.9803\n",
            "Epoch 57/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 1.2789e-04 - accuracy: 1.0000\n",
            "Epoch 00057: val_accuracy improved from 0.98025 to 0.98033, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.2448e-04 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9803\n",
            "Epoch 58/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 4.5755e-05 - accuracy: 1.0000\n",
            "Epoch 00058: val_accuracy improved from 0.98033 to 0.98067, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.5593e-05 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9807\n",
            "Epoch 59/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 3.1897e-05 - accuracy: 1.0000\n",
            "Epoch 00059: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.1824e-05 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9807\n",
            "Epoch 60/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 2.3466e-05 - accuracy: 1.0000\n",
            "Epoch 00060: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.3419e-05 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9805\n",
            "Epoch 61/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 1.7189e-05 - accuracy: 1.0000\n",
            "Epoch 00061: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.7218e-05 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9806\n",
            "Epoch 62/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 1.2710e-05 - accuracy: 1.0000\n",
            "Epoch 00062: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.2739e-05 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9804\n",
            "Epoch 63/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 9.6207e-06 - accuracy: 1.0000\n",
            "Epoch 00063: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.6126e-06 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9802\n",
            "Epoch 64/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 7.5148e-06 - accuracy: 1.0000\n",
            "Epoch 00064: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.5081e-06 - accuracy: 1.0000 - val_loss: 0.1524 - val_accuracy: 0.9801\n",
            "Epoch 65/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 6.0258e-06 - accuracy: 1.0000\n",
            "Epoch 00065: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.0202e-06 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9800\n",
            "Epoch 66/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 4.9307e-06 - accuracy: 1.0000\n",
            "Epoch 00066: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.9307e-06 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 0.9803\n",
            "Epoch 67/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 4.0725e-06 - accuracy: 1.0000\n",
            "Epoch 00067: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.1106e-06 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9802\n",
            "Epoch 68/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 3.4857e-06 - accuracy: 1.0000\n",
            "Epoch 00068: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.4667e-06 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9800\n",
            "Epoch 69/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 2.9043e-06 - accuracy: 1.0000\n",
            "Epoch 00069: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.9745e-06 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9801\n",
            "Epoch 70/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 2.5630e-06 - accuracy: 1.0000\n",
            "Epoch 00070: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.5608e-06 - accuracy: 1.0000 - val_loss: 0.1676 - val_accuracy: 0.9801\n",
            "Epoch 71/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 2.2077e-06 - accuracy: 1.0000\n",
            "Epoch 00071: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.2077e-06 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9802\n",
            "Epoch 72/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 1.9426e-06 - accuracy: 1.0000\n",
            "Epoch 00072: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.9309e-06 - accuracy: 1.0000 - val_loss: 0.1712 - val_accuracy: 0.9804\n",
            "Epoch 73/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 1.6752e-06 - accuracy: 1.0000\n",
            "Epoch 00073: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.7020e-06 - accuracy: 1.0000 - val_loss: 0.1733 - val_accuracy: 0.9802\n",
            "Epoch 74/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 1.5030e-06 - accuracy: 1.0000\n",
            "Epoch 00074: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5020e-06 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9800\n",
            "Epoch 75/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 1.3385e-06 - accuracy: 1.0000\n",
            "Epoch 00075: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.3339e-06 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9802\n",
            "Epoch 76/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 1.2107e-06 - accuracy: 1.0000\n",
            "Epoch 00076: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1777e-06 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9801\n",
            "Epoch 77/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 1.0522e-06 - accuracy: 1.0000\n",
            "Epoch 00077: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0522e-06 - accuracy: 1.0000 - val_loss: 0.1803 - val_accuracy: 0.9800\n",
            "Epoch 78/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 9.4972e-07 - accuracy: 1.0000\n",
            "Epoch 00078: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.4080e-07 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9800\n",
            "Epoch 79/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 8.4904e-07 - accuracy: 1.0000\n",
            "Epoch 00079: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.4173e-07 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9800\n",
            "Epoch 80/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 7.5847e-07 - accuracy: 1.0000\n",
            "Epoch 00080: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.6049e-07 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 0.9798\n",
            "Epoch 81/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 6.7304e-07 - accuracy: 1.0000\n",
            "Epoch 00081: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.8168e-07 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9799\n",
            "Epoch 82/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 5.9210e-07 - accuracy: 1.0000\n",
            "Epoch 00082: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.1306e-07 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9799\n",
            "Epoch 83/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 5.5350e-07 - accuracy: 1.0000\n",
            "Epoch 00083: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.5350e-07 - accuracy: 1.0000 - val_loss: 0.1896 - val_accuracy: 0.9799\n",
            "Epoch 00083: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLqf_rS8Z7u2",
        "colab_type": "text"
      },
      "source": [
        "and draw the plots:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLJAEAQAZ0hR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "7a749803-60cc-4ad1-d982-fbe6f29113d7"
      },
      "source": [
        "  fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "  loss_ax.set_title('Loss')\n",
        "  loss_ax.plot(multi_layer_3_hidden_train.history['loss'], '-r', label='Train 3')\n",
        "  loss_ax.plot(multi_layer_3_hidden_train.history['val_loss'], '-g', label='Validation 3')\n",
        "  loss_ax.plot(multi_layer_4_hidden_train.history['loss'], '-b', label='Train 4')\n",
        "  loss_ax.plot(multi_layer_4_hidden_train.history['val_loss'], '-y', label='Validation 4')\n",
        "\n",
        "  acc_ax.set_title('Accuracy')\n",
        "  acc_ax.plot(multi_layer_3_hidden_train.history['accuracy'], '-r', label='Train 3')\n",
        "  acc_ax.plot(multi_layer_3_hidden_train.history['val_accuracy'], '-g', label='Validation 3')\n",
        "  acc_ax.plot(multi_layer_4_hidden_train.history['accuracy'], '-b', label='Train 4')\n",
        "  acc_ax.plot(multi_layer_4_hidden_train.history['val_accuracy'], '-y', label='Validation 4')\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF6_xMQxcX1X",
        "colab_type": "text"
      },
      "source": [
        "Looking at the plots, we can see that 4 hidden layers did indeed achieve a better validation accuracy, taking however nearly double the number of epochs to converge. Let us test them with the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ss1Cpfn9BXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bb03b8bb-5ce5-4bd5-d149-35a11b686e7b"
      },
      "source": [
        "multi_layer_3_hidden_model.load_weights('multi_layer_3_hidden_model.h5')\n",
        "multi_layer_4_hidden_model.load_weights('multi_layer_4_hidden_model.h5')\n",
        "loss, acc3 = multi_layer_3_hidden_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "loss, acc4 = multi_layer_4_hidden_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for 3: {}, Accuracy for 4: {}'.format(acc3, acc4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1034 - accuracy: 0.9781\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1299 - accuracy: 0.9807\n",
            "Accuracy for 3: 0.9781000018119812, Accuracy for 4: 0.9807000160217285\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te4RWBgr9p7_",
        "colab_type": "text"
      },
      "source": [
        "As we can see, 4 did indeed outperform 3, reaching a solid 98% but taking double the amount of updates, so we will stick with 3 hidden layers for further testing. Let  us now see if regularization can improve this mark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLt8nf4nlKvB",
        "colab_type": "text"
      },
      "source": [
        "##### Regularization\n",
        "\n",
        "To test this is pretty straightforward, we already have a satisfactory hidden layer model, so we'll add regularization to the hidden layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2za5I_cORv4",
        "colab_type": "text"
      },
      "source": [
        "######Kernel Regularization\n",
        "Let us start with kernel regularization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jXhIkxp_OyMi",
        "colab": {}
      },
      "source": [
        "def create_multi_layer_kernel_reg_model(regulizer, name='multi_layer_kernel_reg_model'):\n",
        "  multi_layer_model = tf.keras.Sequential(name=name)\n",
        "  multi_layer_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  multi_layer_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "  for i in range(3):\n",
        "    multi_layer_model.add(tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regulizer, name='hidden{}'.format(i)))\n",
        "  multi_layer_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "\n",
        "  multi_layer_model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "  multi_layer_model.summary()\n",
        "  return multi_layer_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "leaGyn6QOyMk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2354ca7e-8e93-4805-ffcb-c25580157df9"
      },
      "source": [
        "regulizers = {\n",
        "    \"None\":       None, \n",
        "    \"L1 0.01\":    tf.keras.regularizers.l1(0.001), \n",
        "    \"L2 0.01\":    tf.keras.regularizers.l2(0.001), \n",
        "    \"L1 L2 0.01\": tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)}\n",
        "multi_layer_kernel_reg_model_accuracy_lines = test_model_parameter(create_multi_layer_kernel_reg_model, regulizers, 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"multi_layer_kernel_reg_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4428 - accuracy: 0.8770 - val_loss: 0.2053 - val_accuracy: 0.9402\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.9520 - val_loss: 0.1453 - val_accuracy: 0.9586\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1121 - accuracy: 0.9659 - val_loss: 0.1241 - val_accuracy: 0.9637\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0841 - accuracy: 0.9738 - val_loss: 0.1097 - val_accuracy: 0.9678\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0680 - accuracy: 0.9784 - val_loss: 0.1124 - val_accuracy: 0.9658\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0557 - accuracy: 0.9824 - val_loss: 0.1046 - val_accuracy: 0.9682\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0450 - accuracy: 0.9859 - val_loss: 0.0955 - val_accuracy: 0.9718\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0362 - accuracy: 0.9889 - val_loss: 0.0886 - val_accuracy: 0.9758\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.9913 - val_loss: 0.1107 - val_accuracy: 0.9704\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0268 - accuracy: 0.9917 - val_loss: 0.1007 - val_accuracy: 0.9728\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0932 - val_accuracy: 0.9753\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.1175 - val_accuracy: 0.9721\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0170 - accuracy: 0.9950 - val_loss: 0.0986 - val_accuracy: 0.9762\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.1030 - val_accuracy: 0.9741\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.1134 - val_accuracy: 0.9749\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.1176 - val_accuracy: 0.9747\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.1161 - val_accuracy: 0.9744\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.1382 - val_accuracy: 0.9691\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.1244 - val_accuracy: 0.9744\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.1156 - val_accuracy: 0.9764\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.1280 - val_accuracy: 0.9753\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.1199 - val_accuracy: 0.9771\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.1236 - val_accuracy: 0.9775\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1247 - val_accuracy: 0.9770\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.1473 - val_accuracy: 0.9736\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9957 - val_loss: 0.1295 - val_accuracy: 0.9747\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.1226 - val_accuracy: 0.9778\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.1378 - val_accuracy: 0.9761\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1360 - val_accuracy: 0.9762\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1284 - val_accuracy: 0.9783\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.8976e-04 - accuracy: 0.9999 - val_loss: 0.1224 - val_accuracy: 0.9803\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.9152e-04 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9804\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0421e-04 - accuracy: 1.0000 - val_loss: 0.1295 - val_accuracy: 0.9799\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.7813e-05 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9801\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.3923e-05 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9805\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.4678e-05 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9803\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.8098e-05 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9804\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.2413e-05 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9806\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.8088e-05 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9804\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.4429e-05 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9801\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.0678e-05 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9803\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.7526e-05 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9802\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.5364e-05 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9802\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.2686e-05 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9806\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.0698e-05 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9803\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.8695e-05 - accuracy: 1.0000 - val_loss: 0.1432 - val_accuracy: 0.9805\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.7076e-05 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9804\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.6172e-05 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9803\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.4392e-05 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9805\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2744e-05 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9803\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3054 - accuracy: 0.9093 - val_loss: 0.1452 - val_accuracy: 0.9557\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1040 - accuracy: 0.9683 - val_loss: 0.1074 - val_accuracy: 0.9678\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0709 - accuracy: 0.9782 - val_loss: 0.0971 - val_accuracy: 0.9718\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0516 - accuracy: 0.9841 - val_loss: 0.0949 - val_accuracy: 0.9709\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.0880 - val_accuracy: 0.9753\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9910 - val_loss: 0.0881 - val_accuracy: 0.9751\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0236 - accuracy: 0.9931 - val_loss: 0.0904 - val_accuracy: 0.9752\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 0.0940 - val_accuracy: 0.9759\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0130 - accuracy: 0.9965 - val_loss: 0.0931 - val_accuracy: 0.9782\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.1168 - val_accuracy: 0.9732\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0982 - val_accuracy: 0.9767\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1063 - val_accuracy: 0.9762\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1029 - val_accuracy: 0.9769\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.1146 - val_accuracy: 0.9772\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1133 - val_accuracy: 0.9765\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.1212 - val_accuracy: 0.9743\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.1152 - val_accuracy: 0.9763\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.1180 - val_accuracy: 0.9758\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1132 - val_accuracy: 0.9773\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.1155 - val_accuracy: 0.9792\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.1202 - val_accuracy: 0.9783\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.5247e-04 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9801\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.5510e-04 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9800\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0689e-04 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9797\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.8286e-05 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9797\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.5935e-05 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9798\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.5646e-05 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9798\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.8249e-05 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9797\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.1544e-05 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9797\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.5986e-05 - accuracy: 1.0000 - val_loss: 0.1295 - val_accuracy: 0.9797\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.1688e-05 - accuracy: 1.0000 - val_loss: 0.1307 - val_accuracy: 0.9794\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.7149e-05 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9797\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.3294e-05 - accuracy: 1.0000 - val_loss: 0.1332 - val_accuracy: 0.9797\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.0215e-05 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9797\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.7242e-05 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9797\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.4678e-05 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9796\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.2447e-05 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9796\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.0216e-05 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9795\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.8384e-05 - accuracy: 1.0000 - val_loss: 0.1414 - val_accuracy: 0.9798\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.6816e-05 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9795\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5233e-05 - accuracy: 1.0000 - val_loss: 0.1435 - val_accuracy: 0.9798\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.3816e-05 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9797\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2502e-05 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9798\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1406e-05 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9796\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0351e-05 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9796\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.3504e-06 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9797\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.4749e-06 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9794\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.7404e-06 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9794\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.0109e-06 - accuracy: 1.0000 - val_loss: 0.1534 - val_accuracy: 0.9795\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.3885e-06 - accuracy: 1.0000 - val_loss: 0.1545 - val_accuracy: 0.9795\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2910 - accuracy: 0.9107 - val_loss: 0.1363 - val_accuracy: 0.9593\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1048 - accuracy: 0.9678 - val_loss: 0.1069 - val_accuracy: 0.9678\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0696 - accuracy: 0.9781 - val_loss: 0.0960 - val_accuracy: 0.9721\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0521 - accuracy: 0.9843 - val_loss: 0.0902 - val_accuracy: 0.9737\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0378 - accuracy: 0.9885 - val_loss: 0.0888 - val_accuracy: 0.9741\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 0.0851 - val_accuracy: 0.9763\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0215 - accuracy: 0.9940 - val_loss: 0.0876 - val_accuracy: 0.9764\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.0905 - val_accuracy: 0.9764\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.0946 - val_accuracy: 0.9753\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 0.0971 - val_accuracy: 0.9770\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1046 - val_accuracy: 0.9738\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.1045 - val_accuracy: 0.9770\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.1305 - val_accuracy: 0.9726\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.1100 - val_accuracy: 0.9779\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.1105 - val_accuracy: 0.9764\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.1177 - val_accuracy: 0.9758\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1264 - val_accuracy: 0.9764\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.1483 - val_accuracy: 0.9708\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 0.1218 - val_accuracy: 0.9774\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.1238 - val_accuracy: 0.9773\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1217 - val_accuracy: 0.9791\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1259 - val_accuracy: 0.9771\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1403 - val_accuracy: 0.9772\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.1849 - val_accuracy: 0.9708\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.1408 - val_accuracy: 0.9746\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.1361 - val_accuracy: 0.9771\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1252 - val_accuracy: 0.9776\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.6766e-04 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9797\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.4673e-04 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9803\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.8823e-05 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9803\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.9928e-05 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9808\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.7154e-05 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9806\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.7192e-05 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9808\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.9757e-05 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9808\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.3444e-05 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9808\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.7964e-05 - accuracy: 1.0000 - val_loss: 0.1327 - val_accuracy: 0.9807\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.3613e-05 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9807\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.9854e-05 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9806\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.6616e-05 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 0.9808\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.3803e-05 - accuracy: 1.0000 - val_loss: 0.1375 - val_accuracy: 0.9804\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.1230e-05 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9808\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.9193e-05 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9808\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.7174e-05 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9808\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5436e-05 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9807\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.3679e-05 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9810\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2055e-05 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9806\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0635e-05 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 0.9809\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.3506e-06 - accuracy: 1.0000 - val_loss: 0.1527 - val_accuracy: 0.9805\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.3521e-06 - accuracy: 1.0000 - val_loss: 0.1546 - val_accuracy: 0.9803\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.5378e-06 - accuracy: 1.0000 - val_loss: 0.1558 - val_accuracy: 0.9807\n",
            "Model: \"multi_layer_kernel_reg_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.2188 - accuracy: 0.8393 - val_loss: 1.6533 - val_accuracy: 0.8961\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.3766 - accuracy: 0.9020 - val_loss: 1.1891 - val_accuracy: 0.9066\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0577 - accuracy: 0.9093 - val_loss: 0.9524 - val_accuracy: 0.9169\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.8828 - accuracy: 0.9190 - val_loss: 0.8270 - val_accuracy: 0.9215\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7768 - accuracy: 0.9241 - val_loss: 0.7388 - val_accuracy: 0.9259\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6997 - accuracy: 0.9292 - val_loss: 0.6818 - val_accuracy: 0.9311\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6447 - accuracy: 0.9325 - val_loss: 0.6346 - val_accuracy: 0.9285\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5997 - accuracy: 0.9354 - val_loss: 0.5859 - val_accuracy: 0.9354\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5650 - accuracy: 0.9376 - val_loss: 0.5618 - val_accuracy: 0.9340\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5341 - accuracy: 0.9391 - val_loss: 0.5311 - val_accuracy: 0.9381\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5139 - accuracy: 0.9402 - val_loss: 0.5103 - val_accuracy: 0.9400\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4927 - accuracy: 0.9429 - val_loss: 0.4941 - val_accuracy: 0.9408\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4771 - accuracy: 0.9435 - val_loss: 0.4818 - val_accuracy: 0.9415\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4630 - accuracy: 0.9449 - val_loss: 0.4746 - val_accuracy: 0.9452\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4539 - accuracy: 0.9461 - val_loss: 0.4613 - val_accuracy: 0.9445\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4439 - accuracy: 0.9465 - val_loss: 0.4485 - val_accuracy: 0.9439\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4337 - accuracy: 0.9476 - val_loss: 0.4383 - val_accuracy: 0.9463\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4244 - accuracy: 0.9491 - val_loss: 0.4338 - val_accuracy: 0.9458\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4177 - accuracy: 0.9511 - val_loss: 0.4277 - val_accuracy: 0.9467\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4117 - accuracy: 0.9511 - val_loss: 0.4201 - val_accuracy: 0.9477\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4048 - accuracy: 0.9513 - val_loss: 0.4276 - val_accuracy: 0.9448\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4056 - accuracy: 0.9506 - val_loss: 0.4129 - val_accuracy: 0.9482\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3970 - accuracy: 0.9529 - val_loss: 0.4107 - val_accuracy: 0.9495\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3948 - accuracy: 0.9530 - val_loss: 0.4058 - val_accuracy: 0.9459\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3864 - accuracy: 0.9533 - val_loss: 0.3997 - val_accuracy: 0.9500\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3813 - accuracy: 0.9548 - val_loss: 0.3952 - val_accuracy: 0.9505\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3818 - accuracy: 0.9528 - val_loss: 0.4012 - val_accuracy: 0.9462\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3754 - accuracy: 0.9557 - val_loss: 0.3906 - val_accuracy: 0.9501\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3755 - accuracy: 0.9535 - val_loss: 0.3940 - val_accuracy: 0.9509\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3698 - accuracy: 0.9551 - val_loss: 0.3852 - val_accuracy: 0.9506\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3679 - accuracy: 0.9555 - val_loss: 0.3817 - val_accuracy: 0.9507\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3637 - accuracy: 0.9562 - val_loss: 0.3826 - val_accuracy: 0.9496\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3606 - accuracy: 0.9562 - val_loss: 0.3797 - val_accuracy: 0.9507\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3586 - accuracy: 0.9558 - val_loss: 0.3768 - val_accuracy: 0.9517\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3551 - accuracy: 0.9567 - val_loss: 0.3646 - val_accuracy: 0.9528\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3525 - accuracy: 0.9568 - val_loss: 0.3713 - val_accuracy: 0.9521\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3529 - accuracy: 0.9558 - val_loss: 0.3699 - val_accuracy: 0.9529\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3502 - accuracy: 0.9566 - val_loss: 0.3629 - val_accuracy: 0.9532\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3452 - accuracy: 0.9577 - val_loss: 0.3605 - val_accuracy: 0.9534\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3459 - accuracy: 0.9568 - val_loss: 0.3613 - val_accuracy: 0.9526\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3422 - accuracy: 0.9582 - val_loss: 0.3631 - val_accuracy: 0.9492\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3375 - accuracy: 0.9588 - val_loss: 0.3602 - val_accuracy: 0.9524\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3395 - accuracy: 0.9584 - val_loss: 0.3575 - val_accuracy: 0.9532\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3337 - accuracy: 0.9587 - val_loss: 0.3567 - val_accuracy: 0.9507\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3349 - accuracy: 0.9588 - val_loss: 0.3504 - val_accuracy: 0.9538\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3349 - accuracy: 0.9586 - val_loss: 0.3575 - val_accuracy: 0.9515\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3323 - accuracy: 0.9594 - val_loss: 0.3509 - val_accuracy: 0.9538\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3314 - accuracy: 0.9590 - val_loss: 0.3606 - val_accuracy: 0.9488\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3285 - accuracy: 0.9597 - val_loss: 0.3421 - val_accuracy: 0.9557\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3264 - accuracy: 0.9599 - val_loss: 0.3452 - val_accuracy: 0.9548\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.0889 - accuracy: 0.8455 - val_loss: 1.4086 - val_accuracy: 0.8964\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1722 - accuracy: 0.9103 - val_loss: 1.0124 - val_accuracy: 0.9197\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.9119 - accuracy: 0.9224 - val_loss: 0.8366 - val_accuracy: 0.9265\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7679 - accuracy: 0.9315 - val_loss: 0.7229 - val_accuracy: 0.9326\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6804 - accuracy: 0.9364 - val_loss: 0.6528 - val_accuracy: 0.9403\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6210 - accuracy: 0.9401 - val_loss: 0.6115 - val_accuracy: 0.9391\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5807 - accuracy: 0.9429 - val_loss: 0.5828 - val_accuracy: 0.9413\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5512 - accuracy: 0.9442 - val_loss: 0.5478 - val_accuracy: 0.9456\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5252 - accuracy: 0.9462 - val_loss: 0.5216 - val_accuracy: 0.9456\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5066 - accuracy: 0.9488 - val_loss: 0.4994 - val_accuracy: 0.9502\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4889 - accuracy: 0.9490 - val_loss: 0.4993 - val_accuracy: 0.9475\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4739 - accuracy: 0.9514 - val_loss: 0.4757 - val_accuracy: 0.9506\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4637 - accuracy: 0.9516 - val_loss: 0.4683 - val_accuracy: 0.9503\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4538 - accuracy: 0.9525 - val_loss: 0.4603 - val_accuracy: 0.9501\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4415 - accuracy: 0.9535 - val_loss: 0.4482 - val_accuracy: 0.9513\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4353 - accuracy: 0.9543 - val_loss: 0.4437 - val_accuracy: 0.9503\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.4270 - accuracy: 0.9545 - val_loss: 0.4344 - val_accuracy: 0.9533\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4204 - accuracy: 0.9552 - val_loss: 0.4302 - val_accuracy: 0.9533\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4147 - accuracy: 0.9560 - val_loss: 0.4367 - val_accuracy: 0.9490\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4107 - accuracy: 0.9556 - val_loss: 0.4164 - val_accuracy: 0.9527\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4060 - accuracy: 0.9556 - val_loss: 0.4226 - val_accuracy: 0.9510\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4028 - accuracy: 0.9555 - val_loss: 0.4089 - val_accuracy: 0.9546\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3945 - accuracy: 0.9576 - val_loss: 0.4087 - val_accuracy: 0.9525\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3912 - accuracy: 0.9574 - val_loss: 0.4002 - val_accuracy: 0.9548\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3882 - accuracy: 0.9567 - val_loss: 0.3950 - val_accuracy: 0.9541\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3845 - accuracy: 0.9572 - val_loss: 0.3941 - val_accuracy: 0.9557\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3794 - accuracy: 0.9575 - val_loss: 0.4012 - val_accuracy: 0.9524\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3736 - accuracy: 0.9586 - val_loss: 0.3922 - val_accuracy: 0.9537\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3706 - accuracy: 0.9589 - val_loss: 0.3898 - val_accuracy: 0.9539\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3690 - accuracy: 0.9592 - val_loss: 0.3832 - val_accuracy: 0.9551\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3665 - accuracy: 0.9585 - val_loss: 0.3741 - val_accuracy: 0.9575\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3647 - accuracy: 0.9591 - val_loss: 0.3828 - val_accuracy: 0.9576\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3628 - accuracy: 0.9595 - val_loss: 0.3748 - val_accuracy: 0.9556\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3598 - accuracy: 0.9600 - val_loss: 0.3693 - val_accuracy: 0.9567\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3558 - accuracy: 0.9603 - val_loss: 0.3737 - val_accuracy: 0.9546\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3537 - accuracy: 0.9603 - val_loss: 0.3677 - val_accuracy: 0.9557\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3526 - accuracy: 0.9599 - val_loss: 0.3613 - val_accuracy: 0.9593\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3513 - accuracy: 0.9602 - val_loss: 0.3754 - val_accuracy: 0.9526\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3486 - accuracy: 0.9605 - val_loss: 0.3642 - val_accuracy: 0.9588\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3463 - accuracy: 0.9613 - val_loss: 0.3602 - val_accuracy: 0.9567\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3451 - accuracy: 0.9606 - val_loss: 0.3612 - val_accuracy: 0.9566\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3447 - accuracy: 0.9597 - val_loss: 0.3591 - val_accuracy: 0.9557\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3419 - accuracy: 0.9613 - val_loss: 0.3508 - val_accuracy: 0.9597\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3397 - accuracy: 0.9617 - val_loss: 0.3645 - val_accuracy: 0.9557\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3386 - accuracy: 0.9619 - val_loss: 0.3656 - val_accuracy: 0.9548\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3372 - accuracy: 0.9611 - val_loss: 0.3605 - val_accuracy: 0.9537\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3374 - accuracy: 0.9613 - val_loss: 0.3607 - val_accuracy: 0.9560\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3318 - accuracy: 0.9618 - val_loss: 0.3556 - val_accuracy: 0.9575\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3302 - accuracy: 0.9620 - val_loss: 0.3462 - val_accuracy: 0.9578\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3296 - accuracy: 0.9624 - val_loss: 0.3464 - val_accuracy: 0.9582\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.0372 - accuracy: 0.8486 - val_loss: 1.3314 - val_accuracy: 0.9102\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1240 - accuracy: 0.9145 - val_loss: 0.9686 - val_accuracy: 0.9215\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.8674 - accuracy: 0.9284 - val_loss: 0.8051 - val_accuracy: 0.9251\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7350 - accuracy: 0.9330 - val_loss: 0.6902 - val_accuracy: 0.9342\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6488 - accuracy: 0.9369 - val_loss: 0.6236 - val_accuracy: 0.9348\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5876 - accuracy: 0.9400 - val_loss: 0.5822 - val_accuracy: 0.9358\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5443 - accuracy: 0.9428 - val_loss: 0.5422 - val_accuracy: 0.9413\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5096 - accuracy: 0.9451 - val_loss: 0.5106 - val_accuracy: 0.9423\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4875 - accuracy: 0.9470 - val_loss: 0.4932 - val_accuracy: 0.9446\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4681 - accuracy: 0.9487 - val_loss: 0.4745 - val_accuracy: 0.9477\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4534 - accuracy: 0.9499 - val_loss: 0.4635 - val_accuracy: 0.9467\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4412 - accuracy: 0.9512 - val_loss: 0.4520 - val_accuracy: 0.9498\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4327 - accuracy: 0.9518 - val_loss: 0.4473 - val_accuracy: 0.9464\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4237 - accuracy: 0.9525 - val_loss: 0.4305 - val_accuracy: 0.9487\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4134 - accuracy: 0.9544 - val_loss: 0.4214 - val_accuracy: 0.9516\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4076 - accuracy: 0.9533 - val_loss: 0.4131 - val_accuracy: 0.9518\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4019 - accuracy: 0.9546 - val_loss: 0.4451 - val_accuracy: 0.9420\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3970 - accuracy: 0.9544 - val_loss: 0.4085 - val_accuracy: 0.9507\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3907 - accuracy: 0.9557 - val_loss: 0.4048 - val_accuracy: 0.9517\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3867 - accuracy: 0.9556 - val_loss: 0.4034 - val_accuracy: 0.9522\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3826 - accuracy: 0.9564 - val_loss: 0.3938 - val_accuracy: 0.9532\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3782 - accuracy: 0.9565 - val_loss: 0.3919 - val_accuracy: 0.9544\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3749 - accuracy: 0.9571 - val_loss: 0.3848 - val_accuracy: 0.9565\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3693 - accuracy: 0.9569 - val_loss: 0.3801 - val_accuracy: 0.9565\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3663 - accuracy: 0.9571 - val_loss: 0.3809 - val_accuracy: 0.9555\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3653 - accuracy: 0.9573 - val_loss: 0.4033 - val_accuracy: 0.9458\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3595 - accuracy: 0.9586 - val_loss: 0.3691 - val_accuracy: 0.9557\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3600 - accuracy: 0.9576 - val_loss: 0.3739 - val_accuracy: 0.9554\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3558 - accuracy: 0.9582 - val_loss: 0.3729 - val_accuracy: 0.9550\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3538 - accuracy: 0.9587 - val_loss: 0.3758 - val_accuracy: 0.9531\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3484 - accuracy: 0.9599 - val_loss: 0.3666 - val_accuracy: 0.9561\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3498 - accuracy: 0.9591 - val_loss: 0.3592 - val_accuracy: 0.9563\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3462 - accuracy: 0.9590 - val_loss: 0.3690 - val_accuracy: 0.9528\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3416 - accuracy: 0.9605 - val_loss: 0.3589 - val_accuracy: 0.9559\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3421 - accuracy: 0.9589 - val_loss: 0.3553 - val_accuracy: 0.9565\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3403 - accuracy: 0.9595 - val_loss: 0.3564 - val_accuracy: 0.9560\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3348 - accuracy: 0.9604 - val_loss: 0.3525 - val_accuracy: 0.9573\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3346 - accuracy: 0.9599 - val_loss: 0.3491 - val_accuracy: 0.9554\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3325 - accuracy: 0.9604 - val_loss: 0.3501 - val_accuracy: 0.9570\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3282 - accuracy: 0.9615 - val_loss: 0.3482 - val_accuracy: 0.9557\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3314 - accuracy: 0.9608 - val_loss: 0.3463 - val_accuracy: 0.9581\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3270 - accuracy: 0.9611 - val_loss: 0.3462 - val_accuracy: 0.9569\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3261 - accuracy: 0.9611 - val_loss: 0.3475 - val_accuracy: 0.9545\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3258 - accuracy: 0.9610 - val_loss: 0.3459 - val_accuracy: 0.9564\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3237 - accuracy: 0.9607 - val_loss: 0.3565 - val_accuracy: 0.9519\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3202 - accuracy: 0.9621 - val_loss: 0.3357 - val_accuracy: 0.9590\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3221 - accuracy: 0.9609 - val_loss: 0.3482 - val_accuracy: 0.9523\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3215 - accuracy: 0.9612 - val_loss: 0.3389 - val_accuracy: 0.9558\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3225 - accuracy: 0.9607 - val_loss: 0.3583 - val_accuracy: 0.9507\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3179 - accuracy: 0.9613 - val_loss: 0.3343 - val_accuracy: 0.9580\n",
            "Model: \"multi_layer_kernel_reg_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7748 - accuracy: 0.8779 - val_loss: 0.5100 - val_accuracy: 0.9361\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4361 - accuracy: 0.9496 - val_loss: 0.4027 - val_accuracy: 0.9546\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3568 - accuracy: 0.9612 - val_loss: 0.3420 - val_accuracy: 0.9606\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3076 - accuracy: 0.9679 - val_loss: 0.3056 - val_accuracy: 0.9669\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2726 - accuracy: 0.9720 - val_loss: 0.2766 - val_accuracy: 0.9688\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2469 - accuracy: 0.9740 - val_loss: 0.2589 - val_accuracy: 0.9688\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2253 - accuracy: 0.9761 - val_loss: 0.2395 - val_accuracy: 0.9706\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2073 - accuracy: 0.9787 - val_loss: 0.2249 - val_accuracy: 0.9712\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1955 - accuracy: 0.9799 - val_loss: 0.2215 - val_accuracy: 0.9704\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1857 - accuracy: 0.9797 - val_loss: 0.2029 - val_accuracy: 0.9745\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1739 - accuracy: 0.9819 - val_loss: 0.2027 - val_accuracy: 0.9718\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1679 - accuracy: 0.9827 - val_loss: 0.1955 - val_accuracy: 0.9730\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1614 - accuracy: 0.9831 - val_loss: 0.1896 - val_accuracy: 0.9727\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1533 - accuracy: 0.9844 - val_loss: 0.1797 - val_accuracy: 0.9746\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1520 - accuracy: 0.9839 - val_loss: 0.1747 - val_accuracy: 0.9779\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1495 - accuracy: 0.9842 - val_loss: 0.1735 - val_accuracy: 0.9750\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1413 - accuracy: 0.9860 - val_loss: 0.1926 - val_accuracy: 0.9695\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1443 - accuracy: 0.9844 - val_loss: 0.1767 - val_accuracy: 0.9751\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1387 - accuracy: 0.9853 - val_loss: 0.1714 - val_accuracy: 0.9737\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1341 - accuracy: 0.9867 - val_loss: 0.1645 - val_accuracy: 0.9774\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1330 - accuracy: 0.9861 - val_loss: 0.1936 - val_accuracy: 0.9682\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1302 - accuracy: 0.9871 - val_loss: 0.1669 - val_accuracy: 0.9754\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1286 - accuracy: 0.9874 - val_loss: 0.1711 - val_accuracy: 0.9731\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1272 - accuracy: 0.9872 - val_loss: 0.1732 - val_accuracy: 0.9738\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1239 - accuracy: 0.9882 - val_loss: 0.1688 - val_accuracy: 0.9735\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1237 - accuracy: 0.9876 - val_loss: 0.1717 - val_accuracy: 0.9713\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1220 - accuracy: 0.9876 - val_loss: 0.1671 - val_accuracy: 0.9728\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1183 - accuracy: 0.9889 - val_loss: 0.1591 - val_accuracy: 0.9753\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1198 - accuracy: 0.9876 - val_loss: 0.1605 - val_accuracy: 0.9737\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1193 - accuracy: 0.9879 - val_loss: 0.1558 - val_accuracy: 0.9762\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1172 - accuracy: 0.9880 - val_loss: 0.1618 - val_accuracy: 0.9737\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1126 - accuracy: 0.9899 - val_loss: 0.1579 - val_accuracy: 0.9750\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1122 - accuracy: 0.9890 - val_loss: 0.1544 - val_accuracy: 0.9758\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1137 - accuracy: 0.9890 - val_loss: 0.1547 - val_accuracy: 0.9755\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1109 - accuracy: 0.9888 - val_loss: 0.1717 - val_accuracy: 0.9693\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1075 - accuracy: 0.9905 - val_loss: 0.1528 - val_accuracy: 0.9753\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1073 - accuracy: 0.9902 - val_loss: 0.1530 - val_accuracy: 0.9747\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1105 - accuracy: 0.9889 - val_loss: 0.1539 - val_accuracy: 0.9753\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1084 - accuracy: 0.9895 - val_loss: 0.1524 - val_accuracy: 0.9751\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9913 - val_loss: 0.1487 - val_accuracy: 0.9768\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1063 - accuracy: 0.9898 - val_loss: 0.1510 - val_accuracy: 0.9756\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1022 - accuracy: 0.9911 - val_loss: 0.1519 - val_accuracy: 0.9752\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1015 - accuracy: 0.9908 - val_loss: 0.1601 - val_accuracy: 0.9701\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0994 - accuracy: 0.9914 - val_loss: 0.1439 - val_accuracy: 0.9765\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0998 - accuracy: 0.9910 - val_loss: 0.1569 - val_accuracy: 0.9729\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1020 - accuracy: 0.9901 - val_loss: 0.1562 - val_accuracy: 0.9730\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1017 - accuracy: 0.9899 - val_loss: 0.1433 - val_accuracy: 0.9772\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0962 - accuracy: 0.9922 - val_loss: 0.1520 - val_accuracy: 0.9725\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0973 - accuracy: 0.9906 - val_loss: 0.1540 - val_accuracy: 0.9730\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0970 - accuracy: 0.9906 - val_loss: 0.1406 - val_accuracy: 0.9768\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7041 - accuracy: 0.8873 - val_loss: 0.4581 - val_accuracy: 0.9442\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3922 - accuracy: 0.9545 - val_loss: 0.3567 - val_accuracy: 0.9574\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3169 - accuracy: 0.9640 - val_loss: 0.3103 - val_accuracy: 0.9625\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2711 - accuracy: 0.9697 - val_loss: 0.2759 - val_accuracy: 0.9632\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2394 - accuracy: 0.9727 - val_loss: 0.2601 - val_accuracy: 0.9632\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2170 - accuracy: 0.9760 - val_loss: 0.2276 - val_accuracy: 0.9714\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2010 - accuracy: 0.9779 - val_loss: 0.2223 - val_accuracy: 0.9711\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1893 - accuracy: 0.9792 - val_loss: 0.2119 - val_accuracy: 0.9723\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1785 - accuracy: 0.9802 - val_loss: 0.2013 - val_accuracy: 0.9732\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1680 - accuracy: 0.9821 - val_loss: 0.1937 - val_accuracy: 0.9745\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1612 - accuracy: 0.9825 - val_loss: 0.1884 - val_accuracy: 0.9722\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1544 - accuracy: 0.9840 - val_loss: 0.1833 - val_accuracy: 0.9746\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1497 - accuracy: 0.9842 - val_loss: 0.1823 - val_accuracy: 0.9728\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1453 - accuracy: 0.9849 - val_loss: 0.1908 - val_accuracy: 0.9697\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1460 - accuracy: 0.9845 - val_loss: 0.1821 - val_accuracy: 0.9714\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1412 - accuracy: 0.9853 - val_loss: 0.1768 - val_accuracy: 0.9739\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1378 - accuracy: 0.9860 - val_loss: 0.1807 - val_accuracy: 0.9733\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1347 - accuracy: 0.9864 - val_loss: 0.1766 - val_accuracy: 0.9723\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1308 - accuracy: 0.9872 - val_loss: 0.1748 - val_accuracy: 0.9728\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1294 - accuracy: 0.9880 - val_loss: 0.1685 - val_accuracy: 0.9744\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1295 - accuracy: 0.9867 - val_loss: 0.1643 - val_accuracy: 0.9752\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1305 - accuracy: 0.9862 - val_loss: 0.1876 - val_accuracy: 0.9680\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1249 - accuracy: 0.9879 - val_loss: 0.1632 - val_accuracy: 0.9740\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1204 - accuracy: 0.9894 - val_loss: 0.1689 - val_accuracy: 0.9719\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1211 - accuracy: 0.9883 - val_loss: 0.1619 - val_accuracy: 0.9751\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1232 - accuracy: 0.9872 - val_loss: 0.1769 - val_accuracy: 0.9714\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1174 - accuracy: 0.9893 - val_loss: 0.1586 - val_accuracy: 0.9756\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1155 - accuracy: 0.9896 - val_loss: 0.1492 - val_accuracy: 0.9768\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1150 - accuracy: 0.9885 - val_loss: 0.1605 - val_accuracy: 0.9740\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1139 - accuracy: 0.9893 - val_loss: 0.1558 - val_accuracy: 0.9749\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1127 - accuracy: 0.9890 - val_loss: 0.1784 - val_accuracy: 0.9673\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1119 - accuracy: 0.9899 - val_loss: 0.1517 - val_accuracy: 0.9761\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1129 - accuracy: 0.9887 - val_loss: 0.1534 - val_accuracy: 0.9762\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1119 - accuracy: 0.9886 - val_loss: 0.1587 - val_accuracy: 0.9738\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1088 - accuracy: 0.9899 - val_loss: 0.1492 - val_accuracy: 0.9771\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1068 - accuracy: 0.9901 - val_loss: 0.1552 - val_accuracy: 0.9744\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1066 - accuracy: 0.9905 - val_loss: 0.1515 - val_accuracy: 0.9762\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1084 - accuracy: 0.9893 - val_loss: 0.1489 - val_accuracy: 0.9753\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1010 - accuracy: 0.9918 - val_loss: 0.1520 - val_accuracy: 0.9751\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1019 - accuracy: 0.9905 - val_loss: 0.1625 - val_accuracy: 0.9706\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1013 - accuracy: 0.9911 - val_loss: 0.1535 - val_accuracy: 0.9734\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1053 - accuracy: 0.9890 - val_loss: 0.1527 - val_accuracy: 0.9751\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1023 - accuracy: 0.9906 - val_loss: 0.1620 - val_accuracy: 0.9717\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0977 - accuracy: 0.9920 - val_loss: 0.1482 - val_accuracy: 0.9747\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1017 - accuracy: 0.9901 - val_loss: 0.1509 - val_accuracy: 0.9753\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0985 - accuracy: 0.9910 - val_loss: 0.1494 - val_accuracy: 0.9743\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0987 - accuracy: 0.9912 - val_loss: 0.1537 - val_accuracy: 0.9733\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0971 - accuracy: 0.9921 - val_loss: 0.1450 - val_accuracy: 0.9743\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9926 - val_loss: 0.1493 - val_accuracy: 0.9758\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0938 - accuracy: 0.9921 - val_loss: 0.1470 - val_accuracy: 0.9756\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6835 - accuracy: 0.8921 - val_loss: 0.4513 - val_accuracy: 0.9467\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3810 - accuracy: 0.9578 - val_loss: 0.3512 - val_accuracy: 0.9587\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.3055 - accuracy: 0.9671 - val_loss: 0.2924 - val_accuracy: 0.9665\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2594 - accuracy: 0.9726 - val_loss: 0.2636 - val_accuracy: 0.9673\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2318 - accuracy: 0.9742 - val_loss: 0.2372 - val_accuracy: 0.9706\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2059 - accuracy: 0.9789 - val_loss: 0.2283 - val_accuracy: 0.9694\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1910 - accuracy: 0.9800 - val_loss: 0.2080 - val_accuracy: 0.9725\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1795 - accuracy: 0.9816 - val_loss: 0.2028 - val_accuracy: 0.9722\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1691 - accuracy: 0.9821 - val_loss: 0.1927 - val_accuracy: 0.9732\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1639 - accuracy: 0.9821 - val_loss: 0.1842 - val_accuracy: 0.9751\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1554 - accuracy: 0.9842 - val_loss: 0.1840 - val_accuracy: 0.9749\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1509 - accuracy: 0.9844 - val_loss: 0.1786 - val_accuracy: 0.9758\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1463 - accuracy: 0.9852 - val_loss: 0.1785 - val_accuracy: 0.9742\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1426 - accuracy: 0.9855 - val_loss: 0.1717 - val_accuracy: 0.9750\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1360 - accuracy: 0.9871 - val_loss: 0.1803 - val_accuracy: 0.9721\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1366 - accuracy: 0.9854 - val_loss: 0.1731 - val_accuracy: 0.9738\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1326 - accuracy: 0.9864 - val_loss: 0.1869 - val_accuracy: 0.9694\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1319 - accuracy: 0.9869 - val_loss: 0.1608 - val_accuracy: 0.9762\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1279 - accuracy: 0.9870 - val_loss: 0.1638 - val_accuracy: 0.9763\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1274 - accuracy: 0.9875 - val_loss: 0.1598 - val_accuracy: 0.9766\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1248 - accuracy: 0.9873 - val_loss: 0.1835 - val_accuracy: 0.9681\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1237 - accuracy: 0.9881 - val_loss: 0.1646 - val_accuracy: 0.9763\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1236 - accuracy: 0.9875 - val_loss: 0.1739 - val_accuracy: 0.9723\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1195 - accuracy: 0.9889 - val_loss: 0.1620 - val_accuracy: 0.9753\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1184 - accuracy: 0.9885 - val_loss: 0.1570 - val_accuracy: 0.9763\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1158 - accuracy: 0.9888 - val_loss: 0.1614 - val_accuracy: 0.9739\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1148 - accuracy: 0.9895 - val_loss: 0.1625 - val_accuracy: 0.9736\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1145 - accuracy: 0.9891 - val_loss: 0.1612 - val_accuracy: 0.9746\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1144 - accuracy: 0.9882 - val_loss: 0.1578 - val_accuracy: 0.9759\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1107 - accuracy: 0.9898 - val_loss: 0.1616 - val_accuracy: 0.9747\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1129 - accuracy: 0.9887 - val_loss: 0.1590 - val_accuracy: 0.9744\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1097 - accuracy: 0.9896 - val_loss: 0.1553 - val_accuracy: 0.9747\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1124 - accuracy: 0.9887 - val_loss: 0.1542 - val_accuracy: 0.9748\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1111 - accuracy: 0.9895 - val_loss: 0.1598 - val_accuracy: 0.9732\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1059 - accuracy: 0.9902 - val_loss: 0.1490 - val_accuracy: 0.9761\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1035 - accuracy: 0.9911 - val_loss: 0.1546 - val_accuracy: 0.9743\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1041 - accuracy: 0.9907 - val_loss: 0.1544 - val_accuracy: 0.9733\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1024 - accuracy: 0.9912 - val_loss: 0.1527 - val_accuracy: 0.9754\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1047 - accuracy: 0.9899 - val_loss: 0.1602 - val_accuracy: 0.9711\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1048 - accuracy: 0.9894 - val_loss: 0.1574 - val_accuracy: 0.9720\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0997 - accuracy: 0.9914 - val_loss: 0.1547 - val_accuracy: 0.9736\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0986 - accuracy: 0.9914 - val_loss: 0.1494 - val_accuracy: 0.9766\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1012 - accuracy: 0.9900 - val_loss: 0.1502 - val_accuracy: 0.9762\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0985 - accuracy: 0.9909 - val_loss: 0.1471 - val_accuracy: 0.9759\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0964 - accuracy: 0.9912 - val_loss: 0.1647 - val_accuracy: 0.9717\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9899 - val_loss: 0.1507 - val_accuracy: 0.9740\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0945 - accuracy: 0.9918 - val_loss: 0.1507 - val_accuracy: 0.9735\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0962 - accuracy: 0.9918 - val_loss: 0.1491 - val_accuracy: 0.9751\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0960 - accuracy: 0.9911 - val_loss: 0.1549 - val_accuracy: 0.9741\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1027 - accuracy: 0.9893 - val_loss: 0.1488 - val_accuracy: 0.9749\n",
            "Model: \"multi_layer_kernel_reg_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.3449 - accuracy: 0.8441 - val_loss: 1.6721 - val_accuracy: 0.8930\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.3803 - accuracy: 0.8969 - val_loss: 1.1853 - val_accuracy: 0.8949\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0547 - accuracy: 0.9041 - val_loss: 0.9624 - val_accuracy: 0.9054\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.8854 - accuracy: 0.9123 - val_loss: 0.8307 - val_accuracy: 0.9167\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7868 - accuracy: 0.9168 - val_loss: 0.7546 - val_accuracy: 0.9168\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7182 - accuracy: 0.9201 - val_loss: 0.6935 - val_accuracy: 0.9258\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6702 - accuracy: 0.9220 - val_loss: 0.6476 - val_accuracy: 0.9272\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6352 - accuracy: 0.9251 - val_loss: 0.6227 - val_accuracy: 0.9258\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6062 - accuracy: 0.9275 - val_loss: 0.5999 - val_accuracy: 0.9308\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5814 - accuracy: 0.9306 - val_loss: 0.5756 - val_accuracy: 0.9320\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5614 - accuracy: 0.9323 - val_loss: 0.5695 - val_accuracy: 0.9277\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5472 - accuracy: 0.9329 - val_loss: 0.5604 - val_accuracy: 0.9282\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5307 - accuracy: 0.9339 - val_loss: 0.5326 - val_accuracy: 0.9352\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5222 - accuracy: 0.9349 - val_loss: 0.5367 - val_accuracy: 0.9309\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5093 - accuracy: 0.9362 - val_loss: 0.5060 - val_accuracy: 0.9369\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4993 - accuracy: 0.9370 - val_loss: 0.5057 - val_accuracy: 0.9354\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4930 - accuracy: 0.9377 - val_loss: 0.5055 - val_accuracy: 0.9371\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4821 - accuracy: 0.9391 - val_loss: 0.4966 - val_accuracy: 0.9367\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4749 - accuracy: 0.9394 - val_loss: 0.4849 - val_accuracy: 0.9393\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4676 - accuracy: 0.9402 - val_loss: 0.4747 - val_accuracy: 0.9392\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4615 - accuracy: 0.9403 - val_loss: 0.4831 - val_accuracy: 0.9362\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4553 - accuracy: 0.9418 - val_loss: 0.4622 - val_accuracy: 0.9386\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4509 - accuracy: 0.9414 - val_loss: 0.4597 - val_accuracy: 0.9410\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4469 - accuracy: 0.9419 - val_loss: 0.4573 - val_accuracy: 0.9410\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4415 - accuracy: 0.9424 - val_loss: 0.4441 - val_accuracy: 0.9426\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4368 - accuracy: 0.9439 - val_loss: 0.4436 - val_accuracy: 0.9423\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4314 - accuracy: 0.9445 - val_loss: 0.4370 - val_accuracy: 0.9439\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4296 - accuracy: 0.9438 - val_loss: 0.4506 - val_accuracy: 0.9398\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4248 - accuracy: 0.9446 - val_loss: 0.4302 - val_accuracy: 0.9442\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4206 - accuracy: 0.9444 - val_loss: 0.4396 - val_accuracy: 0.9419\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4153 - accuracy: 0.9466 - val_loss: 0.4320 - val_accuracy: 0.9420\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4168 - accuracy: 0.9449 - val_loss: 0.4292 - val_accuracy: 0.9409\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4075 - accuracy: 0.9477 - val_loss: 0.4191 - val_accuracy: 0.9445\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4052 - accuracy: 0.9476 - val_loss: 0.4143 - val_accuracy: 0.9454\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4057 - accuracy: 0.9474 - val_loss: 0.4086 - val_accuracy: 0.9486\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3998 - accuracy: 0.9486 - val_loss: 0.4070 - val_accuracy: 0.9460\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4001 - accuracy: 0.9481 - val_loss: 0.4130 - val_accuracy: 0.9463\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3964 - accuracy: 0.9498 - val_loss: 0.3999 - val_accuracy: 0.9507\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3927 - accuracy: 0.9501 - val_loss: 0.4074 - val_accuracy: 0.9479\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3898 - accuracy: 0.9508 - val_loss: 0.4010 - val_accuracy: 0.9486\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3880 - accuracy: 0.9507 - val_loss: 0.4013 - val_accuracy: 0.9492\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3842 - accuracy: 0.9512 - val_loss: 0.3940 - val_accuracy: 0.9500\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3790 - accuracy: 0.9530 - val_loss: 0.3922 - val_accuracy: 0.9500\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3811 - accuracy: 0.9521 - val_loss: 0.3862 - val_accuracy: 0.9506\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3776 - accuracy: 0.9527 - val_loss: 0.3964 - val_accuracy: 0.9473\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3772 - accuracy: 0.9514 - val_loss: 0.3870 - val_accuracy: 0.9504\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3731 - accuracy: 0.9535 - val_loss: 0.3910 - val_accuracy: 0.9494\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3705 - accuracy: 0.9544 - val_loss: 0.3816 - val_accuracy: 0.9522\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3720 - accuracy: 0.9536 - val_loss: 0.3811 - val_accuracy: 0.9510\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3674 - accuracy: 0.9543 - val_loss: 0.3871 - val_accuracy: 0.9501\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.0297 - accuracy: 0.8459 - val_loss: 1.3461 - val_accuracy: 0.8930\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1355 - accuracy: 0.9028 - val_loss: 0.9939 - val_accuracy: 0.9112\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.9009 - accuracy: 0.9148 - val_loss: 0.8347 - val_accuracy: 0.9166\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7736 - accuracy: 0.9221 - val_loss: 0.7345 - val_accuracy: 0.9237\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6924 - accuracy: 0.9273 - val_loss: 0.6695 - val_accuracy: 0.9254\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6381 - accuracy: 0.9316 - val_loss: 0.6300 - val_accuracy: 0.9293\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5991 - accuracy: 0.9336 - val_loss: 0.5904 - val_accuracy: 0.9345\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5719 - accuracy: 0.9369 - val_loss: 0.5725 - val_accuracy: 0.9341\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5502 - accuracy: 0.9389 - val_loss: 0.5544 - val_accuracy: 0.9353\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5334 - accuracy: 0.9399 - val_loss: 0.5360 - val_accuracy: 0.9391\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5184 - accuracy: 0.9408 - val_loss: 0.5219 - val_accuracy: 0.9402\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5062 - accuracy: 0.9423 - val_loss: 0.5238 - val_accuracy: 0.9382\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4927 - accuracy: 0.9437 - val_loss: 0.5014 - val_accuracy: 0.9403\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4810 - accuracy: 0.9442 - val_loss: 0.4905 - val_accuracy: 0.9427\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4731 - accuracy: 0.9450 - val_loss: 0.4906 - val_accuracy: 0.9386\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4646 - accuracy: 0.9459 - val_loss: 0.4842 - val_accuracy: 0.9391\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4600 - accuracy: 0.9454 - val_loss: 0.4722 - val_accuracy: 0.9417\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4491 - accuracy: 0.9478 - val_loss: 0.4555 - val_accuracy: 0.9460\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4416 - accuracy: 0.9488 - val_loss: 0.4538 - val_accuracy: 0.9438\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4397 - accuracy: 0.9495 - val_loss: 0.4579 - val_accuracy: 0.9423\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4362 - accuracy: 0.9492 - val_loss: 0.4436 - val_accuracy: 0.9456\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4314 - accuracy: 0.9490 - val_loss: 0.4495 - val_accuracy: 0.9441\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4237 - accuracy: 0.9504 - val_loss: 0.4452 - val_accuracy: 0.9434\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4199 - accuracy: 0.9505 - val_loss: 0.4340 - val_accuracy: 0.9467\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4185 - accuracy: 0.9503 - val_loss: 0.4407 - val_accuracy: 0.9421\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4126 - accuracy: 0.9510 - val_loss: 0.4315 - val_accuracy: 0.9460\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4113 - accuracy: 0.9511 - val_loss: 0.4220 - val_accuracy: 0.9471\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4063 - accuracy: 0.9514 - val_loss: 0.4198 - val_accuracy: 0.9488\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4028 - accuracy: 0.9523 - val_loss: 0.4158 - val_accuracy: 0.9481\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3981 - accuracy: 0.9524 - val_loss: 0.4179 - val_accuracy: 0.9473\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3970 - accuracy: 0.9528 - val_loss: 0.4173 - val_accuracy: 0.9478\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3948 - accuracy: 0.9531 - val_loss: 0.4174 - val_accuracy: 0.9458\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3923 - accuracy: 0.9522 - val_loss: 0.3999 - val_accuracy: 0.9512\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3870 - accuracy: 0.9537 - val_loss: 0.4128 - val_accuracy: 0.9475\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3867 - accuracy: 0.9534 - val_loss: 0.3981 - val_accuracy: 0.9498\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3819 - accuracy: 0.9538 - val_loss: 0.4109 - val_accuracy: 0.9467\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3849 - accuracy: 0.9525 - val_loss: 0.4040 - val_accuracy: 0.9477\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3774 - accuracy: 0.9541 - val_loss: 0.3900 - val_accuracy: 0.9498\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3761 - accuracy: 0.9544 - val_loss: 0.3854 - val_accuracy: 0.9510\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3757 - accuracy: 0.9547 - val_loss: 0.3871 - val_accuracy: 0.9518\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3725 - accuracy: 0.9543 - val_loss: 0.4027 - val_accuracy: 0.9451\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3733 - accuracy: 0.9543 - val_loss: 0.3833 - val_accuracy: 0.9532\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3680 - accuracy: 0.9551 - val_loss: 0.3771 - val_accuracy: 0.9532\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3639 - accuracy: 0.9566 - val_loss: 0.3823 - val_accuracy: 0.9503\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3668 - accuracy: 0.9549 - val_loss: 0.3776 - val_accuracy: 0.9523\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3627 - accuracy: 0.9560 - val_loss: 0.3856 - val_accuracy: 0.9493\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3594 - accuracy: 0.9567 - val_loss: 0.3769 - val_accuracy: 0.9502\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3576 - accuracy: 0.9563 - val_loss: 0.3719 - val_accuracy: 0.9518\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3587 - accuracy: 0.9560 - val_loss: 0.3670 - val_accuracy: 0.9526\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3557 - accuracy: 0.9574 - val_loss: 0.3730 - val_accuracy: 0.9515\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.0313 - accuracy: 0.8487 - val_loss: 1.3166 - val_accuracy: 0.9003\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1230 - accuracy: 0.9039 - val_loss: 0.9668 - val_accuracy: 0.9171\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.8857 - accuracy: 0.9153 - val_loss: 0.8097 - val_accuracy: 0.9232\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.7605 - accuracy: 0.9209 - val_loss: 0.7116 - val_accuracy: 0.9273\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6841 - accuracy: 0.9249 - val_loss: 0.6601 - val_accuracy: 0.9285\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.6268 - accuracy: 0.9287 - val_loss: 0.6244 - val_accuracy: 0.9246\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5908 - accuracy: 0.9323 - val_loss: 0.5904 - val_accuracy: 0.9274\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5681 - accuracy: 0.9328 - val_loss: 0.5728 - val_accuracy: 0.9294\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5478 - accuracy: 0.9340 - val_loss: 0.5455 - val_accuracy: 0.9367\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5340 - accuracy: 0.9356 - val_loss: 0.5363 - val_accuracy: 0.9348\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5231 - accuracy: 0.9360 - val_loss: 0.5243 - val_accuracy: 0.9352\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5102 - accuracy: 0.9378 - val_loss: 0.5117 - val_accuracy: 0.9388\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.5009 - accuracy: 0.9385 - val_loss: 0.5073 - val_accuracy: 0.9377\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4911 - accuracy: 0.9401 - val_loss: 0.5064 - val_accuracy: 0.9341\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4854 - accuracy: 0.9399 - val_loss: 0.4889 - val_accuracy: 0.9388\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4778 - accuracy: 0.9408 - val_loss: 0.4847 - val_accuracy: 0.9390\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4716 - accuracy: 0.9410 - val_loss: 0.4883 - val_accuracy: 0.9370\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4693 - accuracy: 0.9406 - val_loss: 0.4728 - val_accuracy: 0.9417\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4653 - accuracy: 0.9413 - val_loss: 0.4775 - val_accuracy: 0.9365\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4557 - accuracy: 0.9428 - val_loss: 0.4703 - val_accuracy: 0.9397\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4518 - accuracy: 0.9440 - val_loss: 0.4673 - val_accuracy: 0.9403\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4512 - accuracy: 0.9424 - val_loss: 0.4577 - val_accuracy: 0.9413\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4451 - accuracy: 0.9435 - val_loss: 0.4536 - val_accuracy: 0.9411\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4391 - accuracy: 0.9450 - val_loss: 0.4565 - val_accuracy: 0.9394\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4340 - accuracy: 0.9455 - val_loss: 0.4434 - val_accuracy: 0.9439\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4322 - accuracy: 0.9444 - val_loss: 0.4500 - val_accuracy: 0.9402\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4307 - accuracy: 0.9446 - val_loss: 0.4405 - val_accuracy: 0.9430\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4254 - accuracy: 0.9465 - val_loss: 0.4396 - val_accuracy: 0.9443\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4222 - accuracy: 0.9468 - val_loss: 0.4409 - val_accuracy: 0.9413\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4219 - accuracy: 0.9465 - val_loss: 0.4343 - val_accuracy: 0.9443\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4144 - accuracy: 0.9482 - val_loss: 0.4370 - val_accuracy: 0.9417\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4105 - accuracy: 0.9486 - val_loss: 0.4353 - val_accuracy: 0.9434\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4112 - accuracy: 0.9475 - val_loss: 0.4186 - val_accuracy: 0.9467\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4079 - accuracy: 0.9483 - val_loss: 0.4259 - val_accuracy: 0.9430\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4036 - accuracy: 0.9492 - val_loss: 0.4171 - val_accuracy: 0.9452\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4024 - accuracy: 0.9493 - val_loss: 0.4141 - val_accuracy: 0.9442\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3987 - accuracy: 0.9500 - val_loss: 0.4363 - val_accuracy: 0.9404\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3961 - accuracy: 0.9507 - val_loss: 0.4128 - val_accuracy: 0.9463\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3939 - accuracy: 0.9501 - val_loss: 0.4070 - val_accuracy: 0.9462\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3922 - accuracy: 0.9499 - val_loss: 0.4056 - val_accuracy: 0.9468\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3906 - accuracy: 0.9512 - val_loss: 0.4209 - val_accuracy: 0.9418\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3878 - accuracy: 0.9521 - val_loss: 0.3996 - val_accuracy: 0.9474\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3834 - accuracy: 0.9524 - val_loss: 0.3966 - val_accuracy: 0.9482\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3826 - accuracy: 0.9520 - val_loss: 0.3970 - val_accuracy: 0.9474\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3821 - accuracy: 0.9513 - val_loss: 0.3900 - val_accuracy: 0.9506\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3764 - accuracy: 0.9541 - val_loss: 0.4028 - val_accuracy: 0.9447\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3787 - accuracy: 0.9535 - val_loss: 0.3894 - val_accuracy: 0.9488\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3777 - accuracy: 0.9515 - val_loss: 0.3913 - val_accuracy: 0.9476\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3774 - accuracy: 0.9518 - val_loss: 0.4164 - val_accuracy: 0.9398\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3727 - accuracy: 0.9535 - val_loss: 0.3839 - val_accuracy: 0.9483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OKlakrjVOyMm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "77e71b74-b4f5-4fc7-b56a-4afa694c2bce"
      },
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "multiple_line_chart(plt.gca(), \n",
        "                    None, \n",
        "                    multi_layer_kernel_reg_model_accuracy_lines, \n",
        "                    \"Validation accuracy variation per type of kernel regulizer\", \n",
        "                    \"Epochs\", \n",
        "                    \"Validation accuracy\")\n",
        "plt.show()\n",
        "plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAG5CAYAAADLbpPTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3hUVfrA8e+ZyaSHkBBISEgIvYUiVamiImB3BUXWwqpgw8KuqCu2n4tr7x0LiFhh7QKiCFKVXkJvgZCQ3uu08/vjTuIkJCG96Pt5nnlm5tb3lpl555xzz1Vaa4QQQgghRPNgauoAhBBCCCHEHyQ5E0IIIYRoRiQ5E0IIIYRoRiQ5E0IIIYRoRiQ5E0IIIYRoRiQ5E0IIIYRoRiQ5Ey2SUkorpbq6Xr+tlHqkOtPWYj1/V0qtqG2con4ppR5SSr1Xh/n3KKXOrceQ/tKUUj2UUjuUUrlKqbsrGL9aKXVLU8RWLo5afwfUcxzTlFLr3N7nKaU6N2VMonnyaOoAxF+TUmo5sElr/Wi54ZcD7wAdtNb26ixLa31bPcUUDRwDLCXr1lp/DHxcH8sXdae1/m91p1VKLQBOaq0fdpu/T0PE1dCUUnHALVrrn5s6lnLuB1ZprQc0dSAtkdbav6ljEM2TlJyJpvIhcJ1SSpUbfj3wcXUTM1E7SqkW98esJcZcU8rQkr6XOwJ7GnIFjblPWuD+L+Ov8Bn5q2ixJ6Fo8b4G2gCjSgYopYKAS4CFSqmhSqmNSqkspdQppdTrSinPihaklFqglJrr9n62a55EpdRN5aa9WCm1XSmVo5SKV0o97jZ6jes5y1XdcE4F1RDDlVKblVLZrufhbuNWK6X+o5Ra76rmWaGUCqkk5iCl1PdKqVSlVKbrdQe38cFKqfmubchUSn3tNu5yV1VSjlLqiFJqgmt4nFLqArfpHldKLXK9jnZV7dyslDoB/OIavlgpleTanjVKqT5u8/sopV5QSh13jV/nGvaDUuquctuzSyl1ZQXbuUwpNbPcsJ1Kqb+5Xr/iOg45SqmtSin38+FxpdQSpdQipVQOMM19m6qKXyk1A/g7cL/rWH5Xfh8ppbyUUi+79nGi67WXa9y5SqmTSql/KaVSXOfTPyo6lq7pVyulnlJKbXJtyzdKqWC38WcrpTa4zuedyq1q1TXvk0qp9UAB0Lncsj8CooDvXNty/5mOgetY362UOqqUSlNKPafckg6l1E1KqX2uc+tHpVTHKrbtMmVUB2e5Yu3lGv4LMBZ43RVX98qW4Zq+vSvG2bXZJ65tuk0pdcg1zxtK/fHnribbVC6uitbVUyn1k1IqQyl1QCl1tdv0bZRS37mO82al1Fzl+o5Qf3zOPMotv8KqXde0XZVS4a59WPIoUEppt+kq3TbXMu5USh0CDlVnm0ULoLWWhzya5AG8C7zn9v5WYIfr9SDgbIyq92hgH3Cv27Qa6Op6vQCY63o9AUgGYgA/4JNy054L9MX4Y9LPNe0VrnHRrmk93NYzDVjneh0MZGKU7nkA17ret3GNXw0cAboDPq73T1ey7W2AqwBfIABYDHztNv4H4HMgCLAAY1zDhwLZwDjXNkQAPV3j4oAL3JbxOLCo3LYtdO0XH9fwm1zr9wJeLtn/rnFvuLYhAjADw13TXQ387jZdfyAd8KxgO28A1ru97w1kAV6u99e59oUH8C8gCfB2i98GXOHaVh/3bapG/AtwnRduw0r3EfAE8BvQDmgLbAD+43ae2F3TWICLMH64gyo5nquBBP447/7ntu8jXPvnItd2jHO9b+s27wmgj2s/WCpYfvljW+UxcB3rVRjnbBRwEKNaFOBy4DDQy7W+h4ENlWxXdyDfFbMFoxrzsNt6Vpcst4r9cgvQyRXDjNruE9c2fQ+0dm1TKjChOtuE23dAJTG6rysQiAf+4Xp/FpAG9HZN/5nr4YtxPsfzx3dENKd/h5TuI9y+T6qKC6Mpxac12LafXMfapzG/w+XRcI8mD0Aef90HMBLjh7rkx3g9MKuSae8FvnJ7X1ly9gFuCZHrx6WqL+aXgZdcryv6Yi39MsVIyjaVm38jMM31ejXwsNu4O4Dl1dwXA4BM1+v2gJMKEgGM9ngvVbKMOM6cnHWuIobWrmkCMX4wC4H+FUznjZGUdnO9fx54s5JlBmD8uHd0vX8S+KCKGDJL1umKf0258aXbVFX85c+LivYRRiJ9kdu48UCc6/W5ru13PxdSgLMrWffqcuddb8CKkdQ+AHxUbvofgRvd5n3iDOdH+WNb5TFw7YcJ5c7Fla7Xy4Cb3caZMBLPjhWs9xHgi3LTJgDnusV+puTsRVf817oNr/E+cW3TSLf3XwAPVmebOHNy9oTb+2uAtRV87h5zHU8b0MNt3FzqMTlz7Zut/PEHqjrbdl5V5488Wt5DqjVFk9Far8P4R3qFUqoLRqnQJwBKqe7KqOpLclVp/ReosIqwnHCMf7IljruPVEoNU0qtUkZ1YjZwWzWXW7Ls4+WGHccoBSiR5Pa6AKiwwa9Sylcp9Y4yqgxzMKpUWyulzEAkkKG1zqxg1kiMpKK2SveNUsqslHpaGVWjORg/oGDsjxCMBOC0dWmtizBK9a5zVZVdC3xU0cq01rkYpYBTXIOuxe0CC6XUfa7qmmylVBZGYuh+PNyPZRlniL86yh/P465hJdJ12baPlR7PCmI9jlHaE4LRLmuyqyouy7WdIzGS8IrmPaNqHoPy8ZRsW0fgFbdYMgBF2fO4RJl9pLV2upZb0bSV+TtGQrfEbVht90lln6+abFNF3NfVERhWLra/A2EYJawe5aav0bGrilJqInAPRml+oVs8Z9q2eotBNA+SnImmthCj6us64EetdbJr+FvAfoySgVbAQxhfSGdyCiOBKRFVbvwnwLdApNY6EHjbbbn6DMtOxPiidBeF8cNTU/8CegDDXNs32jVcYXzRBiulWlcwXzzQpZJl5mNUtZQIq2Aa922cilFlcgFGUhTtFkMaUFTFuj7E+ME6HyjQWm+sZDqAT4FrlVLnYCR8qwCU0b7sfowquiCtdWuMKlv341zVMakq/jPNC6cfzyjXsNoqf97ZMPZjPEYpUWu3h5/W+mm36c8Ua0Xjz3QMysdTsm3xwK3l4vHRWm+oYB1l9pGrjVckNTvnH8fYD5+4/nyUxFDXfeKuJttUEfd1xQO/lluWv9b6doyqVDvQwW169/2c73o+0+fwNEqpHhjH9Gqtdfnk70zbVpN9JVoASc5EU1uI8eM6HeOLqUQAkAPkKaV6ArdXc3lfYDQc762U8sWoinAXgFEqVaSUGorxA18iFaM6sbJ+h5YC3ZVSU5VSHkqpazCqr76vZmzl4yjEuPgg2D1OrfUpjKqMN5Vx4YBFKVWSvL0P/EMpdb5SyqSUinDtH4AdwBTX9IOBSdWIoRijrY8vRulkSQxOjCriF12Nlc3KuEDCyzV+I8a+eoFKSs3cLMX4gX8C+Ny17JL12zH2u4dS6lGg1RmWVa34XZKp/FiCkTQ+rJRqq4wLNx4FFlUx/Zlc53bePQEs0Vo7XMu8VCk13rUfvZVxwUGHqhdXxmnbUo1jMNt1/kRilMZ87hr+NvBv9cfFE4FKqcmVrPcL4GLX+WbB+FNRjNE+r7pswGSMtngLXSV99bFP3NVkm87ke4zP+fWuz5JFKTVEKdXLdTy/BB53lX73xPhzCYDWOhUjcb3OtV03UfkfnFJKqVbAN8AcV41CQ22baCEkORNNSmsdh/FF74dRolXiPozEKRfjwoHPT5u54uUtw2hH9gtGI9pfyk1yB/CEUioX48f4C7d5CzDaRK13VSGcXW7Z6RhXk/4LIyG4H7hEa51WndjKeRmjgXsaRqP05eXGX4/xo7Yfo63Tva4YNmE0VH4Jo5TpV/4o2XgE44cgE/g/XFXEVViIUWWVAOx1xeHuPmA3sBmjKuUZyn5nLMS4uKLKhEZrXYzxg3ZBuZh+xNjug644iqhZ9cyZ4n8f6O06ll+XnxmjrdAWYBfGdm5zDautjzDauSVhlBDeDeAqBbkco/Q3FWMbZ1Oz79+nMBLJLKXUfW7DqzoG32C0XdqBUbX8viuerzCO5Weu6uBYYGJFK9VaH8Ao1X4N41y9FLhUa22tQey4pv8bEIqR9CdQ933ivvxqb1M1lpULXIhRFZ+IcTyfwbjoBGAmRkltEsYx/xQjYS0xHWNb0jEuMqhOIjsQoyT9JeV21WZ9b5toOZTWUhoqhKg5pdQNGFffjWzqWJqaUmo1xoUKtb57QS3XW+ExUEY3DN201ocbM56/IqXUM0CY1vrGpo5F/HlIyZkQosZcVXd3APOaOpa/KjkGTUMZfaD1U4ahwM3AV00dl/hzkeRMCFEjSqnxGFVRyZy56lQ0ADkGTSoAo5o+H6O5xQsYVchC1Bup1hRCCCGEaEak5EwIIYQQohn509wkNSQkREdHRzd1GEIIIYQQZ7R169Y0rXXbisb9aZKz6OhotmzZ0tRhCCGEEEKckVKq/B1nSkm1phBCCCFEMyLJmRBCCCFEMyLJmRBCCCFEMyLJmRBCCCFEMyLJmRBCCCFEMyLJmRBCCCFEMyLJmRBCCCFEMyLJmRBCCCFEMyLJmRBCCCFEMyLJmRBCCCFEMyLJmRBCCCFEMyLJmRBCCCFEMyLJmRBCCCFEMyLJmRBCCCFEM+LRkAtXSk0AXgHMwHta66fLje8IfAC0BTKA67TWJ13jngUuxkggfwLu0VrrhoxXCCFE8+F0agpsDvKK7OQV27CYTfh7eeDv7YGXh7mpwwPA7nBSYHNQaHVQYHWggPDWPnh61E/Zh9XuxOHUeFtMKKXqZZl1obVGa3BojcOpcbqeASxmEx4mhdmkmkWsLVmDJWdKKTPwBjAOOAlsVkp9q7Xe6zbZ88BCrfWHSqnzgKeA65VSw4ERQD/XdOuAMcDqhopXCCH+arTWHErJY0d8FnlFdgptDgqsdgqsDgqKHa6kw/XeaiQgXhYTfp5GghTgSpRKEqY/3lvwMCuKbU6K7Y7S56KS93YnRTbjudDqIN9qJ7fITl6x3ZWIuZ6tdir7S+5pNuHnZS5dn3ssXh4mHCVJhFPj0BqnsySZoDShcNbg/757rIVu+8PqcJ42rVLQvpU3kcG+RAb7EuV6RAb7EBnsS1t/r9LkJafIRmJWIQmZhSS4nk9mFZYOS80rRmtjmb4WMz6eHvh6mvH1NONT8mwxhnl6mLA7nNicGpvdid2psTmcrofG7nBidT2X7hOtcTop3R8l+6aifVUy7EyUAovJhMWs8DCbsJiN1xazCQ+zwlTNxM3Lw0SwnyetfT0J9rUYz36eBPl5EuRrIcj1PsDbA4dTY3OU3d7yr+0Ojd3pdG2LsW0l+6B0+51G4hng5cHEvu2rfX7Ut4YsORsKHNZaHwVQSn0GXA64J2e9gX+6Xq8Cvna91oA34AkowAIkN2CsQgjxl5CeV8y6w2msPZTG2kOpJOcUlxlvNqnSH39fTw98LMbrAG8P2gV4YXM4ySu2E59RYCRRxUZi5ajOr7aLSYG3xYyXhwlvi7k0ufP38qB9oLfx3suCv1vy5edlxuHUpetzT+Ryi2zkFtlJziniSLGdYpsTs0lhMoFZKUwmZTyXvHYNV0pR3QIeT7OJEH9Pojx93ZKjsomSn6cHNoeTk5mFxGcUcCKjoMJ97G0xEdbKm/R8K7lF9tPWE97am4ggH87t0Zbw1j54eZgptNrJL00K/0iYC6x20vOsFNocWO1OPFxJkKcrEbK4kiMfixkPb4/SRMmkjBKukv1jUsaxN6k/xhnP/LHfyuxLXPvSeA+UJoPuSaCtXLJodTiNX/hqKLQ5yCywEp9RQEa+lZxy+6ohdW3n/6dNziKAeLf3J4Fh5abZCfwNo+rzSiBAKdVGa71RKbUKOIWRnL2utd5XfgVKqRnADICoqKj63wIhhGjhiu0Oth7PLE3GYhNyAGjta2FE1xBGdwthaKc2BPla8PE042muefWZ1ppiu7NM0mR1OPG2mMokYSXPHn+xaq8im6NMwhafUcCpnCLa+HkS0dqHiCCf0ucQPy9Mpr/OvqkJu8NJVqGNzHwrmQU2MvKtZBUYCa7ZpLB4mPA0KzxMptNeW0xGKZ7Z5J6UUi4RVa6k3Si1a0oN2uasGu4DXldKTQPWAAmAQynVFegFdHBN95NSapTWeq37zFrrecA8gMGDB0t7NCHEX57WmiOpeaw5aCRjvx3NoNDmwMOkGNgxiPsu7M6obm2JiQjEXE9JgFIKb4sZb4uZtgFe9bLMPxNvi5mu7fzp2s6/qUNp0TzMJkL8vQjx//OfYw2ZnCUAkW7vO7iGldJaJ2KUnKGU8geu0lpnKaWmA79prfNc45YB5wBlkjMhhBCQkW9l/WEjGVt7KI1T2UUAdArx4+rBHRjVrS1nd2mDv1dT/x8XQlRHQ35SNwPdlFKdMJKyKcBU9wmUUiFAhtbaCfwb48pNgBPAdKXUUxjVmmOAlxswViGEaDGsdifbTmSWJmO7E7LRGlp5ezCyWwh3d2vLyK4hRAb7NnWoQohaaLDkTGttV0rNBH7E6ErjA631HqXUE8AWrfW3wLnAU0opjVGteadr9iXAecBujKaDy7XW3zVUrEII0ZxY7U5S84pJzikiJaeY1NwiUnKLSckpJjG7kK3HMymwOjCbFAOjWjPrgu6M6hZCvw6t662qUgjRdNSfpeuwwYMH6y1btjR1GEIIUSoxq5BDKXmnXV1X0g1DaRcVNuMKxJScYlJyi8gssJ22LJOCEH8vQlt5MyCyNaO6hXB2lza08rY0wZYJIepKKbVVaz24onHSAEEI0awU2x1kF9rIKbSR7fbIKbSXee9wau44twvdQgOaOuTTxCZkM2/NUX7YfarSLia8PEx/dFfhaXQnEdXGlyGdgmgX4E27AC/atfIyXrfyoo2fl5SKCfEXIcmZEKLJFNsd7E3MYfuJLLbHZ7H9RCYnMwurnMfX00ygj4W8IjurD6Tw0c3DiIkIbKSIK6e1Zt3hNN759SjrDqfh7+XBzSM7Ma53KH6ndRzqIYmWEKJSkpwJIWrF6LIh3+i53NOMr8UoAarstjVaaxKyCo1E7EQW2+Mz2ZOQU9rDenigN2dFBXHN4Eha+3kS6GOhlbcHgT6W0keAt6V0+XFp+fz9vd+5dt5vLLhpCIM6BjfatruzOZws3X2Kd349yt5TObQL8OLBiT2ZOixKqhyFELUibc6EEDWitWbVgRReWXmYnfFZp433MKnS28r4ukqMfCxmjmcUkJpr9JTu5WGiX4dAzooK4qzI1pwVFURYoHeNY0nMKuTv7/1OUnYR7904mBFdQ+q8fdWVX2zn883xvL/uGAlZhXRt58+MUZ25/KzwZnPfRyFE81VVmzNJzoQQ1aK15qe9ybz6yyFiE3LoEOTDLSM7EeTn6brn4Om3lXFv+B7ayouBHYM4KzKInu0DsJjrpwfulNwirn9vE8fS83lz6kAu6B1aL8utTEa+lfnrj7Fw43GyC20MiQ7i1tFdOK9nO+nZXQhRbZKcCSFqzenU/LgniVd/Ocy+Uzl0bOPLnWO7cuVZEfWWYNVVZr6VG+dvYm9iDi9dM4BL+4fX+zrS8op5d+1RPtp4nEKbgwt7hzJjdBcGdQyq93UJIf785GpNIUSNOZyapbtP8dovhziYnEfnED9evLo/l/UPx6OZJGUlgvw8+fiWYdy8YAv3fLadQpuDqwdHnnnGakjJKeKdNUf5+PfjWO1OLu0fzsyxXZvlVaJCiD8HSc6EqAe5RTb8vTz+FDdztjucfL/LSMqOpObTtZ0/r0wZwCX9wpv1FYYB3hY+vGkoty7ayv1LdlFQbGfaiE61Xt6p7ELe+fUon2w6gcOpuXyAkZR1biv3RxRCNCxJzoSoJYeruu/dtUfZfiKLIF8LPcIC6BEaQI+wVsbrsIAWdz/DR76J5dNN8fQMC+CNqQOZGBNWaVsqh9OB2dR8Gr/7eJp594ZB3P3pdh7/bi/5Vgd3ju1ao2UkZBXy1urDfLH5JE6tuWpgB+4Y24WObfwaKGohhCirZf1qiGbt14OpbD+RyZQhUbW68q6lyCu2s3hLPB+sP0Z8RiFRwb7cfV5XUnKL2Z+Uy+KtJymwOkqn7xDkQ8+wALqHGsnaqG5tCfbzbMItqNzuk9l8tjmeacOjefSS3pUmZXannTd3vMlHez/inXHvMDB0YCNHWjkvDzNvTB3IfYt38tyPB8gvtjN7fA+UUmitKbY7yS2yk1dsJ6/kudhOXrGNTccyWLL1JACTB0dy+5gucn9KIUSjkwsCRJ2l5BTxxPd7+X7XKQB8LGamj+7MraM749fCSo2qciq7kAUb4vjk9xPkFtkZ1DGI6aM6Ma53WJnqPqfT6M9rf1IuB5Jy2J+Uy8HkXI6m5mN3aixmxQW9Qrl6cCSjuoXUqf3W8fR8DibncX49XCmoteaad37jSGoeq2efS0AlfXQl5SfxwJoH2JayDQ+TB+e0P4c3L3izTutuCE6nZs7XsXy66QRhrbwpsjvIK7Jjr6THfgBPs4kpQyO5bUwXwlv7NGK0fy5O7USh/hTV/H9laYVpmJWZIO+/zkUvTu3k68Nfk5iXyMyzZjbouuSCANEgnE7Nx5tO8Oyy/RQ7nPxzXHcu6hvGSz8f4tWVh/hs0wn+dWF3Jg2KbNZtlc5kT2I27609xnc7E3FqzYSYMG4Z1ZmBURV/YZlMishgXyKDfRnn1q1Dsd3BgaRcvt2RyFfbE1gWm0RoKy+uGtiByYMj6RRy5mozm8PJlrhMftmfzC/7UziSmg/Awxf34pZRneu0nctjk9gUl8GTV8ZUmpitObmGOevmUOwo5qlRT3Ey9yRv7HiDI1lH6NK6S53WX99MJsV/r4yhS1s/9ibm4O/tgb+XB/7eHgS4nv29LPh7eRDgGhcS4NXo1dBaa34+8TPrE9ZzXtR5jAgf0ayqiquSb8snLieOuOw44nLiOJZ9jLjsOI7nHCfIO4h7B97LxE4TJUlrYCkFKby+/XUOZB7g9fNep61v2zov81TeKab8MAWAeePm0SO4R52X2dztSt3FU78/RWx6LINCB2F32vEwNU2aJCVnolb2Jubw0Fe72RGfxfAubZh7RUyZhtJbj2cy94e9bD+RRc+wAOZc3ItR3er+hVERm8PJqv0pbI7LIMDbQpCfJ0G+FoJ9PWnt60mwnyetfS14Wyr+wSuyOdzu3/jHvRuzCmz8tDeZjUfT8fU0c82QSG4a0aleqrmsdie/7E9h8ZZ4Vh1IwalhaHQwkwd34KK+7cuUOGbkW1l9IIWV+1NYczCV3CI7nmYTwzoHc17Pdvx6MJWNR9JZes8outSysXqx3cEFL/6Kn6cH39818rTSPJvTxqvbXmXBngX0COrB82OeJzowmsyiTC5cciEXdb6I/xv+f3XaJ39F8TnxPLnpSdYnrMdismBz2mjv156rul3F37r9rVY/slprjuUcY+3JtUT4R3BBxwvqLd7lccvZkrSFuGwjEUspTCkdZ1Imwv3C6RTYiY6tOrI1eSv7MvZxVruzeGDoA/Rp06fe4mgMhfZCdqXuYlvyNnam7aR3cG+m95uOj0fzKVEtsBWwYM8CFuxZgN1px6zMdG7dmfnj5+Nrqf33VIGtgBuW3UBCXgK+Fl8K7YW8dcFb9G/bvx6jbz7SCtN4ZdsrfH34a9r6tOWfg//JxZ0ubvA/FdLPmag3BVY7L/98iPfXHaO1j4WHL+nFFQMiKjyJtdb8sPsUzyzfT3xGIWO6t2XOxb3oXk9dEBxOyeWLLSf5cttJ0vKseJpNpbcCqoivp5kgXyNRK7Y7S5Mwq73yecJaeTNtRDTXDo0i0KdhbsWTnFPEl9sSWLwlnqNp+fh5mrmkXzgdgnxYdSCF7fFZaA1tA7w4r0c7zuvVjpFdQ0oTuJScIsa9tIYubf1YfNvwWpVSvv3rEZ5etp9FNw9jZLeyvewn5CVw/6/3syttF9f0uIbZQ2bjZfYqHf+fjf/hq8NfsWLSCkJ8Gq+H/vqWWZRJQl4CMSExDb4uq8PK+7Hv896u97CYLcwcMJNJ3Sex5uQaFh9czG+nfsNDeTA2aiyTuk/i7PZnY1KVV39bHVa2JG9hzck1rDm5hvjceADMysyCCQsY0G5AnWNeenQpD6x9gADPADoFdiK6VXTpc3SraKJaReFp/qMtpcPp4OvDX/Pq9lfJLMrkym5XctdZdzXbcyTHmsOOlB1sSd7CtuRt7Enfg91pR6GIDozmWPYxIvwjmDNsDqM6jGrSWB1OB98c+YbXt79OamEq46PHc8/AeziSdYR7Vt3D2MixvHjui1WeM5VxaiezVs1i9cnVvHH+G3QK7MSMFTNILUzl1fNe5ez2ZzfAFjUNm9PGZ/s/480db1LkKOL63tdza79b8bM0zsU/kpyJerFyXzKPfrOHhKxCpgyJ5MGJPWnte+aG7cV2Bws3HOe1Xw6RV2znmiFR/HNcd9oGeJ1x3lxrLgqFv6dRIpRbZOP7Xaf4Yks8209k4WFSnN+rHVcPjmRM97Y4NWQVWsnMt5FZYCUz30pGgZWsAhsZ+VYyXa+9LSbXvRsttHK7d2OgT9n3rX0sjdbru9aarccz+WJLPN/vOkWB1UH/DoGc1zOU83q2o094q0pj+Wr7SWZ9vpM5F/Vi+uiaVW+m5hYz9vnVnN05mPduHFJm3MoTK3lk/SNorXl8+OOMjx5/2vxx2XFc9vVlTO83nbvOuqtG624Ocqw5fLjnQxbtXUSBvYC5I+ZyedfLG2x9GxM38uTvT3I85zgToicwe8hs2vm2KzPN8Zzj/O/g//jq8FdkFWcRGRDJpO6TuKLrFQR7G/cQTStMY+3Jtfx68lc2Jm6kwF6Al9mLoWFDGd1hNANDB3L3L3ejtWbxZYtp5dmq1jGfyDnB5O8m0yO4Bx+M/6BGVT251lze2fkOH+/7GG8Pb27rfxtTe07FYm7Y+47anXaKHcUUO4qxOqwU2Yv+eO0owuqwkl2czc7UnWxN3srBzINoNB4mD2LaxDAodBADQwcyoN0AWnm2YkvSFp747QmOZR9jfPR4HhjyQL1UH9bUhsQNvLDlBQ5mHqR/2/7cN/i+Msn3or2LeF9glo8AACAASURBVGbzM0zrM41/Df5XjZf/6rZXeXf3u9w/5H6u7309YJxr01dM53jOcZ4f8zznRZ1Xb9tTmezibGxOW4Ml87+f+p2nNz3N4azDjAgfwQNDH6BTYO273qkNSc5EnSRlF/F/3+1hWWwS3dr58+SVfRnaqeY3mc7Mt/LqL4f4aONxPD1M9AlvRURrHyKCfIho7et6Nh4+nmaOZB1hxooZWJ1Wru50N8fiurEsNolCm4Nu7fy5ZkgkV5wVQYj/mZO8ElprjmQdob1/+0b7d1QbBVY7RTZnta/q1FozfeFW1h5KrbR68/uj35NemE6oXyhhvmGE+oYS4hvCo1/vZ/GWeFbMGl1aNW11WHlx64t8vO9j+rTpw3NjniMyoPJOXe/+5W62p2xnxaQVzarapyr5tnwW7V3Eh3s/JNeay4UdLySrOIutyVt56dyXGBs1tl7Xl1KQwvObn2dZ3DKiAqKYM2wOwyOGVzmP1WHlp+M/sfjgYrYmb8VisjC6w2iS8pPYk74HgFDfUEZ3GM2YDmMY2n5omf2/M3UnNy67kfOjzuf5Mc/XqprG6rBy3dLrSMhLYMmlS2jv377GywA4ln2M5zY/x9qEtXRs1ZH7h9zP6A6ja7Usd1lFWezL2Mfe9L3sy9jHvvR9JOQl4NCOM88M+Hj40L9tfwaGDmRw6GBiQmIqPYetDivzY+czb9c8PM2e3DPwHiZ3n9wobQQPZx7m+a3Psz5hPRH+EcwaNIsLO1542jHVWvPf3//LZwc+49FzHmVy98nVXsf3R7/n32v/zVXdruKxcx4rs+zs4mxu//l29qbv5T8j/sOlXS6tt20rYXPYWJuwlm8Of8OahDXYnXZ6BPVgZMRIRkaMpH+7/lhMdUvqT+Wd4vktz7Pi+Aoi/CO4f8j9jI0c2yTtIiU5E7WSkFXIO78e4fPNRhXJ3ed3Y/qoznh61K13+GNp+cxbc5QjqXkkZBaSlFOEo9wVdEGtk3GGzsNs8sBpC8RhOQF5fbkw7A6uHxpD/w6BNf4wHc06yrObn2V94noCvQK5vtf1TO01lQDP5tPTu9aapPwkDmUdoo13G/qEVL+dTlXVm+sS1nH7z7efNo9C4bD508a7HQMjogn1DaWdbztWHF/B3vS9XNfrOv456J9nLOXYmryVacun8fCwh7mm5zXV3+AmUGgv5LP9n/FB7AdkFWdxbuS5zBwwkx7BPSiwFXDLils4kHGAt8e9zZCwIWde4BnYnXY+P/A5r21/DZvDxi19b+GmvjeVqRqujiNZR1hycAnLji2jQ0AHxnQYw+gOo+ke1L3Kz8L7u9/n5W0v89g5jzGp+6Qax//MpmdYtG8Rr459tV4S1jUn1/Dc5ueIy4ljZMRI/jXoX0QERGBWZkzKhFmZK92e9ML0MknY3vS9JOYnlo6P8I+gd5vedGzVEW+zN15mL7w8vPAye+Fp9sTb7I2n2dMYbvbC1+JLp8BONf7BP5Fzgv/89h9+O/UbfUP68ug5j9IzuGed9ktl0grTeGPHG3x56Ev8LH7c2u9Wru15bZkq5PLsTjt3/XIXGxM38uYFbzI8vOo/AWA0hv/H8n/Qr20/5o2bV+FnPt+Wz92/3M2mpE3MGTaHKT2n1GnbwPjO25exj2+PfMvSo0vJLM6kjXcbLu58MUHeQaxLWMeOlB04tAN/iz/nhJ/DiPARjIwYSahf1ffRtTvtpBakkpifyKn8UxzMOMin+z8F4Oa+NzOtzzS8PZqu2ydJzkSNHEvL563Vh/lyWwIAfxsYwcyx3Yhq0zD9PdkdTlJyi0nIKiQhs5DNSVtYmvIkJu1LQNZM2vu1p33U76xOWYSfxY85w+YwPnp8tZOzHGsOb+14i8/2f4aPhw839rmR2LRYVp9cTYAlgL/3/jvX9bqOQK/ABtm+ymQXZ3Mo8xCHsg4Zz5mHOJx1mDxbHgDeZm8+u+SzGl0F+fX2BO79fEeZ6s0caw5XfnMlAZYA3hv/HplFmSQXJJOUn8Rb67aRWpDMkK5mMopTSc5PJteWSyvPVswdMbfaP8Zaa/6+9O9kF2fz7RXfNsurDYsdxSw5uIR3d71LelE6I8JHcOeAO+nbtm+Z6bKKsrhx+Y0kFyTzwfgP6N2md63XGZsWyxMbn2Bfxj5GhI/goWEPEdUqqq6bUiNO7eS2n25je8p2Pr34U7oGVb9T3tXxq7nrl7v4e6+/8+DQB+stJpvDxif7P+HtnW+Xnu/uFAqTMpUmayZlQilFvi2/dJqOrTrSK7gXvdv0plebXvQK7tWon2GtNUuPLeXZzc+SXZzN9b2v5/b+t9epIb67Pel7+GTfJyw/thyndjKl5xRu7Xcrrb1bV2v+PGseNyy/gVN5p/ho4kdVHvek/CSmfD8FHw8fPrn4kyq7zih2FHPf6vtYfXI19wy8h1v63lLjbQMj6fzh6A98ffhrDmcdxmKyMDZyLJd3vZzh4cPLVJ3nWnP5/dTvrEtYx9qEtaQUGBeidAvqZpSohfQnsziTxDwjCSt5TilIOa0EdVzHcdw3+D7C/ev//rs1JcmZqJb9STm8seoIP+xKxGI2MWVIJDPGdCGiEft7WntyLbNWzyLcP5x54+YR5hdWOu5I1hEeXvcwsemxjOs4jjnD5tDGp02ly3I4Hfzv0P94ffvrZBVncVX3q7jrrLtK2+zsTd/LvF3zWHliJX4WP6b2nMoNvW+o9pdfTRQ7itmesp3fEn9jf8Z+DmUeKnOlW4BnAN1ad6NbUDe6te5Gh4AOPLTuIdr4tOHTiz+tdilLRdWbc9bN4YejP/DxRR+XKYn7eW8ytyzcwuOX9i5zm6N8Wz5mZa7xP8rlccuZ/etsXh77MudHnV+jeRuSzWnj68Nf887Od0guSGZw6GDuOuuuKjvOTcpP4oZlN1DsKObDCR8SHRhd43W+u+td5u2aRxvvNtw/9P4Kq6AaS1phGld9exXB3sF8evGn1Tq2SflJTPpuEuF+4Sy6aFGVJTW1lV6YzrJjyyhyFOHUztKHQztKn7XWpe/b+7Wnd5ve9Azu2WxKvLOLs3l528ssObiE9n7tmTVoFiMjRtYqPpvTxs/Hf+bjfR+zM3UnPh4+XNblMm7ofUOtkvpTeaeYunQqniZPPr744wrbbxXYCpi2fBonck+waOKiaiXvNqeNh9c9zNJjS7kp5ibuHXjvGc9tu9POidwT7E3fy9KjS9mQuAGHdtAvpB+XdbmMCZ0mVCu51lpzKOsQ6xPWsy5hHdtStmF32gHjAph2vu1o79eecP/w0udwv3DC/MNo79e+WTW7kORMVGlHfBav/3KYn/cl4+dp5rpzOnLLyM7VarBfn36M+5EH1z5It9bdeHvc26VJlDu7086CPQt4c8eb+Fv8eejsh5gQPeG06bYkbeHpTU9zIPMAg0IH8eDQByutdjiQcYB5u+bx0/Gf8PbwZkrPKdzY+8YqE78zKWnbtiFxAxtObWBr0laKHEV4KA+6BnX9IxEL6kbX1l0J9Q097cttzck13LnyTq7teS0PDXuo2ut2r96cebGVe1bfzYx+M8o01rfanYx/eQ0mBcvvHY2lHm5kbnfaufjLiwnzC+PDiR/WeXm1lZyfTGxaLLHpscSmxbInfQ+51lz6t+3PzLNmMixsWLWSpLjsOG5cfiNeZi8WTlxY5o9CVY7nHOffa//N7rTdXNr5Uv497N/NIpFYn7Ce236+jau7X80j5zxS5bR2p52bf7yZ/Rn7+eLSL+jYqmMjRdlybU/ZzhMbn+Bw1mFMykSv4F4MCRvCkLAhDGw3sPSipoqkFaax+OBiFh9YTGphKlEBUVzb81ou73p5nc+dPWl7mLZ8Gt2DuvP++PfLJOZO7eS+X+9j5YmVvHbeazVqA+jUTp787Um+OPgFV3e/mjlnz8GkTGitSSlIKVMjcCjrEEezjmJ1WgGjneSlXS7l0i6X0jmwbv0z5tvyOZJ1hLY+bWnr27bJ+iWrDUnORIV+P5rO66sOs/ZQGoE+Fv4xIpppw6OrdQVmffvq0Fc8vvFxBrQdwOvnv37GL6TDmYd5eP3D7EnfU6YULTEvkRe3vsiPcT/S3q89/xr8r2qXWBzOPMy83fP4Me5HPE2eXN3jai7pfAn+Fn98LD74evji7eFd6eXpGUUZ/Jb4GxsSN7AxcWNpyVinwE4MDx/O8PDhDA4dXKNqj2c3P8tHez+qcXufr7cncO/iDYT2fo0Ordry2cWflWlD8v66Y/zn+73MnzaEsT3bVbGkmim5Uuzjiz6mX9t+NZ4/35bPtuRteJo98fEw9rmPxQcfD+PhbfY+rZFybFpsaTK2J20PqYWpAHgoD7oFdSMmJIaxkWMZGTGyxiVXe9P3ctOPNxHqG8qHEz6sslRVa82SQ0t4bvNzWEwWHj3n0Qqvbm1KL255kfl75vPiuS8yruO4Sqd7bftrzNs1j6dGPcUlnS9pxAhbNpvTxvbk7WxJ3sKmpE3sSt2FzWnDpEz0Du79R7IWOhA/ix+7U3fzyf5PWB63HLvTzoiIEUztOZWRESNr1Q1GZVaeWMmsVbMY13Ecz415rnTZr29/nXd2vcN9g+/jxj431ni5Wmte2vYS82PnMzh0ME7t5HDWYXKsOaXTtPNpd9of0h5BPZpl04fGJsmZKCMuLZ+5P+zj533JhPh7csuozlx3dscmu0H3R3s/4tnNzzIifAQvjX2p2sXO5UvRLoy+kK8Pf41CcVPfm5jWZ1qtirCPZR/jvd3v8cPRHyq84svb7G0kDhbf0qSh2FHMwcyDAAR6BXJ2+7MZHj6cc9qfU+ur2+CPK+US8xP536X/O2MD2BJaa85bOINUvYmXRs5nXNc/qvAy862MeW4VA6KC+PAfQ+q1qi3fls+4xeM4J/wcXjj3hRrNm2vN5aYfb2J/xv5Kp1Go0n1uVuYyVcPRraKJCYkpffQI6lEvjX03J23mtp9uo0dwD9698N0Kr/JNK0zj8Q2P8+vJXzm7/dnMHTG32seqMdkcNm5cfiNxOXEsuXRJhe1ufj/1O9NXTOfyrpfznxH/aYIo/zyK7EXsTN3J5qTNbE7azK60XaWdxYb5hZGQl4CfxY8rul7BlB5Talx9XhMf7vmQ57c8zy19b+Gegfew7Ngy7l9zP1d0vYInhj9Rp++BD2I/YNHeRUT4R5TWBpQ00WiIZiJ/FpKcCcC4Yffrvxzmg3XHsJgVM8/rxj9GRFfac35D01rz1s63eGvnW4zrOI6nRz1dq3Yt7qVoE6MnMmvQrDolRCVO5p5kb/peCu2Fpz0KbAVl3gMMDB3I8PDh9AruVa//CuOy47j6+6vpG9KXeePmVWvZK4+v5N7V96KyxtPFciVL3K7efOybWBb9foJl94yqtw6B3b249UU+3PMhP1z5Ax0COlRrniJ7Ebf9fBs7U3byxIgnCPMLM/azvYBCm+u53DGwOqx0DuxMTEgMvdv0btCqw1UnVjFr9SyGhA3hjfPfKHOero5fzWMbHiPPmsesQbOY2mtqvZZ61Lf43Hiu/u5qurbuyvwJ88tUA6UXpjPpu0kEeAbw2cWf1VvjdmEotBeWJmsHMg4wImIEl3W5rFG69dFa88RvT7Dk4BKm9ZnGp/s/pU+bPrx74bsN0p5QnFlVyRla6z/FY9CgQVpUzOFw6i82n9CD5/6kOz7wvf7XFzt0cnZhk8bkdDr1078/rWMWxOiH1z2sbQ5bnZZnc9j0ydyT9RRd8/PVoa90zIIYPW/nvDNOm1GYoUd/NlpP/nay/t+2ON3xge/126sPa621PpiUozv/+wc956tdDRZrUl6SHvDhAP3U709Va3qrw6pn/jxT913QVy89urTB4qqrbw5/o2MWxOhZq2Zpu8Ou8635+rH1j+mYBTF60reT9KGMQ00dYrUtPbpUxyyI0a9sfaV0mMPp0LeuuFUPXDhQ70/f34TRiYZidVj19B+n65gFMXr8kvE6vTC9qUP6SwO26EpympbTck7UyrYTmfzft3vYeTKbAZGtefeGwQyIbJpiZrvTTkJeAnHZcSw9tpSlx5ZyXa/rmD1kdp1LGjxMHkT4R9RTpM3P5V0uZ0PiBt7Y8QZDwoZUeTueJ39/khxrDu9e+C7dWkexfHcqL/x0kPN7hfLk0n34epqZdUH3Bos11C+UiZ0m8uWhL7m9/+1VXoHl1E4eW/8Yq0+u5uFhDzOx08QGi6uuLutyGVlFWTy35Tlmr5nNgYwDxOfGc1PMTdw54M4WVfowsdNEfjv1G+/tfo9h7YcxrP0wFuxZwPrE9Txy9iN/iZtc/xVZTBZeOPcF3tzxJpO7T67woivRPEi15p9Uck4Rzyzbz5fbE2gX4MWDE3tyxYCIRrkVUVZRFnE5xo2R3Z/jc+NLL3lWKG7rfxu397+9yboXaGlyrblM/m5ylbfjKenO4u6z7mZ6v+kApOQWceFLa/Dz9CAhq7BWt3iqqQMZB5j03STuHXgvN/e9ucJptNY8u/lZFu1bxJ0D7uS2/rc1aEz1peT2Nu392vPfkf9lcFjFtRLNXYGtgCk/TCHPmsej5zzKrFWzGBs1lhfGvCCfSSEagbQ5+wsptDr4YP0x3lh1GLtDM310J+44t2vpTbLrk9aa5IJk9qTtKe224EDGATKLM0un8TB5EBUQ9ccNkgOjS2+Y3Nidvv4ZlNyOZ1zHcTw7+tkyP6JphWlc+c2VdPDvwEcXfVSmLdE3OxK457MdRLfxZcWsMXW+y0N1TF8xnaNZR1l+1fIKexuft2ser21/jet6Xcf9Q+5vMQmB1pqNiRvp27Zvs+gioy4OZBxg6g9TsTqtRPhH8MWlX9TpHpxCiOqrKjmTas0/Aa01m+My+d/Wk/yw+xR5xXbG9wllzkW967VX//LdFsSmxZJWmAb80W3BeVHn0SmwU2kyFu4f3qL6nWnuSvrqemXbKwwPH86V3a4EjHNg7m9zKbAVMHfk3NP2+WX9w8nMtzI4OrhREjOAG/vcyO0/386yuGVc1uWyMuM+32/czuiSzpcwe8jsFpOYASilznhPzJaiR3APHhz2IC9tfYlnRz8riZkQzYSUnLVg8RkF/G/bSb7clsCJjAJ8Pc1MjGnPlKGRDImun7YEmUWZvL3zbdYmrCU+N750eKfATsS0iaFPSB9iQmLoGdyzxvcKFLXjcDq49adb2ZW2i88v+ZxOgZ1YenQpD6x9gH8O+if/iPlHU4cIGAnj3779GyZlYsmlS0oTsOXHlnP/GuOm1y+NfanONzIWdWd32uVPlBCNTKo1/0Tyiu0s3X2K/209ye/HMlAKzunchqsGdmBCTFi9VV/anXYWH1zM69tfJ9+Wz7mR59I3pG+jdFsgziylIIWrvr2KML8wXhn7CpO/m0x0YDQLJyxsVp07fnXoKx7d8CjvjHuH4eHDWZ+wnpm/zKRfSD/eGfdOk950WAghmpIkZ38CW49nsOi3EyyPTaLQ5iC6jS+TBnXgyoEd6v3el1uTt/LU709xIPMAw8KG8eDQB2t0s2TROH6N/5WZv8yklWcrih3FLL50MZ0CO515xkZkdVi5cMmF9AzuyW39b2PGTzOICohi/oT5kuALIf7SpM1ZC5ZdaOO/P+zj8y3xBHh7cMVZEUwaFMHAqKB6b6eTnJ/Mi1tfZOmxpYT5hfHCmBcY13Fci2oP9FcyJnIMU3tO5ZP9nzB78Oxml5gBeJo9mdprKq9tf42dqTtp69OWt8e9LYmZEEJUQUrOmrHlsad45Js9ZORbuWVUJ+49vzs+nvVfZWV1WPlo70e8s+sdHE4H/4j5Bzf3vblWtz4SjcvmtLEjZQeDQgc1217ps4qyuPB/FxJgCWDhRQv/1P3RCSFEdUnJWQuTklvEY9/sYVlsEr3bt2L+tCHERDRMtxPrEtbx9KanOZ5znHMjz+X+IfcTGRDZIOsS9c9isjAkbEhTh1Gl1t6tWThxIUFeQc3yfpNCCNHcSHLWjGitWbzlJHN/2EuR3cns8T2YMbozFnP9l4hkF2fzyPpHWBW/iuhW0bx1wVuMjBhZ7+sRAqBncM+mDkEIIVoMSc6aiRPpBfz7q12sP5zO0OhgnrqqL13a+jfIulILUpnx0wyO5xzn3oH3ckPvGyrsJFQIIYQQjU+SsyZmdziZvz6OF346gIfJxNwrYpg6NKrBbrMUnxvPjBUzSC9K580L3uTs9mc3yHqEEEIIUTuSnDWhzHwr0+ZvYufJbC7o1Y7/XBFD+8CGa4R/KPMQt/50K1anlfcvfJ++bfs22LqEEEIIUTuSnDWh51YcIDYxh1evPYtL+7Vv0C4rdqbu5I6f78Db7M2C8Quk3zIhhBCimWqe197/Bew7lcNnm05w/dkduax/eIMmZhsSNzB9xXQCvQJZeNFCScyEEEKIZkySsyagteaJ7/bSysfCvRd0a9B1rYhbwZ0r7yQyIJKFE6WPKSGEEKK5k+SsCfy4J5mNR9P557jutPb1bLD1fHnoS2avmU1MmxjmT5hPiE9Ig61LCCGEEPVD2pw1siKbgyeX7qV7qD9Th0Y12Hrmx87nxa0vMiJiBC+OeRFfi2+DrUsIIYQQ9UeSs0b2wfpjxGcUsujmYXg0QOeyWmte2fYK78e+z4ToCfx35H+lDzMhhBCiBZHkrBGl5BTxxi+HuaBXKCO71X8VY2ZRJnN/m8uK4yuY3H0yc4bNwWyq/3txCiGEEKLhSHLWiJ778QBWh5M5F/eq92WvOrGK/9v4f2Rbs7l34L3cFHNTg14BKoQQQoiGIclZI9l1Mosl204yY1RnOoX41dtyc6w5PLPpGb498i09g3vyzrh36BHco96WL4QQQojGJclZIyjpOqONnyczz6u/PsY2JGzgkQ2PkF6Yzq39buXWfrdK+zIhhBCihZPkrBF8t+sUW45n8vTf+hLgXffkKd+WzwtbXmDxwcV0DuzMK2NfISYkph4iFUIIIURTk+SsgRVaHTy9dB+927di8uDIOi9vc9JmHln/CIl5iUzrM42ZZ83Ey+xVD5EKIYQQojmQ5KyBzVtzlMTsIl66ZgBmU+0b6BfZi3hl2yss2reIyIBIFkxYwMDQgfUYqRBCCCGaA0nOGlBiViFv/XqYi/u2Z1jnNrVeTkZRBresuIVDmYeY0mMKswbNkk5lhRBCiD8pSc4a0DPL9+PU8ODEnrVeRnZxNjNWzOBEzgnePP9NRnUYVY8RCiGEEKK5kXtrNpCtxzP5ZkciM0Z1JjK4dqVcOdYcZvw0g6PZR3l17KuSmAkhhBB/AVJy1gCcTs0T3+0htJUXt5/bpVbLyLflc/vPt3Mw8yCvjH2F4RHD6zlKIYQQQjRHUnLWAL7ZmcDOk9k8MKEnfl41z38LbAXc8fMd7Enbw/Ojn2d0h9ENEKUQQgghmiMpOWsAy3YnERnswxUDImo8b6G9kLt+uYsdqTt4ZvQznN/x/AaIUAghhBDNlZScNYA9iTkMiAzCVMOuM4odxdy76l42J21m7oi5TIie0EARCiGEEKK5kuSsnmXkW0nIKiQmvFWN5rM5bPxz9T/ZkLiB/xv+f1za5dIGilAIIYQQzZkkZ/VsT2I2ADERgdWex+a0MXvNbNacXMPDwx7mym5XNlR4QgghhGjmJDmrZ7EJOQD0qWbJmd1p56G1D7HyxEoeGPIA1/S8piHDE0IIIUQzJ8lZPYtNzKZDkA+tfT3POK1TO3l0/aMsj1vOrEGzuK73dY0QoRBCCCGaM0nO6tmehGxiwqtXpbnyxEq+O/odd/S/g5tibmrgyIQQQgjREkhyVo9yimzEpRcQE1G9Ks0vDnxBmF8YM/rNaODIhBBCCNFSSHJWj/YmGu3NqnMxwImcE/x26jeu6nYVZpO5oUMTQgghRAshyVk9ik0wrtTsU41qzSWHlmBWZv7W7W8NHZYQQgghWhBJzurRnsQcwlp50zbAq8rpbA4b3xz+hjEdxtDOt10jRSeEEEKIlkCSs3oUm5BdrfZmK0+sJKMog8k9JjdCVEIIIYRoSSQ5qycFVjtHUvOqVaW5+OBiIvwjGB4+vBEiE0IIIURLIslZPdl3KhenPvPFAMeyj7EpaROTuk/CpGT3CyGEEKIsyQ7qyR+3baq6WnPJwSV4KA+u6HpFY4QlhBBCiBZGkrN6EpuQTRs/T8JaeVc6TbGjmG+OfMPYqLGE+IQ0YnRCCCGEaCkaNDlTSk1QSh1QSh1WSj1YwfiOSqmVSqldSqnVSqkObuOilFIrlFL7lFJ7lVLRDRlrXcUm5NAnIhClVKXT/HT8J7KLs5ncXS4EEEIIIUTFGiw5U0qZgTeAiUBv4FqlVO9ykz0PLNRa9wOeAJ5yG7cQeE5r3QsYCqQ0VKx1VWx3cDA5l5gz3Ox88YHFRAZEMqz9sEaKTAghhBAtTUOWnA0FDmutj2qtrcBnwOXlpukN/OJ6vapkvCuJ89Ba/wSgtc7TWhc0YKx1cjApD7tTV3kxwJGsI2xL2SYXAgghhBCiSg2ZJUQA8W7vT7qGudsJlHSRfyUQoJRqA3QHspRSXyqltiulnnOVxJWhlJqhlNqilNqSmpraAJtQPbElFwNU0Y3G4oOL8TDJhQBCCCGEqFpTF+HcB4xRSm0HxgAJgAPwAEa5xg8BOgPTys+stZ6ntR6stR7ctm3bRgu6vNiEbAK8PYgM9qlwfJG9iG+PfMu4qHEEewc3cnRCCCGEaEkaMjlLACLd3ndwDSultU7UWv9Na30WMMc1LAujlG2Hq0rUDnwNDGzAWOskNjGHmPDKLwb4Me5Hcq25ckcAIYQQQpxRQyZnm4FuSqlOSilPYArwrfsESqkQpUobYP0b+MBt3tZKqZLisPOAvQ0Ya63ZHE72ncqpsn+zxQcXE90qmsGhgxsxMiGEEEK0RA2WnLlKvGYCPwL7gC+01nuUUk8opS5zTXYucEApdRAIBZ50zevAqNJcqZTaDSjg3YaKtS6OpOZhtTsrvRjgYOZBdqbuZFL3nLdyzwAAIABJREFUSVV2syGEEEIIAUbbrgajtV4KLC037FG310uAJZXM+xPQryHjqw+xCTkAld5Tc/GBxXiaPLm8S/kLVYUQQgghTtfUFwS0eLEJ2fh6mukU4nfauAJbAd8f/Z5x0eNo7d26CaITQgghREsjyVkd7UnMpnf7VphNp1dZLo9bTp4tj6u7X90EkQkhhBCiJZLkrA6cTs2exJxK25stPrCYLoFdOKvdWY0cmRBCCCFaKknO6uBoWj4FVgd9Krht0770fcSmxzK5x2S5EEAIIYQQ1SbJWR3sKbkzQAUlZ4sPLsbL7MUlnS9p7LCEEEII0YJJclYHsQnZeHqY6NrOv8zwfFs+Pxz9gfHR4wn0qvyWTkIIIYRoZvJSIWl3k4bQoF1p/NnFJuTQKywAi7lsjrv02FIK7AVM7i53BBBCCCFajMw4+OhKcNjhrq3g4dkkYUjJWS1prYlNzKZPBVWaGxM3EuEfQf+2/ZsgMiGEENVSkNHUEYjmJGk3vH+hcV5Mer/JEjOQ5KzW4jMKyS2yE1NB57OHMg/RI6iHXAgghBDNka0IvrsHnu0EG9+sv+XGb4Zfn5OkryWKWwfzLwKTB9z0I0QObdJwJDmrpdjSiwHKXqlZ7CjmRO4JugV1a4qwhBBCVCXjGLw/DrYugLY94cd/w+4Kb1RTM/GbYeHlsGouvDoA1v8/e/cd3mT1BXD8e5ume5e2QEvLEpClIiCIuHCAslFRceFEcO8t+nPhFge4Bw6GIOIAHCgqMmQoUyjDQgu0lO6ZJrm/P27BIqWkbUYL5/M8edIkb973BNCc3nHORJMEioZv/RyYMhzCm8E130F8B19HJMlZXa3NyMffT9EuIfyA57fmbcWpnbSNbuujyIQQQlTr72/hrdMgLw0umQrXL4SUU+CLMbD5x7qfd9dq+GQEhMXB5bMhqSd8/zC81h3+mgZOp/s+Q305nbB3Czgdvo6kYVj+Hsy4EpodB1fPg8gkX0cESHJWZ2t3FnBMQjhBVssBz6fmpQLQLqqdL8ISQgjxXw47fP8ITL0EolvCDb9A+wFgDYJLPjUjaNMuh4wVtT/3nk1mAXlAGFwxB9qcAZd9Dld8CSEx8MX18NapsOUnt38sl9ltJvn86jZ4sQO82g3eOh12LPNdTL6mNfw8Ab6+Hdqe/e/fVwMhyVkdaK1Zl5FP52qKz6bmphLgF0ByRLIPIhNCCHGAwt3w0WBY9Ap0vxqu/s4kaPsERZpkKjQWPrkQsje7fu6cbebcys8kZtEp/77W+nS47mcY/g6U5sOUoWbqzFslGmzFsP5LmHkdPNcWPh4Oq6dBi5PgrMegONtM7345zvx8NHE64Nu74Oen4LhL4eJPICDE11EdQEpp1MHugjL2FtuqLT6bmptK66jW+PvJH60QQvjUtl/h86vBVgTD3oLjRlZ/XHhTuOwLeO8c+HgYXPO9ea4m+RlmjVlFKYz+FppUs5TFzw+6XggdB8Oyt+GX52ByXzjuEjjzQfdPoZXkwKZ5sOFr2PIj2MsgOBqOHQgdBppRPWuwObbHtfDLs7D4ddjwFfR7BE4cDX6Wmq/R2NnLYdZ1JnHtc6tJVBvg5j3JIOpgbUYBcPBmADDTmic1PcnbIQkhROPkdJiRJ3d+QTqdsOhlWPA/iGkDV86B+GNrfk+TtjBqBnwwCD6+AEZ/Y0bVqlO0xyRmJTlw5ZeQ0Knmc/sHwsk3wQmj4LeXYMlkWDMD4tpDTCsTY0xrc4ttA2FNTWJX7WdzQP4Os24sZ6sZvcup/HnvFtAOiEiEbleYhCylD1iq+aoPDIOzH4fjR5lRpG/uhJUfwfkvQlL3mj9PY1VWAFMvhX9+hXOeNH8nDZQkZ3WwNiMfpeDYZgcmZ/nl+WSVZMlmACFE4+B0wuJXYdk7EBxlvtQjmlfeEqvcN4OAUPde215ukqclkwBlkoXAcAiMqLz/7y3CJDmWAFPuwBJQebNW3gLAz2oSkSWTzAhS5xEw6BXzflcknggjp8CnF8HUUTDqc7MurarSXLPGLD8dLp9l3uOq4GiTEPW4Dv54G7L+NreN88BZ8e9x/sGVSVtlwuaoqEzEtkBuWjXHtjaJXseh0L4/NO/merIb195Mya6bBfMfhHf6mcSu33gz1esuTif8/TWseB/Cm0Pr06DVqYcfoawve7lZW7dtIaz7whSZrWkUtYGQ5KwO1u3Mp01cGCEBB/7xpeaazQDHREkZDSFEA1e4G764Abb+DC37gjXEJBw7lkJpNXW6giqTt64XQq+xJlGqq8x1MOt6yFwLXUea85YXVrkVQFGWGQna95y91PXz+1nhvOfN1F1tR+Ta9oOhk2HWtWb668IP/p3qKy80o2rZG81uz5STa3fufaJamCRtn32jYTlbK0fAKu+zUyH1O/N5YlpDfEc4dtC/SVtMG5Pc1HfUUSmTyB5zDiycYJLb9XPgrEeh25X1m+p0OswU4i/PQdZ6iEyGnavgz4/N63EdoNVpZo1eyz6HHq2szfV2r4atC01ClrbY/NtRfiZpvXS6+Ttu4CQ5q4O1GQX0an3wro59OzWlxpkQokHbOA++HAu2EjOy1O3KA7/gK0qhYGeVW4a5z9oAP4yHFR/CuU9C+/Nqlxg4nbB0EvzwGARFwCXTzEiPKxwVZhTEWWF+dtgq7ysqn6vyODLxwEX/tdX1QijOgvkPmCm/8180fyafXmwSi5FT3PsF72cx8Ua3hDZnHvia02n+jL2xLiowHM55onKq826zk/G3l01C2GGgKczqaqLmdMDaWSYpy94ITdrB8Leh03CTKO1ebZKnrT+b6dRlb/6bQLU+zSRscR1c+9ylubDtF3O+bb9CWZ55Pu5YOPFKcy53JH5eJMlZLe0pLGd3QVm1mwE2524mPCCchJAEH0QmhBCHUVFmSkosexOadoER70FcNWV/rMFm7VNsm4Nf27IA5t1v1u60PgP6P+Na0c78DJh9o/kCbX8eDJpo6oK5at/0pbf0HgdFmWaXZ0gs7PwT0hbBiHegw/nei+NQa888Kf5YuPIrWD8b/vwUlr0Fi1+D0HjocB50GGSmJKtrb+Swm/V0vz4PezebBOmC98yUa9XErvnx5tbnVpN0p/9hRru2/mwSwl9fqH3ckS1MEumtKVMPkuSsltbt7wxQzU7NvFSOiTpG2jYJIRqerL/NzsWsdWZa8qzxdZuabHMmjPnNFO/86UmYdDL0vA5Ov8+sqarOms/hmzvMF/egiWZNU2P4/+RZj5nF/788Zx4PfhW6XODbmLxFKeg0zNzKCmDz92ZX55rPTXeFwAgzDXrsQFMnzD8Q/ppqkqrcbZDQGS76yCRyh0sw/QOh5SnmduaD5nppv0NBumux+gdDci8z1dsY/l25QJKzWlq30+zU7PifGmdaazbnbua81uf5IiwhhKie1iaRmv+AKZR66Qxod079zmmxwkk3QOcLTIK27C1YPd18sVYtx1CaZ6YF18yAxO4w/K3qR+MaKqVg8ESzWaFpV+h2ua8j8o2gCLMmrfMIM/q6baFJ1DZ+C2s/B0ugScyLdptK+xd/Cu0G1H3ULyjC9enuI5QkZ7W0NiOflrEhRAQdOLy+u3g3hRWFshlAiMaoeC9smgvFe6D3zdWXHvC0ilJz/aI95r44q/I+2yyOL658viQHQptUWRReWX4hprXpDVh15KAkB+bcbHbJtTnTLHQPd+Oyi9BYGPiiKe467z5TjmH5+2aqE0xbpMJdcPoD0PdO3/y51pfFCuc95+soGg5rELQ719ycDti+xPz7ytkG3Ueb0bQjZPTKlxrhfym+tXZnPl2Tog56XjYDCOFFWpvEIzi67r+d56fD39+YEYC03019KDB9Eoe/7b1EoiQHvnvIrO1BH/x6QBiExplbdCtI7GYSuKwNsHFu9WUVYlqZxeVrZ5mE7pwnzVSmp9YvNe1s1ihtmAPzH4IPB5rnY9qYgq5JtSg3IRoPP4tZaN+yj68jOeJIclYL+SUV7Mgp5dKeKQe9tq+MRpuoRjRkL0RD53RC/nbYsxH2/F3lfhPYCsEaahajxx8L8Z0goaO5P9RC8z0bTTL299dm1x2YHWGn3G7Wzmz7xSyYR5u2O55M0LQ2C66/vdvsNjvpBrNOZ18iFhYHIU1qbivjsJt1OfsKkOZsqyzBsMmUYIhuCZd8ZhZee5pS0HGIGTlZ8oaZ0jz9PvfXRxPiKCDJWS38uxmg+s4ACSEJRAY2nq26QjQ4BTvhr8/+TcKyU6Gi5N/XwxJM0czjL4GoFFMbKnOdGUFa9fG/x4U0+TdRiz/WFJ78+2uTtIApHNrvUVMioEmV0e7mJ5jt/N89ZJKnEe94ZodgwU745i7Y+I255uVfmN2TtWXxr6EEgwcq77vCGmymMIUQdSbJWS2srUzOOjWvvqemTGkKUQ+Fu+H9ASaRikgyJR5O7GOSsbgOpk5SyMH1BfcryjKJWtZ6yFxv7ld+aJI7VTn90uM6UwYhMvHQ5zn5ZkDBdw+CdpoyAO5K0JxOE9P3j5h6XOc8ASfd6JkRuiO9R6IQRzBJzmphbUYBiVHBxIQeWNulwlnBtvxt9EmUeXch6qQ0F6YMN2uprv2xbr39wuLNrc0Z/z7ndELeP6a6fU2J3X+dfJMZcZr/gCk/4Y4Ebe8WmHMLpP1mKvIPnmjWhwkhxH9IclYLa3fm06n5wVOa2wu2U+GskJ2aQtSFrQQ+HWmmHEfNcG/TZT+/uidAvccBCubfD5+Phgver1uC5rCbAp4/P21KDgx+FU64XHa0CSEOSZIzF9kdTuLCAunRspq2TbmyU1OIOrHbYPoVpjr4Be8fOOrVEPQea5KoeffBjKtMjNVVRa+O0wHbF5vRt11/mfVt5z3fqKuWCyG8Q5IzF/lb/Jh2Q+9qX9uUuwmLstA6UqYohHCZ02na+Wz+3vR37DTU1xFVr9eNZmH93Hv+HUE7VIJWmgubfzQ7JVO/Nw3EQ+NNpfSOQ7wbtxCi0ZLkzA02520mJSKFAIuLv1ELcbTTGubda6qL93sUTrzK1xHV7KQbAAVz7zYjaBd+YBI0rc3O0tT5sGm+KcipHaYXY7tzTVmJY842DaWFEMJFkpy5QWpuKp2adPJ1GEJ4j9MBSybB8ndNCYfe42q3tuvnZ0zLn5NvNjXGGoOTrjdTnN/eZZp+x7QyCVlemnk9oYv5LO36m0KxsltSCFFHkpzVU0lFCelF6QxpK1MW4iiR9Td8OQ4ylkOz42HlR6Z347GDoc8tpoZYTZa+CQufgeMvg7P/17gWxve8ztx/e5epxt/6dDjlNjNCFpnky8iEOCRncTEVmVnYM3dTsTsTR04Oob17EdSxo69DqxdHUTH5c76kbM1a4u+5G//oaF+H5DaSnNXT5rzNgGwGEEcBRwUsegUWTjAthUa8axohF2XC0snwx3um4n3LvtDnVmh71sGJ1+rpZu1Wh4FmnVljSsz26XmdWdwfFGkKrgrRADhLSyn4di4Vu3btT8Lsu3dTkZmJs6Cg2vcEdelC9MUjiRgwAL+QGjpRNDDlqankfvYZ+bO/xFlSAkpRvnkzye+/jyXsyOhIobSuppdbI9S9e3e9fPlyr193VuosHv39Ub4d9i0tIlp4/fpCuGzjXPAPNMlTbUtC7FoNX46F3Wug0zAY8NzBLZLKCkyB1SWToCAD4jvCybeYBM4/wEwBTr0UknvDqM9NA2UhhFtk3H0PBV99BYAlrgnWhKb4N034975pU/wTzL1fSAgFc+eRO20qts1b8AsLI3LIEKJGXkRQu3YuXU9rTcWOHZQsX0HJ8uU4CwuIu+MOAlu18sjn0xUVFP7wA7mffkbJH3+gAgKIGDCA6Esvwb43h/Sbbyake3davPUmfoGB9bpWyapVVGzfTuQQz86IKaVWaK2rrR0kyVk9TVg2gZmpM1ly6RL8lIeaCgtRX3+8A99UttQJijTrojoMhLb9au59aC+HX56H316E4Bg4/wXoOLjma9ltsHYm/D7RVOkPbw7HjTRJW1wH0yA76OB6gUKIuinbuIltQ4cSc8UVxN95ByrAtc1pWmtKV64kd+o0CufNQ1dUENytG9EjLyK8f/8DkhztdFK+eTMly5dTunw5JctXYM/KAsASGYl2OsHhoNkT/yPivPPc9tkqMjPJmzad3BnTcezJxpqURPQlFxM5fPgB05j5c+aw8557CTvzTJJeeRllrVvR6IJvv2XnffdjTUqi9ewvXP6zrAtJzjzo2vnXUlxRzGcDP/P6tYVwydqZ8Pk1Zl3UiVfChq9h01xT9sE/2CzoP3aQ2V1YtYp++nKztmzP33DcJXDuU7Wrsq81bP7BTIX+8yvEHgNXz4PQJu7/jEIcxXaMHUfJH3/Q9vvvsERF1ekc9txc8r+YTd60adjS0rBERhI5dCj+8fGUrFhByYoVOPNNC0P/+HhCuncnpEd3Qrp3J6BNG+yZmWTcfgelf/5J1CUXk3DfffUawSpZuZKcDz6k8Mcfwekk7NRTib70EkJPOQVlqX6zTc4nn5D5vyeIGDyI5s88g/JzfcBEa83eyZPZ88pEgrufSNKrr3p8DVtNydlh15wppW4GPtZa57o9siNAal4qpyWd5uswRGPh7WbUm3+AWTdAci9T/iEgxPSWdNghbZFpBr7ha9OAW1mg5SkmUctLg8WvQ3gzuHQGtDun9tdWypSROOZs0+syvGntkjshxGGV/vknRQsWEHfbrXVOzAD8o6OJvXo0MaOvomTpUnKnTiPnk0/AbicgJYXws/oR0r0HId1PxJqUhPrP/8OszZqRMuUjsl56mZz33qPsr9UkvvwSAcnJtYqjbP16sl5+meJffsUSFUXs6KuIGjmSgBaHXzYUM2oUzoIC9rwyEUt4BAkPPXhQnNVx2mzsfvgR8r/8kojBg2j2xBP4eXDEzBWubAhIAP5QSq0E3gPm6yNluK2eskuzySnLkc0A4vDydsCSN8zORj+LWY8V3xESOv77c3Dd/8darR3LYNrlZirxkqkmMdvH4g+tTzO3Ac/CzpWw4SuTqH17lznmxKvg7MfNNGh9JTTuXWHi6FaRkYF2OLC2aOHSl/2hOMvLKVn2B0W//kLZ2nU0ffghgo49ts7n01qT9dLLWGJjibn88jqfpyqlFKG9ehHaqxf23Fyw2/GPizv8GwFltZJwz92EdO/OzvvvZ9vwETR78kkizj38L3flW7exZ+JECufNwxIZSfzddxF96aX4Bddu003smDE48gvI+eADLJERxN1yS43H23Nzybj5FkqWL6fJLTfT5MYb6/V37C6HTc601g8ppR4GzgFGA68ppaYD72qtt3g6wIZMdmqKw9q9BhZNNFOLSkGn4aYgadZ6WPM5LM//99iIxAMTtpSTIap2v3Xul7kePrkQwhLgspk1J35KmfIXiSfCWeNNUVWnHRKkdp8QFVlZbB06DGdhIZYmTQg54QSCTziBkG4nENSx42HXJNnS0ij65VeKfv2FkmV/oMvKUAEBKKuVjLvvptXMmXWe/itZvJiSpUtJeOAB/ELdv0uxrtN64WeeQauZM8m44w4ybr2VkssvJ+Huu6r9s6rYuZM9b7xB/hezUYGBNBl7IzGjR2MJr1vhZqUU8ffeg6OwgOw3JuEXEUHsVVdVe2z5tm3sGDMG+67dNH/+eSIHnl+na3qCS6U0tNZaKbUb2A3YgWjgc6XU91rrezwZYEO2v6emNDwXVWkN2xaatVZbFpiyE71uNLeqtbC0NrsaM9ebZC1rvfl520Jw2MDPH04aA6fdU7vRq9x/YMow8A+CK2ZDeELt4o9rX7vjhTiCZT0zAV1eTvw991D29wZKV66i8PvvAVCBgQR16VyZsHUj+ITj8QsKomTZMop+/Y2iX3+hIm07ANaUZKIuuICwvqcQ0rMnJctXsOO669jzykQS7rm71nHtGzXzb96MqItHuvUzu0NAUiItP55C1gsvkPPhR5T++SeJL71EQFIiAPa9e8l+803yPpsKQMxlo4i9/nr8Y2PrfW2lFM0efxxnYRFZz0zAEh5B1IjhBxxTvGwZGTffAn5+JH/wASHdTqj3dd3psBsClFK3AlcA2cA7wGytdYVSyg9I1Vq38XyYh+eLDQGPLHqEhekLWThyoVevKxooh93U+Vr0CuxebUatThoD3a+u3ZSlowL2bq6cBp1iWgH1ewROuOzwVecLM+G9c81i/9FzZTpRiHoo+m0RO669liY330TcuHH7n6/IyqJ01Z+UrlxJyapVlK1fD3a7edFqhYoKVFAQISf1JOyUvoSd2peAlJSDzr/r0fHkTZ9OypSPCOle7brwQyr4/nsybr6FZk8+eVDi0dAUfPcdux58CJSi6aOPUL55MzkffoQuLydq+DCa3Hgj1ubN3X5dp81G+o1jKV68mMSXXyLiHDO9mjd7NrsefoSAFi1o8eZkl9azeUK9dmsqpR4D3tNap1Xz2rFa6w3uCbN+fJGcXfL1JYRaQ3nn3He8el3RwNjLYcUHsPg1yNtudiX2uQW6jjR1xepj558w7z7YvhiadjXrw1J6V39saR58MBBytsAVX0KLnvW7thBHMWdZGVsHD0H5+dFqzpc1LhB3lpZStnYtJStX4cjPJ7R3b0J6dMcvqOZafs7iYrYOHQZA69lfuDw1qR0Otg4ZAk5N6zlfovwbfj15244dZNx2O2Xr1gEQcd4Amtx0M4GtPVMXbR9nSQnbr76GsnXrSJo8iZLly9k7aTIhvXuR9MorWCJ8V9anvslZL2Cd1rqw8nEEcKzWeqnbI60HbydnTu2k16e9GHHMCO7tea/XrisamNx/TCPsnaugRS9TGb9df6jFFu7D0tqsWfv+ETMN2nmEWahfdYrUVgIfDzflLy6daqrzC3GEcOTns/P+BwjpdgIx11zjlQXbeyZOJPuNSSS//x6hvQ/xC5EblCxfTtrlVxB10UU0e2y8S+/J+2I2u+6/n8SXXyai/7kei83dnDYbedNn7F+v5y2O/HzSLr+C8tRU0JqoCy+g6SOP1LkWmrvUq5QGMAnoVuVxUTXPHXUyCjMotZfKZoCj2YavTdV8DYz82JSg8ASloMsF0H6AmTJd9Ar8/a1psn3yzaba/4yrYPsSuOBdScyEzzmKinAWl2BNiK//uQoK9o98FC1YgC0tzeNfrOVbt5L99jtEDBrk0cQMIKR7d2JGjybnvfcIP6sfYX371ni802Yj+9VXCerUiXAXdkE2JH4BAcRcNsrr17VERpL87jtk3HU3YaefTsxVVzaIHZk1ceXXe1W1dIbW2on05GRT3iYA2ka19XEkwuvsNpj3AEwbBTGtYcwvnkvMqgoIhTMegJv+gPb94een4PWe8NnFkDrfVO/vPMLzcQhRA+1wsP3qa9jSv78pIFoP+xOzTZtImvQGsTeOIW/G5+wYOw5HUbGbIj6Q1prdjz2OX3AwCfd6Z79b3K23ENC2DbsefAhHfn6Nx+ZNn0HFzp3E3XZbg08wGhL/uDhSPvyA2NFXNYo/N1eSs61KqVuUUtbK263AVk8H1tDt26kpyVkjU1YA394Ny942P9dW3g54fwAseR163gBXz4folm4Ps0ZRyaag7FXfQFCUKTR75kPQ4xrvxiFENXI/m0rZ6tX4R0eTftPN7H3/A+pSGtNRWMj2a66lbONGkia+QvgZZxB/6600/d/jFP/+O2mXX05FZpbb4y+YM4eSpUuJv+MO/Jt4p5uFX2AgzZ+ZgD0nh91PPHnI45wlJWRPnkxIjx6EntLHK7EJ33AlORsDnAxkAOnAScD1ngyqMdict5mksCRCrCGHP1g0DMXZ8OEgWPaWKbT6QgeYc7NZL+aKjfNg8immDtiFH8B5z9Z/wX99tDwFblgIY5dA37t8F4cQlSoyM9nz0kuEnnwyrb/5mvCzzyZrwgR2j38MXVHh8nn2J2Z//03SKyYx2yf6wgtpMXkSFWlp/HPxxZRt2uS2+B15eWROeJbg444j6qIL3XZeVwR37kSTMWMo+OorCuZ/V+0xOVM+xpGdTdzttzeK0R9Rd4dNzrTWWVrri7XW8VrrBK31pVpr9/+60sik5qbKerPGJD/djHjt+RsunQ7XLYDOw2D1DHjrdHNb+RHYqpkqcVTAdw/DZyMhqoVJiDoN8/YnqJ6fBeKP9V47KCFqkPnU02i7nabjH8UvOJjEl18i9rrryJs2jR1jbsRRWHjYcziKith+7bWUbdhA0ssvEX7mGQcdE9a3LykfTwG7nbRLR1G8ZIlb4s968SUc+fk0fWx8rfoyukuTG64nqFMndj/6KPbs7ANec+Tns/fddwk7/fQGV5NLuN9h//UppYKUUuOUUm8opd7bd/NGcA2VzWEjrSBNpjQbi+zN8O65ULgbLv/CNPhOPBGGvA53/g0DnoOKMjOK9kIH+OYuyDTbvcnPMOUpfp9o6pVd8wPENojSfkI0KIU//0zh/Pk0uXHM/n6Kys+P+DvvoNmTT1C8dClpl16KLT3jkOdwFBWx49rrKFu3nqSXXiS8X79DHhvUsSMtp03F2qwp26+7nvwvv6xX/CUrV5E3fToxl19OUIcO9TpXXSmrleYTnsFZUsKuRx49YDp477vv4SwoIO7223wSm/AuV341mAI0Bc4FFgJJwOF//TmCbc3fikM7aBfdztehiMPZ+acpymovg6u+Ni2RqgqOgpOuh7GLzfqx9gPMCNqkk+Gds800ZuZaGPEuDHwJrDXXLRLiaOQsKSHz8f8R0KYNsVdffdDrUSNGkPzOO1RkZvHPyJGU/vXXQcc4iorZcd31lK5dS+JLLxJ+1uF3HVubNyflk08I6daNnffeR/akSXVa36YrKtg9fjz+TZsSd/NNtX6/OwW2bUvcbbdRtGAB+bNNwmnfs4ecKVOIOP98gtpLB4+jgSvJWVut9cNAsdb6Q+B8zLqzo9b+tk0yrdmw/bPIrDGzBpvEq9lxhz5WKUjuBcOzAnLqAAAgAElEQVTfMqNp5zwJZflmN+b1P5tSFkKIamW/8QYVO3fSbPyjh+w1GdrrJFpO/Qy/0FDSrriSgnnz9r/mKCpmx/XXU7pmDYkvvkDE2We7fG1LRATJb79FxOBB7HllIrsefrhW69sAcj6aQvmmTTR96EGP9KisrZgrryC4+4lkPvkkFTt3kj35TbTNRtwtN/s6NOElrpTE2PevPE8p1RnTX7P+xWsasdS8VKx+VpIj6tiUWnjepvkw/Qqzs/HyLw4s2Ho4ITFw8k3mJoSoUdnGTez94EMiRwwnpEePGo8NbN2altOmkj7uJjJuux3b7duJHjWKHTfcQOlff5H44ov7W+zUhgoIoPmECVgTE9k7aTLlqalEDRtG2JlnYo2v+euqYudO9rz2GmFnnEFYDdOo3qQsFpo//TRbhwwl/fbbKVu/gagRI6ptASWOTK50CLgWmAl0AT4AwoCHtdZvejy6WvBmh4Abf7iRPSV7+Hzw51653lEt9XuzOzKlNzQ9Diwu/D6xegbMHgMJneGyWRBa/0a6QoiDaaeTtEtHYUtLo/W33+AfHe3S+5w2G7sefIiCr77C0qQJjtxcEl94wS3V7vO+mE325Emm4bhSBB9/POFnnUX42WftXwtX1Y5xN1H8+++0+forrImJ9b6+O+VOncbu8eNRgYG0+W4+1oQEX4ck3KjOHQIqm5sXaK1zgV+A1h6Ir9FJzU2le9PaNakVdbB3C0y7zKwXAwgIg6QekNLHrB1LPPHgNWDL3jZ1zFqeAhd/CkG+65smxJEub/oMSv/8k2ZPP+1yYgamUnzzZycQkJLC3nffJfGF593Whihq2FAihw6hPDWVwh9+oPCHH8h67jmynnuOwHbt9idqgR06ULRgAUU//kj8XXc2uMQMIGrkRZSnphLYto0kZkcZV0bOlh8qs2tIvDVyVmAroM9nfbit221c00WKfnqM1ma92K6/4MqvTDPvtMWQ9jtkVe6ktASYBC25t0nYMlaYqvntz4ML3pfF+0J4kD07my3nnU9Qhw4kf/hBnetuaYcDZbG4OboD2dLT9ydqpStWgtZYk5JwlpbiHxNDq1kzfd5nURx96ttb8wel1F3ANGB/ESitdY6b4mtUNuduBmQzgMet/Aj++RUGvgzNjze3fa2JSnJgx1KTqKX9bspc/Paiee24S2Dwa65NfwrhQY6CAjInTMC27R8CkpMJSEkmICUFa3IKAS1TsISFuXwu7XTiyM/HkZ2NPScXnA7ws6AsflXuzU1ZLPvv/ePisER4ZvQ485kJ6NJSmo4fX6+CqJ5OzAACkpKIveoqYq+6CvvevRQuWEDh999TtmYtTR9/TBIz0eC48g02svJ+XJXnNEfpFOe+nZpSRsODCnaZoq8pp0C3Kw9+PSTGlLxoP8A8thVD+h+mHVOHgeZLSggfKlmxgoy778aetYfgLl0o/v138mfPPuAYS0xMZdKWgjUlGf8mTSoTsL3Yc3Jw7M3GvjcHe85eHDm54HDUPhClCOrUidDevQjp1YuQbt3wCw6u9+crWrSIgq+/psnYsQS2blXv83mTf2ws0RdeSPSF3u0AIERtHDY501o3rv/yPCw1L5VwazgJITL/7zFz7zbrzAa94lqiFRAKrU/3dFRCHJa228meNJnsSZOwJibS8tNPCO7aFTC1wGw7dmBLS6Ni+3ZsaduxpaVRvHQp9ioFVFVwMP6xsVhiY7AmJhLctQuWmNj9z/nHxIDFAk4n2uEApwanA+1wgt73nLm3bfuH4iWL2fvBh+x9+x2U1UrwCSfsT9aCu3RB+ddulNlZVsbuxx4nICWF2BuO+k5+QnjEYf+rVEpdUd3zWuuP3B9Ow5eam0rb6LbS18xT1s+BDV9Bv0ehiXRgEI1HRUYGGXffQ+nKlUQOGUzCww8fMHXpFxJCUPv21RYRdZaV4di7F0t0NH4h7u3XG3fTOJzFxZSsWEHx4iUUL1nCnlcmwisT8QsLI6RHD0JO6klQh2MJbHeMSf5qkP3mm1Rs307y++/hF+jD3rJCHMFc+ZWpauGaIKAfsBI46pIzrTWpeakMaDnA16EcmUpzTUPypl3gZCm2KBqPgrlz2fXIo+B00vy5Z4kcNKhW7/cLCsLPg7sF/UJDCTv1VMJOPRUAe24uJUuXUvz7YoqXLKHop5/2H2tp0oSgdscQeEw7Atu1I7DdMQS2bYtfcDDlW7aw9513iRg8iNDevT0WrxBHO1emNQ/4llRKRQFTPRZRA5ZZkkmhrVA2A3jKdw9DcbZpTG6RBbqi4XMWF7P7qafInzmLoK5dSXzheQJatPB1WIflHx1NRP/+RPTvD0BFVhblm1Ip37SJ8lRznzt1Krq83LxBKazJLaDCjl9ICAn33uvD6IU48tVlS1sxcFSuQ9u3GUAannvA1oWwagr0udXszBSigStdt46dd96FLS2N2BtuIO6mcY121581Ph5rfDxhp/TZ/5x2OLBt316ZrJmEzbZtG3F33IF/rBR2FsKTXFlz9hVmdyaYXpwdgemeDKqhSs2TnpoeYSuBr24xfSxPv9/X0YijjNaaiu3bKVu/HtuOdFCg/Cxg8aty73dA6YqK9HSy334b/5gYkt9/n9BeR167YWWxENiqFYGtWkEdWioJIerOlZGz56v8bAfStNbpHoqnQducu5n4kHgiAyN9HcqR5eenIPcfU2zWWv9t/kIcinY6sf3zD2Xr1lO2bh1l69dTtmEDzsLCWp8rrF8/mj3xv1pVxhdCCFe4kpxtB3ZprcsAlFLBSqmWWut/PBpZA5SalyqjZu6WsRIWvw7droBWp/o6GnEE2Z+IrVlD6bp1lK1bT/mGDThLSgBQgYEEdmhPxMDzCerYkeBOnQho2RKUMmUpnA5TlkJrcDjQTuf+e+Xnh3+zZrJrWwjhEa4kZzOAk6s8dlQ+16P6w49MDqeDtII0ejeTHUpu46iAOTdDaDyc/T9fRyMaMa019p07KV2zlrK1a8z9unU4i4oAUzssqEMHIocPJ6hjR4I6dSKwdatGu0ZMCHFkcyU589da2/Y90FrblFIBHoypQbL4Wfhl5C+UO8p9HcqRY9ErkLkWRn4MwVG+jkY0IvacHDMitmYtpWtWU7ZmLY6cyo5yVitB7dsTOXgQQZ27ENylMwGtW3ulTZAQQriDK8nZHqXUYK31HACl1BAg27NhNUxB/kEE+UszbbfIToWFz8Kxg+HY2tWEEkcXR1GxWR+2ZrUZEVuzhoqdO82LShHYtg1hp51GUJfOBHfpQmD79vgFHHW/PwohjiCuJGdjgE+UUq9VPk4Hqu0aIMQhVZRB4U4oqLwtnQzWIDjv+cO/V9SbttvZ8/LLWJOTibrgArP7sAFy2myUb9iwPwkrXbsW29atZt0XYE1KIui4rkSPGkVQl84EdeyEJSzUx1ELIYR7uVKEdgvQSykVVvm4yONRicbJVgIb5kD+jn+TsIIMc1+y98Bj/fxh6CQIlx6lnqa1Ztf48eR/PhOA/Flf0PSxxwhq387HkZlK9aWrVlG6ciUlK1dRtnYt2mZWUViaNCG4c2cizhtAcNeuBHXuLDsjhRBHBVfqnD0FPKu1zqt8HA3cqbV+yNPBiUZm9o2wfrb5OSQWIppDRCIk9fj353334c0gMKzm8wm3yH71NfI/n0nsmBsIbNWKzGcmsG3ECGKvupImY8e6vZfjoWitsW3btj8RK121Ctu2beZFq5Xgjh2JHjWK4OOPJ7hrF/ybNpXdkEKIo5Ir05oDtNYP7Hugtc5VSp0HSHIm/pX6vUnMTr0H+t5ppiyFz+VOnUb2G28QOWI4cbfeilKK0FNPJev559n7zrsUzJ1H00ceJuy009x2TUdBARXp6dh2pFORvgNbejoV23dQtm4djrw8ACyRkQSfcAKRw4YR0u0Egjp3xi9I/s0IIQSA0lrXfIBSq4EeWuvyysfBwHKtdafDnlyp/sArgAV4R2v9zH9eTwHeA+KAHOCyqgVulVIRwHpgttb6ppqu1b17d718+fLDhSQ8wVYCb5wE/kEw5jfwD/R1RAIo/OEH0m+5lbC+fUl6/TWU/4G/i5X88Qe7Hh2PbetWwvv3J+H++7EmxLt0bqfNRvnGjZSt30DFju2ViVg6tvR0nPn5BxzrFxlJQGIigR06ENLtBIK7dSOgZcsGu+5NCCG8QSm1QmvdvbrXXBk5+wT4USn1fuXj0cCHLlzUArwOnI3ZRPCHUmqO1np9lcOeBz7SWn+olDoTeBq4vMrr/wN+cSFG4Uu/PAt52+GqbyQxayBKVq4k4867COrcmcSXXjwoMQMI6dGDVrO/IOfdd8meNJni334j7vbbiL744gPKTmiHA9vWrf/WEFu9hvKNG9EVFQAoqxVrYiLWFi2I6NqFgKQWWJOSCGiRhDUpCUtEhNc+txBCHAkOO3IGoJQaAPSrfPi91nq+C+/pDYzXWp9b+fh+AK3101WOWQf011rvUGZxSb7WOqLytROBu4F5QHcZOWugMtfDm32h60gY+oavoxFA+ebN/DPqMvyjo0n57FOXFtHb0tLY/dhjFP++mKCuXYm++GLKU1MpW7OGsvXr91fV9wsNJahTp8qyFV0J6twJa/PmMgomhBC1VN+RM7TWc4G5tbxuIrCjyuN04L/dgf8ChmOmPocB4UqpWCAXeAG4DDjrUBdQSl0PXA+QnJxcy/BEvTmd8PVtEBghFf4biIrdu9l+3fWoACst3nnb5d2NASkptHj3XQq+/prMZyaw64EHUFYrgR2PJXLYsP01xAJatZJETAghPMyV3Zq9gFeBY4EAzPqx4n0jXPV0F/CaUuoqzPRlBqY91FjgW611ek27tbTWbwFvgRk5c0M8ojZWfQQ7lsKQNyA01tfRHPUcBQXsuO56nAUFpEz5iICkpFq9XylF5KBBhJ1xBhUZGQS2aoWSYq5CCOF1roycvQZcjOmn2R1TgNaVAkkZQIsqj5Mqn9tPa70TM3JGZR21EVrrvMop0b5KqbFAGBCglCrSWt/nwnWFNxRlwfePQMopcPylvo7mqOcsLyd93E2U//MPyW+9SVDHjnU+lyUsDEv79m6MTgghRG24ND+htd4MWLTWDq31+0B/F972B3CMUqpVZS/Oi4E5VQ9QSjVRSu2L4X7Mzk201qO01sla65aY0bWPJDFrYOY/aHZpDnwJpBaVT2mHg5333EvJH3/Q/OmnCe3d29chCSGEqAdXkrOSyuTqT6XUs0qp2115n9baDtwEzAc2ANO11uuUUo8rpQZXHnY6sFEptQlIAJ6sy4cQXrblJ1gzHU65HeJ8X2X+aKadTjKffobC+fOJv+9eIgee7+uQhBBC1JMrdc5SgEzMerPbgUjgjcrRtAZDdmt6SUUZTDoZ0HDjYik26wPO8nJKli6l8McFFP30E/asLGJGjybh3nt8HZoQQggX1Wu3ptY6rfLHMuAxdwYmGqHfXoScLXD5bEnMvMiem0vRwoUU/biAokWL0CUlqJAQwk45hfBzziHivAG+DlEIIYSbuFRKQwgA9myC316CLhdBmzN8HU2jU/rXX2TcfgeOwkL84+Lwj48391Vv8ft+jseRvYfCBT9RuOBHSleuAqcT//h4IgcPIrxfP0J69sQvUIr+CiHEkUaSM+EareHr28EaDOceHUsD87/+Bnv2HmIuu6zaCvu1UTBvHjvvva8yuRqMfc8e7Hv2ULpqFfasLLTNdsj3BrZvT5MxNxB2xpkEde4kzcCFEOIIJ8mZcM1fn0HabzDwZQhzrf9iY5Y/Zw4777kXgMLvfyDxuWexNm9e6/Nordn71tvseeklgrt1I+m1V/GPiTnoGGdBwf6Ezb5nD/asLFRwMGGnnU5AUqJbPpMQQojGwZUitO0wbZRSqh6vtT7Tg3GJhqQkB757CFqcBN2u9HU0Hle4YAE773+AkF69iBw0iMwnn2Tr0GE0e/xxIvqf6/J5tM3GrvGPkT9rFhEDB9LsySeqnYZUSmGJjMQSGUlg27bu/ChCCCEaIVdGzmYAk4G3MdX7xdHEVgxf3QJl+aam2RHeuqd4yVIybrudoE6dSHrtNSxhoYT06E7GXXeTcdttFF94AQn3349fSEiN53Hk5ZF+y62ULFtGk3HjaHLTOJmOFEII4RJXkjO71nqSxyMRDc8/i+DLcZC7Dc5+HBI6+Toijypds4b0sWMJSEmmxZuTsYSFAhCQnEzLTz5mz8RX2fvOO5QsX0HiC88fsgq/LS2NHTeMoSIjg+bPPUvkoEHe/BhCCCEaOVeGQb5SSo1VSjVTSsXsu3k8MuE7tmKYey98cB6g4apvoc+tvo7Ko8o3b2bHtddhiYmhxTvvHtQwXFmtxN95B8nvv4ezuJh/Rl7M3g8+QDudBxxXsmIF/4y8GEdeHsnvvyeJmRBCiFpzpQjttmqe1lrr1p4JqW6kCK2bVB0tO2kM9HsEAkJ9HZVH2dLTSbt0FFo7afnJJwQkJ9d4vD03l10PPkTRggWE9u1L86efwr9JE/K/+opdDzyINTGRFm9OJiAlxUufQAghRGNTUxHawyZnjYUkZ/VkK4YfH4elkyG6JQx5A1r28XVUHleRlUXaZZfjyM8nZcpHBLVzrR2V1pq8qVPJfGYCfmFhhJ95JnkzZhDSsydJE1/BEhXl4ciFEEI0ZvXqEKCUsgI3AqdWPvUz8KbWusJtEQrfqjpa1vMGOOvRI360DMyi/R3XXoc9O5uU999zOTEDs8My+pJLCD7xRHbeeRd5M2YQOWwYzR4bjwoI8GDUQgghjnSubAiYBFiBNyofX1753LWeCkp4yX9Hy676Blqe4uuovMJZXMyOG8Zg27aNFm+9SfBxx9XpPEHt2tFyxnTK1q0juFs32ZEphBCi3lxJznporat+cy1QSv3lqYCEl2z7Febc3KBHy8q3bSN/1ixAETl0CIFt2rjlvE6bjfSbb6F0zRoSX3mZ0N6963U+v6AgQk480S2xCSGEEK4kZw6lVBut9RYApVRrpN5Z41WaB98/Ais/bJCjZdpmo/DHH8mdOo2SpUuhsm3S3rffJvj444kcMZyIAQOwhIXV+txOm43SlavY+/57FP/+O82efpqIs89290cQQggh6sWV3Zr9gPeBrYDCdAoYrbX+yfPhuU42BLhgw9fwzZ1QnAW9x8HpD0BAzcVUvcW2Ywd502eQN2sWjr17sTZvTtRFFxE1YjgoRf6cr8ibORPbli2o4GAizj2XyOHDCOnR45BTiVprbFu3UrxoEUWLFlGy7A90aSlYrSTcey8xl43y8qcUQgghjHrv1lRKBQLtKx9u1FqXuzE+t5DkrAaFmTD3blj/JSR0hsGvQmI3X0eFttsp+vlncqdOo3jRIlCKsDPOIHrkRYT26YOyWA48XmvKVq8mb+YsCr75BmdxMdbkZKKGDyNy6FCsTZtiz82lZPFiihYtonjR79h37wYgoGVLQvv0IbRPH0J69txfYFYIIYTwhTolZ0qpM7XWC5RSw6t7XWs9y40x1pskZ9XQGv78FOY/ABWlcNo9ppisxerbsJxO9r71Nrmffoo9Kwv/hASiLriAqAsvwNq0qUvncJaWUvjdd+TNnEXJsmXg50dAy5bYtm0DrfGLiCC0d29C+5xM6Ml9pHm4EEKIBqWupTROAxYA1ZU410CDSs7Ef+T+A1/dBlt/guTeZrSsyTG+jgqA/Dlz2PPyy4SefDJNH32EsNNOQ/m7svzxX37BwUQOGULkkCHYtm8n74svKFuzloiB5xPWpw9BnTsfNPImhBBCNAaurDlrpbXedrjnfE1Gzio5HaY0xoInQFng7PFw4tUNpmG5s7SULf0H4B8XR8vp01ANJC4hhBDCm+pVhBaYCfx3gdLngNQOaIjmP2CSs3b94fwXIDLJ1xEdYO/772PPzCTxheclMRNCCCGqccjkTCnVAegERP5n3VkEEOTpwEQd7FoNy96CE0fDwJeggRVErcjKYu877xJ+zjmEdK/2lwUhhBDiqFfTyFl7YCAQxYHrzgqB6zwZlKgDpxO+vQuCY0xB2QaWmAHsmTgRXVFB/F13+joUIYQQosE6ZHKmtf4S+FIp1VtrvdiLMYm6WD0VdiyFwa9BcLSvozlI2d9/kz9zFjFXXklAcrKvwxFCCCEaLFfWnK1SSo3DTHHun87UWl/tsahE7eyr+p/YHY5veIVVtdZkTpiAJSKCJjeO8XU4QgghRIPmyorsKUBT4FxgIZCEmdoUDcXPT0NxNpz/fIPZlVlV0cKFlCxeQpNx47BERvo6HCGEEKJBc+WbvK3W+mGgWGv9IXA+cJJnwxIu273WbALoPhqan+DraA6iKyrIevY5Alq2JPqSi30djhBCCNHguTKtWVF5n6eU6gzsBuI9F5JwmdZmE0BQFJz5sK+jqVbu9OnYtm4l6Y3XUVbfdiYQQgghGgNXkrO3lFLRwMPAHCAMeMSjUQnXrJ4O2xfDoFcgJMbX0RzEUVBA9muvE9KzJ2FnnOHrcIQQQohG4bDJmdb6ncofFwKtPRuOcFlZAXz/MDTvBidc4etoqpX95ps48vKIv/ceVAMs7SGEEEI0RDUVob2jpjdqrV90fzjCZT8/A0VZcMlnDXITgC09ndyPphA5dCjBnTr5OhwhhBCi0ahp5Cy88r490AMzpQmmIO0yTwYlDiNzvWnR1O0KSGyYXbSyXngB/P2Ju+1WX4cihBBCNCo1FaF9DEAp9QvQTWtdWPl4PPCNV6ITB9Mavr0bgiKg36O+jqZaJStXUTh3Hk3GjcOakODrcIQQQohGxZUNAQmArcpjW+VzwhfWzoS03+D8FyE01tfRHMQUnH0G/7g4Yq+ROsVCCCFEbbmSnH0ELFNKfVH5eCjwgcciEodWXgjfPQTNjoMTr/J1NNUq+PZbyv5aTbOnnsIvJMTX4QghhBCNjiu7NZ9USs0F+lY+NVprvcqzYYlqLZwAhbvgoingZ/F1NAfQTifOkhL2vPAigcceS+TQIb4OSQghhGiUatqtGaG1LlBKxQD/VN72vRajtc7xfHhiv6y/YckkOOEyaNHDa5fVTieZTz5F8dIl6IoKqLCjKyrMzf7vzzid+9+T/NSTqAa4g1QIIYRoDGoaOfsUGAisAHSV51XlY6l55k3zH4CAUDjrMa9eNvu118j95BNC+/TBEhWFslpRVn9T7d/fv/KxFeVv7gPbtiG0Vy+vxiiEEEIcSWrarTmw8r6V98IR1creDFt+hH6PQGgTr122YN48st+YROTw4TR78gkpJCuEEEJ4QU3Tmt1qeqPWeqX7wxHV+vNjUBY4/jKvXbJswwZ23v8AwccfT9Pxj0piJoQQQnhJTdOaL9TwmgbOdHMsojoOO/z5GbQ7F8K9U8HEnpND+ribsEREkPTqRPwCArxyXSGEEELUPK0pnaobgs0/QNFusxHAC7TNRsYtt2Lfu5eUjz/GPy7OK9cVQgghhOFKnTOUUp2BjkDQvue01h95KihRxaopEBoPx5zjlcvtfuopSpYvp/lzzxHcpbNXrimEEEKIfx02OVNKPQqcjknOvgUGAL9hitMKTyrKgk3zoNdYsFg9frncqVPJmzqN2GuvIXLQQI9fTwghhBAHc6UY1QVAP2C31no0cBwQ6dGohLF6GjjtXpnSLF62jN1PPEnoaacSd/vtHr+eEEIIIarnSnJWqrV2AnalVASQBbTwbFgCrWHlFEjqCXHtPXopW3oGGbfeRkByMonPP4+yNKzuA0IIIcTRxJXkbLlSKgp4G1OQdiWw2KNRCUhfDtkbodvlHr2Ms6SE9HHj0HY7Sa+/hiU83KPXE0IIIUTNaqpz9jrwqdZ6bOVTk5VS84AIrfVqr0R3NFs1Bawh0GmYxy6htWbn/Q9QnppKizffJLCV1BsWQgghfK2mDQGbgOeVUs2A6cBn0vDcS2zFsHaWScwCPTeSlT1pEoXz5xN/zz2E9T3FY9cRQgghhOsOOa2ptX5Fa90bOA3YC7ynlPpbKfWoUqqd1yI8Gq3/EmyFcILnpjQLvvuO7ImvEjlkMDGjr/LYdYQQQghRO4ddc6a1TtNaT9BanwBcAgwFNng8sqPZyikQ0waSPdNAvHTNWnbec69pzfT449KaSQghhGhADpucKaX8lVKDlFKfAHOBjcBwj0d2tMreDNt/N+UzPJA0VezeTfrYsfjHxpL0+mv4BQa6/RpCCCGEqLuaNgScjRkpOw9YBkwFrtdaF3sptqPTn59UNjm/1O2ndhYXs+PGsThLSmj53rv4x8a6/RpCCCGEqJ+aNgTcD3wK3Km1zvVSPEc3hx3+/BSOORvCm7r11NrhIOOuuynfuJEWb04m8Jhj3Hp+IYQQQrhHTY3Pz/RmIALY8qPHmpxnPfc8RT/9RMLDDxHWt6/bzy+EEEII93ClCK3wlpUfQWgctOvv1tPmTptOzgcfEH3ZZcSMGuXWcwshhBDCvSQ5ayiK9pgm511HurXJefHixez+3/8IPbUvCffd67bzCiGEEMIzJDlrKPY3OXdfbbPyrVtJv+VWAlu1IvHFF1H+NS0xFEIIIURDIMlZQ6C1adeU1APiO7jllPbcXHbcMAYVEECLyZOwhIW55bxCCCGE8CxJzhqCjBWw52+3bQRw2myk33Qz9sxMWrz+GtbERLecVwghhBCeJ/NcDcH+Juf1r+2rtWb3ww9TumIFiS++QPDxx7shQCGEEEJ4iyRnvmYrhjUzoeNQCIqo82m03U7Rr7+SO3UqxQt/ocnNNxFx3nluDFQIIYQQ3iDJma+tn1PZ5LxuU5oVGRnkzZxJ3sxZ2DMzscTGEnfrLcSOGePmQIUQQgjhDZKc+dqqKRDTGlJOdvkt2majcMFP5H3+OcWLFgEQesopJDz4AOFnnIGyuq8UhxBCCCG8S5IzX9q7BdIWQb9HXGpyXr5tG3mff07+7C9x7N2Lf7NmNBk7lqgRw7E2b+6FgIUQQgjhaZKc+dLqaYCCrgYUM5MAAB61SURBVBcf9tCdDz5I/sxZ4O9P+BmnE3XhhYT26YOyWDwfpxBCCCG8RpIzX3E64a/PoPXpEFlzqQtbegb5M2cROXQo8XfegX9cnFdCFEIIIYT3SZ0zX9m+GPK2w3GXHPbQwnlzAWhy0zhJzIQQQogjnCRnvvLXZ2ANhWMHHvbQgrnzCOralYCkJC8EJoQQQghfkuTMFypKYd1s6DgEAkJrPNS2fTtl69YR0b+/l4ITQgghhC9JcuYLf39japsdd/iNAAVz5wEQ0f9cT0clhBBCiAZAkjNf+GsqRCRBy76HPbRg3jyCjz9eSmUIIYQQRwlJzrytMBO2/AhdLwK/mv/4y7dto3zDBiIGyJSmEEIIcbTwaHKmlOqvlNqolNqslLqvmtdTlFI/KqVWK6V+VkolVT5/vFJqsVJqXeVrIz0Zp1etmQHa6dKUZuE8M6UZLuvNhBBCiKOGx5IzpZQFeB0YAHQELlFKdfzPYc8DH2mtuwKPA09XPl8CXKG17gT0B15WSkV5Klav+msqNO8Gce0Pe2jB3HkEn3gi1oQELwQmhBBCiIbAkyNnPYHNWuutWmsbMBUY8p9jOgILKn/+ad/rWutNWuvUyp93AllA4y/wtXsNZK5xqbZZ+ZYtlG/aRMSAAV4ITAghhBANhSeTs0RgR5XH6ZXPVfUXMLzy52FAuFIqtuoBSqmeQACw5b8XUEpdr5RarpRavmfPHrcF7jF/TQU/f+g84rCHFsydB0oRfs7ZXghMCCGEEA2FrzcE3AWcppRaBZwGZACOfS8qpZoBU4DRWmvnf9+stX5La91da909rqFXznfYzXqzY86F0NgaD9VaUzB3LiHdu2ONj/dSgEIIIYRoCDzZWzMDaFHlcVLlc/tVTlkOB1BKhQEjtNZ5lY8jgG+AB7XWSzwYp3ds/RmKMl3aCFCemoptyxZiLhvl+biEEEII0aB4cuTsD+AYpVQrpVQAcDEwp+oBSqkmSql9MdwPvFf5fADwBWazwOcejNF7/voMgqKg3eGLyRbOmwd+foSfLVOaQgghxNHGY8mZ1toO3ATMBzYA07XW65RSjyulBlcedjqwUSm1CUgAnqx8/iLgVOAqpdSflbfjPRWrx5UVwN9fm7Vm/oE1Hqq15v/t3XtwlfW97/H3NxdyIQS5UxIwtUuRoFQ4KKjQCrYCsTutZ0ehuqkVzujZA60V9xbtnEEKso9tGXu0dKbj2aic4iZHqYUoIeKtsjs6G+GoJCTYhAKbRCAhAiGSC1n5nT/WIoas3Fm3JJ/XDLOe5/f8npXv4hkW3/yuNfk7SZ5xE3EjR4YpQBEREYkWoezWxDmXD+S3KVvV6ngrENAy5pzbDGwOZWxhVbwdmuq7N0vzs89oPHKE4Q88EIbAREREJNpEekLAwPBpLgz/BqRP77JqTf5OiI3VLE0REZEBSslZqJ0+Ckf/4ms1M+u0qnOOmoICBs+cSdywYWEKUERERKKJkrNQ2/+K73XKPV1WrS8u5sJ//qf20hQRERnAlJyFknO+WZoZs2HYlV1WP7dzJ8TFMeQ73wlDcCIiIhKNlJyFUvle+OJQt9Y28y08W8DgW24m9or+sY2oiIiI9JySs1D6dAvEJcGk7C6r1hcWcqGigtT52ktTRERkIFNyFipNDVD0R5j0PUhM7bJ6zc4CiI9nyHduD0NwIiIiEq2UnIXKX9+E+jPd79IsKCDl1luJTe06kRMREZH+S8lZqHyaCylj4eu3dVm17pNPaDp+nNQsdWmKiIgMdErOQuHLaih9E6bcDbFdb8JwrqAAGzSIlLlzwxCciIiIRDMlZ6FQ9EdoburWdk2uuZmagjcZPHs2sSkpYQhOREREopmSs1A48u8wLAPGTO6yat3HH9N08iSpC9SlKSIiIkrOQqPqIIzuOjED3yxNS0gg5bbbQhuTiIiI9AlKzoKtqQGqD8Hoa7us6rxeat4sIOXb3yY2ZXAYghMREZFop+Qs2KrLwHlhdGaXVc/v3Ye36hSp8+eFITARERHpC5ScBVtlie91VNctZzX5+Vhysro0RUREpIWSs2CrLAGLhZFXd1rNXbjAuTffZMicOcQkJ4cpOBEREYl2Ss6CreogjPgGxCV0Wu3LDz7Ae+YMqXfeGabAREREpC9QchZslSXd7tKMSU0lZdatYQhKRERE+golZ8F0oQ6++BuMntRpteb6es699TZD7vguNmhQmIITERGRvkDJWTCd+ivgumw5q/3z+zSfP89QdWmKiIhIG0rOgqnyoO+1i2U0avLziR05kuSbbgpDUCIiItKXKDkLpspiiIn3TQjogLe2lto//5nU+fOx2NgwBiciIiJ9gZKzYKo6CCM8EBvfYZVzb7+Na2wk9c6sMAYmIiIifYWSs2CqLOly26aa/Hzix40j6YYbwhSUiIiI9CVKzoKl8Us4c7TT8WZNp0/z5QcfknpnFmYWxuBERESkr1ByFixV/skAnczUPPfmm9DUpIVnRUREpENKzoKlZaZmx2uc1byxg0Hf+AYJEyeGKSgRERHpa5ScBUtVCcQmwLCvt3v5wokTnN+3j9SsBerSFBERkQ4pOQuWyoMw8hqIjWv3cs3OAnBOC8+KiIhIp5ScBUsXMzVrduwgcfJkBmVkhC8mERER6XOUnAVDfQ3UlHc4GaDx6FHqi4pIzdLaZiIiItI5JWfBUPWZ77WDZTRq8vMBSM1aEK6IREREpI9SchYMlcW+13a6NZ1znN2xg6Tp/4X4r30tzIGJiIhIX6PkLBiqDkJcElyREXCp4a+lNJYdUpemiIiIdIuSs2CoLIFR10BM4F9nzY4dEBtL6vz5EQhMRERE+holZ8FQdbDd8WbOOWry8xl8883EDR8egcBERESkr1FydrnqTsO54+3O1Kzfv58L5eXq0hQREZFuU3J2uTrZtunsjh3YoEEM+e53whyUiIiI9FVKzi5XVYnvtU1y5rxeanbuJOXb3yJ2yJAIBCYiIiJ9kZKzy1V5EAalwNDxlxSf/2gv3qpT6tIUERGRHlFydrkqi2HURGizmXnNjh3EJCeTctttkYlLRERE+iQlZ5er6iCMatOl2dhIza5dpNx+OzFJSREKTERERPoiJWeX48tq+LIqYLxZ7Qcf0Hz2rLZrEhERkR5TcnY5WiYDXLqMRu077xIzZAgpt94agaBERESkL1Nydjkq/clZm27Nuv37SfrmN7FBgyIQlIiIiPRlSs4uR2UJJKRC6riWoua6OhrKyki8/roIBiYiIiJ9lZKzy1F10DferNVMzfqSg+D1knT99REMTERERPoqJWe95Zx/GY1Lx5vVFxUCkHidWs5ERESk5+IiHUCfVVvp21ezzUzNusIi4saMIX706AgFJiIicvkaGxs5dOgQ58+fj3Qo/U5ycjJpaWnxHV1XctZbHWzbVF9YqPFmIiLS5x06dIgrrriCiRMnEhOjjrZgaW5u5sSJEzz//POTsrOzvw3szsvLc63r6G+7ty5ueN5qpqa3pobGI0dIuk7jzUREpG87f/48Y8aMUWIWZDExMYwdO5bRo0fHA0uB7IA64Q+rn6gshqRhkPJV92X9gQMAajkTEZF+QYlZaMTExGC+yYQVwJyA62GPqL+4uG1Tq5madYVFACRpMoCIiIh0rQlIbFuo5Kw3nPN1a7Yz3iz+ygnEDh0aocBERET6DzPj0UcfbTlfv349q1evjlxAYaLkrDfOHYeGs4EzNYuKNN5MREQkSBISEnjttdc4depUpEMJK83W7I3KYt9rqzXOmk6doun4cY03ExGRfucXrx+g+POaoL5n5rhUnvy7yZ3WiYuL48EHH+Q3v/kN69atu+TakSNHWLJkCadOnWLUqFG8+OKLTJgwgR//+Mekpqayd+9eTpw4wa9+9StycnIA+PWvf80rr7xCQ0MDd911F7/4xS+C+pmCRS1nvXFxpmarlrO6Qt/is9oZQEREJHiWLVvGyy+/zNmzZy8p/8lPfsL999/P/v37ue+++/jpT3/acu348eP85S9/4Y033uDxxx8HYNeuXZSWlrJnzx4++eQT9u3bx+7du8P6WbpLLWe9UVUCg0fB4JEtRfWFRRATQ+KkSZ3cKCIi0vd01cIVSqmpqfzoRz/iueeeIykpqaX8ww8/5LXXXgNg8eLFPPbYYy3XfvCDHxATE0NmZiYnT54EfMnZrl27mDp1KgC1tbWUlpbyrW99K4yfpnuUnPVGZUnAtk11RYUkeDzEJCdHKCgREZH+6Wc/+xnTpk3jgQce6Fb9hISElmPnXMvrE088wUMPPRSSGINJ3Zo95RxUfXZJl6ZzjvrCIo03ExERCYHhw4dzzz33sHHjxpayW265hdzcXABefvllZs+e3el7zJs3jxdeeIHa2loAKioqqKysDF3Ql0HJWU+dPQaNtZckZxcqPsd7+rTGm4mIiITIo48+esmszd/+9re8+OKLTJkyhT/84Q88++yznd5/xx13cO+993LzzTdz/fXXk5OTw7lz50Iddq+oW7On2tm2qb7INxkgUctoiIiIBM3FVi6AMWPGXLIJ+5VXXsm7774bcM9LL73U4Xs8/PDDPPzww8EPNMjUctZTF5fRGP3VmLO6wkIsPp7Ea66OUFAiIiLSXyg566mqg5Ay1revpl99YREJ116LDRoUwcBERESkP1By1lOVJZdOBmhupv7AAZI0GUBERESCQMlZTzQ3B8zUbDx8mOYvv9R4MxEREQkKJWc9ceYINNVdssbZVzsDqOVMRERELp+Ss55oZ9um+sIiLDmZQVddFaGgREREpD9RctYTVSW+19YtZ0WFJGVmYrGxEQpKRESkf0pJSQko2717N9OmTSMuLo6tW7d2eG9BQQETJ07E4/Hw9NNPt1unoaGBhQsX4vF4mDFjBkeOHAGgurqaOXPmkJKSwvLly4PyWXpCyVlPVJZAajokpgLgGhtpKDlIohafFRERCYsJEybw0ksvce+993ZYx+v1smzZMnbu3ElxcTFbtmyhuLg4oN7GjRsZNmwYZWVlPPLII6xcuRKAxMRE1q5dy/r160P2OTqjRWh7ovLgJeub1ZeW4hobNd5MRET6t52Pw4nC4L7n2OthQfstWp3JyMgAICam4/alPXv24PF4uMo/5GjRokVs376dzMzMS+pt376d1atXA5CTk8Py5ctxzjF48GBmzZpFWVlZj+MLBrWcdVezF744FDDeDFDLmYiISBSpqKhg/PjxLefp6elUVFR0Wi8uLo6hQ4dSXV0dtjg7EtKWMzObDzwLxAL/6px7us31K4EXgFHAF8A/OOfK/dfuB/6Hv+pTzrlNoYy1SzGx8M+HwNvQUlRXVEjsFVcQn54ewcBERERCrBctXNJ7IWs5M7NY4HfAAiAT+KGZZbapth74P865KcAa4H/67x0OPAnMAG4CnjSzYUTaoOSAnQESr7sOM4tgUCIiItJaWloax44dazkvLy8nLS2t03pNTU2cPXuWESNGhC3OjoSyW/MmoMw59zfnXCOQC3y/TZ1M4OKupe+1uj4PeMs594Vz7jTwFjA/hLH2WHNdHQ1lZSRqvJmIiEhUufHGGyktLeXw4cM0NjaSm5tLdnZ2QL3s7Gw2bfJ1zG3dupW5c+dGRYNLKLs104Bjrc7L8bWEtfYp8F/xdX3eBQwxsxEd3BuQ8prZg8CD4Ju9EU71JSXg9ZKk8WYiIiIhcf78edJbDR1asWIFs2fP5q677uL06dO8/vrrPPnkkxw4cOCS++Li4tiwYQPz5s3D6/WyZMkSJk+eDMCqVauYPn062dnZLF26lMWLF+PxeBg+fDi5ubkt75GRkUFNTQ2NjY1s27aNXbt2BUwoCJVIz9b8J2CDmf0Y2A1UAN7u3uycex54HmD69OkuFAF2pN6/M0DidWo5ExERCYXm5uZ2y8vLy7u8Nysri6ysrIDyNWvWtBwnJiby6quvtnv/xTXPIiGUyVkFML7Vebq/rIVz7nN8LWeYWQrw9865M2ZWAdzW5t4/hzDWHqsrLCJuzBjiR4+OdCgiIiLSj4RyzNlHwNVm9nUzGwQsAvJaVzCzkWZ2MYYn8M3cBHgTuMPMhvknAtzhL4sa9YWFGm8mIiIiQRey5Mw51wQsx5dUlQCvOOcOmNkaM7s4Ku824DMz+yswBljnv/cLYC2+BO8jYI2/LCp4a2poPHqUpOs03kxERESCK6Rjzpxz+UB+m7JVrY63Au1ujOWce4GvWtKiSn3RxcVn1XImIiIiwaUdAnqhzr8zQJImA4iIiEiQKTnrhfqiQuKvnEDs0KGRDkVERET6GSVnvVBXWKTxZiIiIiGWkpISUPbMM8+QmZnJlClTuP322zl69Gi79xYUFDBx4kQ8Hg9PP93+9lMNDQ0sXLgQj8fDjBkzWpbPqK6uZs6cOaSkpLB8+fKgfZ7uUnLWQ01VVTSdOKHxZiIiIhEwdepU9u7dy/79+8nJyeGxxx4LqOP1elm2bBk7d+6kuLiYLVu2UFxcHFBv48aNDBs2jLKyMh555BFWrlwJ+NY/W7t2LevXrw/552lPpBeh7XNaxptpZwARERkgfrnnlxz84mBQ3/Pa4dey8qaVPb5vzpw5LcczZ85k8+bNAXX27NmDx+PhqquuAmDRokVs3749YIX/7du3s3r1agBycnJYvnw5zjkGDx7MrFmzKCsr63F8waCWsx6qLyqEmBgSJ02KdCgiIiID2saNG1mwYEFAeUVFBePHf7UOfnp6OhUVFZ3Wi4uLY+jQoVRXV4cu4G5Sy1kP1RUWkeDxEJOcHOlQREREwqI3LVyhtnnzZvbu3cv7778f6VCCTi1nPeCc084AIiIiEfb222+zbt068vLySEhICLielpbGsWPHWs7Ly8tJS0vrtF5TUxNnz55lxIgRoQu8m5Sc9cCFigq8Z85ovJmIiEiEfPzxxzz00EPk5eUxuoP9rW+88UZKS0s5fPgwjY2N5Obmkp2dHVAvOzubTZs2AbB161bmzp2LmYU0/u5Qt2YP1BcWApCoZTRERERC7vz586Snp7ecr1ixgvz8fGpra7n77rsBmDBhAnl5l2zdTVxcHBs2bGDevHl4vV6WLFnC5MmTAVi1ahXTp08nOzubpUuXsnjxYjweD8OHDyc3N7flPTIyMqipqaGxsZFt27axa9eugAkFoaLkrAfqCouw+HgSr7k60qGIiIj0e83NzQFlK1as6Na9WVlZZGVlBZSvWbOm5TgxMZFXX3213fsvrnkWCerW7IH6wkISJk3CBg2KdCgiIiLSTyk56ybn9VJ/4ID20xQREZGQUrdmd5kxYdMmYgZrCQ0REREJHSVn3WQxMSRpCQ0REREJMXVrioiIiEQRJWciIiIiUUTJmYiIiESllJSUgLLdu3czbdo04uLi2Lp1a4/ufeaZZ8jMzGTKlCncfvvtHD16tN17CwoKmDhxIh6Ph6effrrdOg0NDSxcuBCPx8OMGTNalt6orq5mzpw5pKSksHz58m58ykBKzkRERKTPmDBhAi+99BL33ntvj++dOnUqe/fuZf/+/eTk5PDYY48F1PF6vSxbtoydO3dSXFzMli1bKC4uDqi3ceNGhg0bRllZGY888ggrV/r2H01MTGTt2rWsX7++5x/OTxMCREREpFMn/uVfaCg5GNT3TJh0LWN//vMe35eRkQFATEzP25fmzJnTcjxz5kw2b94cUGfPnj14PB6uuuoqABYtWsT27dsDdgfYvn07q1evBiAnJ4fly5fjnGPw4MHMmjWLsrKyHsd3kVrOREREZMDZuHEjCxYsCCivqKhg/PjxLefp6elUVFR0Wi8uLo6hQ4dSXV0dlNjUciYiIiKd6k0LVzTbvHkze/fu5f333490KO1Sy5mIiIgMGG+//Tbr1q0jLy+PhISEgOtpaWkcO3as5by8vJy0tLRO6zU1NXH27FlGjBgRlBiVnImIiMiA8PHHH/PQQw+Rl5fH6NGj261z4403UlpayuHDh2lsbCQ3N5fs7OyAetnZ2WzatAmArVu3MnfuXMwsKHGqW1NERESi0vnz50lPT285X7FiBbNnz+auu+7i9OnTvP766zz55JMcOHCgW/fm5+dTW1vL3XffDfhmfubl5V1yX1xcHBs2bGDevHl4vV6WLFnC5MmTAVi1ahXTp08nOzubpUuXsnjxYjweD8OHDyc3N7flPTIyMqipqaGxsZFt27axa9eugAkFnVFyJiIiIlGpubm53fLy8vJe3btixYpu/dysrCyysrICytesWdNynJiYyKuvvtru/RfXPOstdWuKiIiIRBElZyIiIiJRRMmZiIiItKujbkW5PM3NzTjnOryu5ExEREQCJCcnc/LkSSVoQdbc3MyJEyeoqqpqAgwIyNL6zYSAffv2nTKz9ncwDa6RwKkw/BzpOT2b6KbnE730bKJbRJ5PWlpa/O9///trxo4dmxisJSIEnHNUVVU1PfXUUxdGjBgxFKhqW6ffJGfOuVHh+Dlmttc5Nz0cP0t6Rs8muun5RC89m+gW6eeTnZ19C/DfADWhtfH5559/f9y4cdt7c69/wdoY4IW21/pNciYiIiLBl5eX90F2dnYpMAxfN5z4lZaWzhg3btyve3l7M3AyLy+vpu0FJWciIiLSqby8vCra6X4b6MysIS8v77Ngv68mBPTc85EOQDqkZxPd9Hyil55NdNPziV4heTbW2VROEREREQkvtZyJiIiIRBElZyIiIiJRRMlZN5nZfDP7zMzKzOzxSMcz0JnZC2ZWaWZFrcqGm9lbZlbqfx0WyRgHKjMbb2bvmVmxmR0ws4f95Xo+UcDMEs1sj5l96n8+v/CXf93M/sP/Hfd/zWxQpGMdqMws1sw+NrM3/Od6NlHCzI6YWaGZfWJme/1lQf9uU3LWDWYWC/wOWABkAj80s8zIRjXgvQTMb1P2OPCOc+5q4B3/uYRfE/Cocy4TmAks8/970fOJDg3AXOfcN4EbgPlmNhP4JfAb55wHOA0sjWCMA93DQEmrcz2b6DLHOXdDq7Xngv7dpuSse24Cypxzf3PONQK5wPcjHNOA5pzbDXzRpvj7wCb/8SbgB2ENSgBwzh13zv0///E5fP/JpKHnExWcT63/NN7/xwFzga3+cj2fCDGzdOBO4F/954aeTbQL+nebkrPuSQOOtTov95dJdBnjnDvuPz4BjIlkMAJmlgFMBf4DPZ+o4e82+wSoBN4CDgFnnHNN/ir6jouc/wU8xler8Y9AzyaaOGCXme0zswf9ZUH/btMitNIvOeecmWmdmAgysxTgj8DPnHM1rffm0/OJLOecF7jBzK4A/gRcG+GQBDCz7wGVzrl9ZnZbpOORds1yzlWY2WjgLTM72PpisL7b1HLWPRXA+Fbn6f4yiS4nzexrAP7XygjHM2CZWTy+xOxl59xr/mI9nyjjnDsDvAfcDFxhZhd/Ydd3XGTcCmSb2RF8w2fmAs+iZxM1nHMV/tdKfL/Y3EQIvtuUnHXPR8DV/hkzg4BFQF6EY5JAecD9/uP7gV5tRiuXxz9GZiNQ4px7ptUlPZ8oYGaj/C1mmFkS8F184wLfA3L81fR8IsA594RzLt05l4Hv/5l3nXP3oWcTFcxssJkNuXgM3AEUEYLvNu0Q0E1mloVvLEAs8IJzbl2EQxrQzGwLcBswEjgJPAlsA14BJgBHgXucc20nDUiImdks4N+BQr4aN/NzfOPO9HwizMym4Bu0HIvvF/RXnHNrzOwqfK01w4GPgX9wzjVELtKBzd+t+U/Oue/p2UQH/3P4k/80Dvg359w6MxtBkL/blJyJiIiIRBF1a4qIiIhEESVnIiIiIlFEyZmIiIhIFFFyJiIiIhJFlJyJiIiIRBElZyLSr5mZ18w+afUnaBuum1mGmRUF6/1EREDbN4lI/1fnnLsh0kGIiHSXWs5EZEAysyNm9iszKzSzPWbm8ZdnmNm7ZrbfzN4xswn+8jFm9icz+9T/5xb/W8Wa2f82swNmtsu/6j5m9lMzK/a/T26EPqaI9EFKzkSkv0tq0625sNW1s86564EN+HYAAfgtsMk5NwV4GXjOX/4c8L5z7pvANOCAv/xq4HfOucnAGeDv/eWPA1P97/PfQ/XhRKT/0Q4BItKvmVmtcy6lnfIjwFzn3N/8G7WfcM6NMLNTwNeccxf85cedcyPNrApIb71tjpllAG855672n68E4p1zT5lZAVCLb1uxbc652hB/VBHpJ9RyJiIDmevguCda73Ho5auxvHcCv8PXyvaRmWmMr4h0i5IzERnIFrZ6/dB//AGwyH98H75N3AHeAf4RwMxizWxoR29qZjHAeOfce8BKYCgQ0HonItIe/SYnIv1dkpl90uq8wDl3cTmNYWa2H1/r1w/9ZT8BXjSzfwaqgAf85Q8Dz5vZUnwtZP8IHO/gZ8YCm/0JnAHPOefOBO0TiUi/pjFnIjIg+cecTXfOnYp0LCIiralbU0RERCSKqOVMREREJIqo5UxEREQkiig5ExEREYkiSs5EREREooiSMxEREZEoouRMREREJIr8f/6T9VPLUmpWAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCF-jmzdtt_-",
        "colab_type": "text"
      },
      "source": [
        "Looking at the plot we can see that kernel regularization is detrimental in this case, namely L1. For this reason we won't use it. Regardind Bias regulizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QY5XUajwuVWN"
      },
      "source": [
        "######Bias Regularization\n",
        "Moving to Bias regularization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lWa1yHAGuVWR",
        "colab": {}
      },
      "source": [
        "def create_multi_layer_bias_reg_model(regulizer, name='multi_layer_bias_reg_model'):\n",
        "  multi_layer_model = tf.keras.Sequential(name=name)\n",
        "  multi_layer_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  multi_layer_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "  for i in range(3):\n",
        "    multi_layer_model.add(tf.keras.layers.Dense(128, activation='relu', bias_regularizer=regulizer, name='hidden{}'.format(i)))\n",
        "  multi_layer_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "\n",
        "  multi_layer_model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "  multi_layer_model.summary()\n",
        "  return multi_layer_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qhUpVNenuVWU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bca3796b-2b2d-4e47-bdf0-09f60bd369b7"
      },
      "source": [
        "regulizers = {\n",
        "    \"None\":       None, \n",
        "    \"L1 0.01\":    tf.keras.regularizers.l1(0.001), \n",
        "    \"L2 0.01\":    tf.keras.regularizers.l2(0.001), \n",
        "    \"L1 L2 0.01\": tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)}\n",
        "multi_layer_bias_reg_model_accuracy_lines = test_model_parameter(create_multi_layer_bias_reg_model, regulizers, 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"multi_layer_bias_reg_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4415 - accuracy: 0.8721 - val_loss: 0.2052 - val_accuracy: 0.9392\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1595 - accuracy: 0.9524 - val_loss: 0.1404 - val_accuracy: 0.9570\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1094 - accuracy: 0.9678 - val_loss: 0.1205 - val_accuracy: 0.9636\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0851 - accuracy: 0.9729 - val_loss: 0.1052 - val_accuracy: 0.9681\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0644 - accuracy: 0.9806 - val_loss: 0.0959 - val_accuracy: 0.9732\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0499 - accuracy: 0.9845 - val_loss: 0.1006 - val_accuracy: 0.9702\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0427 - accuracy: 0.9863 - val_loss: 0.0953 - val_accuracy: 0.9728\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 0.0964 - val_accuracy: 0.9742\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 0.0998 - val_accuracy: 0.9726\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.0928 - val_accuracy: 0.9746\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.0992 - val_accuracy: 0.9759\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.1047 - val_accuracy: 0.9723\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0998 - val_accuracy: 0.9771\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.1026 - val_accuracy: 0.9767\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.1124 - val_accuracy: 0.9727\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0140 - accuracy: 0.9953 - val_loss: 0.1466 - val_accuracy: 0.9671\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0989 - val_accuracy: 0.9781\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.1156 - val_accuracy: 0.9772\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.1231 - val_accuracy: 0.9749\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.1244 - val_accuracy: 0.9753\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.1440 - val_accuracy: 0.9711\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.1300 - val_accuracy: 0.9754\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 0.1263 - val_accuracy: 0.9768\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.1373 - val_accuracy: 0.9758\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1327 - val_accuracy: 0.9761\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.1238 - val_accuracy: 0.9772\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.1379 - val_accuracy: 0.9755\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.1359 - val_accuracy: 0.9745\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.1380 - val_accuracy: 0.9728\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.1273 - val_accuracy: 0.9778\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.1257 - val_accuracy: 0.9776\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.8189e-04 - accuracy: 0.9999 - val_loss: 0.1203 - val_accuracy: 0.9798\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.3455e-04 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9803\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.4957e-05 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9808\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.7376e-05 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9810\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.6460e-05 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9810\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.8250e-05 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9815\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.2285e-05 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9813\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.7440e-05 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9814\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.3414e-05 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9816\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.0000e-05 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 0.9815\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.6651e-05 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9818\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.4015e-05 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9818\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.1763e-05 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 0.9818\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.9468e-05 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9819\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.7896e-05 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9818\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.6289e-05 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9819\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.4734e-05 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9821\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.3372e-05 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9820\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2212e-05 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9820\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3004 - accuracy: 0.9090 - val_loss: 0.1409 - val_accuracy: 0.9597\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1025 - accuracy: 0.9688 - val_loss: 0.1051 - val_accuracy: 0.9694\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0678 - accuracy: 0.9787 - val_loss: 0.0924 - val_accuracy: 0.9728\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9847 - val_loss: 0.0874 - val_accuracy: 0.9733\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0368 - accuracy: 0.9889 - val_loss: 0.0972 - val_accuracy: 0.9728\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0265 - accuracy: 0.9919 - val_loss: 0.0801 - val_accuracy: 0.9778\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.0918 - val_accuracy: 0.9765\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.0885 - val_accuracy: 0.9772\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.0934 - val_accuracy: 0.9773\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.1063 - val_accuracy: 0.9736\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.1128 - val_accuracy: 0.9739\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.1130 - val_accuracy: 0.9754\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.1207 - val_accuracy: 0.9737\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.1131 - val_accuracy: 0.9755\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.1215 - val_accuracy: 0.9758\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.1104 - val_accuracy: 0.9783\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.1224 - val_accuracy: 0.9753\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.1213 - val_accuracy: 0.9743\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1251 - val_accuracy: 0.9779\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.1185 - val_accuracy: 0.9789\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.1162e-04 - accuracy: 0.9999 - val_loss: 0.1200 - val_accuracy: 0.9791\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.6052e-04 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9789\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.1057e-04 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9792\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.0322e-05 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9790\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.6559e-05 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9789\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.6676e-05 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9793\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.9356e-05 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9791\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.2318e-05 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9794\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.6322e-05 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9793\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.1899e-05 - accuracy: 1.0000 - val_loss: 0.1291 - val_accuracy: 0.9794\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.7603e-05 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9794\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.3854e-05 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9794\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.0348e-05 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9797\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.7527e-05 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9794\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.5361e-05 - accuracy: 1.0000 - val_loss: 0.1340 - val_accuracy: 0.9796\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.2570e-05 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9796\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.0712e-05 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9796\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.8901e-05 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9797\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.6962e-05 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9796\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.5382e-05 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9796\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.3914e-05 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9795\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2712e-05 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9794\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.1691e-05 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9794\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0394e-05 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9793\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.4990e-06 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9794\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.6349e-06 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9795\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.7932e-06 - accuracy: 1.0000 - val_loss: 0.1482 - val_accuracy: 0.9795\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.0529e-06 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9794\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.4254e-06 - accuracy: 1.0000 - val_loss: 0.1506 - val_accuracy: 0.9797\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.8403e-06 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9795\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2882 - accuracy: 0.9121 - val_loss: 0.1401 - val_accuracy: 0.9596\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1046 - accuracy: 0.9678 - val_loss: 0.1113 - val_accuracy: 0.9655\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0691 - accuracy: 0.9793 - val_loss: 0.1013 - val_accuracy: 0.9694\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0521 - accuracy: 0.9844 - val_loss: 0.0880 - val_accuracy: 0.9733\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0378 - accuracy: 0.9888 - val_loss: 0.0843 - val_accuracy: 0.9739\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0282 - accuracy: 0.9917 - val_loss: 0.0831 - val_accuracy: 0.9771\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.0820 - val_accuracy: 0.9782\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.0928 - val_accuracy: 0.9758\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.0954 - val_accuracy: 0.9756\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.0872 - val_accuracy: 0.9790\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0968 - val_accuracy: 0.9774\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.1090 - val_accuracy: 0.9748\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.1268 - val_accuracy: 0.9738\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.1113 - val_accuracy: 0.9768\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.1147 - val_accuracy: 0.9779\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1140 - val_accuracy: 0.9773\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.1198 - val_accuracy: 0.9774\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.1180 - val_accuracy: 0.9766\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.6874e-04 - accuracy: 0.9998 - val_loss: 0.1132 - val_accuracy: 0.9793\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.1431 - val_accuracy: 0.9757\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.1365 - val_accuracy: 0.9763\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.1274 - val_accuracy: 0.9766\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.1316 - val_accuracy: 0.9755\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1296 - val_accuracy: 0.9781\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.1321 - val_accuracy: 0.9779\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.1923 - val_accuracy: 0.9681\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.1394 - val_accuracy: 0.9760\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.1282 - val_accuracy: 0.9787\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.8873e-04 - accuracy: 0.9999 - val_loss: 0.1300 - val_accuracy: 0.9797\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.9449e-04 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9800\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.1955e-05 - accuracy: 1.0000 - val_loss: 0.1312 - val_accuracy: 0.9798\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.8989e-05 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9797\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.9673e-05 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9797\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.3333e-05 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9799\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.8040e-05 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9800\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.3571e-05 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9798\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.9770e-05 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9799\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.6589e-05 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9802\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.3871e-05 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9798\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.1444e-05 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9799\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.9326e-05 - accuracy: 1.0000 - val_loss: 0.1414 - val_accuracy: 0.9798\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.7404e-05 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9798\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5758e-05 - accuracy: 1.0000 - val_loss: 0.1432 - val_accuracy: 0.9797\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.4225e-05 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9796\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2879e-05 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9797\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.1690e-05 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9797\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0626e-05 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9797\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 9.5885e-06 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9799\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.6330e-06 - accuracy: 1.0000 - val_loss: 0.1490 - val_accuracy: 0.9798\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.8371e-06 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9803\n",
            "Model: \"multi_layer_bias_reg_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4318 - accuracy: 0.8802 - val_loss: 0.2049 - val_accuracy: 0.9418\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1556 - accuracy: 0.9539 - val_loss: 0.1626 - val_accuracy: 0.9517\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1097 - accuracy: 0.9664 - val_loss: 0.1212 - val_accuracy: 0.9647\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0801 - accuracy: 0.9756 - val_loss: 0.1100 - val_accuracy: 0.9657\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0634 - accuracy: 0.9805 - val_loss: 0.1198 - val_accuracy: 0.9653\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0506 - accuracy: 0.9843 - val_loss: 0.1010 - val_accuracy: 0.9705\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0415 - accuracy: 0.9869 - val_loss: 0.1025 - val_accuracy: 0.9689\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9900 - val_loss: 0.1016 - val_accuracy: 0.9718\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9925 - val_loss: 0.1074 - val_accuracy: 0.9696\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.1026 - val_accuracy: 0.9731\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.1041 - val_accuracy: 0.9745\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 0.1240 - val_accuracy: 0.9697\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0165 - accuracy: 0.9952 - val_loss: 0.1197 - val_accuracy: 0.9711\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.1169 - val_accuracy: 0.9705\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 0.1136 - val_accuracy: 0.9734\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.1122 - val_accuracy: 0.9749\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.1241 - val_accuracy: 0.9730\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.1400 - val_accuracy: 0.9715\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.1289 - val_accuracy: 0.9748\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.1329 - val_accuracy: 0.9719\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1269 - val_accuracy: 0.9754\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1255 - val_accuracy: 0.9751\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.1472 - val_accuracy: 0.9728\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.1436 - val_accuracy: 0.9718\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0125 - accuracy: 0.9963 - val_loss: 0.1434 - val_accuracy: 0.9734\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.1364 - val_accuracy: 0.9767\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.1287 - val_accuracy: 0.9770\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.1332 - val_accuracy: 0.9766\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.1519 - val_accuracy: 0.9744\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.1793 - val_accuracy: 0.9678\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.1573 - val_accuracy: 0.9739\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1613 - val_accuracy: 0.9720\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.1570 - val_accuracy: 0.9741\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.1771 - val_accuracy: 0.9706\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.1455 - val_accuracy: 0.9752\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.1377 - val_accuracy: 0.9777\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.9871e-04 - accuracy: 0.9999 - val_loss: 0.1325 - val_accuracy: 0.9794\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.2530e-04 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9794\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.6688e-05 - accuracy: 1.0000 - val_loss: 0.1339 - val_accuracy: 0.9793\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.3709e-05 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9794\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.6007e-05 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9793\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.0506e-05 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 0.9792\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.6291e-05 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9795\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.2622e-05 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9793\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.0188e-05 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9794\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.7536e-05 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 0.9795\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.6374e-05 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9797\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.4613e-05 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9797\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.2406e-05 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9797\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.1486e-05 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9797\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3106 - accuracy: 0.9065 - val_loss: 0.1465 - val_accuracy: 0.9566\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1041 - accuracy: 0.9690 - val_loss: 0.1103 - val_accuracy: 0.9675\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0683 - accuracy: 0.9791 - val_loss: 0.0930 - val_accuracy: 0.9732\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0487 - accuracy: 0.9852 - val_loss: 0.0924 - val_accuracy: 0.9724\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0348 - accuracy: 0.9897 - val_loss: 0.0904 - val_accuracy: 0.9728\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 0.0948 - val_accuracy: 0.9738\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0918 - val_accuracy: 0.9752\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.1040 - val_accuracy: 0.9737\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.1028 - val_accuracy: 0.9756\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 0.1029 - val_accuracy: 0.9762\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.1153 - val_accuracy: 0.9748\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1334 - val_accuracy: 0.9735\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.1248 - val_accuracy: 0.9728\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.1116 - val_accuracy: 0.9764\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1260 - val_accuracy: 0.9752\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1164 - val_accuracy: 0.9782\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.1377 - val_accuracy: 0.9753\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.1229 - val_accuracy: 0.9760\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.1149 - val_accuracy: 0.9775\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.1354 - val_accuracy: 0.9766\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.1331 - val_accuracy: 0.9770\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.1418 - val_accuracy: 0.9756\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9962 - val_loss: 0.1413 - val_accuracy: 0.9736\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 0.1381 - val_accuracy: 0.9753\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.1388 - val_accuracy: 0.9777\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.3100e-04 - accuracy: 0.9999 - val_loss: 0.1322 - val_accuracy: 0.9787\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.6061e-04 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9791\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1384 - val_accuracy: 0.9785\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.6776e-04 - accuracy: 0.9998 - val_loss: 0.1347 - val_accuracy: 0.9796\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.1476 - val_accuracy: 0.9763\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.1509 - val_accuracy: 0.9729\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1381 - val_accuracy: 0.9759\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.1421 - val_accuracy: 0.9769\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1467 - val_accuracy: 0.9776\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1400 - val_accuracy: 0.9762\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.1530 - val_accuracy: 0.9735\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.1518 - val_accuracy: 0.9762\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1467 - val_accuracy: 0.9755\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.1595 - val_accuracy: 0.9758\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.1788 - val_accuracy: 0.9710\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.1347 - val_accuracy: 0.9787\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.4235e-04 - accuracy: 0.9998 - val_loss: 0.1365 - val_accuracy: 0.9787\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.7151e-04 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9789\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.6036e-05 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9793\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.4754e-05 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9797\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.7607e-05 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9799\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.3145e-05 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9799\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.9059e-05 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9800\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.6933e-05 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9801\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.4672e-05 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9801\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3261 - accuracy: 0.9031 - val_loss: 0.1415 - val_accuracy: 0.9603\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1088 - accuracy: 0.9668 - val_loss: 0.1176 - val_accuracy: 0.9663\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0714 - accuracy: 0.9778 - val_loss: 0.0989 - val_accuracy: 0.9715\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0505 - accuracy: 0.9843 - val_loss: 0.0871 - val_accuracy: 0.9747\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0389 - accuracy: 0.9876 - val_loss: 0.0901 - val_accuracy: 0.9735\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0287 - accuracy: 0.9907 - val_loss: 0.0913 - val_accuracy: 0.9739\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.0917 - val_accuracy: 0.9750\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.0844 - val_accuracy: 0.9766\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9967 - val_loss: 0.1014 - val_accuracy: 0.9744\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.0965 - val_accuracy: 0.9743\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.1014 - val_accuracy: 0.9760\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.1073 - val_accuracy: 0.9758\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.1124 - val_accuracy: 0.9769\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9990 - val_loss: 0.1054 - val_accuracy: 0.9782\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.1189 - val_accuracy: 0.9753\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.1230 - val_accuracy: 0.9753\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.1274 - val_accuracy: 0.9748\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1166 - val_accuracy: 0.9772\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1294 - val_accuracy: 0.9754\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.1182 - val_accuracy: 0.9784\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.1350 - val_accuracy: 0.9755\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.1214 - val_accuracy: 0.9752\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.1168 - val_accuracy: 0.9786\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.1335 - val_accuracy: 0.9746\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.1172 - val_accuracy: 0.9789\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.1440e-04 - accuracy: 0.9999 - val_loss: 0.1161 - val_accuracy: 0.9796\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.1057e-04 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9799\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.2560e-04 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9805\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0370e-04 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9805\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.2166e-05 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9807\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.4782e-05 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9805\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.7808e-05 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9805\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.3806e-05 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 0.9805\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.9924e-05 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9803\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.6633e-05 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9803\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.3593e-05 - accuracy: 1.0000 - val_loss: 0.1295 - val_accuracy: 0.9804\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.1111e-05 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9802\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.9728e-05 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9805\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.7172e-05 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9803\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.5541e-05 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9803\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.3517e-05 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9803\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.2632e-05 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9802\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.1627e-05 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9803\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.0662e-05 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9801\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.9748e-05 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9802\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.8516e-05 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9804\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.8012e-05 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9803\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.7217e-05 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9803\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.6796e-05 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9801\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.6744e-05 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9799\n",
            "Model: \"multi_layer_bias_reg_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4438 - accuracy: 0.8731 - val_loss: 0.1856 - val_accuracy: 0.9456\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1505 - accuracy: 0.9551 - val_loss: 0.1432 - val_accuracy: 0.9555\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1035 - accuracy: 0.9686 - val_loss: 0.1186 - val_accuracy: 0.9657\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0774 - accuracy: 0.9768 - val_loss: 0.1129 - val_accuracy: 0.9666\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0599 - accuracy: 0.9814 - val_loss: 0.1014 - val_accuracy: 0.9706\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0481 - accuracy: 0.9851 - val_loss: 0.0913 - val_accuracy: 0.9732\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0388 - accuracy: 0.9881 - val_loss: 0.0947 - val_accuracy: 0.9719\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0314 - accuracy: 0.9905 - val_loss: 0.0898 - val_accuracy: 0.9747\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0267 - accuracy: 0.9914 - val_loss: 0.0960 - val_accuracy: 0.9748\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9925 - val_loss: 0.0944 - val_accuracy: 0.9754\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.1106 - val_accuracy: 0.9730\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.1140 - val_accuracy: 0.9739\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.1142 - val_accuracy: 0.9741\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.1104 - val_accuracy: 0.9752\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.1156 - val_accuracy: 0.9751\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.1100 - val_accuracy: 0.9765\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.1211 - val_accuracy: 0.9755\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.1314 - val_accuracy: 0.9725\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.1221 - val_accuracy: 0.9752\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.1301 - val_accuracy: 0.9738\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.1383 - val_accuracy: 0.9716\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.1293 - val_accuracy: 0.9743\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.1339 - val_accuracy: 0.9770\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.1353 - val_accuracy: 0.9726\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.1504 - val_accuracy: 0.9741\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1398 - val_accuracy: 0.9755\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 0.1483 - val_accuracy: 0.9733\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1256 - val_accuracy: 0.9761\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.1236 - val_accuracy: 0.9781\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.1321 - val_accuracy: 0.9784\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.1506e-04 - accuracy: 0.9999 - val_loss: 0.1256 - val_accuracy: 0.9798\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.3431e-04 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9802\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.3125e-05 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9806\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.6723e-05 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9804\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.6390e-05 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9806\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.8056e-05 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9806\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.1965e-05 - accuracy: 1.0000 - val_loss: 0.1303 - val_accuracy: 0.9808\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.6708e-05 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9806\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.2469e-05 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9808\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.8885e-05 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9806\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.5982e-05 - accuracy: 1.0000 - val_loss: 0.1350 - val_accuracy: 0.9805\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.3558e-05 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9807\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.1223e-05 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9808\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.9142e-05 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9806\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.7454e-05 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9807\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5898e-05 - accuracy: 1.0000 - val_loss: 0.1398 - val_accuracy: 0.9805\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.4321e-05 - accuracy: 1.0000 - val_loss: 0.1409 - val_accuracy: 0.9807\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.3260e-05 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9807\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1928e-05 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9807\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0945e-05 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9808\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3035 - accuracy: 0.9090 - val_loss: 0.1643 - val_accuracy: 0.9507\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1065 - accuracy: 0.9674 - val_loss: 0.1107 - val_accuracy: 0.9664\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0696 - accuracy: 0.9781 - val_loss: 0.1326 - val_accuracy: 0.9599\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0542 - accuracy: 0.9833 - val_loss: 0.0871 - val_accuracy: 0.9744\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0367 - accuracy: 0.9887 - val_loss: 0.0822 - val_accuracy: 0.9762\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.0874 - val_accuracy: 0.9753\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0223 - accuracy: 0.9930 - val_loss: 0.0866 - val_accuracy: 0.9781\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0957 - val_accuracy: 0.9758\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0990 - val_accuracy: 0.9781\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9972 - val_loss: 0.1099 - val_accuracy: 0.9755\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.1147 - val_accuracy: 0.9740\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.1030 - val_accuracy: 0.9785\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.1101 - val_accuracy: 0.9772\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.1138 - val_accuracy: 0.9779\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.1267 - val_accuracy: 0.9758\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1260 - val_accuracy: 0.9760\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.1489 - val_accuracy: 0.9726\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.1333 - val_accuracy: 0.9748\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1153 - val_accuracy: 0.9787\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.1264 - val_accuracy: 0.9777\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.1337 - val_accuracy: 0.9763\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.1377 - val_accuracy: 0.9759\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.1349 - val_accuracy: 0.9763\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.1235 - val_accuracy: 0.9793\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1402 - val_accuracy: 0.9772\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.1298 - val_accuracy: 0.9771\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1323 - val_accuracy: 0.9778\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.1265 - val_accuracy: 0.9787\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.1334 - val_accuracy: 0.9792\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.7937e-04 - accuracy: 0.9998 - val_loss: 0.1301 - val_accuracy: 0.9809\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5494e-04 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9815\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.8215e-05 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9813\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.0959e-05 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9811\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.2448e-05 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.9813\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.6433e-05 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9812\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.1772e-05 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9812\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.8071e-05 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9812\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.4849e-05 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9812\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.2213e-05 - accuracy: 1.0000 - val_loss: 0.1368 - val_accuracy: 0.9814\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.9980e-05 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9814\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.7954e-05 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9814\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.6232e-05 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9815\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.4754e-05 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9813\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.3362e-05 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9815\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.2081e-05 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.9814\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1016e-05 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9812\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0051e-05 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9815\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.0706e-06 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9813\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.3226e-06 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9812\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.5884e-06 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9814\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2936 - accuracy: 0.9099 - val_loss: 0.1444 - val_accuracy: 0.9588\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0997 - accuracy: 0.9696 - val_loss: 0.1244 - val_accuracy: 0.9628\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0696 - accuracy: 0.9790 - val_loss: 0.0975 - val_accuracy: 0.9721\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0502 - accuracy: 0.9847 - val_loss: 0.0902 - val_accuracy: 0.9733\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0376 - accuracy: 0.9883 - val_loss: 0.0897 - val_accuracy: 0.9739\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.0861 - val_accuracy: 0.9754\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.0895 - val_accuracy: 0.9752\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.1027 - val_accuracy: 0.9743\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.1017 - val_accuracy: 0.9742\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.1043 - val_accuracy: 0.9762\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.1026 - val_accuracy: 0.9772\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.1209 - val_accuracy: 0.9737\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.1120 - val_accuracy: 0.9758\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.1171 - val_accuracy: 0.9753\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.1126 - val_accuracy: 0.9766\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.1156 - val_accuracy: 0.9768\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1316 - val_accuracy: 0.9755\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.1187 - val_accuracy: 0.9777\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.1205 - val_accuracy: 0.9788\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.0554e-04 - accuracy: 0.9999 - val_loss: 0.1236 - val_accuracy: 0.9786\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.7965e-04 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9796\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5212e-04 - accuracy: 1.0000 - val_loss: 0.1260 - val_accuracy: 0.9795\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1613e-04 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9796\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.6708e-05 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9798\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.3611e-05 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9797\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.2510e-05 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9797\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.3613e-05 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9801\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.5848e-05 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9798\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.0372e-05 - accuracy: 1.0000 - val_loss: 0.1364 - val_accuracy: 0.9797\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.4617e-05 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9801\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.1303e-05 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9798\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.6186e-05 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9797\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.2856e-05 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9797\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.9633e-05 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 0.9797\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.6437e-05 - accuracy: 1.0000 - val_loss: 0.1434 - val_accuracy: 0.9799\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.4242e-05 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9797\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.1869e-05 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9799\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.9604e-05 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9801\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.7911e-05 - accuracy: 1.0000 - val_loss: 0.1486 - val_accuracy: 0.9797\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.6573e-05 - accuracy: 1.0000 - val_loss: 0.1496 - val_accuracy: 0.9799\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0483 - accuracy: 0.9879 - val_loss: 0.1191 - val_accuracy: 0.9712\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0188 - accuracy: 0.9934 - val_loss: 0.1291 - val_accuracy: 0.9733\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1194 - val_accuracy: 0.9753\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.1178 - val_accuracy: 0.9793\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.6989e-04 - accuracy: 0.9999 - val_loss: 0.1259 - val_accuracy: 0.9784\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.7068e-04 - accuracy: 0.9999 - val_loss: 0.1260 - val_accuracy: 0.9797\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5791e-04 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9799\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1016e-04 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 0.9797\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.7019e-05 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9795\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.2799e-05 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9797\n",
            "Model: \"multi_layer_bias_reg_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4322 - accuracy: 0.8792 - val_loss: 0.2012 - val_accuracy: 0.9453\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1519 - accuracy: 0.9553 - val_loss: 0.1442 - val_accuracy: 0.9576\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1078 - accuracy: 0.9682 - val_loss: 0.1229 - val_accuracy: 0.9657\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0799 - accuracy: 0.9759 - val_loss: 0.1150 - val_accuracy: 0.9674\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0635 - accuracy: 0.9804 - val_loss: 0.1014 - val_accuracy: 0.9705\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0526 - accuracy: 0.9838 - val_loss: 0.1002 - val_accuracy: 0.9713\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0420 - accuracy: 0.9876 - val_loss: 0.1100 - val_accuracy: 0.9688\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9895 - val_loss: 0.0897 - val_accuracy: 0.9741\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0290 - accuracy: 0.9909 - val_loss: 0.0905 - val_accuracy: 0.9760\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 0.0963 - val_accuracy: 0.9753\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.1023 - val_accuracy: 0.9726\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.1048 - val_accuracy: 0.9747\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9951 - val_loss: 0.1043 - val_accuracy: 0.9736\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0960 - val_accuracy: 0.9764\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.1110 - val_accuracy: 0.9743\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.1074 - val_accuracy: 0.9762\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.1021 - val_accuracy: 0.9785\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.1065 - val_accuracy: 0.9773\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1250 - val_accuracy: 0.9742\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.1393 - val_accuracy: 0.9703\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.1137 - val_accuracy: 0.9761\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1223 - val_accuracy: 0.9772\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1272 - val_accuracy: 0.9758\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.1245 - val_accuracy: 0.9768\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.1317 - val_accuracy: 0.9769\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1414 - val_accuracy: 0.9746\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.1396 - val_accuracy: 0.9740\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.1236 - val_accuracy: 0.9763\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.1321 - val_accuracy: 0.9757\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1343 - val_accuracy: 0.9759\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.1229 - val_accuracy: 0.9774\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.1426 - val_accuracy: 0.9738\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.1358 - val_accuracy: 0.9771\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1336 - val_accuracy: 0.9780\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.3244e-04 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9792\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.6591e-04 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9800\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1332e-04 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9797\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.1965e-05 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9799\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.2834e-05 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9804\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.5768e-05 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9801\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.1219e-05 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9802\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.6686e-05 - accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9803\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.3872e-05 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 0.9804\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.0730e-05 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9801\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.8674e-05 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9804\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.7132e-05 - accuracy: 1.0000 - val_loss: 0.1372 - val_accuracy: 0.9803\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.5477e-05 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9802\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.3930e-05 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9802\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.3163e-05 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9801\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.2068e-05 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9799\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3077 - accuracy: 0.9086 - val_loss: 0.1415 - val_accuracy: 0.9579\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1070 - accuracy: 0.9675 - val_loss: 0.1059 - val_accuracy: 0.9682\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0699 - accuracy: 0.9787 - val_loss: 0.0902 - val_accuracy: 0.9735\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0501 - accuracy: 0.9848 - val_loss: 0.0950 - val_accuracy: 0.9718\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 0.0860 - val_accuracy: 0.9762\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0265 - accuracy: 0.9924 - val_loss: 0.0818 - val_accuracy: 0.9763\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0213 - accuracy: 0.9935 - val_loss: 0.0900 - val_accuracy: 0.9762\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0174 - accuracy: 0.9949 - val_loss: 0.0874 - val_accuracy: 0.9774\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0124 - accuracy: 0.9965 - val_loss: 0.0979 - val_accuracy: 0.9752\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.0913 - val_accuracy: 0.9756\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.1195 - val_accuracy: 0.9737\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.0987 - val_accuracy: 0.9758\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 0.0975 - val_accuracy: 0.9770\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.1149 - val_accuracy: 0.9745\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.1144 - val_accuracy: 0.9764\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.1168 - val_accuracy: 0.9757\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.1227 - val_accuracy: 0.9761\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.1276 - val_accuracy: 0.9756\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.1358 - val_accuracy: 0.9750\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1171 - val_accuracy: 0.9765\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1252 - val_accuracy: 0.9762\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.1180 - val_accuracy: 0.9782\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.1202 - val_accuracy: 0.9790\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.9030e-04 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9804\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.2916e-04 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9801\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0847e-04 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9801\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.8237e-05 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9803\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.9722e-05 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9800\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.3556e-05 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9797\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.8577e-05 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9800\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.3755e-05 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9799\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.0997e-05 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9802\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.7580e-05 - accuracy: 1.0000 - val_loss: 0.1290 - val_accuracy: 0.9802\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.4880e-05 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 0.9803\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.2849e-05 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9802\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.0926e-05 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9800\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.9548e-05 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9804\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.7529e-05 - accuracy: 1.0000 - val_loss: 0.1337 - val_accuracy: 0.9804\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.7085e-05 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.9805\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.5389e-05 - accuracy: 1.0000 - val_loss: 0.1359 - val_accuracy: 0.9805\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.3716e-05 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.9807\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.2511e-05 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9806\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.1421e-05 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9805\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.0744e-05 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9808\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.9787e-05 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9805\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.9216e-05 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9807\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.8661e-05 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9806\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.8181e-05 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9804\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.7926e-05 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9808\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.7153e-05 - accuracy: 1.0000 - val_loss: 0.1459 - val_accuracy: 0.9811\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2871 - accuracy: 0.9147 - val_loss: 0.1388 - val_accuracy: 0.9594\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0999 - accuracy: 0.9697 - val_loss: 0.1104 - val_accuracy: 0.9691\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0666 - accuracy: 0.9791 - val_loss: 0.0940 - val_accuracy: 0.9726\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0498 - accuracy: 0.9846 - val_loss: 0.0880 - val_accuracy: 0.9761\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0370 - accuracy: 0.9891 - val_loss: 0.0837 - val_accuracy: 0.9753\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.0817 - val_accuracy: 0.9765\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 0.0895 - val_accuracy: 0.9748\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.0876 - val_accuracy: 0.9763\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.0961 - val_accuracy: 0.9758\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.1011 - val_accuracy: 0.9764\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.1188 - val_accuracy: 0.9708\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.1021 - val_accuracy: 0.9761\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1071 - val_accuracy: 0.9767\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.1044 - val_accuracy: 0.9771\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.1062 - val_accuracy: 0.9781\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1214 - val_accuracy: 0.9768\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.1353 - val_accuracy: 0.9727\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.1130 - val_accuracy: 0.9781\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.1327 - val_accuracy: 0.9756\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.1208 - val_accuracy: 0.9784\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.1412 - val_accuracy: 0.9746\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.1400 - val_accuracy: 0.9743\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.1261 - val_accuracy: 0.9768\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1170 - val_accuracy: 0.9792\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.9978e-04 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9801\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.0294e-04 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9802\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5233e-04 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9804\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.2764e-04 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9804\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1292e-04 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9803\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0296e-04 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9805\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.3856e-05 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 0.9802\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.7333e-05 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9806\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.1606e-05 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9802\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.7000e-05 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.9805\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.3078e-05 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9805\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.9182e-05 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9804\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.6388e-05 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9805\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.3346e-05 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9804\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.1019e-05 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9804\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.9774e-05 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9806\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.7798e-05 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9805\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.7568e-05 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9806\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.4782e-05 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9805\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.3236e-05 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9803\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.2217e-05 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9803\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.0859e-05 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 0.9803\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.9745e-05 - accuracy: 1.0000 - val_loss: 0.1467 - val_accuracy: 0.9802\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.9288e-05 - accuracy: 1.0000 - val_loss: 0.1473 - val_accuracy: 0.9804\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.8708e-05 - accuracy: 1.0000 - val_loss: 0.1486 - val_accuracy: 0.9804\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.7953e-05 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3XLBF2M9uVWW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "17dac5e8-f249-4b1a-b064-d309ac8256c1"
      },
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "multiple_line_chart(plt.gca(), \n",
        "                    None, \n",
        "                    multi_layer_bias_reg_model_accuracy_lines, \n",
        "                    \"Validation accuracy variation per type of bias regulizer\", \n",
        "                    \"Epochs\", \n",
        "                    \"Validation accuracy\")\n",
        "plt.show()\n",
        "plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0disLv-IuVWX"
      },
      "source": [
        "Looking at the plot we can see that bias regularization appears to have no impact in the final accuracy. It does however impact convergence, converging a little  bit faster with L2, whilst L1 takes considerably longer to converge. Since the benefits of L2 aren't very noticeable, we won't use any bias regularization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "veOMwgu-vSMV"
      },
      "source": [
        "######Activity Regularization\n",
        "Let us now end with activity regularization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0qzdDCl6vSMX",
        "colab": {}
      },
      "source": [
        "def create_multi_layer_activity_reg_model(regulizer, name='multi_layer_activity_reg_model'):\n",
        "  multi_layer_model = tf.keras.Sequential(name=name)\n",
        "  multi_layer_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "  multi_layer_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "  for i in range(3):\n",
        "    multi_layer_model.add(tf.keras.layers.Dense(128, activation='relu', activity_regularizer=regulizer, name='hidden{}'.format(i)))\n",
        "  multi_layer_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "\n",
        "  multi_layer_model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "  multi_layer_model.summary()\n",
        "  return multi_layer_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XxsersqDvSMZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "585b0660-4573-4c06-9d3e-7d39439d4bb8"
      },
      "source": [
        "regulizers = {\n",
        "    \"None\":       None, \n",
        "    \"L1 0.01\":    tf.keras.regularizers.l1(0.001), \n",
        "    \"L2 0.01\":    tf.keras.regularizers.l2(0.001), \n",
        "    \"L1 L2 0.01\": tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)}\n",
        "multi_layer_activity_reg_model_accuracy_lines = test_model_parameter(create_multi_layer_activity_reg_model, regulizers, 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"multi_layer_activity_reg_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4287 - accuracy: 0.8770 - val_loss: 0.2139 - val_accuracy: 0.9387\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1562 - accuracy: 0.9535 - val_loss: 0.1436 - val_accuracy: 0.9591\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1073 - accuracy: 0.9681 - val_loss: 0.1180 - val_accuracy: 0.9653\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0837 - accuracy: 0.9740 - val_loss: 0.1075 - val_accuracy: 0.9680\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0644 - accuracy: 0.9804 - val_loss: 0.0959 - val_accuracy: 0.9711\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0504 - accuracy: 0.9839 - val_loss: 0.0970 - val_accuracy: 0.9719\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9870 - val_loss: 0.0957 - val_accuracy: 0.9728\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0344 - accuracy: 0.9898 - val_loss: 0.0885 - val_accuracy: 0.9743\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 0.0860 - val_accuracy: 0.9762\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0952 - val_accuracy: 0.9738\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0187 - accuracy: 0.9936 - val_loss: 0.1149 - val_accuracy: 0.9673\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.0934 - val_accuracy: 0.9762\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 0.0954 - val_accuracy: 0.9764\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0943 - val_accuracy: 0.9772\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.1110 - val_accuracy: 0.9747\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.0977 - val_accuracy: 0.9743\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.0986 - val_accuracy: 0.9769\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0997 - val_accuracy: 0.9776\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.1201 - val_accuracy: 0.9732\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 0.1246 - val_accuracy: 0.9740\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.1069 - val_accuracy: 0.9782\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1215 - val_accuracy: 0.9764\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.1099 - val_accuracy: 0.9766\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0147 - accuracy: 0.9954 - val_loss: 0.1153 - val_accuracy: 0.9773\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.9968 - val_loss: 0.1187 - val_accuracy: 0.9763\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.1109 - val_accuracy: 0.9785\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.1144 - val_accuracy: 0.9773\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.1118 - val_accuracy: 0.9787\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.1556 - val_accuracy: 0.9709\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.1304 - val_accuracy: 0.9751\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.1158 - val_accuracy: 0.9777\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1163 - val_accuracy: 0.9787\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.1133 - val_accuracy: 0.9803\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.1490 - val_accuracy: 0.9745\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1173 - val_accuracy: 0.9789\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.1474 - val_accuracy: 0.9737\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.1134 - val_accuracy: 0.9794\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1266 - val_accuracy: 0.9777\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.1144 - val_accuracy: 0.9809\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.1096 - val_accuracy: 0.9809\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.4141e-04 - accuracy: 0.9999 - val_loss: 0.1162 - val_accuracy: 0.9808\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.8261e-04 - accuracy: 0.9999 - val_loss: 0.1085 - val_accuracy: 0.9825\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.1049e-05 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9827\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.1874e-05 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 0.9826\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.4196e-05 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9827\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.9217e-05 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9827\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.5398e-05 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 0.9827\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.2305e-05 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9827\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.0058e-05 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9830\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.7940e-05 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9831\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3271 - accuracy: 0.8997 - val_loss: 0.1554 - val_accuracy: 0.9549\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1103 - accuracy: 0.9672 - val_loss: 0.1210 - val_accuracy: 0.9644\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0723 - accuracy: 0.9781 - val_loss: 0.1073 - val_accuracy: 0.9683\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0537 - accuracy: 0.9833 - val_loss: 0.0879 - val_accuracy: 0.9741\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0396 - accuracy: 0.9878 - val_loss: 0.0860 - val_accuracy: 0.9753\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9911 - val_loss: 0.0859 - val_accuracy: 0.9764\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 0.0856 - val_accuracy: 0.9764\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0146 - accuracy: 0.9960 - val_loss: 0.0891 - val_accuracy: 0.9759\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.0951 - val_accuracy: 0.9755\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0969 - val_accuracy: 0.9757\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 0.0989 - val_accuracy: 0.9756\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 0.1042 - val_accuracy: 0.9758\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.1073 - val_accuracy: 0.9754\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.1102 - val_accuracy: 0.9761\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.1183 - val_accuracy: 0.9757\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.1196 - val_accuracy: 0.9764\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.1161 - val_accuracy: 0.9765\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.1179 - val_accuracy: 0.9765\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1234 - val_accuracy: 0.9763\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1318 - val_accuracy: 0.9763\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.1596 - val_accuracy: 0.9702\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.1230 - val_accuracy: 0.9767\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1183 - val_accuracy: 0.9778\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1235 - val_accuracy: 0.9785\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.1246 - val_accuracy: 0.9781\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.1176 - val_accuracy: 0.9792\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.1276e-04 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9807\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.0631e-05 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9807\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.3503e-05 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9808\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.3112e-05 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9807\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.6069e-05 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9806\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.0312e-05 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9808\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.5839e-05 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9808\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.1848e-05 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9808\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.8562e-05 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9806\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.5641e-05 - accuracy: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9806\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.3116e-05 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 0.9805\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.0871e-05 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9804\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.8971e-05 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9803\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.7159e-05 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9801\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.5587e-05 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9801\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.4113e-05 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9803\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.2872e-05 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9799\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.1735e-05 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9801\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0689e-05 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9799\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.6695e-06 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9801\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.8054e-06 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9798\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.0263e-06 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9803\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.3490e-06 - accuracy: 1.0000 - val_loss: 0.1437 - val_accuracy: 0.9802\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.7263e-06 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 0.9800\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2978 - accuracy: 0.9084 - val_loss: 0.1410 - val_accuracy: 0.9597\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1047 - accuracy: 0.9684 - val_loss: 0.1103 - val_accuracy: 0.9677\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0725 - accuracy: 0.9772 - val_loss: 0.1010 - val_accuracy: 0.9696\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0521 - accuracy: 0.9839 - val_loss: 0.0965 - val_accuracy: 0.9720\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0392 - accuracy: 0.9880 - val_loss: 0.0975 - val_accuracy: 0.9719\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.9905 - val_loss: 0.0926 - val_accuracy: 0.9748\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 0.1013 - val_accuracy: 0.9718\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0181 - accuracy: 0.9946 - val_loss: 0.1009 - val_accuracy: 0.9739\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 0.1110 - val_accuracy: 0.9724\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.1012 - val_accuracy: 0.9755\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.1082 - val_accuracy: 0.9737\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.1053 - val_accuracy: 0.9753\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1143 - val_accuracy: 0.9752\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 0.1139 - val_accuracy: 0.9764\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.1129 - val_accuracy: 0.9779\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.1131 - val_accuracy: 0.9786\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.9934e-04 - accuracy: 0.9999 - val_loss: 0.1160 - val_accuracy: 0.9781\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.3559e-04 - accuracy: 0.9999 - val_loss: 0.1305 - val_accuracy: 0.9770\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.1499 - val_accuracy: 0.9715\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.1223 - val_accuracy: 0.9747\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.1237 - val_accuracy: 0.9761\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.1244 - val_accuracy: 0.9761\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.1269 - val_accuracy: 0.9768\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.9017e-04 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9791\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.2032e-04 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9782\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.3310e-04 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9793\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.9154e-05 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9794\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.3603e-05 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9796\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 6.3811e-05 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9793\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 5.5686e-05 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9796\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.8808e-05 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9794\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 4.3809e-05 - accuracy: 1.0000 - val_loss: 0.1321 - val_accuracy: 0.9796\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.9039e-05 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9792\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.4907e-05 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9791\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 3.1570e-05 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9795\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.8336e-05 - accuracy: 1.0000 - val_loss: 0.1372 - val_accuracy: 0.9790\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.5658e-05 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9793\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 2.3260e-05 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9790\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.1084e-05 - accuracy: 1.0000 - val_loss: 0.1407 - val_accuracy: 0.9790\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.9034e-05 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9790\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.7343e-05 - accuracy: 1.0000 - val_loss: 0.1432 - val_accuracy: 0.9791\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.5659e-05 - accuracy: 1.0000 - val_loss: 0.1447 - val_accuracy: 0.9792\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.4216e-05 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9792\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.3015e-05 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9789\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1821e-05 - accuracy: 1.0000 - val_loss: 0.1478 - val_accuracy: 0.9790\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 1.0773e-05 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9789\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.6762e-06 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9789\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 8.7957e-06 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9793\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.9523e-06 - accuracy: 1.0000 - val_loss: 0.1530 - val_accuracy: 0.9790\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 7.2617e-06 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 0.9790\n",
            "Model: \"multi_layer_activity_reg_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5717 - accuracy: 0.8788 - val_loss: 0.2896 - val_accuracy: 0.9507\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2296 - accuracy: 0.9620 - val_loss: 0.2038 - val_accuracy: 0.9656\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1639 - accuracy: 0.9755 - val_loss: 0.1707 - val_accuracy: 0.9712\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1300 - accuracy: 0.9823 - val_loss: 0.1561 - val_accuracy: 0.9722\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1059 - accuracy: 0.9874 - val_loss: 0.1437 - val_accuracy: 0.9725\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0870 - accuracy: 0.9914 - val_loss: 0.1394 - val_accuracy: 0.9738\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0753 - accuracy: 0.9935 - val_loss: 0.1327 - val_accuracy: 0.9752\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0652 - accuracy: 0.9956 - val_loss: 0.1320 - val_accuracy: 0.9734\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0616 - accuracy: 0.9953 - val_loss: 0.1312 - val_accuracy: 0.9738\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0545 - accuracy: 0.9966 - val_loss: 0.1230 - val_accuracy: 0.9758\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0457 - accuracy: 0.9988 - val_loss: 0.1184 - val_accuracy: 0.9780\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0398 - accuracy: 0.9995 - val_loss: 0.1207 - val_accuracy: 0.9763\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0411 - accuracy: 0.9984 - val_loss: 0.1364 - val_accuracy: 0.9719\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0502 - accuracy: 0.9951 - val_loss: 0.1465 - val_accuracy: 0.9688\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0515 - accuracy: 0.9941 - val_loss: 0.1398 - val_accuracy: 0.9707\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0410 - accuracy: 0.9971 - val_loss: 0.1282 - val_accuracy: 0.9741\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0413 - accuracy: 0.9966 - val_loss: 0.1308 - val_accuracy: 0.9756\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0360 - accuracy: 0.9984 - val_loss: 0.1240 - val_accuracy: 0.9753\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0323 - accuracy: 0.9986 - val_loss: 0.1215 - val_accuracy: 0.9754\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9997 - val_loss: 0.1130 - val_accuracy: 0.9764\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0252 - accuracy: 0.9999 - val_loss: 0.1133 - val_accuracy: 0.9761\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9758\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9753\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9750\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9746\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9744\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0577 - accuracy: 0.9898 - val_loss: 0.1829 - val_accuracy: 0.9608\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0595 - accuracy: 0.9887 - val_loss: 0.1364 - val_accuracy: 0.9729\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9967 - val_loss: 0.1281 - val_accuracy: 0.9735\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9982 - val_loss: 0.1262 - val_accuracy: 0.9743\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0228 - accuracy: 0.9995 - val_loss: 0.1144 - val_accuracy: 0.9766\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0203 - accuracy: 0.9999 - val_loss: 0.1114 - val_accuracy: 0.9769\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0191 - accuracy: 0.9999 - val_loss: 0.1186 - val_accuracy: 0.9748\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.1126 - val_accuracy: 0.9758\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0175 - accuracy: 0.9998 - val_loss: 0.1237 - val_accuracy: 0.9738\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0259 - accuracy: 0.9975 - val_loss: 0.1556 - val_accuracy: 0.9684\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0427 - accuracy: 0.9931 - val_loss: 0.1563 - val_accuracy: 0.9685\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0375 - accuracy: 0.9944 - val_loss: 0.1407 - val_accuracy: 0.9732\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9979 - val_loss: 0.1296 - val_accuracy: 0.9758\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0205 - accuracy: 0.9993 - val_loss: 0.1223 - val_accuracy: 0.9760\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0180 - accuracy: 0.9999 - val_loss: 0.1222 - val_accuracy: 0.9745\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9754\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0161 - accuracy: 0.9999 - val_loss: 0.1200 - val_accuracy: 0.9753\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9753\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9745\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9737\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9735\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9743\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9728\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0238 - accuracy: 0.9973 - val_loss: 0.2126 - val_accuracy: 0.9624\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4056 - accuracy: 0.9061 - val_loss: 0.2224 - val_accuracy: 0.9597\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1749 - accuracy: 0.9704 - val_loss: 0.1758 - val_accuracy: 0.9679\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1313 - accuracy: 0.9802 - val_loss: 0.1605 - val_accuracy: 0.9707\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1040 - accuracy: 0.9871 - val_loss: 0.1486 - val_accuracy: 0.9725\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0860 - accuracy: 0.9909 - val_loss: 0.1371 - val_accuracy: 0.9743\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0719 - accuracy: 0.9943 - val_loss: 0.1356 - val_accuracy: 0.9740\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0618 - accuracy: 0.9963 - val_loss: 0.1314 - val_accuracy: 0.9742\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0543 - accuracy: 0.9976 - val_loss: 0.1279 - val_accuracy: 0.9762\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0502 - accuracy: 0.9976 - val_loss: 0.1326 - val_accuracy: 0.9733\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0490 - accuracy: 0.9970 - val_loss: 0.1342 - val_accuracy: 0.9734\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0456 - accuracy: 0.9976 - val_loss: 0.1379 - val_accuracy: 0.9717\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0459 - accuracy: 0.9968 - val_loss: 0.1347 - val_accuracy: 0.9727\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0427 - accuracy: 0.9974 - val_loss: 0.1343 - val_accuracy: 0.9728\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0374 - accuracy: 0.9985 - val_loss: 0.1241 - val_accuracy: 0.9750\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0325 - accuracy: 0.9993 - val_loss: 0.1228 - val_accuracy: 0.9758\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0297 - accuracy: 0.9997 - val_loss: 0.1194 - val_accuracy: 0.9747\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9995 - val_loss: 0.1242 - val_accuracy: 0.9742\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9993 - val_loss: 0.1420 - val_accuracy: 0.9699\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0493 - accuracy: 0.9932 - val_loss: 0.1671 - val_accuracy: 0.9642\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0532 - accuracy: 0.9917 - val_loss: 0.1385 - val_accuracy: 0.9736\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0326 - accuracy: 0.9982 - val_loss: 0.1310 - val_accuracy: 0.9730\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9990 - val_loss: 0.1201 - val_accuracy: 0.9757\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9998 - val_loss: 0.1174 - val_accuracy: 0.9754\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0224 - accuracy: 0.9999 - val_loss: 0.1164 - val_accuracy: 0.9753\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9750\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.1165 - val_accuracy: 0.9752\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9999 - val_loss: 0.1256 - val_accuracy: 0.9732\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9999 - val_loss: 0.1189 - val_accuracy: 0.9743\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9735\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0467 - accuracy: 0.9923 - val_loss: 0.1736 - val_accuracy: 0.9652\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0486 - accuracy: 0.9918 - val_loss: 0.1458 - val_accuracy: 0.9709\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0299 - accuracy: 0.9974 - val_loss: 0.1382 - val_accuracy: 0.9722\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9988 - val_loss: 0.1239 - val_accuracy: 0.9744\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0203 - accuracy: 0.9997 - val_loss: 0.1276 - val_accuracy: 0.9742\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9998 - val_loss: 0.1229 - val_accuracy: 0.9738\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9999 - val_loss: 0.1238 - val_accuracy: 0.9732\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9735\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9727\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0158 - accuracy: 0.9999 - val_loss: 0.1289 - val_accuracy: 0.9725\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0156 - accuracy: 0.9999 - val_loss: 0.1396 - val_accuracy: 0.9717\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0454 - accuracy: 0.9923 - val_loss: 0.1684 - val_accuracy: 0.9664\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0378 - accuracy: 0.9940 - val_loss: 0.1520 - val_accuracy: 0.9707\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9981 - val_loss: 0.1441 - val_accuracy: 0.9722\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0205 - accuracy: 0.9989 - val_loss: 0.1377 - val_accuracy: 0.9713\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0175 - accuracy: 0.9997 - val_loss: 0.1335 - val_accuracy: 0.9727\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9999 - val_loss: 0.1335 - val_accuracy: 0.9732\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0150 - accuracy: 0.9999 - val_loss: 0.1354 - val_accuracy: 0.9717\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9716\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0147 - accuracy: 0.9998 - val_loss: 0.1467 - val_accuracy: 0.9697\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0232 - accuracy: 0.9975 - val_loss: 0.1663 - val_accuracy: 0.9703\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4040 - accuracy: 0.9080 - val_loss: 0.2173 - val_accuracy: 0.9606\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1704 - accuracy: 0.9712 - val_loss: 0.1752 - val_accuracy: 0.9684\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1271 - accuracy: 0.9808 - val_loss: 0.1521 - val_accuracy: 0.9724\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1010 - accuracy: 0.9876 - val_loss: 0.1431 - val_accuracy: 0.9732\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0843 - accuracy: 0.9910 - val_loss: 0.1408 - val_accuracy: 0.9731\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0704 - accuracy: 0.9944 - val_loss: 0.1284 - val_accuracy: 0.9744\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0600 - accuracy: 0.9964 - val_loss: 0.1320 - val_accuracy: 0.9739\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0559 - accuracy: 0.9964 - val_loss: 0.1309 - val_accuracy: 0.9738\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0507 - accuracy: 0.9970 - val_loss: 0.1311 - val_accuracy: 0.9717\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0455 - accuracy: 0.9982 - val_loss: 0.1282 - val_accuracy: 0.9731\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0406 - accuracy: 0.9988 - val_loss: 0.1295 - val_accuracy: 0.9733\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0422 - accuracy: 0.9976 - val_loss: 0.1518 - val_accuracy: 0.9711\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0470 - accuracy: 0.9957 - val_loss: 0.1421 - val_accuracy: 0.9707\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0452 - accuracy: 0.9960 - val_loss: 0.1383 - val_accuracy: 0.9717\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0410 - accuracy: 0.9971 - val_loss: 0.1313 - val_accuracy: 0.9743\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9989 - val_loss: 0.1367 - val_accuracy: 0.9713\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9994 - val_loss: 0.1257 - val_accuracy: 0.9731\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9999 - val_loss: 0.1231 - val_accuracy: 0.9735\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0243 - accuracy: 0.9999 - val_loss: 0.1225 - val_accuracy: 0.9739\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9733\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9727\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0483 - accuracy: 0.9925 - val_loss: 0.2137 - val_accuracy: 0.9571\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0590 - accuracy: 0.9897 - val_loss: 0.1430 - val_accuracy: 0.9713\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9976 - val_loss: 0.1327 - val_accuracy: 0.9719\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9988 - val_loss: 0.1321 - val_accuracy: 0.9730\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9998 - val_loss: 0.1261 - val_accuracy: 0.9734\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0212 - accuracy: 0.9999 - val_loss: 0.1254 - val_accuracy: 0.9734\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9733\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9727\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9722\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9718\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9713\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9712\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0636 - accuracy: 0.9877 - val_loss: 0.1815 - val_accuracy: 0.9627\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0455 - accuracy: 0.9920 - val_loss: 0.1574 - val_accuracy: 0.9688\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9970 - val_loss: 0.1406 - val_accuracy: 0.9718\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0234 - accuracy: 0.9988 - val_loss: 0.1254 - val_accuracy: 0.9739\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9995 - val_loss: 0.1257 - val_accuracy: 0.9733\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0177 - accuracy: 0.9999 - val_loss: 0.1265 - val_accuracy: 0.9720\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0168 - accuracy: 0.9999 - val_loss: 0.1277 - val_accuracy: 0.9714\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9999 - val_loss: 0.1383 - val_accuracy: 0.9707\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.9706\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.9703\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9693\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9697\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0283 - accuracy: 0.9961 - val_loss: 0.2095 - val_accuracy: 0.9616\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0618 - accuracy: 0.9886 - val_loss: 0.1523 - val_accuracy: 0.9704\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0295 - accuracy: 0.9966 - val_loss: 0.1496 - val_accuracy: 0.9722\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9983 - val_loss: 0.1332 - val_accuracy: 0.9739\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9996 - val_loss: 0.1341 - val_accuracy: 0.9732\n",
            "Model: \"multi_layer_activity_reg_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.5320 - accuracy: 0.8838 - val_loss: 0.2437 - val_accuracy: 0.9532\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1894 - accuracy: 0.9652 - val_loss: 0.1784 - val_accuracy: 0.9635\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1312 - accuracy: 0.9771 - val_loss: 0.1490 - val_accuracy: 0.9693\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0999 - accuracy: 0.9840 - val_loss: 0.1392 - val_accuracy: 0.9709\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0779 - accuracy: 0.9894 - val_loss: 0.1284 - val_accuracy: 0.9736\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0639 - accuracy: 0.9922 - val_loss: 0.1163 - val_accuracy: 0.9727\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0518 - accuracy: 0.9953 - val_loss: 0.1156 - val_accuracy: 0.9731\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0477 - accuracy: 0.9952 - val_loss: 0.1119 - val_accuracy: 0.9728\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0434 - accuracy: 0.9956 - val_loss: 0.1141 - val_accuracy: 0.9740\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0385 - accuracy: 0.9967 - val_loss: 0.1204 - val_accuracy: 0.9721\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9977 - val_loss: 0.1118 - val_accuracy: 0.9742\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0294 - accuracy: 0.9982 - val_loss: 0.1126 - val_accuracy: 0.9759\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0350 - accuracy: 0.9962 - val_loss: 0.1213 - val_accuracy: 0.9713\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9962 - val_loss: 0.1222 - val_accuracy: 0.9711\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.9956 - val_loss: 0.1217 - val_accuracy: 0.9737\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9965 - val_loss: 0.1074 - val_accuracy: 0.9756\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0246 - accuracy: 0.9982 - val_loss: 0.1099 - val_accuracy: 0.9744\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0223 - accuracy: 0.9986 - val_loss: 0.1120 - val_accuracy: 0.9747\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0198 - accuracy: 0.9991 - val_loss: 0.1090 - val_accuracy: 0.9739\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9999 - val_loss: 0.1029 - val_accuracy: 0.9747\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9998 - val_loss: 0.1043 - val_accuracy: 0.9754\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9738\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9997 - val_loss: 0.1189 - val_accuracy: 0.9697\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0486 - accuracy: 0.9897 - val_loss: 0.1381 - val_accuracy: 0.9685\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0389 - accuracy: 0.9932 - val_loss: 0.1202 - val_accuracy: 0.9728\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9964 - val_loss: 0.1202 - val_accuracy: 0.9728\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0211 - accuracy: 0.9980 - val_loss: 0.1133 - val_accuracy: 0.9734\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0196 - accuracy: 0.9984 - val_loss: 0.1090 - val_accuracy: 0.9743\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9994 - val_loss: 0.1135 - val_accuracy: 0.9756\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0154 - accuracy: 0.9992 - val_loss: 0.1269 - val_accuracy: 0.9711\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 0.9981 - val_loss: 0.1205 - val_accuracy: 0.9718\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0210 - accuracy: 0.9976 - val_loss: 0.1296 - val_accuracy: 0.9734\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0232 - accuracy: 0.9968 - val_loss: 0.1289 - val_accuracy: 0.9712\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9980 - val_loss: 0.1207 - val_accuracy: 0.9744\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0178 - accuracy: 0.9984 - val_loss: 0.1287 - val_accuracy: 0.9728\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0168 - accuracy: 0.9985 - val_loss: 0.1339 - val_accuracy: 0.9718\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9974 - val_loss: 0.1291 - val_accuracy: 0.9728\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9986 - val_loss: 0.1229 - val_accuracy: 0.9747\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0186 - accuracy: 0.9980 - val_loss: 0.1316 - val_accuracy: 0.9708\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0199 - accuracy: 0.9978 - val_loss: 0.1250 - val_accuracy: 0.9742\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0186 - accuracy: 0.9979 - val_loss: 0.1234 - val_accuracy: 0.9722\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0166 - accuracy: 0.9983 - val_loss: 0.1394 - val_accuracy: 0.9704\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0203 - accuracy: 0.9975 - val_loss: 0.1294 - val_accuracy: 0.9725\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9985 - val_loss: 0.1280 - val_accuracy: 0.9727\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9980 - val_loss: 0.1282 - val_accuracy: 0.9732\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0140 - accuracy: 0.9990 - val_loss: 0.1259 - val_accuracy: 0.9729\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0155 - accuracy: 0.9985 - val_loss: 0.1318 - val_accuracy: 0.9735\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0169 - accuracy: 0.9983 - val_loss: 0.1303 - val_accuracy: 0.9736\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0154 - accuracy: 0.9985 - val_loss: 0.1405 - val_accuracy: 0.9723\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9987 - val_loss: 0.1454 - val_accuracy: 0.9716\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.3977 - accuracy: 0.9018 - val_loss: 0.1973 - val_accuracy: 0.9582\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1460 - accuracy: 0.9713 - val_loss: 0.1467 - val_accuracy: 0.9681\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1027 - accuracy: 0.9815 - val_loss: 0.1295 - val_accuracy: 0.9726\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0788 - accuracy: 0.9873 - val_loss: 0.1192 - val_accuracy: 0.9722\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0623 - accuracy: 0.9912 - val_loss: 0.1142 - val_accuracy: 0.9752\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0524 - accuracy: 0.9935 - val_loss: 0.1208 - val_accuracy: 0.9715\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0422 - accuracy: 0.9962 - val_loss: 0.1116 - val_accuracy: 0.9762\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0364 - accuracy: 0.9971 - val_loss: 0.1122 - val_accuracy: 0.9746\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0331 - accuracy: 0.9975 - val_loss: 0.1057 - val_accuracy: 0.9759\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0290 - accuracy: 0.9983 - val_loss: 0.1130 - val_accuracy: 0.9731\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0323 - accuracy: 0.9967 - val_loss: 0.1206 - val_accuracy: 0.9725\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0323 - accuracy: 0.9963 - val_loss: 0.1108 - val_accuracy: 0.9743\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0285 - accuracy: 0.9976 - val_loss: 0.1140 - val_accuracy: 0.9741\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0239 - accuracy: 0.9985 - val_loss: 0.1067 - val_accuracy: 0.9750\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9985 - val_loss: 0.1147 - val_accuracy: 0.9725\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0200 - accuracy: 0.9990 - val_loss: 0.1092 - val_accuracy: 0.9763\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0242 - accuracy: 0.9974 - val_loss: 0.1328 - val_accuracy: 0.9707\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9955 - val_loss: 0.1390 - val_accuracy: 0.9697\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0334 - accuracy: 0.9948 - val_loss: 0.1170 - val_accuracy: 0.9745\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9977 - val_loss: 0.1106 - val_accuracy: 0.9760\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9984 - val_loss: 0.1138 - val_accuracy: 0.9743\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0165 - accuracy: 0.9993 - val_loss: 0.1130 - val_accuracy: 0.9740\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0153 - accuracy: 0.9994 - val_loss: 0.1114 - val_accuracy: 0.9743\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9998 - val_loss: 0.1091 - val_accuracy: 0.9747\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 0.9746\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.9998 - val_loss: 0.1167 - val_accuracy: 0.9739\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0331 - accuracy: 0.9941 - val_loss: 0.1407 - val_accuracy: 0.9705\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0382 - accuracy: 0.9927 - val_loss: 0.1169 - val_accuracy: 0.9739\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0234 - accuracy: 0.9970 - val_loss: 0.1293 - val_accuracy: 0.9700\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0177 - accuracy: 0.9986 - val_loss: 0.1117 - val_accuracy: 0.9757\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0152 - accuracy: 0.9990 - val_loss: 0.1191 - val_accuracy: 0.9734\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0142 - accuracy: 0.9990 - val_loss: 0.1150 - val_accuracy: 0.9743\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 0.9980 - val_loss: 0.1245 - val_accuracy: 0.9722\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0253 - accuracy: 0.9961 - val_loss: 0.1206 - val_accuracy: 0.9744\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0222 - accuracy: 0.9971 - val_loss: 0.1298 - val_accuracy: 0.9723\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9976 - val_loss: 0.1180 - val_accuracy: 0.9751\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0153 - accuracy: 0.9989 - val_loss: 0.1173 - val_accuracy: 0.9745\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9993 - val_loss: 0.1177 - val_accuracy: 0.9755\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9994 - val_loss: 0.1189 - val_accuracy: 0.9741\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9990 - val_loss: 0.1256 - val_accuracy: 0.9733\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9984 - val_loss: 0.1384 - val_accuracy: 0.9720\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0219 - accuracy: 0.9966 - val_loss: 0.1426 - val_accuracy: 0.9696\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0191 - accuracy: 0.9977 - val_loss: 0.1283 - val_accuracy: 0.9727\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9989 - val_loss: 0.1318 - val_accuracy: 0.9716\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9995 - val_loss: 0.1242 - val_accuracy: 0.9724\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9992 - val_loss: 0.1278 - val_accuracy: 0.9735\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0132 - accuracy: 0.9990 - val_loss: 0.1224 - val_accuracy: 0.9746\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0163 - accuracy: 0.9983 - val_loss: 0.1289 - val_accuracy: 0.9737\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0215 - accuracy: 0.9965 - val_loss: 0.1362 - val_accuracy: 0.9712\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9971 - val_loss: 0.1417 - val_accuracy: 0.9721\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4043 - accuracy: 0.9004 - val_loss: 0.1862 - val_accuracy: 0.9626\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1440 - accuracy: 0.9719 - val_loss: 0.1450 - val_accuracy: 0.9678\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1016 - accuracy: 0.9824 - val_loss: 0.1346 - val_accuracy: 0.9697\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0774 - accuracy: 0.9878 - val_loss: 0.1195 - val_accuracy: 0.9734\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0611 - accuracy: 0.9922 - val_loss: 0.1144 - val_accuracy: 0.9734\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0487 - accuracy: 0.9951 - val_loss: 0.1074 - val_accuracy: 0.9758\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0414 - accuracy: 0.9962 - val_loss: 0.1064 - val_accuracy: 0.9771\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0389 - accuracy: 0.9963 - val_loss: 0.1102 - val_accuracy: 0.9746\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0335 - accuracy: 0.9976 - val_loss: 0.1088 - val_accuracy: 0.9754\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9980 - val_loss: 0.1053 - val_accuracy: 0.9758\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0270 - accuracy: 0.9984 - val_loss: 0.1222 - val_accuracy: 0.9718\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0279 - accuracy: 0.9978 - val_loss: 0.1060 - val_accuracy: 0.9742\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9976 - val_loss: 0.1249 - val_accuracy: 0.9699\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0324 - accuracy: 0.9958 - val_loss: 0.1298 - val_accuracy: 0.9697\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0309 - accuracy: 0.9958 - val_loss: 0.1245 - val_accuracy: 0.9707\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9981 - val_loss: 0.0986 - val_accuracy: 0.9776\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0198 - accuracy: 0.9990 - val_loss: 0.1094 - val_accuracy: 0.9762\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0208 - accuracy: 0.9986 - val_loss: 0.1084 - val_accuracy: 0.9746\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9985 - val_loss: 0.1189 - val_accuracy: 0.9717\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0265 - accuracy: 0.9966 - val_loss: 0.1420 - val_accuracy: 0.9676\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0339 - accuracy: 0.9940 - val_loss: 0.1244 - val_accuracy: 0.9720\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0228 - accuracy: 0.9975 - val_loss: 0.1210 - val_accuracy: 0.9733\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0181 - accuracy: 0.9989 - val_loss: 0.1111 - val_accuracy: 0.9746\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9987 - val_loss: 0.1164 - val_accuracy: 0.9743\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9995 - val_loss: 0.1174 - val_accuracy: 0.9736\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0183 - accuracy: 0.9983 - val_loss: 0.1208 - val_accuracy: 0.9726\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0156 - accuracy: 0.9990 - val_loss: 0.1304 - val_accuracy: 0.9697\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0240 - accuracy: 0.9965 - val_loss: 0.1290 - val_accuracy: 0.9724\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0223 - accuracy: 0.9971 - val_loss: 0.1251 - val_accuracy: 0.9729\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0192 - accuracy: 0.9977 - val_loss: 0.1343 - val_accuracy: 0.9700\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9970 - val_loss: 0.1207 - val_accuracy: 0.9751\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0167 - accuracy: 0.9989 - val_loss: 0.1116 - val_accuracy: 0.9753\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9987 - val_loss: 0.1187 - val_accuracy: 0.9746\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0165 - accuracy: 0.9986 - val_loss: 0.1317 - val_accuracy: 0.9712\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0196 - accuracy: 0.9976 - val_loss: 0.1267 - val_accuracy: 0.9732\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0208 - accuracy: 0.9971 - val_loss: 0.1267 - val_accuracy: 0.9726\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0185 - accuracy: 0.9978 - val_loss: 0.1210 - val_accuracy: 0.9736\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9979 - val_loss: 0.1189 - val_accuracy: 0.9744\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0166 - accuracy: 0.9984 - val_loss: 0.1225 - val_accuracy: 0.9753\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9988 - val_loss: 0.1145 - val_accuracy: 0.9753\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9990 - val_loss: 0.1229 - val_accuracy: 0.9737\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0169 - accuracy: 0.9982 - val_loss: 0.1386 - val_accuracy: 0.9713\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0161 - accuracy: 0.9984 - val_loss: 0.1240 - val_accuracy: 0.9740\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0147 - accuracy: 0.9986 - val_loss: 0.1348 - val_accuracy: 0.9719\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0154 - accuracy: 0.9986 - val_loss: 0.1328 - val_accuracy: 0.9734\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0210 - accuracy: 0.9967 - val_loss: 0.1303 - val_accuracy: 0.9737\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0183 - accuracy: 0.9977 - val_loss: 0.1249 - val_accuracy: 0.9742\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0178 - accuracy: 0.9980 - val_loss: 0.1267 - val_accuracy: 0.9732\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0125 - accuracy: 0.9993 - val_loss: 0.1183 - val_accuracy: 0.9753\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0154 - accuracy: 0.9983 - val_loss: 0.1301 - val_accuracy: 0.9741\n",
            "Model: \"multi_layer_activity_reg_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.6241 - accuracy: 0.8825 - val_loss: 0.3019 - val_accuracy: 0.9534\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.2398 - accuracy: 0.9631 - val_loss: 0.2175 - val_accuracy: 0.9648\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1710 - accuracy: 0.9761 - val_loss: 0.1868 - val_accuracy: 0.9687\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1332 - accuracy: 0.9840 - val_loss: 0.1688 - val_accuracy: 0.9708\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.1078 - accuracy: 0.9887 - val_loss: 0.1549 - val_accuracy: 0.9724\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0927 - accuracy: 0.9910 - val_loss: 0.1505 - val_accuracy: 0.9718\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0795 - accuracy: 0.9932 - val_loss: 0.1551 - val_accuracy: 0.9704\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0717 - accuracy: 0.9942 - val_loss: 0.1412 - val_accuracy: 0.9735\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0635 - accuracy: 0.9956 - val_loss: 0.1443 - val_accuracy: 0.9711\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0576 - accuracy: 0.9963 - val_loss: 0.1331 - val_accuracy: 0.9751\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0522 - accuracy: 0.9973 - val_loss: 0.1349 - val_accuracy: 0.9732\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0513 - accuracy: 0.9966 - val_loss: 0.1371 - val_accuracy: 0.9702\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0521 - accuracy: 0.9962 - val_loss: 0.1353 - val_accuracy: 0.9729\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0489 - accuracy: 0.9963 - val_loss: 0.1309 - val_accuracy: 0.9729\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0465 - accuracy: 0.9966 - val_loss: 0.1308 - val_accuracy: 0.9733\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0441 - accuracy: 0.9966 - val_loss: 0.1400 - val_accuracy: 0.9712\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0455 - accuracy: 0.9964 - val_loss: 0.1302 - val_accuracy: 0.9737\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0378 - accuracy: 0.9981 - val_loss: 0.1316 - val_accuracy: 0.9737\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0352 - accuracy: 0.9985 - val_loss: 0.1257 - val_accuracy: 0.9743\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0387 - accuracy: 0.9971 - val_loss: 0.1340 - val_accuracy: 0.9738\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0455 - accuracy: 0.9948 - val_loss: 0.1475 - val_accuracy: 0.9710\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0402 - accuracy: 0.9965 - val_loss: 0.1366 - val_accuracy: 0.9712\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0331 - accuracy: 0.9985 - val_loss: 0.1279 - val_accuracy: 0.9742\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9991 - val_loss: 0.1237 - val_accuracy: 0.9738\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9996 - val_loss: 0.1287 - val_accuracy: 0.9741\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0278 - accuracy: 0.9987 - val_loss: 0.1398 - val_accuracy: 0.9707\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0421 - accuracy: 0.9950 - val_loss: 0.1556 - val_accuracy: 0.9689\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0394 - accuracy: 0.9961 - val_loss: 0.1489 - val_accuracy: 0.9708\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0359 - accuracy: 0.9966 - val_loss: 0.1384 - val_accuracy: 0.9720\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9979 - val_loss: 0.1465 - val_accuracy: 0.9692\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9987 - val_loss: 0.1361 - val_accuracy: 0.9718\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9985 - val_loss: 0.1368 - val_accuracy: 0.9727\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9992 - val_loss: 0.1385 - val_accuracy: 0.9712\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0250 - accuracy: 0.9989 - val_loss: 0.1443 - val_accuracy: 0.9722\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0336 - accuracy: 0.9965 - val_loss: 0.1430 - val_accuracy: 0.9719\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0334 - accuracy: 0.9966 - val_loss: 0.1486 - val_accuracy: 0.9695\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9978 - val_loss: 0.1465 - val_accuracy: 0.9710\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9977 - val_loss: 0.1445 - val_accuracy: 0.9707\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0283 - accuracy: 0.9980 - val_loss: 0.1561 - val_accuracy: 0.9697\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0280 - accuracy: 0.9979 - val_loss: 0.1418 - val_accuracy: 0.9705\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0264 - accuracy: 0.9981 - val_loss: 0.1580 - val_accuracy: 0.9700\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9979 - val_loss: 0.1530 - val_accuracy: 0.9718\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0268 - accuracy: 0.9981 - val_loss: 0.1526 - val_accuracy: 0.9711\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9991 - val_loss: 0.1633 - val_accuracy: 0.9697\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9986 - val_loss: 0.1511 - val_accuracy: 0.9712\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0257 - accuracy: 0.9979 - val_loss: 0.1592 - val_accuracy: 0.9718\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9976 - val_loss: 0.1582 - val_accuracy: 0.9703\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0265 - accuracy: 0.9980 - val_loss: 0.1592 - val_accuracy: 0.9704\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9985 - val_loss: 0.1449 - val_accuracy: 0.9717\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0224 - accuracy: 0.9989 - val_loss: 0.1497 - val_accuracy: 0.9704\n",
            "TEST 2/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4421 - accuracy: 0.9010 - val_loss: 0.2371 - val_accuracy: 0.9571\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.1808 - accuracy: 0.9708 - val_loss: 0.1896 - val_accuracy: 0.9654\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1310 - accuracy: 0.9818 - val_loss: 0.1641 - val_accuracy: 0.9698\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9881 - val_loss: 0.1537 - val_accuracy: 0.9714\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0878 - accuracy: 0.9908 - val_loss: 0.1463 - val_accuracy: 0.9714\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0742 - accuracy: 0.9936 - val_loss: 0.1440 - val_accuracy: 0.9718\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0660 - accuracy: 0.9946 - val_loss: 0.1329 - val_accuracy: 0.9735\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0572 - accuracy: 0.9964 - val_loss: 0.1362 - val_accuracy: 0.9722\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0509 - accuracy: 0.9976 - val_loss: 0.1291 - val_accuracy: 0.9732\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0488 - accuracy: 0.9974 - val_loss: 0.1321 - val_accuracy: 0.9737\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0458 - accuracy: 0.9978 - val_loss: 0.1301 - val_accuracy: 0.9735\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0420 - accuracy: 0.9983 - val_loss: 0.1324 - val_accuracy: 0.9731\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0413 - accuracy: 0.9980 - val_loss: 0.1312 - val_accuracy: 0.9746\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0512 - accuracy: 0.9946 - val_loss: 0.1559 - val_accuracy: 0.9672\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0522 - accuracy: 0.9941 - val_loss: 0.1381 - val_accuracy: 0.9709\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0429 - accuracy: 0.9965 - val_loss: 0.1347 - val_accuracy: 0.9719\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0410 - accuracy: 0.9971 - val_loss: 0.1340 - val_accuracy: 0.9737\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9980 - val_loss: 0.1207 - val_accuracy: 0.9753\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9991 - val_loss: 0.1209 - val_accuracy: 0.9738\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.9994 - val_loss: 0.1252 - val_accuracy: 0.9744\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9994 - val_loss: 0.1286 - val_accuracy: 0.9735\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0283 - accuracy: 0.9988 - val_loss: 0.1306 - val_accuracy: 0.9733\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0375 - accuracy: 0.9960 - val_loss: 0.1612 - val_accuracy: 0.9660\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0493 - accuracy: 0.9932 - val_loss: 0.1593 - val_accuracy: 0.9686\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9967 - val_loss: 0.1378 - val_accuracy: 0.9727\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0314 - accuracy: 0.9980 - val_loss: 0.1267 - val_accuracy: 0.9742\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0257 - accuracy: 0.9995 - val_loss: 0.1261 - val_accuracy: 0.9731\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0247 - accuracy: 0.9993 - val_loss: 0.1293 - val_accuracy: 0.9718\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0239 - accuracy: 0.9994 - val_loss: 0.1270 - val_accuracy: 0.9728\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9992 - val_loss: 0.1421 - val_accuracy: 0.9703\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9958 - val_loss: 0.1589 - val_accuracy: 0.9699\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0403 - accuracy: 0.9949 - val_loss: 0.1458 - val_accuracy: 0.9696\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0328 - accuracy: 0.9969 - val_loss: 0.1393 - val_accuracy: 0.9732\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9985 - val_loss: 0.1314 - val_accuracy: 0.9735\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0250 - accuracy: 0.9989 - val_loss: 0.1352 - val_accuracy: 0.9733\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9985 - val_loss: 0.1314 - val_accuracy: 0.9728\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0233 - accuracy: 0.9990 - val_loss: 0.1308 - val_accuracy: 0.9736\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9989 - val_loss: 0.1386 - val_accuracy: 0.9722\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0238 - accuracy: 0.9986 - val_loss: 0.1354 - val_accuracy: 0.9721\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.9982 - val_loss: 0.1402 - val_accuracy: 0.9712\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0287 - accuracy: 0.9974 - val_loss: 0.1554 - val_accuracy: 0.9687\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0270 - accuracy: 0.9979 - val_loss: 0.1456 - val_accuracy: 0.9721\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9978 - val_loss: 0.1678 - val_accuracy: 0.9678\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0317 - accuracy: 0.9964 - val_loss: 0.1531 - val_accuracy: 0.9683\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0293 - accuracy: 0.9970 - val_loss: 0.1430 - val_accuracy: 0.9728\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9977 - val_loss: 0.1420 - val_accuracy: 0.9708\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0233 - accuracy: 0.9988 - val_loss: 0.1378 - val_accuracy: 0.9725\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0223 - accuracy: 0.9989 - val_loss: 0.1321 - val_accuracy: 0.9737\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9988 - val_loss: 0.1409 - val_accuracy: 0.9718\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0218 - accuracy: 0.9988 - val_loss: 0.1428 - val_accuracy: 0.9712\n",
            "TEST 3/3\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.4363 - accuracy: 0.9078 - val_loss: 0.2403 - val_accuracy: 0.9567\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1784 - accuracy: 0.9720 - val_loss: 0.1962 - val_accuracy: 0.9636\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1293 - accuracy: 0.9822 - val_loss: 0.1635 - val_accuracy: 0.9698\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9880 - val_loss: 0.1509 - val_accuracy: 0.9704\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0870 - accuracy: 0.9911 - val_loss: 0.1476 - val_accuracy: 0.9712\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0732 - accuracy: 0.9937 - val_loss: 0.1413 - val_accuracy: 0.9728\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0664 - accuracy: 0.9946 - val_loss: 0.1397 - val_accuracy: 0.9737\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0590 - accuracy: 0.9960 - val_loss: 0.1367 - val_accuracy: 0.9734\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0520 - accuracy: 0.9970 - val_loss: 0.1351 - val_accuracy: 0.9742\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0529 - accuracy: 0.9961 - val_loss: 0.1350 - val_accuracy: 0.9735\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0467 - accuracy: 0.9976 - val_loss: 0.1377 - val_accuracy: 0.9720\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9978 - val_loss: 0.1335 - val_accuracy: 0.9731\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0432 - accuracy: 0.9973 - val_loss: 0.1373 - val_accuracy: 0.9712\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0402 - accuracy: 0.9979 - val_loss: 0.1414 - val_accuracy: 0.9718\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0386 - accuracy: 0.9977 - val_loss: 0.1417 - val_accuracy: 0.9710\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0478 - accuracy: 0.9948 - val_loss: 0.1486 - val_accuracy: 0.9695\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0430 - accuracy: 0.9960 - val_loss: 0.1367 - val_accuracy: 0.9735\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0432 - accuracy: 0.9962 - val_loss: 0.1268 - val_accuracy: 0.9758\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0335 - accuracy: 0.9985 - val_loss: 0.1353 - val_accuracy: 0.9727\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9991 - val_loss: 0.1272 - val_accuracy: 0.9736\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0284 - accuracy: 0.9991 - val_loss: 0.1296 - val_accuracy: 0.9736\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0290 - accuracy: 0.9987 - val_loss: 0.1363 - val_accuracy: 0.9726\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0301 - accuracy: 0.9985 - val_loss: 0.1280 - val_accuracy: 0.9749\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0349 - accuracy: 0.9971 - val_loss: 0.1478 - val_accuracy: 0.9703\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0404 - accuracy: 0.9956 - val_loss: 0.1756 - val_accuracy: 0.9646\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0425 - accuracy: 0.9948 - val_loss: 0.1371 - val_accuracy: 0.9722\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9963 - val_loss: 0.1357 - val_accuracy: 0.9735\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0297 - accuracy: 0.9983 - val_loss: 0.1337 - val_accuracy: 0.9728\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9987 - val_loss: 0.1331 - val_accuracy: 0.9741\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0258 - accuracy: 0.9989 - val_loss: 0.1351 - val_accuracy: 0.9737\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9973 - val_loss: 0.1448 - val_accuracy: 0.9709\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9980 - val_loss: 0.1373 - val_accuracy: 0.9740\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0320 - accuracy: 0.9970 - val_loss: 0.1395 - val_accuracy: 0.9732\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0305 - accuracy: 0.9977 - val_loss: 0.1437 - val_accuracy: 0.9713\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0262 - accuracy: 0.9983 - val_loss: 0.1387 - val_accuracy: 0.9722\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9981 - val_loss: 0.1541 - val_accuracy: 0.9698\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0263 - accuracy: 0.9985 - val_loss: 0.1590 - val_accuracy: 0.9684\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9964 - val_loss: 0.1492 - val_accuracy: 0.9707\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0262 - accuracy: 0.9984 - val_loss: 0.1444 - val_accuracy: 0.9729\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9981 - val_loss: 0.1425 - val_accuracy: 0.9729\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0246 - accuracy: 0.9987 - val_loss: 0.1378 - val_accuracy: 0.9740\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0221 - accuracy: 0.9991 - val_loss: 0.1470 - val_accuracy: 0.9716\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0238 - accuracy: 0.9987 - val_loss: 0.1451 - val_accuracy: 0.9719\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9980 - val_loss: 0.1569 - val_accuracy: 0.9694\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9968 - val_loss: 0.1627 - val_accuracy: 0.9703\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9978 - val_loss: 0.1595 - val_accuracy: 0.9702\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9983 - val_loss: 0.1412 - val_accuracy: 0.9737\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0220 - accuracy: 0.9990 - val_loss: 0.1483 - val_accuracy: 0.9722\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9976 - val_loss: 0.1666 - val_accuracy: 0.9707\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9978 - val_loss: 0.1567 - val_accuracy: 0.9697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LvIBVw-KvSMb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "f27c7593-c57c-43d7-dd47-c7e80bc53f04"
      },
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "multiple_line_chart(plt.gca(), \n",
        "                    None, \n",
        "                    multi_layer_activity_reg_model_accuracy_lines, \n",
        "                    \"Validation accuracy variation per type of activity regulizer\", \n",
        "                    \"Epochs\", \n",
        "                    \"Validation accuracy\")\n",
        "plt.show()\n",
        "plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAG5CAYAAAA3e7gZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3wURf/A8c+kVxLSKEkghNACBCmhd1SKig3BBqigqCAqKqg/RUVRVER9xMcKoiAPCCpFASnSlRZqqAmEkIRAKun1bn5/7CZceiGVzPv1ulfudmdnZ8vtfTM7MyuklCiKoiiKoih1n1ltF0BRFEVRFEUpHxW4KYqiKIqi1BMqcFMURVEURaknVOCmKIqiKIpST6jATVEURVEUpZ5QgZuiKIqiKEo9oQI3pd4TQkghhJ/+/mshxJvlSVuJ9TwihNhc2XIqVUsI8boQ4vsbWP6kEGJwFRapQRNCtBNCHBVCpAghplfzulKFEL7lSHdD50htqsh1TWlYhBrHTaltQohNwAEp5exC0+8GvgG8pJS5pSwvgTZSytByrKtcaYUQPkAYYFnaupX6QQixBIiUUr5R22W5UUKIi8BkKeXW2i6LKSHEIiBZSvliFee7A1gmpbyhAKy+facrcl1TGhZV46bUBT8CjwohRKHp44Gf68NFtj4TQljUdhkqqj6WuaKEpj5do1sCJ2u7EDWlvp+DQgjz2i6DUklSSvVSr1p9AbZAEjDQZFpjIBPoAvQE/gWuAdHAQsDKJK0E/PT3S4D3TOa9oi9zGXiiUNo7gCNAMhABvG2y3CU9bar+6gM8BuwxSdMXOKiX/SDQ12TeDuBdYC+QAmwG3ErY/sbAH0AskKi/9zKZ7wL8oG9DIrDGZN7dwFF9G84DI/TpF4FbTdK9jVZrAeCjb9skfTt36dNXAVf07dkFdCx0jD4BwvX5e/RpfwLPFdqe48C9xWznRmBaoWnHgPv095/rxyEZCAIGFCr/amCZPn+y6TaVVn7gKSAHyNaP5frC+wiwBj7T9/Fl/b21Pm8wEAm8BMSgnU+Pl3I+7wA+AA7oZV0LuJjM7w38g3Y+HwMGF1p2rn7eZKCfqybzlwJGfV4qMLOsY6Af6+nABSAO+BgwM0n7BHAa7dz6C2hZyraNRgvOrull7aBP/xswoH1nU4G2xSz7uL6eFL0sUwrNL3Iu6/vCNN+Fpt95oJd+zM1N8rkXOF7MeV/4Oz0ISAA6myzrAaQD7sWU/zH9uHwKxAPv6efNfD3vq8DXgK3JMjO5fv2ZTMHrzw60mlPT/E2vL8Ve14D1JtuQqp8Pj+nz2gNb9O06C4w1yW8J8BWwAUjD5PqgXvXrVesFUC/1klICfAd8b/J5CnBUf98d7cfOAi3oOA28YJK2pAvcCP1i2gmwB5YXSjsY6IxW8xygp71Hn+ejp7UwWU/+hRUtmEpEqxW0AB7SP7vq83eg/fi0RQtwdgDzSth2V+B+wA5wRAtATIOzP4GVaAGeJTBIn94TLUi5Td8GT6C9Pu8iZQduP+n7xVaf/oS+/rwg5qjJ8l/q2+AJmKMFrdbAWGC/SbouaD9qVsVs5wRgr8lnf7QAIC9AelTfFxZoQdIVwMak/DnAPfq22lI0cCut/EswCegL7yNgDrAP7YfbHS2wetfkPMnV01gCo9B+3BuXcDx3AFFcP+9+Ndn3nvr+GaVvx236Z3eTZS8BHfX9YFlM/oWPbanHQD/W29HO2RbAOfSAAS1YCgU66Ot7A/inhO1qi/aDf5u+H2bqy1qZlH1yccvq8+8AWgMCLWhKB7qV41wuki8Fv8fngdtM5q0CXi3lvDf9Tv8X+NDk8/PogX0x5X9MPw+e0/eVLVoQt07ft45oQdUHJtefK/qxtEP7p+OGA7dCZRqJFhR6o51rEWgBsgXQFS1Q9zfJIwnop+9jm6q+jqtXzbxqvQDqpV5SSoD+aD/ieT/Ue4EXS0j7AvC7yeeSArfFmARL+g9Pftpi8v0M+FR/X9xFPv/CihawHSi0/L9c/893B/CGybxngU3l3Be3AIn6+2Zo/1EXCRLQ2v99WkIeFyk7cPMtpQzOehon/SKfAXQpJp0NWsDaRv88H/hvCXk6ov3wt9Q/zwUWl1KGxLx16uXfVWh+/jaVVv7C50Vx+wjtx3+UybzhwEX9/WB9+03PhRigdwnr3lHovPNHq+0zB2YBSwul/wuYaLLsnDLOj8LHttRjoO+HEYXOxW36+43AJJN5ZmgBVcti1vsm8EuhtFHoNYaUEbgVk98a4PlynMtF8qXgd/69vPOomHMs/xyh+O90L7RAOa+99yFMaqkKrfMx4JLJZ6Gvq7XJtD5AmP5+MXoQp3/2owoDN7TrWQzQX/88DthdKM03wFsmefxU3uOjXnX3VZ/aTyg3MSnlHrT/Du8RQrRG+w98OYAQoq0Q4g8hxBUhRDLwPuBWjmybo/0HmifcdKYQopcQYrsQIlYIkQQ8Xc588/IOLzQtHK2mIM8Vk/fpgENxGQkh7IQQ3wghwvXt2wU4621QvIEEKWViMYt6owUclZW/b4QQ5kKIeUKI83oZLuqz3PSXTXHrklJmotUGPqq3x3oI7XZeEVLKFLTawwf1SQ8BP5uU4WUhxGkhRJIQ4hpa0Gh6PEyPZQFllL88Ch/PcH1annhZsK1licezmLKGo9VQuaG1A3tACHEt74X2T0uzEpYtUzmPQeHy5G1bS+Bzk7IkoAUknhRVYB9JKY16vsWlLUIIMVIIsU8IkaCvaxTXj8+NnMvLgfuEENbAfcBhKWXh72axpJT70Y7lYCFEe7Tgal0pi5juR3e0mrQgk/23SZ8ORa8/FTqupRFCOKHdgn9Dv3aCdix7FTq3HgGaVkcZlNqjAjelLvkJ7Xbao8BfUsqr+vSvgDNoNQqNgNfRflzKEo32g5CnRaH5y9Eu0t5SSie09il5+coy8r6MdqE01QKtBqKiXgLaAb307RuoTxdoF1oXIYRzMctFoN16Kk4a2o9KnqbFpDHdxofRbpvdihYw+ZiUIQ6tjVFJ6/oR7QdiGJAupfy3hHQA/wMeEkL0QQsGtwMIIQag3Xobi1a76Ix2W8f0OJd2TEorf1nLQtHj2UKfVlmFz7sctP0YgVbj5mzyspdSzjNJX1ZZi5tf1jEoXJ68bYtAa2tmWh5bKeU/xayjwD7SOxN5U45zXg+qfkWrDWyiH98NXD8+pZ3Lpe4PKeUptIByJNp5sLyC+fyIds0ZD6zWA+ESV2fyPg6tJrajyb5zklLmBfTRgJdJetNjAOX7jhahB+fLge1Sym9NZkUAOwsdSwcp5TMllF+pp1TgptQlP6H98D6JdjHN44jWYDlV/6/4mWKWLc4vwGNCCH8hhB3wVqH5jmi1WZlCiJ5oF/08sWi3KEsaK2oD0FYI8bAQwkIIMQ7tltgf5Sxb4XJkANeEEC6m5ZRSRqPdzvqvEKKxEMJSCJEX2C0CHhdCDBNCmAkhPPX9A1oj7wf19D2AMeUoQxZa2yg7tFrNvDIY0W77LBBCNNdrt/roP8boQYIRrfNCsbVtJjag/fjPAVbqeeetPxdtv1sIIWYDjcrIq1zl112l5GMJWkD5hhDCXQjhBsxGa5NUWY+anHdz0AICg57nXUKI4fp+tBFCDBZCeJWeXQFFtqUcx+AV/fzxRmvHtVKf/jXwmhCiI2g1OUKIB0pY7y/AHfr5Zon2D0cWWnvAslihtT2MBXKFECOB203ml3Yul3XsQAtknkf7p2dVCWlK+k4vQ+vQ8CjaNahc9HP3O+BTIYQHgF7u4XqSX/Rt6qCfB4XHYTuKVlNoJ7Tx2iaVc9Vz0dqzPV9o+h9o16Tx+vfeUggRKIToUN5tUuoHFbgpdYaU8iLaj4A9BW9XvIwWVKWgXShXFlm4+Pw2orVb+xutEfXfhZI8C8wRQqSg/VD/YrJsOnrvPv22Q+9CeccDd6L9eMWj1RbdKaWMK0/ZCvkMraFzHFoD+U2F5o9Hq7E5g9am5QW9DAfQGiJ/ilY7tZPrNSJvotVgJALvUHItRJ6f0GotooBTejlMvQycQOs9mwB8SMHrx09oHT1KDXaklFnAb2gBummZ/kLb7nN6OTKp2G2dssq/CPDXj+WaYpZ/D61903G07TysT6uspWhtiq6g1SxOB5BSRqDVDL6OFkhEoPV8rsi1+AO0IPOaEOJlk+mlHYO1aD11j6Ldrl6kl+d3tGO5Qr/FHIxWc1WElPIsWnDzBdq5ehdwl5Qyu6wC67fJp6N9xxLRvs/rTOaXdi5/DowRQiQKIf5Twir+h9bh4e+SvoMlfaf1Y3IYrTZqd1nbUsgstGvLPn3/bUWrPc+7/vwHrVY5lOvnZJb+91O0to9X0f5R/ZnyeQits1ai0AYiThVCPKLv49vRmiJcRjv3PkQLmJWbiBqAV1GUGyaEmAA8JaXsX9tlqW2iigaMrcR6iz0GQg3kWiYhxGLgsqzGAZr1mq9gtF7UamxKpdJUjZuiKDdEvw30LPBtWWmV6qGOQeUJ7YkK96HXQlZx3vcKIayFEI3Rar/Wq6BNuVEqcFMUpdL09jyxaLd7yrodq1QDdQwqTwjxLlot2MdSyrBqWMUUtOYN59EGEi5v+1xFKZG6VaooiqIoilJPqBo3RVEURVGUeqJePyS3vNq3by8XLFiAh4cHoshzzJXKklISExPDggULuHbtWm0XR1EURVFuCkFBQXFSSvfi5jWIW6UbNmyQXbt2pUmTJpiZqUrGqmI0Grl69SoJCQn4+/uroFhRFEVRqoAQIkhK2aO4eQ0iivHw8FBBWzUwMzOjSZMmZGRksHv3boxGY9kLKYqiKIpSaQ0ikhFCqKCtmpiZmSGEICgoiMjIyNoujqIoiqLc1FQ0o1QJIQTp6em1XQxFURRFuampwK2GCCF46aWX8j/Pnz+ft99+u/YKVA0aQntJRVEURalNKnCrIdbW1vz222/ExVXmUZaKoiiKoigqcKsxFhYWPPXUU3z66adF5l28eJGhQ4cSEBDAsGHDuHTpEgCPPfYY06dPp2/fvvj6+rJ69er8ZT7++GMCAwMJCAjgrbfeqrHtUBRFURSl9jSIcdxMvbP+JKcuJ1dpnv7NG/HWXR3LTDd16lQCAgKYOXNmgenPPfccEydOZOLEiSxevJjp06ezZs0aAKKjo9mzZw9nzpxh9OjRjBkzhs2bNxMSEsKBAweQUjJ69Gh27drFwIEDq3S7FEVRFEWpW1SNWw1q1KgREyZM4D//+U+B6f/++y8PP/wwAOPHj2fPnj358+655x7MzMzw9/fn6tWrAGzevJnNmzfTtWtXunXrxpkzZwgJCam5DVEURVEUpVY0uBq38tSMVacXXniBbt268fjjj5crvbW1df77vMb/Ukpee+01pkyZUi1lVBRFURSlblI1bjXMxcWFsWPHsmjRovxpffv2ZcWKFQD8/PPPDBgwoNQ8hg8fzuLFi0lNTQUgKiqKmJiY6iu0oiiKoih1ggrcasFLL71UoHfpF198wQ8//EBAQABLly7l888/L3X522+/nYcffpg+ffrQuXNnxowZQ0pKSnUXW1EURVGUWtYgnlUaFBQku3fvXtvFuGkFBQWxe/duhg8fTocOHWq7OIqiKIpSrzX4Z5UqiqIoiqLcDFTgpiiKoiiKUk80uF6liqIoiqLc/C5fyyAjx4C1hRnWFuZYW5phbWGGlbkZQojaLl6lqcBNURRFUZR6LyPbwL4L8ew8F8vOc7GExaWVmFYL5sywtjS//t4kuLPJn67/tbz+/tHeLWnubFuDW1aQCtwURVEU5SZ16GIC76w/RVaugUY2ljSytaSRjYX+15JGthYm0wt+drSxwNK8+lpU5RqMpGTmkpyZQ3JGLkKAh6M1LvZWWJRjvVJKQmNS8wO1/WEJZOcasbE0o4+vKxP6tMTF3oqsXKP2yjFcf59rICunhPe5RhLTc8jKMZBdTPoRnZqqwE1RFEVRlKpjNEq+3X2Bj/86S3NnGzo2cyI5M4eYlExCY/KCpRyMZQwsYWdlXkyAZ4G9tQVm5bjdKJGkZRlIzsjJD9Dy1p2WbSh2GSHA1d4KNwdr3B2tcc/7q7/MhOCf8/HsOhdL1LUMANp4ODChd0sGtXMn0McFG0vzCu+z+kIFbjXEwcEhf8DcPLt27eKFF17g+PHjrFixgjFjxhS77KZNm3j++ecxGAxMnjyZV199tUiarKwsJkyYQFBQEK6urqxcuRIfHx/i4+MZM2YMBw8e5LHHHmPhwoXVsn2KoihK3ZCYls1Lq47x95kY7ujcjA/u70wjG8si6aSUpGVfD6qS0nNMasBySM7MLRJw5QV+qVm55S6PvbUe/NlY4uNmV2INn8FoJDY1m9iUrOuv1CwuxKYRm5JFtsGYn6eDtQX9/FyZOsSPQe3c8azFGrCapgK3WtSiRQuWLFnC/PnzS0xjMBiYOnUqW7ZswcvLi8DAQEaPHo2/v3+BdIsWLaJx48aEhoayYsUKZs2axcqVK7GxseHdd98lODiY4ODg6t4kRVEUpRYFhScwbfkR4lOzeffujjzau2WJDfGFEDhYW+BgbUFz6nbgI6UkOSOX2NRMMrKNtG/mWK23ceuyhrnVdYSPjw8BAQGYmZV8GA4cOICfnx++vr5YWVnx4IMPsnbt2iLp1q5dy8SJEwEYM2YM27ZtQ0qJvb09/fv3x8bGptq2Q1EURaldRqPkm53nGfvNPizNzfjt2b6M7+NTr3tPmhJC4GRniZ+HI529nBps0AbVXOMmhBgBfA6YA99LKecVmt8SWAy4AwnAo1LKSH3eR8AdaMHlFuB5KaUUQnQHlgC2wIa86eUu1MZX4cqJG9yyQpp2hpHzyk5XCVFRUXh7e+d/9vLyYv/+/aWms7CwwMnJifj4eNzc3KqlXIqiKErdYHprdFTnpsy7P6DYW6PKzaHaQlYhhDnwJTAS8AceEkL4F0o2H/hJShkAzAE+0JftC/QDAoBOQCAwSF/mK+BJoI3+GlFd26AoiqJUjVyDkbVHo5jxy1GupWfXdnFqlNEo2XzyCpuCowkKT+BSfDoZJTTMr6ig8ETu+M9u9oTEMefujnz5cDcVtN3kqrPGrScQKqW8ACCEWAHcDZwySeMPzNDfbwfW6O8lYANYAQKwBK4KIZoBjaSU+/Q8fwLuATaWu1TVVDNWXTw9PYmIiMj/HBkZiaenZ4npvLy8yM3NJSkpCVdX15osqqIoShGZOQZWBUXy7a7zRCRoPQBbuNjxwq1ta7lkNWf+5rP8d8f5ItMdrC0K9JbM6z3ZyNbSZGyx4scSs7YwZ9PJaD7adJbmzrb8+kxfOns51cLWKTWtOgM3TyDC5HMk0KtQmmPAfWi3U+8FHIUQrlLKf4UQ24FotMBtoZTytBCih56PaZ5FoxhACPEU8BTAoUOHqmBzakdgYCAhISGEhYXh6enJihUrWL58eZF0o0eP5scff6RPnz6sXr2aoUOH3jRtGxRFqX+SMnJYti+cH/aGEZeazS3ezrx5hz8rDkaw9N9wnh7U+qYesiHPr0GR/HfHeR4M9GZ8n5YFekua9p48HZ3MrpQsUjLL31sTYGSnpnw4Rt0abUhqu1fpy8BCIcRjwC4gCjAIIfyADoCXnm6LEGIAkFHejKWU3wLfAgQFBZW/DVw1SU9Px8vLK//zjBkzGDBgAPfeey+JiYmsX7+et956i5MnTxZYzsLCgoULFzJ8+HAMBgNPPPEEHTt2BGD27Nn06NGD0aNHM2nSJMaPH4+fnx8uLi6sWLEiPw8fHx+Sk5PJzs5mzZo1bN68uUivVEVRlKoQk5zJor1h/LzvEqlZuQxq684zg1vTq5VLfi/Gh7/fz7qjlxkb6F12hvXYwYsJvPrbcfq2duXdezqVq0F9Zo6B1KzcogPGFjN4rLOdJUPbe6h/0huY6gzcogDTb6WXPi2flPIyWo0bQggH4H4p5TUhxJPAPillqj5vI9AHWMr1YK7YPOsqo9FY7PTIyMhip5saNWoUo0aNKjJ9zpw5+e9tbGxYtWpVsctfvHixfIVUFEWppItxaXy7+wKrgyLJNRi5I6A5Tw/ypWPzgrfv+rR2pUOzRny/5wIP9PCqk0HHjrMxONtZcYu3c6XzuBSfzpSlQXg3tuOrR7qXuxekjaV5g6iJVCqvOvvTHgTaCCFaCSGsgAeBdaYJhBBuQoi8MryG1sMU4BIwSAhhIYSwROuYcFpKGQ0kCyF6C+3bPgEoOjaGoijKTSAlM4cle8O4kpRZ20Up0aX4dF5ceZShn+xgdVAkD3T3YvvLg/nioa5FgjbQhnWY3L8V566msjsk7obXfzo6mbVHq+7/95iUTJ76KYgxX/3D0n3hVGTQgjzJmTk88eNBDEbJoscCcbJTtzGVqlNtNW5SylwhxDTgL7ThQBZLKU8KIeYAh6SU64DBwAdCCIl2q3SqvvhqYChwAq2jwiYp5Xp93rNcHw5kIxXpmKAoilIPSClZe/Qy7284TUxKFiExqcy9t3NtF6uA2JQsFv4dwvIDlzA3Ezw5wJdJ/Vvh0ajsMSPv6tKceZvOsGhPGAPbule6DDkGI9OWH+ZCXBqdPZ3wdXeodF55lv0bTrbBSG9fF95cE8ypy8m8M7ojVhblq+fINRiZtvwIF+PS+GlST1q52d9wmRTFVLW2cZNSbkAba8102myT96vRgrTCyxmAKSXkeQhtiBBFUZSbzqnLyby1LpiDFxMJ8HKipasdf528wpy7O2FuVvu3FZMzc/hu1wUW7QkjK9fIg4HeTB/WhiblCNjyWFmYMbFPS+ZvPse5qym0beJYqbIs2xfO+dg0zAR8tzuMD+67seA2M8fAsv2XuLWDB9+M78Enem/Q0JgU/vtId9wdrcvM470/T7PrXCzz7utM39ZqHE2l6jXcoYcVRVHqkKT0HN5aG8ydX+wmNCaVefd1Zs2z/XisbyviUrM5EJZQq+XLzDHw3a4LDPxoO1/8HcqwDk3YOmMQc+/tXKGgLc/DvVpiY2nG4j1hlSpPYlo2n20Nob+fGw/2bMGvhyOJSbmxW8q/H4kiIS2bSf19MTcTzBzRni8e6sqJqCTuXriH4KikUpdf+u9Flvxzkcn9W/FgzxY3VBZFKYkK3BRFUWqR0Sj55WAEQz/ZwdJ94TzSqyXbXx7Mgz1bYGYmGNLeHRtLMzYGR9dK+XINRlYevMSQ+TuYu+E0AV7O/PFcf754qOsN3QZ0sbfivm5e/HYkivjUrAov//m2EFIyc3jjzg48NcCXHIORJXsvVro8UkoW7QnDv1kjevu65E+/q0tzVj/dF4D7v/qnxPZ0u0NieXv9KYa19+C1UR0qXQ5FKYsK3BRFUWrJ8chr3PvVP8z89Tg+bvasm9afd+/phLOdVX4aOysLhrTzYGPwFQzGmh3ZaOupqwz/bBezfj1Bk0Y2LH+yFz890ZNOnlUz0OsT/VqRnWtk2b5LFVouNCaFpfvCebhXC9o3bYSPmz0jOzVl6b5wUjJzKlWWnediCY1JZfKAVkV6unbydGLdc/3p4uXM8yuOMm/jmQLHIjQmhWd/PkwbDwc+f6hrnbilrdy8VOBWQxwcijaaXbBgAf7+/gQEBDBs2DDCw8OLXXbTpk20a9cOPz8/5s0r/skPWVlZjBs3Dj8/P3r16pU/BEh8fDxDhgzBwcGBadOmVdn2KIpScVJKopMy2BMSx2u/HefuL/cSlZjBgrFdWP10nxIDopGdmxGbkkVQeGKNlXPBlnNM/ukQQgi+Gd+d35/tW+Vttvw8HBjSzp2l+y6SmVP+R0C99+dp7KzMedHk6QtTBrYmJTOXFQciSlmyZIv2hOHhaM2dAc2Lne/mYM2yyb14uFcLvt55nkk/HiQpI4eEtGyeWHIIawszvp/YAwfr2h4eVbnZqTOsFnXt2pVDhw5hZ2fHV199xcyZM1m5cmWBNAaDgalTp7Jlyxa8vLwIDAxk9OjRRQbQXbRoEY0bNyY0NJQVK1Ywa9YsVq5ciY2NDe+++y7BwcEEBwfX5OYpSoOVlWsgPD6d8zGpnI9NJTQmlfOxaVyITSVNf0aluZlgUr9WPH9rGxzLGPV+aHsPrCzM2HAimp6tXEpNe6Oyc4289tsJfj2sDe3x/n2dyz0GWWVMHuDLIxUYkHf72Rh2nI3ljTs64OpwvbNAF29n+vi6smhPGBP7+pS7FyjA2Ssp7A6J45Xh7UpdzsrCjPfv7Yx/s0a8ve4k9365F2c7S64kZ7Liqd54NbYr9zoVpbJU4FaLhgwZkv++d+/eLFu2rEiaAwcO4Ofnh6+vLwAPPvgga9euLRK4rV27lrfffhuAMWPGMG3aNKSU2Nvb079/f0JDQ6tvQxRFAeD73RdYti+cSwnpmN7V9HS2xdfdngd6eNPaw4HW7va0a+JYIPAojYO1BYPburMxOJrZd/pjVk234pIzc3h22WH2hMbx4q1tmT7Mr9oHyO3b2pX2TR1ZtCeszAF5cwxG5v55Gh9XOyb08Sky/+nBrZm4+ABrjkYxtkf5n8qwaM8FbCzNeLicHQoe7d2SNh4OPPOzNhTJ5w/eQrcWjcu9PkW5EQ0ucPvwwIecSThTpXm2d2nPrJ6zbiiPRYsWMXLkyCLTo6Ki8Pa+fgHy8vJi//79paazsLDAycmJ+Ph43NxUd3RFqQnHI68xd8NpurdozOhbPGntbk9rdwd83e2xs7rxS+2ozs3YfOoqRyIS6d6y6mvdopMyePyHg4TGpDL/gS6M6e5V9kJVQAjBpP6teGX1cfaExjGgTcnjui3ff4nQmFS+m9Cj2JqxgW3c6NCsEd/uusCYbl7lCnBjU7JYc+QyYwO9aGxvVWb6PL18XdkwfQAXYlPp66eus0rNaXCBW120bNkyDh06xM6dO2u7KIqiVILRKHlzTTBuDtYsfjywWh74PbSDB1bmZvx5/EqVB26no5N5/IeDpGblsuTxnvRvU7OByOhbmvPhprN8vzusxMDtWno2n249Rz8/V27t4FFsGiEETw/y5fkVR9l2Jobb/JuUue5l+7QBdx/v16rC5W7qZENTp4oPhaIoN6LBBW43WjNW1bZu3crcuXPZuXMn1tZFb5t4enoSEXG9sW1kZCSenp4lpvPy8iI3N5ekpCRcXeaeQdUAACAASURBVF2rteyKomhWHorgWGQSn427pVqCNoBGNpYMbOvGxuBo3rijQ5XdLt0dEsszyw7jYG3Bqqf70KFZoyrJtyKsLcyZ2Kcln2w5R8jVFNoUMyDvZ1tDSM7I4c07/Uu9nXpH52Z8tOks3+w8X2bglpljYNm+cIa196B1FTx1QVFqgupVWouOHDnClClTWLduHR4exf8HGRgYSEhICGFhYWRnZ7NixQpGjx5dJN3o0aP58ccfAVi9ejVDhw6tkw9vVpSbTUJaNh9uOkOvVi7cfUvxPRKryshOzYhOyuRY5LUqyW/VoQge/+EgXo1t+X1q31oJ2vI80rsl1hZmLN5bdEDevOE/HuqpDf9RGgtzM54c0IpD4Ykculj6oMVrjkQRn5bNpAEVr21TlNrS4Grcakt6ejpeXtfbjMyYMYMNGzaQmprKAw88AECLFi1Yt25dgeUsLCxYuHAhw4cPx2Aw8MQTT9CxY0cAZs+eTY8ePRg9ejSTJk1i/Pjx+Pn54eLiwooVK/Lz8PHxITk5mezsbNasWcPmzZuLdG5QFKVyPv7rDCmZubx7T6dq/2fpVv8mWJoLNpyIpusNNIaXUvL5tpD8Jw/899Fu1VZTWF55A/L+ejiSl29vV6Djxtw/T2Nnac6M29qWksN1YwO9+XxbCF/vvMD3PsXfVs4bcLdDs0b08VV3J5T6QwVuNcRoNBaZNmPGjHItO2rUKEaNGlVk+pw5c/Lf29jYsGrVqmKXzxvTTVGUqnXkUiIrDkYwuX+rSj9vsyKcbC3p7+fGhhNXeH1Uh0oFijkGI6//doJVQZHc382LD+7rXKGhM6rTpP4+/O/AJX7ef4npw9oAsONsDNvPxvJ/ozqUuxeunZUFE/r48Pm2kBJvve4KiSMkJpVPHuii7k4o9Urd+LYqiqLUMwaj5M21wXg4WvP8reWrCaoKIzs3I+paBifKeG5mSb7acZ5VQZFMH9aG+Q8E1JmgDcDPw5HB7dz56V9tQN5cg5H39OE/Jvb1qVBeE/v6YGNpxje7LhQ7P2/A3bu6VO/tbUWpanXnG6soilKDTl5O4v0Npyv9iKTlBy4RHJXMG3f41+ho+bf7N8HCTPDniYo/uzQiIZ0vt4dyR0AzZtzWtk7WNE3u70tcajbrjl1m+QFt+I/XR3WocIDpYm/Fg4EtWHs0iuikjALzzl5JYde5WCb0aVmnAldFKQ91xiqK0uAkZ+YwZWkQ3+66wNhv9nE1ObNCy8elZvHxpjP0be3KnQHNqqmUxXO2s6KvnxsbT1xByoo9u/Sd9ScxNxO8eUfdbePaz08bkPebnedZsOUcfVu7lmtYj+JM6t8Ko4TFewp2eFi8J0wbcLdXy6oosqLUKBW4KYrS4Ly19iTRSZnMGtGeS/Fp3PvlXs5eSSn38h9uPENGjoE5d1d/h4TijOrUlEsJ6Zy8nFzuZbaeusrW0zG8cGubOj32mBCCJ/q34nxsWrmG/yiNt4sddwY0Y/n+SyRlaDWrcalZ/H40ivu7eeFSgQF3FaWuUIGboigNytqjUfx+JIrnhvrxzODW/PJ0H3KNkjFf/cM/oXFlLh8UnsCqoEgm9ffFz6N2xv66vWNTzM203qXlkZlj4O31J2nj4VCpgWZr2t23NMfT2ZbxvVve8BAlTw30JS1bG68N9AF3c4080b/u7wdFKY4K3BRFaTAiE9N54/dgurVwZtoQPwA6Nnfi96n9aOZsw8QfDvDb4cgSl881GHljzUmaO9kwfZhfTRW7CBd7K/r4urLhRHS5bpf+d8d5IhMzmHN3p2p9YHxVsbYwZ/vLg3nrro43nFfH5k4MbOvOD3svkpyZw9J/wxmqBtxV6rG6/w2+STg4FL1I7Nq1i27dumFhYcHq1asrtOyCBQvw9/cnICCAYcOGER4eXuyymzZtol27dvj5+TFv3rxi02RlZTFu3Dj8/Pzo1atX/vAh8fHxDBkyBAcHB6ZNm1aOrVSUustglMxYeQwJfDauKxYmAYynsy2rnu5Lj5YuzPjlGAv/Dik2IFq2L5zT0cm8ead/lTx/9EaM6tyMi/HpnI4u/Rbvxbg0vt55nrtvaU6f1vVnvDIrC7MqezrE04N8iUvN4skfDxGfls1kVdum1GMqcKtFLVq0YMmSJTz88MMVXrZr164cOnSI48ePM2bMGGbOnFkkjcFgYOrUqWzcuJFTp07xv//9j1OnThVJt2jRIho3bkxoaCgvvvgis2ZpjwWzsbHh3XffZf78+RXfOEWpY77eeZ4DFxOYc3dHWrjaFZnvZGvJj0/05L6unszffI7XfjtBjuH6+IuxKVl8svkcA9q4MaJT05oserFu79gEMwEbg0u+XSql5O31J7EyN+P/RnWowdLVLX18XQnwcmJ/WALtmzrWqwBWUQpTgVst8vHxISAgADOzih+GIUOGYGen/fj07t2byMiit3cOHDiAn58fvr6+WFlZ8eCDD7J27doi6dauXcvEiRMBGDNmDNu2bUNKib29Pf3798fGpu42ZFaU8jgacY1Pt5zjri7Nubdr0Wf95rGyMOOTsV14bqifNrDuj4dIzcoF4IMNp8nKNdZah4TC3Bys6dXKlT9LuV3618mr7Dgby4u3tcWjUcP9HgsheGZQawCeHOBbJ46folRWg3tywpX33yfr9JkqzdO6Q3uavv56leZZEYsWLWLkyJFFpkdFReHt7Z3/2cvLi/3795eazsLCAicnJ+Lj43Fzc6u+QitKDUnLyuWFFUfwcLTmvXI8lkoIwUu3t6O5sy1vrAlm3Df/8szg1vx2JIppQ/xo5WZfQyUv26iAZry5JphzV1Np17Tg0wHSs3N5949TtG/qyMQ+atiLEZ2asnZqPwK8nGq7KIpyQ1SNWz23bNkyDh06xCuvvFLbRVGUOmnO+lOEJ6SzYNwtONmW/3mcD/VswfcTe3AxLo1py4/g6WzL1CG11yGhOMM7NkEIiu1d+uX2UKKuaR0SLOpBh4TqJoSgi7ezqm1T6r0GV+NWmzVjVW3r1q3MnTuXnTt3Ym1d9Bl+np6eRERE5H+OjIzE07PobaK8dF5eXuTm5pKUlISrq2oDotR/m4KjWXkogmcHt6Z3JR4kPqSdByun9OGNNcG8dHtbbK3Mq6GUlefhaEOgjwsbTkTzoskD2M/HpvLtrgvc182Tnq2Kf8i6oij1k/o3rJ46cuQIU6ZMYd26dXh4eBSbJjAwkJCQEMLCwsjOzmbFihWMHj26SLrRo0fz448/ArB69WqGDh2q/itV6r0rSZm8+tsJAryceOEGniXaydOJNVP7MaCNexWWrurc0bkZITGphFzVepdKKXl73UlsLM15bWTD7ZCgKDerBlfjVlvS09Px8vLK/zxjxgwGDBjAvffeS2JiIuvXr+ett97i5MmT5Vp2w4YNpKam8sADDwBaD9V169YVWM7CwoKFCxcyfPhwDAYDTzzxBB07auMizZ49mx49ejB69GgmTZrE+PHj8fPzw8XFhRUrVuTn4ePjQ3JyMtnZ2axZs4bNmzfj7193H5ejKABGo+SlVUfJyjHy2bhbburnUY7o1JS3159kY/AV2jRxZGPwFXaHxPHO6I64OxatiVcUpX4TFX3WXX0UFBQku3fvXtvFuGkFBQWxe/duhg8fTocO6j/8uuLQxQSSMnJo7e6AV2PbBtXO6btdF5i74TTz7uvMgz1b1HZxqt0DX/9DSmYuvz7Tl2Gf7MTF3op10/o1qGOuKDcTIUSQlLJHcfNUjZui3GSMRslnW8/xn79D86dZmZvh42ZHa3cH7eVhT2t3B3zdHXCwvrkuAycvJ/HRX2e43b8J4wK9y17gJjCyUzPm/HGKl345xpXkTL58pJsK2hTlJnVzXbEVpYHLzDHw0qpj/Hk8mge6e/FgT2/Ox6ZxPjaV8zFpnL2SwuZTVzEYr9e0N3OyYVgHD967p3MtlrxqBIUnMm35YRrbWTHv/oAG01ZzZOemzPnjFJtOXmFsDy+6t2xc20VSFKWaNIjATUqJ0Wis1EC3SumMRmPZiZQaEZOSyZM/BXE88hqvjmzPlIHaQKPdWxbsVZida+RSQhqhMVpAt+tcLMv2XWL60Db1dpBWo1Hy/Z4LfLTpLM2cbfhuQg9c7K1qu1g1ppmTLd1bNiY0JpVZI9rXdnEURalGDSJwi4mJ4cqVKzRt2lQFb1XIaDRy5coVcnJyarsoDd7p6GQm/3iIhLRsvnqke6mPZLKyMMPPwxE/D23A1kFt3bnziz38cz6ee0p5qkBdlZiWzcurjrHtTAwjOzVl3v0BFRqv7Wbx2bhbyMgx4OqgOiQoys2sQQRuCxYsYN68eVy+fLnB3DqpKTk5OVy6dAkhBObmdWuMq4bi7zNXeW75ERxsLFj1dB86eVZsZHj/Zo1wtrNkT2hcvQvcDl9KZNrPh4lNzeKd0R2Z0Kdlg/2Oe7sUff6qoig3nwYRuF27dg03Nzd+//137OzsVIBRhaSUZGdnY2VlRZMmTWq7OA2KlJIf9l7kvT9P4d+8Ed9PCKSpU8VvdZqZCfq2dmVvaBxSynoR+Egp+X53GB9uOkMzZxt+faYvAV7OtV0sRVGUatcgAjfQxiO76667OHnyJFlZWbVdnJuKg4MDgYGBODmpZwAWFhaXhpuDFY42VXvrLsdg5O11J/l5/yWGd2zCp+Nuwc6q8l/nfn5ubDhxhbC4NHzdHaqwpFXvWrp2a3Tr6RiGd2zCR2O6NMhbo4qiNEwNJnAD8PPzw8+vbj1rULl5bTwRzXP/O4KjjQVTh/jxaO+W2FjeWG1vWk4aXx9dRNDxW/gnJIWnB7Vm5vB2mJndWC1Zfz83APaGxtXpwO3wpUSeW36EmJRM3rrLn8f6+tSLGkJFUZSqolrqK0o1yAvaOns50cnTiff+PM3Q+Tv45VAEuYbK9cTNzDHwyZ7VLDn1HYfjtvPRmABeHdn+hoM2gBYudng627InNO6G86oO2q3RC4z9+l+EgNVP9+Xxfq1U0KYoSoPToGrcFKUm5AVtXbydWfJ4II42lvwTGseHf51l5urjfLvrAi/f3o7hHZuUGXhIKTkemcTqoEjWHbtMZqM9WLlAtw6RjO1RdYPLCiHo7+fGxuBoDEaJeRUEg1Vpy6mrvPfnaW73b8LHD6hbo4qiNFwqcFOUKrQpuGjQBtDXz401rV356+RVPv7rDE8vC6KLtzOzRrSjb2u3IvnEJGfy+5EoVgdFEhKTirWFGSM6NSXUIpFLaXA66RAp2Sk4WjlWWdn7+rmy8lAEwVFJdPGuOw39s3ONfLDxDH4eDvxXPRFAUZQGTgVuilJFNgVHM2150aAtjxCCEZ2acmsHD347EsVnW87x8Hf7GdDGjVkj2tOmiQPbTsewOiiSnediMRgl3Vo48/69nbkjoBk2VkZ6Lz9PN49uHI45zK7IXdzhe0eVlT8vgNx7Pq5OBW7L9oUTFpfGD48FqqBNUZQGTwVuilIFygraTFmYmzG2hzejuzRn2b5wvtweyp1f7MHR2oKUrFyaNrJhykBf7u/uRWuTjgLHYo+Ra8zlkQ6PEJESwdbwrVUauLk7WtO+qSN7Q+N4dnDd6MRzLT2bz7eFMKCNG4Pbudd2cRRFUWqdCtwU5QZtCr7CtOVHCPByKjNoM2Vjac7kAb6MDfRm8Z4wIhMzuKtLc/r7uRXbxiw4LhiALu5dGNpiKGtD15KRm4GthW2VbUs/PzeW7gsnM8dwwz1gq8IXf4eSnJnD66M6qI4IiqIoqF6linJDtKDtMAFeTvz4RM9KjdfWyMaSF25ty/wHujCorXuJHQNOxJ3Aw9aDJvZNuK3lbWQaMtkbtfdGN6GA/n5uZOcaCQpPrNJ8K+NiXBo//XuRcT286dCsUW0XR1EUpU5QgZui6NKzcwmLSyMzx1Cu9FURtFVEcFwwndw6AdC9SXecrZ3ZEr6lStfRs5ULFmaiTgwLMm/jGSzNzZhxe9vaLoqiKEqdoW6VKorulVXH+fNENABNGlnj1dgOr8a2+ssu/29zZxu2n4mt0aAtKSuJ8ORw7vG7BwALMwuGeA9hS/gWsg3ZWJlbVcl67K0t6NrCmb21HLjtvxDPppNXeOm2tng4VvwxXoqiKDcrFbgpCmAwSnaHxNLPz5VerVyJTEwnMjGDI5eu8efxaHKNskB6IaCrt3ONBG1wvX1bXo0bwK0tb+X30N/ZF72PgV4Dq2xd/fzc+HxbCEnpOTjZ1fx4aUajZO6G0zRtZMPkAb41vn5FUZS6TAVuigKcjk4mOTOXsT28ufsWzwLzDEbJ1eRMIhMz8gO6XIORJwf61kjQBlr7NoGgo2vH/Gm9m/XGwdKBreFbqzxw+2xrCP9eiGNEp2ZVlm95rT0WxfHIJBaM7YKtVe13kFAURalLVOCmVFpYUhgbwjbwdMDTmJvV7x/YfRfiAejVyrXIPHMzQXNnW5o729KzlUtNFw3QatxaObUqMOCulbkVA70Gsj1iO7nGXCzMqubrfIu3M/ZW5uwNja/xwC0j28BHm87S2dOJewoF0IqiKIrqnKDcgC+OfMHXx77m15Bfa7soN2zfhQRaudnT1KnutaeSUnIi7kSB26R5bmt5G9eyrhF0NajK1mdpbkYvX9daaee2aM8FopMy+b87OlTJM1gVRVFuNipwUyolNj2W7Ze2Y2FmweeHPychM6G2i1RpBqPkQFg8vX1rpzatLNFp0SRkJtDZrXOReX2b98XG3KbKe5f2be3Khbg0Ll/LqNJ8SxOTksl/d5zndv8m9PYtWvOpKIqiqMBNqaRfQ34lV+ayYNAC0nPT+Szos9ouUqXltW+rq8HC8bjjAMUGbnaWdvT37M/fl/7GKI1Vts7+bfTHX9VgrdunW86RnWvktVEdamydiqIo9U21Bm5CiBFCiLNCiFAhxKvFzG8phNgmhDguhNghhPDSpw8RQhw1eWUKIe7R5y0RQoSZzLulOrdBKSrXmMvqc6vp3aw3Q1oMYYL/BH4P/Z2jMUdvOO/z184TmhhaBaUsv9Lat9UFwbHBWJlZ0bZx8eOZDWs5jNiMWI7HHq+ydbZr4oibg1WNBW5nriSz8mAE4/u0pJWbfY2sU1EUpT6qtsBNCGEOfAmMBPyBh4QQ/oWSzQd+klIGAHOADwCklNullLdIKW8BhgLpwGaT5V7Jmy+lvPFoQamQXZG7uJp+lXHtxgEwJWAKTeyaMHf/XHKNuZXONywpjEc3PMrjfz3OtcxrpaaVUpKaVfl1mdp3IQEfV7s62b4NtB6l7V3bY2lefA/WQV6DsDCzqNLbpUII+rZ2Y+/5eKSUZS9QyD/n49gUHE1CWnaZaaWUzP3zNI42ljw/rE1liqsoitJgVGeNW08gVEp5QUqZDawA7i6Uxh/4W3+/vZj5AGOAjVLK9GorqVIhv5z7BQ9bDwZ7Dwa023UzA2dyJuEMv5z9pVJ5pman8vz25zE3Myc1O5VPD39aJE12rpHdIbG8uSaYPh/8TY/3thCddGNtsK63b6ubtW25xlxOJ5wu9jZpHkcrR/o068O2S9sqFWRJKTGmF/169fdzIzYli5CY1Arld/ZKChMXH+DpZYfp9u4WRny2i7fXnSwxkNtxLpbdIXE8N9QPZ7uqGUhYURTlZlWdgZsnEGHyOVKfZuoYcJ/+/l7AUQhR+Bf0QeB/habN1W+vfiqEsC5u5UKIp4QQh4QQh2JjYyu3BUoRESkR/BP1D/e3vb/A8BO3tbyNvs37svDIQuIyKnZ7zSiNvL7ndS4lX+LTwZ8y3n88v4X8xpGYI6Rm5bLhRDTPrzhC9/e2MH7RAVYHRdKhmSOZOUb+Cr5yQ9tT19u3nb92nozcjGJ7lJq6teWtRKVGcTrhdIXyl1Jy+aWXCL3tdnILfU/6+mn7ZE9I+Y+nwSiZ+etxHG0sWTqpJ68Mb4e7ozUrD0YUG8jFpmQx98/T+LjaMaGPT4XKrii1LSo1qso7BilKWWq7c8LLwCAhxBFgEBAF5D8oUgjRDOgM/GWyzGtAeyAQcAFmFZexlPJbKWUPKWUPd3f3aip+w7Pq3CrMhBn3t7m/wHQhBK/1fI0MQwafBhWtLSvNt8e/ZXvEdl7u8TKBTQMZ0/oJGlm4M2XDa3R7dxPP/nyYXediGdGxKd9P6MGR2bfxw+M9advEgU0nbyxwy2/f5uvCsdhjVf7Q9huV98SE0mrcAIZ4D8FcmLM1fGuF8k/67TeSN2zEEB9P9DvvFKix82psh4+rHf+cL3/gtnhPGMcirvHWXf4MaOPO1CF+LJ3Ui2Nv3c6vz/QpEsgFzt1KaEwqr45sj5VFbV+OFKX8MnIzeHbrs8zYMYN/Lv9T28VRGpDqHIA3CvA2+eylT8snpbyMXuMmhHAA7pdSmjZuGgv8LqXMMVkmWn+bJYT4AS34U2pAtiGbNSFrGOw9mCb2TYrM93Hy4fGOj/Pdie+4r819dG/SHYCoaxk8+/NhYpIziyyTa32STJfvscjowcK1TVm4ZhtXUzIxtx+BrfdSArucZHr3yXRv2RgL84I/7CM6NmXh9lDiU7NwdSi24rVMee3b3BwtmPjbK2TkZrBj7I46M6DwibgTNLJqRAvHFqWma2zTmB5NerD10lamd5terryzL17kytz3sevdG/t+fYn9ZAHJf27A6c478tP083Nj7dHL5BiMWJqXHlhdjEtj/uaz3NrBg9FdmheYZ2VhRveWLnRv6cLUIX5k5xo5EXWNfRcSMBglwzs2LVeZFaWu+OTQJ1xIuoCbrRtz983lt7t/w9q8ctchRamI6vwX9yDQRgjRSghhhXbLc51pAiGEmxAirwyvAYsL5fEQhW6T6rVwCCEEcA8QXA1lV4qxOXwziVmJjG03tsQ0TwY8STP7ZvkdFVKzcpm05CAXYlLp7+fGgDbXX91a55DruoxG5i0Z6vYsA9u4M7CtGy8Ma8v6SU8zyGsQIdm/0sIju0jQBjC8U1OMEraevlqp7TFt37b54mai06K5lnWNE3EnKpVfdTgRd4LObp3RTvfSDWs5jLCkMM5fO19mWpmTQ9QrMxGWljSf9wGuTzyBbZcuXH333QK3TPv5uZGalcvxyNI7ixiNklm/HsfK3Iz37im7vHmB3NQhfkwf1qZc26codcXOiJ2sPLuSif4Teb//+1xKucSiE4tqu1hKA1FtgZuUMheYhnab8zTwi5TypBBijhBitJ5sMHBWCHEOaALMzVteCOGDVmO3s1DWPwshTgAnADfgveraBqWgX87+QgvHFvRu1rvENLYWtszqOYuQxBB+PrWM2Uu3Yhl7gp+HZfLxve35aEwXPhrThdmjWxNp9RWO1jasuvcbPnkgMH/e87e2oUOzRrze63UA5h2YV+y6/Js1wtvFlr9OVi5wy2vf1quVC0tOLsHLwQtzYc7OyMKnXO1Iz0kn9Fpome3b8gxrMQygXLdLY7/8kswTJ2g2Zw6WTZsizM1p9sH7GDMyCtwy7ePrihCwNzS+1PyWH7jE/rAE/u+ODnW2d66iVIW4jDhm/zObdo3bMb3bdPo078PIViP5/sT3hCeH13bxlAagWhuVSCk3SCnbSilbSynn6tNmSynX6e9XSynb6GkmSymzTJa9KKX0lLLgqKJSyqFSys5Syk5SykellBXr8qZUyrnEcxyJOcLYdmMxy6skTbkKJ1bDv1/Cltnw+9Ow9F6G/vkmA7IMfHXwY16Nfpj1lq8T8PcE2DYH0Doj/N+e/yM8OZz5g+bT3KF5sets7tCcKQFT+Dvib3ZE7CgyXwjBcP+m7AmJIyUzp2gGZchr32bd6DxnEs4wufNkunp0ZVfkrgrnVR1OJ5zGKI1ltm/L42HnQRf3Lmy9VHrgln7oEPHffofT/ffRaPjt+dOtfX1xf346qVu3kfznBgAa21vRsXkj9pQyntvlaxnM23iGfn6ujAvUW0ccXgpBP4LRUOJyilLfSCl5Y+8bpOWk8eHAD7Ey13pBzwycibW5NXP3za1Uz25FqQjVGlgpQErJpCUHGb9oP/Gp+XE0v5z9BSszK+72GQEn18DPY2FBB/h1Evz1Ouz7Ci7ugcwkhHNLHrboSibmzPDqA+N+ho73wf5vIP483x3/jr8j/ualHi/Rs1nPUsszwX8CrZ1a88H+D0jPKTpkxYhOTck2GNl+toSewxnX4NxmyEwqMmt/mNa+bV3Y/3C1ceXO1ncyyGsQ5xLPEZ0aXUxmNSuvY0JHt47lXua2lrdxJuEMESkRxc43JCcTNXMmll5eNH399SLzXR57DJsuAdot0zgtWOvn58aRS4mkZxcdN09Kyeu/n8BglMy7L0C75ZmTAX++BOunw7eDIeJAuctfbxkNkHgRQrZAQlhtl6bGxWXEEZZ082/38jPL2Ru1l5d6vERr59b5091s3Xiu63P8G/0vmy5uqsUSKg2BCtyUAjYFX2HbmRj2hMYxeuFeTl5OIi07lfWhaxlu6Ybzwl6waiJcOQ79psNTO2HWRXgjBl4Mhif/5t+eC3ks9BHcuZNjZpc42LgJjJgHFtbs2vQ8Xx79kjt87+DRDo+WWR5Lc0ve6P0Gl9Mu8+3xb4vM79aiMe6O1teHBTEa4fIR2PUxLB4BH/nC8gdg6X2QnZa/nNEoORCWgH/LNPZe3ssjHR7B2tyagd4DAepErdvx2OM0t2+Om61buZfJu1267eJm2PoOhG4rMP/KnHfJvRqD58cfYWZf9AkFwtyc5u9rt0yv6LdM+/u5kWPQ9ldhvx+JYsfZWF4Z3g5vFztt4qV/wZAFvZ6BtDhYdBv8/gykxlRg6+uo7DSIPqbVNG9/H1Y9Bl/1g/ebw+dd4OcxWs1zAxKRHMG49eN46M+HSMxMrO3iVJvQxFAWHFrAAM8BPNjuwSLzx7Ubh7+rPx8d/IiU7JRKrcMojSw6sYhNYSr4U0qmAjclX3aukQ83naGNhwO/PdMXZ2MCf3z9Or9+N4B0QyZjw4Oh9VB49Fd48STc0fWJewAAIABJREFU+jY0vwVsG4PeuDwsLo2nlwXh42bP8gdew9PBk7n75pJj70J478m8mhVGe3tP3urzVrkbpPdo2oO7W9/Njyd/LPI4LDMzwT1trbA/+yuG1U/C/DZaLc/f70FOOvR/QQsaLx+GleMhVxsA9vSVZJIycki23oqthW1+h4tWjVrh7ehdJ9q5BccFl7t9Wx4vRy86uLRny9HvYM8CWP2EdksbSFq/nuQ//sB92lRsu3QpMQ/r1q1xn/4cKVu2krxhAz1aumBlblbk8VexKVnM+eMU3Vo4M7Gvz/UZ5/8GcysY9iZMOwj9X4QTq+CL7lrNrKFqnnhRbaTU9lnYbji4CDa+qgX+n3bWArRvBmo1zbs+hstHoZEnBE6Gu/4D7e+Eq8HaPxANwOXUy0zaPIlMQyYZuRl8f+L72i5StcgyZDFr9ywcrByY029OsdcuczNzZveeTXxGPAuPLKzwOozSyJx/5/DZ4c+Y/c/sCo+HqTQc1TkciFLHZBuy89tkFGf5/nAuxqfz28hcuu55mj9ytoCZgTstW9IcZzpP2wn2LiUun5Sew6QlBzETsHhiIO4OdrzW8zWm/T2Nb49/y5bkI5gLMz6NTcTWrGIj5M/oMYPtEdt5b/97/DD8B4xxl0n/+T0cbE/zevRRhJkk+5wz5u1uA79btQDTweN6Blb2sO45WPss3Pst+y4kICyuEZy0g4faP4STtROgtZsb5DWIVedWkZGbga2FbYXKWVXiMuK4nHaZhzs8XLEFjUZuTcvgC2MaV7pPoOnRlbDhZbL7zePKO3Ow7d4d16eeKjMbl8cfJ3nLFq6++x6+vXrRvWXjIh0U3loXTHqWgY/GBGBuZvJDdn4HePfS9jloAf4tj8LGmbDpVTj8E4z6GHz6V2zbqoKUkJsFuZna38xrEPf/7J11WFX3G8A/lxJRkLKxwEIuioG62d01xe6Y7Zy6OZ0x5+zOOacTuztnd+tUFBNEEJDu5t7398dRHNIxFz8/z3Mf9Jxv3nvuue958zkEPkv+N+5PpnX9fGBZFkrWBsu+YFkOLMuDuTXofxCIIRp4cgTCvMCs1Mfd20fGL8qPQb8PIjIhkvXN17PtyTZ2PNlBb9veFM1f9O9eXq6y7O4ynoU8Y1WTVelqwO0s7ehWoRs7nu6gfdn22Flkzs0hUZvItCvTOOx+mM7lOnPgxQF+uf8L39f+Pre28J8hLC6My96XaVqq6f9t+pVPgtv/Cc9DntPzaE86lO3AxJoT0ddJXvcyPDaBZWeeM7nwTaqeXw75CqH6fDS3S1TD88YUYn0bMXSPG0u6GWNsmLJmZoJGy4htd/AKiWbr4NqUtFDMZg1KNKChVUPW3F+DjkqHtRUHUPz3GcqPd40BmV6/uaE546qP44drP3Do+X6qTZhN5LMoCjU0xbTbJHpfyI9V2c9Y0Lla6gNU6wtRAUqAhJEF1/27YFn8JglAn0p9kjWtZ1WPLY+3cNP3Jg1KNMj0GnOTR4GPALKmcROBo+No6naNFVbFOFv2M3qalkFOzcBnu+IDWGzePFS6Geeoe2cyfdnpC97MmEGdjqNZeOp5Us68Ew99Oebyhm9aVKBsIeP3HSP9wc8FmkxLPqBlWUVT+/SYIrw5twF1F2g+E0xSD07JNufnwZPDyQW0P/9NC+OiilBW2UkRzN69TIolaZQzpNDbcsz+j//TgltgTCCDTw4mJC6EX5v9iq2FLSOqjOCY+zFW31/NzDoz/+4l5hpXva+y2XUz3St0p75V/Qzbj6k2htOep5l5bSZbW2/NMCdkgjaByZcmc8LjBKMcRjG0ylB0VbrsebaH3pV6U8rkv3sdZRW3UDfGnB2DZ4Qn1g+s+bHOj1QpmLb14L/KJ1Pp/wnrH64nUZvIzqc7GXl6JOHx4cnO/3zuBT3jdvNl2FJUNo1hzF1oNoN9ATfIp5+PifV6cO5pAJ1WX+VlYFSyviLC9EOPuPIiiDlfVKZmmeRauYk1J1LYqDATHSdSq/bXUPJzxZSZSsBAenQq14kqBatwbe0MIp9FoWdpgv/lSOIKNKeobR1OPQkkQZOOiaruOKg9Am6soYLHLyQaXaV56eYpolprFK6BkZ7R32oudQl0QUelg625beY6iMCJSXBnA9a1RmNdwFqJLv18DEGvyxLz5BVFvhuHgdWHVefS5s8m03qv7wFw1S2IsOgEph58RKWiJnxZ3zr5Mp6fIfy1IV6/3SV485bkA6pUULENjLwJDb6Dx4fxWl2TLSdGcsfvDjGJOas7qyxA4PpqxRetsB2UqgMVWkGVHlBrKDSYqAiVLWZDm0XQaS0MOQvfecH4J9DvsHK81lCwaQQFimdeaAMoWFH56++a8738QwmJDWHIySH4Rfvxc9OfsS+oRD0XzV+U7hW7c8jtUKZyCf4bCIkN4fsr32NdwJrxNcZnqo+xgTHf1PiGR0GP2P1sd7pt4zXxTDg/gRMeJxhXfRxDqwwFYLjDcPR19Vl+d3mO9/Bf4ZznOXoe7UlUQhTf1fyO6MRo+hzrw4JbC3Ln3vFvQkT+86/q1avL/zNe4V5SZWMVmX9zvux7tk8cNjpI+/3txTPcU0REvIMjZdNUJ5HpJiJ7h4gkxouISEhMiFTbVE1mXpspIiJXXwSKw4zfxX76CTn/1D9p/PWX3KXUxCMy59jjNNeg1Wrf/8f7rsj0AiK/T8nyXh4fXyh37CvKuRZVJDE0VJ43ay7P6jeQk1ceS6mJR+Ty84D0B9BoJGRzP1m/uLiondXyKPBRqs3Gnh0rjXc1Tr7uj8jQk0Pli4NfZK6xVitycqry+R3/TkSrleV3l0vljZXlzc2L4mpbSV43Ly2yb2iW16FNSBB3p67ypFZtqTNxt3y3976M33VPrCcdFZfXoUnt4n19xX/5CnnmWFlcK1SUx/aVxdW2kkTduZvm2OFvXKTtBgdRO6tF7ayWKhuriNMhJ5l5baYcenFIPMI8sv7+B3so78PNdVnea66xyFZkz+C/b/6/kNDYUOlyqItU31xdbvjcSHE+OCZYam+tLV+d/epvWF3uotVqZfSZ0VJ1U1V5HJT2vS2tvoN+HyS1t9aWgOjU70mxibEy/NRwUTurZYvrlhTnV/6xUtTOanng/yBb6/+voNVqZc29NaJ2Vku3w93EN9JXREQi4iJk5rWZonZWS+u9reWW762/eaW5C3Bb0pBpPmnc/g9wfuSMSqWiT6U+dCrXibXN1xIUG0TPoz2563MDvw296KPzOxHVhkHHNaCrmEIPvDhAvDaebhW6AfCZjQWHRtWlmGleBmy4ya8X3Tn3xJ+fjrrSvFJhvm1RIc01JHPmLVYVHHopjupBmX8yF/9nGM7+BT1gRutEXOJeYrVsKZqQEMquW4CRnooTGRWd19Fhd4lv+M3EnJoxsVTyT33++lb18Y/252nI00yvL7cQkaSKCZni/Fy4sgxqDFI0SSoVTUs2xSBWg+83E9EvUoQio/vA/e1KuoosoNLTo9ic2Uh0NN8+PsihP7zZc+c1wxpYY1fUmMhLl/AaOYoXjZsQuHo1eQrEYdWzPOUuXkC/aFF8vv0WTWTKVIsiwlTXdXiptKx4E8BKu+EMVA/ExMCEw26HmXx5Mm33t6X+zvqMOD2CNffXcMP3BlrJwOnf977yt6hDlvaZqxSyVUyl/zEi4yMZdmoYbqFuLGu0LNVUPmaGZvS3688ZzzPcD7j/N6wy99j7fC/nvM7xVbWvqGheMUt9VSoVU2pNIU4Tx4JbC1Kcj0mMYdSZUVz2vsy0z6bRy7ZXijb97fpjbmjOkrtL/m9zw0UnRDPhwgRW3ltJG+s2OLd0pkg+pTxefoP8TKk9hfXN16MVLQN+H8Cs67OISojKYNR/P58Et/84gTGBHHhxgHbW7ZIueMcijmxtvRVTA2MGnxyMl/YmZ0qMxrj9PNBRLgmtaNn1bBfVClWjnFm5pPFKmBuxb8TntFQXYdaxxwzedBvboiYs7e6Ajk4WTEpNpiqRh6emZdwWID6aoO+6E+OvS5FvvkK3aBF+vP4jUq40had8T+zVq0wIuMrvj96g1aZ/kzvqcYowPWGAfhHYM0iJHvyAelb1gL8nLYhnhCfh8eGZE9wuLYILcxXn/9YLk8x6Fc0rMvayCfp+IXh+/QW6Lb9XzHiHx0JseAaDJiePjQ2Wo0dR7ultqr+8S5X8Gvq4X8CteQu8hnxJzL17WAwejM321ZSs44tx287omppSbMF8Enx88JuZsrjJhkcbOON5hvFVhtMwJoYGcYmMqTaGdS3WcbXHVfa238v0z6bTqEQjfCJ9WHVvFYNPDmbK5SkkatOJSvW9DypdKFwpS3tMjwRtAutd1uMalEnzZyFbCHz6z4+ezQLRCdGMODOCJ8FPWNxwMXWK10mzbZ9KfTA3NGfpnaX/WoHjZdhL5t+aT+2itVP4wGaW0gVKM8h+EMdeHuO67/Wk41EJUQw/PZybb24ys85MnMo7pdo/n34+hlYeyq03t7jknfIe9V/HO9KbPsf7cNrzNOOrj2dO3TkY6qWsylKzaE32tt9Lb9ve7Hy6ky8OfsFVn6t/w4o/Hp8Et/842x5vI14TzwB18kCAUjp52RwQjkNsLN8XtOCuvWUybcZ1n+t4RXilWpfUyECPVT2rMaF5edTFTFjXrwZGBlmMczEuAvXGKRF4LzMQjkSIXTuYgOvRGNdxoGDvoUypPYUXIS8YdmoYeh1aYdK+HbUv7qOY+0P+8Eq7rqZGo8Ut/ijGqhLU6X4AzErD9h7vNTVvscxridpC/fH83DwuK3nXnp3ExUdJWJthYMK1VUqwhb0TtF+eJHQDaEJCqHY7jLt1C/NV8Bo2PNmGtFsB4d5w+ocsL89iwAB0K6kZd283c3Z8T8iypegXL07xJYspd+4shcZ9jUHMW8HGuhEARtWqYTlsGGEHDxJ+7FjSWDd8b7Ds7jJalm5J7ypDoUBJ8L2XdF5XR5fyZuXpUr4LP9b5kQMdD3ClxxWGVxnOYffDfHfpOxK0aVTK8L2nCE76uRcNvPj2YpbeXUqPoz2Yd3Neqomgk1GoEmjiIdg919bwdxKbGMvos6N5EPCA+Q3m07BEw3TbG+kbMbTyUG773eaKz5WPs8hcQkQ473WeUWdGYaBrwKy6s95XiskGg+0HU8K4BLOuzyJeE09EfARDTw3lnv895tSdQ4eyHdLt71TeiRLGJVh6dyma/6MqJLfe3KL7ke74Rvqyqskq+qv7p5s+ykjfiIk1J7Kp1SYMdA0YemooP1z9Idv59P7pfBLc/sNExkey48kOmpZqSpkCZd6fCH4J65tj7P8cjWcf1MbN2fR4PRMuTEhy8tz1bBfmhuY0K9Us1bFVKhWjGpfj4Ki6FC2QzR/Jz0YqP9onJqdbGkl7ZQ0+m2+iZ2xEkYWrUalUNCzRkHn15/Eg4AGDTw3GcNJY9MtYM/H2Vi5eTVszsv3RSTB4QzOrrqjyWUCffWBYALZ0TmG2rV+iPi4BLgTFpF+nM8ckxilJWy8vhm1OPDz1LXkFbG5vVkybcancfG7+qlSssG2vmLc/iFyLPHsWtFo6fKUISIvvLGaWz0k0tYbD7fWKoJgFVHp6lFowF5Ny1lj06oX1saOU2uiMSatWqAzepnZxOwsWZcG0RFI/yxHDyVulCr4/zCDBx4c3UW/49uK3lDYpzYzPZyg342JVlKTJ6WBiYMIIhxGMrz6e3z1+Z8L5CcRr4pM3ElHyqhXNvSiz4y+Ps+XxFpzKO+FU3omtj7fS4WAHznmeS7tTobcBJbkQoBAdG0r3DQ4s3liXxDvOEPNxE9zGa+IZe24st97cYlbdWanfD2LD4foa2Pdl0svJ9SzFVXlYdnY82r1Dkp3jyNepX9N/M3f87tD3eF9Gnx2NSqViScMlFDIqlHHHdMijm4fva32PR7gHy+8u58uTX/Io6BELGyyktXXrDPvr6+ozpuoYnoc854j7kRyt5d+AiLDjyQ6+PPklZoZmbGuzjbrFM582yKGQA3va72GQehD7X+yn48GO6X9X/6V8Etz+w+x6touIhAgGqQe9P+j7ANY3R2JDGWc4Ew+zeji3m8+EGhM4/eo0A04M4FHgI857nadj2Y7p5n3LMfp5odkMJX3EH5tTb+N1i4CFc4kL06fovCXomZklnWpVphXLGi/DLdSNgReGk2/+NIy0CdismYs2IXWNzNbHm9AmmDDQ4QvlQAEr6LNfERy3fAER733kGlg1QBAue2dNyMkyf2xW8n512wJ9D+FiWQpbDNC7vkbJxD+3FPzaWDErPz+lJIU9NgHKt4LO60E3pbYz/NQp9IsXx9iuMvPqz2OAegA7n+5krH4Y0WallJx28Rlojj4gj40N1vv3UXjSd+SxTh5NSmIcvLqi5M/7Eyo9PYotmA+JibyeOJEJZ8cRp4ljSaMlGOm/rbRQrKqinYpJW1P6jv7q/kyqOYmzXmcZe24scZr3ZdmI8IXowFwT3F6EvGD61elULVSVSbUmMaX2FDa12kR+/fyMOTeGsefG8iYqFZ9KywqAKlf83E65bOKRjoYNhPHlrVkELqoA27rBg11/ufCj0WqYcGECV3yuMOPzGbSxbpO8QfBLJZJ5cSU4MRE8roDXDfC6gf7rW4yKjOeJNprf/W4kHcfzGtz+DR7tz3D+j2VmfRr8lBGnR9D/RH98In2Y9tk09nfYj2MRx1wZv05hR1qY27PRdSNPgx+ztP4impZqmun+zUs3x87CjpX3Via/3v9jJGgSmHFtBrNuzKJO8Tpsa72N0gVKZ3mcPLp5GFt9LNtab6NAngLpf1f/pXwS3P6jxGni2Oy6mdpFa7+vdfnyImxoDboGnHB05mBQcb5tUZE8+rr0s+vH8sbLcQ9zp9exXmhFS5fyXf76hdp1ghK14czMlOlBIgOIWtqX4CdGmDp1In/DlDnV6lvV5+emP+MX7cfAp9N43r8/5fxe8HRWSofgR0GPeB3rQr7YRpQyN3l/omB56LVbyUG2o1dS1ntbc1sK5i341/q5JcTCxUVKwtqKbUko9TlPEiOwt+sB33lC34OKSVnXAK6tVgS5o+PApgl03Qh6KQVrTUQE0VevYdysGSqVCh2VDuOqj2Nyrclc9LnCoBIlCQz1gPOzM73MR0GPmHxpMvV31GfpnaUpf0C8biqVKt6aSf+MQcmSFJ46ldhbtyl99D4z68zEusCfBL93gQS+mXNm72nbk2mfTeOy92VGnRn1PhVAUmBCzgW3yPhIvj7/NUZ6RixqsCgp76FDIQd2tdvF2GpjueJ9hQ4HOrD18dbkZiwDIzAvkysatwMexyiZkMCsql/zIJ8x3UqV4n6gC+wbAgvKwq6+4HpIqQ+by6x9sJZzXuf4ruZ3dCrXSTkoomhrd/SC5VXh5lqo2BqGnINxj+Cr+0mv1sPvUd6sPCuKWJEw6vbb4w/ArEyGgtuDgAe02teKEadH/GV1g70ivJh4cSJOh524F3CPr6t/zZEvjuBU3ilFnsts8cZFqbqxuCLf3jtB3Zg4Vvr40mDvaCWYKJPa03ff3zdRb9j+eHvO1/UPIzQ2lI2PNtLxYEf2Pt/LEPshLGu0jPwG+XM0rp2lHTvb7kz/u/ov5ZPg9h/l4IuDBMYEMsh+0NvcVmsUc2CB4sT0PcYP1xOpWtKU1vZFkvo0LNGQza02U9CoIE1LNaWEcYl0ZsglVCpoOUfRlFxa9P64JhHNlr74nNNgYFWUwpOmpDmEYxFH1jdfT2RCJCusDnDcpgrs2EzE2bPJ2m1wcQatIXULt005iFUNaLsEvG/D/W1vl6aivlV9rvpcJUGThk9VTrm7CSJ8oNFkUKl4FvKMeG086oJqRQCwbgiNp8DAE+8FufYrFe2cXupZwyMvXEQSEjBuntys1aNiD5Y2XMqLaD96lynLy1u/gPedNJem0Wo4/eo0/Y73o/uR7pzxPEMF8wqsf7he+bHzf++XhttZJSggjWoIl+x1uGqroscloW74B1n1i1VV/v7Jzy0jnMo7MbPOTG6+ucnw08OVSDLf+4AKCmetTNiHiAhTr0zFK8KLhQ0WUtCoYLLz+jr6DLIfxL4O+6haqCpzb86l17FePA76k4atUKUca9y8wr24He1Nx1ihvf0AtrTZhoGRJf3N8rCjxXeIQ294dRV29YEF5WDfUEWjngtc9bnKz/d/pr1Ne3pW7KloVO9tg1/qKcmTPa9B/Qkw9iF8sRaKp0x8raPS4atqX+EV4cW+5/uUgyqV8rDmfkGpY/sBIsKup7vof6I/GtFw2+82HQ92ZNfTXRlHFGeSwJhAZl2fRfv97TnreZaB6oEc/+I4A9UDc14pJSpQiZZfU1d53V4PpetSqNt2fh78kM87blCE+lPTFE3l0fFKpY4MqFm0JnWK1+FXl18Ji8ta/st/IiLCPf97TL40mSa7m7Dw9kIs8lqwovEKxlQbk2HS4sySqe/qv5G08oT8l17/b3ncEjQJ0nJPS+l+uLtow/1ENndWcltt7SoSFSTLTz+TUhOPyK2XQWn2j9fEf9xF7xsm8qOlSJCb8v+TU8W7RUlxtbWV6Hv3MjXE8+Dn0mhnI6n+q6OcqNtQnjjWlDgvLxFRctnZO1eW8otGyL67XqkPoNWK/NpUZH5ZkZgwERE58+qMqJ3Vct3neo63mIL4aJEF5UV+a6XMLSLbH28XtbNavCO8sz2s11dj5WnduqLVaFI9/8D/gdTfXk/q/GYnd352FEmIS3Y+PC5cnB86S4s9LUTtrJYWe1rIxocbJTwuXERErry+Is12NxN7Z3uZd3OeRCdEi/zSQGR9i1TnexL0RGpsriHD9vWRZw0ayIsWLUUTFZW80RK1yK5+Wd7rMfdjUmVjFel1tJeEb+kissIxy2N8yG8uv4naWS3OD50zbKvVauWY+zFpsKOBVN5YWebfnC9R8VEiZ2aK/GAqEh+T7XUsv7tcKm9Qi++mdknHQmNDk3J/Tbo4SaJjw0VenBU5MFJkdgklh1wan3tmeRP5RurvqC8dD3SUqBAPkXNzRObbKPeQlbVEbjsr124m0Gq10u94P2m4s6HyvoiI+D5Qxrr1W7K2MQkxMvnSZFE7q2XYqWESGhsqXuFeMuj3QaJ2VsvAEwOTck9mh4DoAFl2Z5k4bnGUKhuryI9XfxS/KL9sj5dEYrzI4yMi23uKzDBX9vZLA5Eba0WiUr/His99kf3DlXvedBORLU7K55hO3sInQU/E3tleFt1alPM1/01ExEXI9sfbpdPBTqJ2VkutrbXkp2s/ydPgp3/53Gl+V/+hkE4et79dqPoYr/83we24+3FRO6vl1PVFihDyY0HlJqLVin94rFSaely+3PRxkxUmhoeLNjEx7QZhPiI/FRXZ0Uvk0UEJG1BIXCtUFP/lK7I0j2e4p9TZ0lQaLXIQl6pVxb1zF9HExcns67OlsrODlP5+q3iHpPOj8/q2ciP9/XsREYmKj5Jqm6rJvJvzsrSOTHF1lTLXy0tJhyZfmiz1d9TPduJfTUyMPK5aTXymTU+3nWe4p7Td0Uiq/WYnJ44MExGRV2GvZPb12VJzS01RO6ul3/F+ctrjtCRqUn5ukfGRSckvW+1uITfnFBI5NzdFu7C4MGm1t5U03tlYAqIDJPL6DXGtaCs+U6clb7ijt8jSKtna82mP0+KwyUG6/Wonobv7Z2uMd1z3uS6VN1aWcefGZekzCI0NlRlXZ4jaWS2DTgwScdmjfLa+2UuemqhJlCa7GsvQn8sqQuCf0Gg1svrearF3tpfOBzuLZ9hbYeb+LmXOV9eyNaeISLwmXvoe6ys1t9QUtwBXkQXlMi1YpMUffn+I2lkta++vVQ5otSLLq4k4vxdIvcK9pMuhLmLvbC+r/lglGu174VOr1cqep3uk9tba4rjFUTY/2pzqNZkaWq1Wrvtcl3HnxonDRiXZ84TzE8QjzCPL+0iVRwdE5lkr79H8ssp9403qSb1TJcIvDcE4dYF/0sVJUm1TtaQktLnN0+Cn8iToSa6P6xroKtOvTBfHLY6idlaL0yEn2f10998iOP35u9p0d1M553nuo68hM3wS3P6PBDetViudD34hbTfXFs10E5FVtZPdSL7f/0BsJh0VN/+Ij7KeeG9v8Z40WVxtK8kTx5riOXyEBG7YIDGPHqUU5C7MF5luIvGTisjTKrbi3rmzaOOzrvm75+MhtmuayKDJShZ/j2lTxHGLozRyHir155/NeID9I0RmWIgEPBcRkaGnhkrbfW2zvI50iYtUbtbOycdtv7+9jDw9MtvDhp85I64VKkrEpcsZtg2JCZE+mz4TtbNa+h5UfjQdNjnIpIuT5GHgw0zNd9P3prTaXl/UzmqZeWqURMZHJp3TaDUy6vQocdjoIH/4/ZF03G/hInGtUFHCT516P9DFRcoPV3Rw5jf7Jy48OyjVfrOTztsaSFBMGlqODPCN9JX6O+pLu/3tku0jK2xw2SBqZ7X88eSAsp/7O7M1zpXXV0TtrJbj84uIPD6aapuLXhfl822fy2fbPpMLXhck5sEdiRpdVOTYxGzNKSKy6NYiUTur5ajbUZGH+5Q9PDmW7fHeMerMKKm9tbaExIQoB95pJCP8U+wjLXwjfZO0jb2P9ha3ULc024bEhIjzQ2dpu6+tqJ3VUmd7HZl/c764h7rneC9J+NwTmVlI0a49PSGSmJD9sRJiRf7YKrK6jvKe7x6QajPvCG+puqmqfH/p++zPlQZarVZa7GkhNTbXkHv+mbNyZERQTJD0PdZX1M5qqbG5hky9PFVcAlz+too0f+au313peKCjqJ3VMvbs2L9MGM4u6Qlun3zc/mNcebyLpyHPGPjmFTqOQ5Q6jG+Tkb7wj2T7TS961iqJdcGcOX5mRGJICH5z5uLWoiXhR45g1r07Ji2aE+f2Av+583j5RWeeffY5XiNGEuTsTKyrK1JzOGJihe8NE7RiQLH5C1CaT9JgAAAgAElEQVTpZ91JuErRUpROmMA9mxIcralL9M491LkVRaD3Z9QuY5HxAE2mgZ6hkm4DqF+8Ph7hHniEeSh7CwoidN9+RJMDJ9db65Wi9w0nJx2KiI/gZdjLrBWW/4CIk6fQMTEhX82MI+JMDU35tcMeWsUk4hH8lC8rf8nJzieZXW82dhZ2mZrPsYgje/Pa0Scyjl3eF+h0sBNXvZXkl+tc1nH+9Xm+cfwGh0LvKxkUHD0Kw0qV8J0ylQQ/f+VgsawFKHxIfYxY4R/Aq8RwBp4YiH+0f5b6J2gSGH9hPLGJsSxtuJR8+vmytY6uFbpiYmDChtenQUc/2wEKB14cwEQnD42io9/7AH5APat67Gi7g+L5i/Pj7hE86zcArwtmaO4dTAqwyQrnPM+x4dEGulXopqSqcNkD+QtDuebZ2sOf+arqV0QlRLH+4XrlgF0ntKLl54uTGXlmJEXzFWVn253pFnEvkq8Iq5qsYnbd2biHueN0yIn1LuuTEjKLKH5T31/+PslvyjSPKbPrzuZ0l9N84/hN8rRIOSEqCHb0BiML6LkbyrdINbo70+jlAYeeMOwSOA5RAk6ig1M0K5a/GD0r9uSQ2yGehTzLwQZS8jDwId6R3gjC6DOjeRX+KkfjRcRHMOzUMB4FPWKi40TOdD3Dj3V+RG2pTjcn28eiaqGq7Gq7i6+qfcUl70u02teKby98y603txSt1j+YT4LbfwURuOPM+kvTKKTR0rbNL9BmYbJEpPNOPCGvvi5fNSmXzkA5QxsVRcDq1bg1bUbw5s2YtG+HzYnjFJk2laIzZ1L2998pe/4cxRbMTynINWjKq+u2RHnrUGjit+Sxzv5Nto1dWQJfDOB+56rctVbx5QktrW7dp7a1WcadjQtDg2/h+e/w/FTSj8nF1xeJc3+JR7fu+E6eTMSp09lbXFwkXFmqpM4o9VnS4UdBjxAk86WuPkASEog4dw7jRg3f51bLgDwmxZhfawrnPV4xyrBUCkf8jCcV8rpf4lsLRza12oShniFDTw9l9NnRrPxDKVPTo2KPZF1UBgYUW7gQbWwsvpMmIVrt+8hSn8wHKCTD9x6fx8SyusEifKJ8aLVXuQlf8b6SqSiy+bfm8yDggRLxamqdYfu0MNI3okfFHpx7fQH3gjbZClAIiwvjjOcZ2uiakydfETApmmbbEsYl2NhwLT8ezU9CYjzaOC2e9yPg9a0szfk64jXfX/meShaV+NbxWyXC+/kpJZAgFxzFy5qVpZ1NO7Y93sabqDeEFbBiVInSrA64TjubdmxuvTlTwVAqlYp2Nu042PEg9azqsfTuUnod68XGRxvpcrgLfY734YznGTqV68SednvY3Hoz7WzapZpxP9toEmFPf4j0U4KE8mfxO5MeKhVU7Q3aBHA9kGqTwfaDya+fn2V3l+XevMAJjxPo6+izseVGVCoVw04NIzAmZQBJZnhX0ut5yHMWN1xM70q9MTEwybjjR0ZfV5/B9oM50OEA3St057LPZQb+PpAOBzuwxXXLPzYQ5JPg9l8gOhh29eXeyW+4bWhAP4fh6Nu2S9bk0vMATrn6MbyhDRb5U49GzAna+HiCN2/hRbPmBC5fQb7PP8P68CGKzZqFfrFiydrqFylCgXbtUgpyzZuRGBaBccuWmPXokcZMmaOFXRHQGtLQcgrhPw7H27EW/R8fp/L+3xRBISNqDQNzGzjxHVZ5C1HWtCxuF47g0aMH2uhodC0tCd29O3uLu7kWooOSadtAeeKFTFRMSIPoW7fQhoVh3Cz1pMlpUrkbKouycG5O1jU1QW4Q5gk2jXAo5MDudrsZbD+YS68vYWNqw7Ta01J9us5jXYbCkyYRdfUqwb/9huQ1A9NSGSbiTRPfe2BujWPJRuxos4PO5Ttz1fcqw04Po/me5iy9sxT3sNQrGRx2O8yOpzvoV6kfzUvnXLvUo2IPDHQNcDYxypbG7fjL48Rr4+kYFpKmtu0dIkLIzDmYeYfjP7kPLta6+D03Zve1xZmOwozTxDH+wngAFjVYpORufHIUNHGgzr2UQCMdRiIIP177ke5Hu3NND6YEhfBT5dFZjua0zGvJkoZLWNBgAW+i3rDw9kJ0VDpM+2waZ5zOMKX2FCqYp107OUecnq6kVmq7JNVo2hxTtApYllc0nqlgamjKIPtBXHx9kVtvsiagp4VWtPzu8Tt1itXBztKOlY1XEhQbxMgzIzOuFPIBCZoEvj7/NX/4/8Gc+nPS1aL+5YR4ZCpfpZWxFRNrTuSM0xlm1pmJsb4x827No8nuJky5PAWXAJd/lhYuLRvqf+n1n/Zx8/5DiSSbYSGjdreROtvqpHD4jIlPlPrzz0rDBeckJj5zTr2ZRZuYKKEHDsjzxk0Uf7I+fTMdBfpX02TReemxVnHUHuJ8Q5Z/MUJcK1SU119/LZq4uAx6i+K3Mt1E5MoK2bZypNyrVFGeNW8ucZ6e4r98hbhWtJU4r9dZW1RMmMjcUkqk7weMOTNG2uxrk7Xx/oTvjBnyuIqDaKIzF/GXjHeO7Q/3Za3fjbVKv6Dk/kaeYZ4SGhuabletViueI0eKa4WK8qJ5C/H/srHETrPP6soVUolKjUuMk5MeJ2Xk6ZFSZWMVUTurpefRnrLzyU4Ji1Oiht9FvPY/3l8SNDnwUfqAmddmioNzZfH70UwkNjxLfbse7iqdD3QS7fQCqQZ8/JmgrVuVIJ5Vq0RE5OXZw+JaoaJ8PaaSDDje/33gQgZrVTur5eyrP/l/buokssQ+W8EI6TH3xlxRO6ul8a7Gcu+dH+CNtTkaMywuTNxC3D6O39S778nRCX/tPOcVf18JSf3zi0mIkca7GkuPIz1yZd93/e6K2lkth90Ov1+C53mpvLGyDDs1LNNZBhI1iTLu3DhRO6tlz9M9OV5Xjri/U+QHM+Xe8Oxklru7BrrKjKszkgVU7Hq666MFVPDJx+0/SnQw7OwNqHjRfQPno17R07bn+4z0b1lx9jmvgqKZ1VGNoX7u5McRESLOneNlpy/wmfgdOgVMKLFuHSU3OpO3Su6VHMoJLewKc+NlMEGRcdzwCMWr+xAKTRhP+LHjvB42DE1kVPoDlG+B2DQlaNViHFacwb0ovFowDIMSJTDtrFReCN2b+lNxmtz8RUm82WhSilMPAx9mW9smWi0Rp06Tv149dPJmIxeV+gsl4//5uemWH0uB2zlFU2ae3LxYwqQEBfIUSLerSqWi+MKFFJn5I3rFihJ40Rf3nQm4t2tH4C9riffyytwaooMh1DNF4l0DXQOalWrGyiYrOe10mgk1JhCdEM3M6zNptLMR3174lq/Pf42xgTELGixATycHPkof0M+uH1qELSbGEPA00/2ehTzDNciVjpZVUSHpatxi7t3Db85c8jdogOWwYQCUatgGw7LF6Xc1gaf+D+l8uDNbXLekaS4+5n6MnU93MsBuAI1Kvk2eHBUI7udB3Vkx3eUig3Tqs/RBZTbG98HW0AGxrJCpKgrpYWJggrWp9V/vN+X7QKk4UvJzaJH55NXZwv6tpvNh6vcXQz1DhlUZhkugC3/4Z1NL/SdOvDhEHpUujc4shK1dIew1DUo0YGrtqVz2vszMazMz1DiJCDOuzeDkq5NMqDGBzuU753hd2ebWOqW8WomaoJdXSVy+u3+yyjgZYWthy7TPpnHW6SxTa09FIxp+vPYjjXc3zpX3PCd8Etz+rYjAwZHKhdhtM7/5XSOvXl4lWeafeOYXwS8X3OlczYrPy1rmytTRd+7wqldvXg8fgTYuluKLF1Fmzx7y163zj3A6fUdLu6JotMKqc26ExSRQ28YSi8GDKTpnDlE3buLZrx+JQWnXIRWNBr8nZfC/k4f89oVY2s+Mc+G3AdAvVox89eoStncfkpiYuQXFhsHVFUqpquLVk53yi/LDP8Y/2/5tMffvkxgQkCLpbqbR0YWG30HAk8z/kGoSFJORTcpqCZme1tAQMycnSm3YQLnNcyhcLRQdfSFgyRLcmjXnZdduBDk7k+Dnl/Ygb94mnU2nYoJlXkv62fVjX/t97Gj73pTqG+XLooaLsMybO9+Nd5QwLkHzYnXYZZKfCN/M3+QPvDiAno4ebbRvfbKKOaTaLjEoiNdfjUW/SBGKzZ+HSke5latUKixHfIVBhC7bPa2pUbgG827No/+J/ilMxe5h7vxw7QeqFarG6Gqj3594tB9E8154yAXi3Nx4PXo0Ab0HUuzEfSJmzsOtRUtebNHgvcOVkE3riH/1KlPmKBEhMSiI6Fu3CNm5C785cwlaty7X1poqUUFKtQgjc6ViiW4uVFZID/MyYFUTHqTtjtGmTBvy6+dn17Nd2Z/nzUM0h7/m5JNd1IuMIF9CnFIZ4+c64HqILuW7MKzKMPa/2M/q+6vTHEZEWHB7Aftf7Gdo5aH0s+uX/TXllEuLlcTG5VtCnwMw7DI0mgJPjsFKR0Woy4JLSH6D/HSt0JU97fawpfUWWpZuSQWzv8gMn0ly7xHzEx+XG2vg6TFoORefAkU49vIYPSr2wNTQNKmJVitM2ueCsaEe37exzfGUsU+fErB4CZEXLqBXsCBFfvgB085fZCvy82OgLm5CcdO8bLrmAUAtayWi1LRTR3TNTPEe+zUePXtScv16DKyskvXVxsTgPX4CkWfPYt64HIUKXqR2oa5c9r6MVrToqHQwdXLCe/QYIi9ewrhxJoSX6z8rwlsq2jaXQBdlzdnUuEWcOg36+uRvkLIsWKap1BEKLYDzc5R/ZxQl530H4iNS1CfNLnp29TEvH415k8Yk2Kwl/Phxwo8ew3/uPPznzceoenUKTZxIXvsP3qOkUlepCzl/RqVSYWdhh52FHRNqTCAkNoTC+QrnyvoB4l+/RuLiyGNjwwCHUZzwucwuz5MMchySYd8ETQJH3I7QqEQjzPyegIkV5E9Z5FwSE/EeNx5NaCild2xHt0ByzWb+lm0wmD2VxGMPWPmdC0dfHWfuzbk4HXJihMMI+tn1I14Tz/jz48mrl5f59ecnL/H0cC8UtIXCmYssTndPvr4ErFxJ2P4D6OTNi+WY0Zj37Uei3xuib94k6tIZoq5cJHz2Ipi9CL0iRTCq6Ui+mjUxcnREtFriX74k3t2dOPe3f1++RBv2J6dxXV3QaDCqWZO8lSvneM0p0CTCngFKMMLA46l+Jn8JlbsqNYn9HqX6WRjpG9HOph17nu1houNEzAwzEXgFSnm0RweUmrGvb3I3nzGBhcxoUXMcVB+h1A3eO0ipyFG9PyOaz8Ivyo8199dQ2KhwqqUQ19xfw2bXzfSy7cVIh5E53Xn2EIHTPyiBX/ZO0PHn9wJ2g28Uq8KRrxWh7v4OaLcsS9e4SqWiSsEqVCn491uUPmnc/o1434WTU6FCa6g1jI2PNqJCleIpZ8ctL+68CuH7NpUwz5f9YvHxXl54f/stLzt2IvqPPyg4fhw2J3/HrHu3f6zQBsoXrYVdERK1QklzI4qbvjchGjdsSMkNv6EJDcOjRw9inzxJOpcYFMSrfv2JPHeOwlOmUHjxZlT5LWng/Zjg2OCkIALjhg0zH6QQEwLXVkHFtik0Qz6RPhx8cRA9HT0qmlfM8j5FhIhTp8hXuza6JjmI3NLRgYaTIOhFmiaaZLidA5UOlMkl5+O8ZmBWGnzvoV+sGBaDBlFm316sjx/DcvQo4r28eNWzJyEfvt8+96BASUUbkgUMdA1yVWiTxEQ8BwzEvW07fGfMoIJ+cWpr9dkS+Zx4TXyG/S++vkhIXAgdy3ZUgjTS0LYFLFtG9I0bFPnhBwxtUz6QqXR0sOjairhgiD6wISkKs75V/aQozEmXJuEW6sbcenOTvwehXko5K/ucmbkSQ0Lwm6to1cIPHca8Tx9sTp+i4IgR6ObPRx4bG8x69MBq9TrKfWmB9aBiFJk+jbxVHYi6chXfKVNxa9ES91ateT1iJP4LFxF56SIqAwNMWrWk8OTJlFi3jrJnz1D+xnV0TU0JWLUqR2tOk9PT4eWFt8EI1TNun1tU6qiUkXuQtkbNqbwTCdoEDrkdyni8wOdwYjIsqggHhin3pBZzOFG7H3n18lK/ygDFNG5hAwNPQp2xcGcjql8bMbV0R+oUr8NP13/igteFZMNudt3M6vur6WDTgW8dv01udYmPgqcnIC4iu+9C5tBqlRrOV5ZCjYHQaW1KraiFjVIysNNaRTj9pT6cmp6p4IV/HGk5v/2XXv+p4ISYUJGllUUWVRKJCpKgmCCpsblGioSMfuExop5+Qrr9cjXbzqsJAQHi++NMcVXby+MqDuK3cJEkhqbvcP5P44Z7kJSaeES+2Z16wETs8+fyrEFDeVK9hkRevyGx7u7yvGkzeVzFQcJPn37f8M5GCZ1hKlWc7WX53eVJh/0WLhJX20oS/+ZN+gs5M/NtJn0XEVGceM97npcRp0eIvbO92Dvby/yb87O1x5gnT8S1QkUJ3pm9ZK/J0GiUJKDLHDJOKPprU5G1jXI+55/Z1U9xJk6FhOBgeTVgoLhWqCje338vmthY5cSyqkq5ob+ZsKNHxbVCRXk1ZIi4VrKTp7Vqy+1vm4r9b3aZctQeeXqkNNrZSBIiA5Rr5cKClHOcPCmuFSqKz/Tp6Y6lDQ+UZ1XLiUfrOu+PabVy4uUJqb9DSZi8+o/VKTteXppqsElm0URGSsDq1fKkeg1xta0k3pMmS7x3BuXb3jnih3knrTP2xQsJ3rFTQvbtl+h79yQxLCzdIQJ+WSuuFSpK9P372Vp3mjzYraztyPjcHTezbO6s3OvTKWPW51gfabOvTdr3+bgokS1dlH3MMFe+Y+4XRLRaSdAkSP0d9WXC+TSCLdzOKWX5frSUqMtLpOuhruK4xVEe+CsVQfY92ydqZ7V8fe7r98E9Wq2IxxWRAyNEZhVT5j01PZtvQCZIjBfZM+j9PJn5vYsKUsrETTd5G7xwKuM+HxnSCU74ZCr9NyECh8YoT8UDjoOROZvuLCVWE8tA9cBkTWceeUxcgpZZneyz7HemiYgg6LffCN64CYmLw9SpC5bDR6Bf+COZCHKR6qXM6O5Ygm6OqeeIylO2LKW3b8Nz8BC8Bg9GZWSESleXUh8GWTj0psCt9VRJCOKi53lGV1V8gkyduhD066+E7duH5fDhqS8iOhiur4FKHQkwKcy++7+w9/lefKN8scxryZDKQ+hcrjPF8hdLvX8GRJw8BSoVxo1zwWSpo6OYcnf0hAc7oWqv1NvFhCqm0nrjcj7nnynqoPhYRQen0KDpmZlR4te1BKxYQdCaX4h7/ASrBbPQD3aDKjlLH5NTRITAdeswKFOGEmvWEPf8OX4zf0Jz8DaLrwv7wlbRsWzHNItnB8YEctn7Mv3s+qHn90g5+EGqibiXL/H9bhKGlStTePLkVEZ5j8rYAot6JfH73ZvoO3cwql5d0UCXbkHNIjW58eYGzUqm4g/psgeKVUsRbJLh/uPjCdm1m8Cff0YTFIRxs6YU/Oor8pQtm3Fnu45w7idwPQi1h6NSqchjY0MeG5vMTe56CDOLRwS/1bqV/OWXLK09TXwfwMFRSjBCyzm5M2ZWqdwV9g1RtKCl66TaxKm8E5MvT+bmm5vUKlorZYOba+H5SWjwnaKNMn6vYb3pe5Pg2GBalm6Z+vzWDWH4VTg0CqNT01ll05DehqaMPDOSQfaDWHxnMZ8X+5y59eaiF+6rmCDvbYWQl2CQX/ls3zxUEgo3mZ4rwS6xT5/iv2AhoklER18fVcADVNG+qEo0QueqLqo7C1DlMUAnTx5Uhnkxad4M/eLFkw9iZA4dVir3jSNjYWtnqD0SWv7FQSe5xCdT6b+J278pSRmbTIOStQiIDmDr4620KtMqWdLQ80/9OXzfh5GNymKThQoJ8a9f4zdnLi8aNSbo5zUYN2yAzdEjFP3hh3+l0Aagq6NibufKVC2Ztv+HftGilN66BcPKldGzsKD0ju0pI2N1dKDVPBpEhPIk9BlvopToJIOSJTGqXZvQPXvTzA+nvbKc6zoJjCtgQPM9zVl5byWlTEqxuOFiTnY5yeiqo7MttAFEnDpF3urV0LPMJQf7Cq0Vc+6FeUoAQmp4XFIc2K2zH5iQKu+iKNPI56bS1aXQ2LFYrV5F/KtXvOzem8g3edINTPgYRF29SpzrYywGDUSlo4NhhQqU3LyJYt/0o3CEMHqNL398PSTNYJjDbofRiOa9mRSS+expo6LwHjMGlYEBVkuXoJOJBMumPfuha6AhaMXCZMfNDM1oWbplSiEy8LkS6JHFoATRavEaPRq/n34ij40NpXdsx2rFiswJbQCW5aCwffaiS4PcYP9QdF02YF7LjKgLF4l58CDr43xIdDDs7KWY7z9GMEJaVGgN+kbgkra5tHnp5hTIU4BdT1NpExsGl5dA2WbKA5lxcteA3z1+J59+Pupa1U17DfksoPs2aLMIy1fXWeP1EtHEs/D2QqpYqFliUReDLV1gqb0igJuWgE6/wIRn0GEVVOsDwW5K4FMO0URG8XrMGGIfPkRiYkh8dpN4n0BiYooR9TyU8GPHCNmxg6C1vxKwbDn+8+bh3ukLIi9cSH3A0nWU4AV1Z0XA/ZeYTT8Jbv8W3rjAiUlQtil8PgaAXx78QqI2kVEOo5KaxcRrmHLgITYF8zGsYcZPzSJC9O3bvB49BrfmLQjeupX8DRpQeu8eii9ejEHp0n/Vjv5R6JqaUmrLZqyPHMagZMnUG5WsTYN3VRSevf+RMXXqQoK3N1FXryUdC4oJ4qr3VX65vYT2r3YxpGghboY8ppdtL450OsKvzX+lWalmyZ3Cs0G8hwdxz55hktWku+mhUkGj7yH0Fdzblnobt3Ognw+sMi6tlSXeCWC+6VdQMG7cmDJ7dqNnnAev8+YEnnDJXGLlv4jg9evRK1gQk/btk46pVCoKOPWlQis/zn5miOGpa7i1bEXw5i3JIpFFhP0v9uNQ0EEpyeTzh+Lr91bjKCL4Tp1GnJs7xRctTJHQOi10qnTArGIckdfvEfssE+WRXPYAKrD7IitbJ3jjJqIuXKTQdxOVdEAOGQeJpMCuI3jdgLDXme+jSVRSPugaQK3hmOW/im4+g5z7usVHwa6+byP2t3y8YITUyJMfKrZRggkSU/eTzKObhw42HTjreTZlpYOrKyE2FJpMTdEvQZPA6VenaVSiEXl0M0jKrlKB42D48jylDQuy5pUb3TBh5YOLGB0apSS6bTgJvnoA/Q5Dle5g8LZsXMW2gAoeH87y9j/E76efSPB6jdWCWZRu7EeZRp5Y/zqbshevUe7Cecpfv0bFP+5S8dFDKro8wPrYMfSLF8dr2HACVqxM/R6hl0fRvGkTlGvwX8Anwe3fQFykkoPGyFx5ktHRwTPck73P9tK5fGdKmrwXNJaeecbrkBhmd7Inj17aOdskPp6wgwfx6NyFV737EH3zJhaDB1P29CmKL1pIXrucR5T921CpVElpFdLCutl8iidquOSyGbzvon19m5AyGjT5Dbm1ehrDj/Si8fZ6NNzVkKGnh7Ly0W+YaRKZXWUMZ5zOMMFxAqVMSuXamiNOK2W3jJs2zbUxAaU+ZfHqcHFB6j8Y7uegTD3Qy37QS6rkNVXMdJmooGBQujSlh1TAxAYCVq/j9ajRaMLDc3c9mSDm4SOirl7DvF/flJow46IYGJtg0caG8YN1SShfEr9Zs3jZuQsR588T4/IQl8v7UT1xp7s4EuPykJh7d4iRcsq/XR4StGYN4ceOUfCrr8j3+eeZX5ihCeYta6LSg6BfM0iXIaIEpJSum26JrdT27r94MfmbNsG8X7/spwOy66T8dT2Y+T6XF4P3bWi7GFrOQbd2P8xtAnOmdYsJhc2d4NUVRVtk9RGDEdLCvqsifL04lWaTLuW7kCiJHHjxpzJZkQFKQJRdp1Q10td8rxEeH562mTQ1CtnCkLPYVR3IFH9/TGzbQf+jMOYeNJwIZqnc24yLKPnUHmcigCIdwg4fJuzAASwH98PI5Xsl2rb7VsWc/AEqlQqVvj55rMtQettWCrRvT+CqVXgNH44mNDTl4CVrK4EgHpdytMaPxScft386Ikq0TLC78iSTTzGHrfxjJfq6+gyrMiyp6WPfcNZdeknXGlZJqS8+JDEoiJCdOwnZvh1NQCAGNjYUmTGDAu3bZS9x6/8ZKlMr6pvbsTf0MX2OdOepgT4xOjr0tdXQ8o4PUTVf85lePBXiE6gYr/wtoHYCh/TTQWhjY9FGRmbZ3Bl+6hSGdnYpfThyikoFjSbDls7wx2ZwHPT+XIiHcj3WHJq7c76jqAO8vp2ppjpBDynWszJ5te3xmzePl05OWC1fgWGF8n/N2lIh+Lf16OTPj2m3bilPqlRQqBIdwyP4ubgFq+0LMrffMvzmzuX1MMUnUh+YC8DPePDz246PYI1T0jD5GzfGYsjgLK9Nt3oXzGyuE3z0KAW/+goDqzSuE9/7SjTxZ6NSP58KmsgovMePQ8/cnKIzZ+Ysh6OFDRSpDA/3wWeZSCfhfUdJFm3vpJi5AFovwizQh+AnDwic/wMltuzL2hoiA2BLJ/B/Ak7OUKlDlrfxl2DTSClm77Jb0b6lQpkCZahZpCZ7nu1hoHogOiodRbBNjCG+7AB8+/TFctQo8tWqmdTnd4/fMTYw5vNiWXgYANA3hFbzlFdmqdgWTk1V7h1mpbM2HxDv6cmbH2aQt3p1LCvHw+XHSoSodcbpj3Ty5qXo3DnkdajCm9lzeNnFCavlyzCsVOl9ozzGik/py3+H4PZJ4/ZP595WxUm84STlaRh4HPSY4x7H6W3bOylxqOZtzjbTvPpMbp0yRYAmMhLfqdN40agxgctXYGhrS4l167A+chizbl0/CW1ZoF3dqZgZmqFb0JYvitXnR+uutO3aHz0tLInpwKxmP9O3zTpqdtpEge47oM2idMfTxsbyqncf3Jq3IPp25gQWgAQ/P2LvP8h6bdLMYtMEStWl3rAAACAASURBVNSCS4sgIfb9cbdzb8/nsn/bO4pVVeqfRqWdHBlQTFqBz1AVc8C8T29KbdqIRMfg0b074ceP/zVr+3AJnp6En1BS4+gaG6feqJAthv6P6VGxB5d8LvPGsTQ2R49SYu0vFFq5lKXdjTg3+jOsfl6N1bShWNULwuqHkcr/f15NiV9/pfjSJRlqg1OlQkvMK8WDSgjesCHtdg/3gI5eloQVv59+IsHTi2IL5qNnlskcYulh10nRoIW8Sr9dfDTsG6pocloveH9cVw/dXs6Y1yxA5O3HxJzekfm5Q71gQ0sIfAE9d/xzhDZQ/OvsvoCnxyE2bY2yU3knvCO9uepzVdnPrXXEl+zEq69/IPrWLd5Mn44kKD6rcZo4znqepUnJJuh/DP8927bK38dHstxV4uPxHj8BdHUpPm8uKpedyr0nE0LbO1QqFWY9elB68yYkIQGPHj0J3X8geaPS9cDnrmLh+ofzSXD7J+P/BI5OUPJk1RufdHjZ3WUUyFOAAeoBSce23XjFPa9QprS1xdQoubkmMTAQz779CN23jwKdOmF99Agl1679x1U6+LdgX7Ayp3tcwvmLg3zX4mc61ZuKbbtvyVutGqEXXJDyLaBCS+VVvoXyNJcGIsKbH2YQ+/AhOgUK4DnkS6KuX8/UOpLMpM1y2Uz6DpVKeWAI94a7m94fdz8HJsWVQth/Be/yl2VUccDvEYg2yQxkVK0aZfbtxbBSJby/Hkfwpk3p988Fgp2dUenqYtanb9qNClWC2DB6FG9IXr28OD90RidvXvLXr8/VMvFcLROPY+fhGDdqhLFVAsbF4zDu2Ef5f6NG5K9XN1PBCKliWAD9yo0pUFYI3bMn9eAIrRYe7lcE9UzmwksyWw0fRr6aNTPukBkyay49PR2CnkPH1UrwwJ8xyIfZ7D3o5oHAudOUgIuMCHwBv7VUNG59Dyh+xP80KneFxFh4krbg06RkE8wNzZUghYvzSYjSwXOTO9qYGAqOG0e8hwch27cDcMX7CpEJkVkzk+YEc2slACUbfm4BK1YQ6+JC0Zkz0U9wVx7qHNKIds+AvA4OlNm3l7wODvhOmoTvjBlo49+6gpSpB9pE8Mzc/ffv5JPg9k8lPlrxa8uTH774VSlJhBK+fcXnCoPVgzE2UAQCv/BY5p94St2ylnR0SG4KiffywqNnL+JevqTEz6spOuOHzIfZfyJLmHZ1It7Dg+hbtzLdJ2TrNuUHcORIyuzehYGVFV5DhxF56XKGfSNOncbA2vqv/TytGyrpEC4vVjKuazXgfkGJJv2rhP53/jgZ+bklVUx477+jV7AgJX9bj3GzZvjNnoP/4iWZKqOUHRKDggjduw+TDu3Tj7oupGjAC4S+pnO5zhx/eRzfSF9AKXFlld+KGoVrKG197oFFWTBMv85rlqjUEQsbPyQ+nuDNm1Oe97oB4a8zHU0a7+WlmK2qVsVyxIjcW6d5GUXbml506YvTSvRf7RHKtZkKuoVKYj6gH5GvdYlZ3Aki0iuX5qJo2hJjof9hxdcpFxERou/cwWfKFJ7V/oynNWvxrF49XjRpilvrNrh3+gKPbt151bcfnkO+xGvUKLzHjSd0797k162Vo2JiTCcZr76uPp3KduKC1wV8ru/k1eUSaCKiKLluHRZDBpPv888JWLmKxJAQTnicwDSPKTWL5pLQnRls2ynXWhbqhUZeuULQr+sw7doVkxbNlWCpPAXSNBlnBj0LC0quX4fF4EGEbt/Bqz59SHjzBv7H3p3Hx1VX/x9/nUz2bZJmadN0X+gGLYUKKCICCkVZCyiLC6i4sOlPUTYXQBFRFFxwQUEWWYQCiogosghflUKhm3SB0kKbdJmkWZt9Zj6/P+7N0jZNp+mdJA3v5+ORR2bu3LnzmTRNTj6fzzln7BGQkgZvv9Dvaw8UBW5D1T+u8dKnF9zuLQng/RC49bVbGZk9krOnn9116nV/eZ32WJzvnXbgDjNoratW8fY55xKvr2f87+8k9wMBVbiXXuWfcAIpeXnUPZxY4/nmV15h6w9+QO4xx1B88UWkFhcz7p67SZ80iYqLLqLx2ed2+9xobS3Nr7ySvGXSTp173Ro3w6t3eYFFa13ylknBC1pGTPZeqy+blkJ2sTf710NKRgblt95Cwcc/zrbbb2fzN7+ZeD/ZvVDzhz/g2tsp+sxn+z6xxN+6EFnFp2Z6M3P3rLyHisYKXt7yMqdOObX7/+2mJX02lu+XafPJKAyRN7uM2vsfILZ9p6Wg/y30GnFP+8geL+U6Orxlq5QUym/+EZYa8DbpWad7y1W1b+/6WHMN/OliKJnulUTqQ+HnLiWUl0v1ola4/6zeK/dvWAR3fdTLSv3MU4GWlOnYtInqX/2Kt+bP553zPkHDk38j5wNHET71VPKOOZbsefPImHYAaWVlpOTmQjxOrL6ejo0VNC9dwuZrvknFJZcSra31Lmjm7edb/68+A9EzDjiD3KYYm54bQbQpztjf3k7WQd7vhdIrryC+fTtbfv5Tnt/4PB8a/6F9zmrfExePE7n1Vhqefho3/STAweq/JvTc6LZtbLryStInT2bkVVd6/4Yr/+y1rkrbt609lppK6eWXU/7Tn9L+5lrWLziDpiX/gzHz9ot9bkpOGIpiUa+Q4dzzdugD+eyGZ1lRvYLr3ncdmaleE+rn10R4csUWvn7CNCYU53Sd2/TSIiouvpiU/HzG3X2XZtkGQEpWFuGTT6Zu4UJi11xNqKBgt+d2bN5MxZe/QvqYMTs0CU8tLGT8Xb9nw+cupOKyyyj/8Y+9vzR3sv3Z5yAWS37gBt4SwoSjvObNh3zSOzbpg8l9zdEHw8aX+z5n8zLvl20vM38WCjHq2u+QWlxM9W23EauppfwnPw5sL2e8qYna+x8g97hjyZg0se+Tc4ogdyREVlGWW8aJE0/kkTcfIeZiGMapk/39VI1bvWXpoAO3zDBMPo6i5uU0LnPU/fEhij7rF+yORb1SE9Pme7P7e1D1s5/Tunw55bfeEnxCDHhtnp7+tjem93+l+7hzXp/J5m1w3kN7/MUdys1hxOcupOqWW2h5fTVZD30azv1jdz22t571msbnlXnLowW7KQG0F+ItLTT+85/UP/YYTf99CZwj+7DDKP7il8g//sOk5OTs+SJ4wU7NPfcQ+fFPWH/qaYz+4U3kHHGEF7i98COvl+x7e5/pLNu0kR/cFyWt0Rh9x21kz+3+Xso84AAKPv4xah98iBGfNeYfm/xl0qb//pdtv/YKIucceSQjx00kY/UTOyY79cLF42y66iri9Q2M+93vvP+3r90LHc39XibtTf4Jx5MxdQoVl17GxgsvZNzFR5O95V6v/l2Qs94B04zbUFS12vsGndi9+TIaj/KzJT9jYngip0zurhX1pyWVFOemc+FR3TXbGp76OxsvvJDUslFMeOB+BW0DqOBjZ3mlVh7f/V6OeFsbFZd9GdfWxpjbfrHLpvZQOMy4399J1uzZVH71q9T/Zdd9LY1PP03q6DIyZ83c5bGkOOZqaIrAv3/qZf/lBFTsd3dGz4X6jdBU3fvjHa1QtarPWRIzo+TSSxj1nW+z/fnn2fDZz/VeCqAf6hYuJF5fT/HnEsz0LJ0BkZUAnH/g+bREW3hg9QMcUXYEZbl++Y3O2nWjD9nNRfbBrNPIyqgk55BZ1Nx1V/e+nvXPQ3M1HLjnZdKm//yHbb/7HQVnnUX+/CT90i8c75Wh2Xm5dMXDXvHxY65KeGas8LzzCIXDVFcdBm8943Wdcc7bZ3X/x719V595ap+CNuccza+9xuZvfYs3338Um77+Ddrf2UDxxRcz+Z9PM/6euyk4/bSEgzbwe82efz4T//ggKTk5bLjgM0R+/BNcwSTv/95uivHGGhrY+MVLKKqDm85M4dWy1l3OKbnsMtozUvjcc6Hu5fkkqn/kUVLCYUqvuIKWZctY91A7kcdeJb6tss/n1d57L00vvEjpFd8gc9o07+DS+6FoqjcrFqCMSZMY/4d7SRszho2/eZHWmhR45797fuIgUuA2FFX6mYU9Ghr/5a2/sK5+HZfNvYzUFG+i1DnHovU1HD6xiPRU75+y9sEHqfx//4/MAw9kwh/+QNqoUQM+/HezzOnTyTzoIOoefrjXvVVdyQgrVjD6hzftNqgO5eYy7re3k33ooWz6xjeoe6S7tEFsexNN//kPeR/60MAll4x/n7evLR5N7jJpp86uAbtbLo2s9MaSwC/xwnPOofyWW2hdsaJ7P8s+cB0dbLvrbrLnzUu82GzpTC/ZKB7ngMIDOKr8KABOn3p69zmbloClwKiD9ml8vZp2IoTSKTqigGhVFfV/8jPqVjwCGfl73JAframh8oorSJ80iZFXXxX8+HqadboXxNas8+7XbfSStMYe7jU+T1AoN4cRF1zA9iVv0TLhc7DsfnjgbK+4btnBcP4Te11c1zlH25tvUnPffVR8+Su8eeT7eefc86h/4q/kffjDjLv7biY//Q9KLrmY9DFj9uraO8ucOZOJjyyk4Eyvrd7b555H+8gTvO+T6rU7nBvb3sTGT59L69ZmRn/peLbOHMVDb+wa4LXlprPw/SnMWttOy//9e5/Gtyexujoa//lPwiefTNEF5zP5qb8R/tD72bYyh7dOPp36v/6115+RLa+/ztabf0zuscdSeO653sFtb8GG/8DB5yZlb21qYSHjfvdbUvLCbPhXMe2Lnwr8NYKkwG0oqljsZUv5/QLbYm3ctvQ2Diw6kOPGHdd9Wm0Lm+tbOWziCJxzVP38F2y59jpyjz6acXfe0edSnSRPwVln0vbmm7QuW7bLY7X330/9Y49RfNFF5B13XC/P7paSk8PY3/yanPe+l83XXEPtg38EoOnFF3Dt7cF2S0jEsd/y9kLNOGXP5+6rPSUo9JKY0Jf8+Scw9re/pWPTZt4+51za3nqr30NrePJJops3M+Jze9jb1lPpDIi2QN3bAHzl0K9wyuRTOHZcj/6ym5ZA8bSEliz3mr9cmt3xHzIPnMW2391By5JXcSuf8DaNp2Xu9qnOua5lq/If35z80kGdpThef8zLeP3Tl7wg/fRfdyVpJarwE/6s20vNMPeT8MZTXpb+Jx/bNSO1F8452tau3SFQW3fyKWz97vdoWb6c3KOOYvRNP2Dqiy8y+gc3knP4Yf0r27IbKdnZlH33em8v1oYNrP/uo9Stz8Yt/2PXOfHmZjZ+4Qu0rH6L8mPiFHz+Rk6fejr/rvw3ldt3nNl6fuPzPDE3RnzMKLb+4Kau8iDJUP/EX3Ht7RSc6dXZSy0uZvQtv2b8KZCaEWXT1y5nw6c+vUNXj3hTE5u+drlXG/CG73X/YbrsAe+Pmjln9/ZSgUgbPZpxd/wOSGXDz54mWr2b2f4hQIHbUFT5qjfb5n/TPrj6QbY2b+Urh35lhxmWRetrADhsfJgt111H9W23EV6wgDG/+Lnqsg2i/I98FMvOpvbhh3c43vzKK2y98QfkfvCDFF+SQJFRvH1zY371S3KPPpot115LzT330Pj004RGjCDrkCQsqfVlzKFwdWXgSxW9ysz3sit31/pq8zIvGNmLYp45RxzOeL+O0zvnnkdLL4H1njjn2Pa7O8iYOpXcoxOvI0Wpv6QdWQXAAYUHcMP7b+huNeRcchITepp1GtZYScm5J9JRWcnb53yCNx7IZsPCCNvuuIOWFSt6TeKovfder6XVN75B5vTpyRtfp4JxXhbl64/Bol951ezn37jXje/Bm7keccEFbH/+eVomXAjnPgznPtRncBytraX2oYeo+Mr/8wK1k07eIVAru+EGJv/zaaY8+wyjb/oB4VNPJZSb+FJof+SfcDyT/vQYmbMOZPOiAjb95H5iDQ3EW1vZePHFtCx5jfL31pD/qcshPYczpp6BmfHIG4/scJ2n3n6KoryRjL36m7SvW9f1x2Ay1D3ilebZ4XsmJYXsD57EhGMqGfXNK2l94w3Wn76ALd//PrHGRrZ8//u0v/MOo3/YozZgPA5LH/D2e+f3v6dzIjKmTGHsZfOJbo+y4bOfIdbYS1LLEKDAbahpa/R+uJd7vxwb2xv57Yrf8r7R7+PwssN3OPXl9dsoyYDcH3yHugf/SNGFF3p/pQSd6SV7JZSbQ/ijH6Hhyb91ZfB1bNlCxVf+n5eM8KMf7tVf5SkZGYz5+c/I+/CH2Pr9G2n4x9PkHXccFtq72YdA7OWMxz4ZPbePGbelu01M6EvmzJlMuP8+UsJh3jn/gt03n96NphdeoO3NNxnx2c/s3TJ1ib9Px9/ntouGTbB9a3IDN3+5NDdnHVOff47ysyaRP8XRUdNM5Ec38/ZZH+ONw49gwxe+0BXItaz4H5Ef3UzuMcdQeN65yRvbzmYt8Ep1PP0dOOBEOKSPOnl70DXr9qtfwwHHe70pdxLbvp26P/2JDZ//PG8e9QG2fPs7tCxb1mugVnDGAtLHjBnwGphpZWWMu+v3lHzsaBreirH+lI+y8QtfpPmlRZR9OJf8g0rh0E8DUJZbxgfKP8Cjbz5KR9ybVWtob+Dflf/mhAknkHfMseS8771U/eIX3ZmrAWpduZK2VasI+7NtO5hxMhZvpfCQAiY/9TcKzjyT2nv/wNoPfZj6Rx6l6Itf2KHDA2+/4JWrOXhgvv+yjjuDMe+vpW3tW1RcfAnxtrYBed29ocBtqNm0BHBdsxp3vX4X9W31fPmQL+9y6qL1NVy+5q9sf/ppRl51JaVf+6oK6g4RBWedhWtpoeGJv3rJCJdehmtpYcwvfr77Cvt9sPR0yn/yE/I/8hGIRsmbf0ISRj3ElB3sZVluj+x4PNbhFd/tZ/mG9HHjmHD/faRPnMDGL3yRisu+TOuaNQk9d9tvf0dqWRnhj+5lHamMPG8myZ9x20VngJrMwM1fLuX1P5Gal05+xmLKLjyFyU8+ydQXX6D8Jz8m/+ST6NhY0RXIvX3WWYQKCyn7/g0D+7Olc7k0Mwyn/Gyf9jXtMOu24n9dx+MtLTT87W9UXHopb77vSDZfeRXta9+i6ILzmfjYo4MeqPXGQiGKr76JCcc3QHszzYsWMeoLp1NQuMZL3OgRlJ417Sy2tW7juQ1eWaHnNjxHR7yD+RPme+VBrriSeGMj1bf9MvBx1i18BEtP7/3/ybj3QdYIWPUEqYWFlF13LRMefpiMKVPIOfJISi7eaTVi6f3e98G0/tdu2yvlh5I71hh9zsE0v/wymy7/Oi4WG5jXTpCmZoaaiu7EhOqWau5deS/zJ8xnZtGO2YNb6lvJfmMls5c+x4jzz2fEpz89CIOV3ck86CAypk2j7uGHaVm+nNYVKxjzi5+TMWVKv69paWmM/tEPKfrC57szrYazziBm01JvpqRT1WqItXcnMPRDanExE+69l213/p6au++m8R//IO/44ym++KLdfm1bli6lefFiRl51JZbWj/pXpTP7DtwsBKMO3Pvr7o1Zp8Ebf4NnvusVnfWL7qaWlJD/kY94fxgA0aoqml95heYlSwmffFIwLa32Rrgc5v/A+zfeywSC3hR+4jxqfv97qn7+MwrPPoeGJ5+k8dlncc3NhEqKKTj744Q/8hEy58wZEgFanzLDZL3vOCaW/peOUx4h818XensjZ+/YK/fI0UdSllPGQ288xPETjuept5+iPLecg4q95JfMaQdQ8LGzqH3gAQrPOTuw6gPx1lbqn3iCvOOPJxTupaRGKNWrGbjqcYi2Q2o6WQfOYsJ9f9j13NZ6WPm4N9vWxz7MQKVmwNjDCTe/Tezqq9j6/RvZct31jLru2iHzvaEZt6Gm8lVvL0f2CH6z7De0x9q5ZO6ujZ8XrY1wybJHcCWlFF+SeGNoGRhmRsFZZ9H6+uvUP/ooxRd9ibwP7XsrHQuF3h1BG0DZbMB23ee2l4kJu5OSk0PJpZcw5Zl/UnzxxTT95z+sP/W03c7AbbvjDlLCYQrOTKzDwC5KZ0D1G94vq51tWuIFdvtYWHSP/OVSXvkthMfCmN4r53cGcqOuuZqs2bOTO6bdOeJLMP69gVyqc9at6YUXqbjoIppefJHwSScx7q67mPr884y6+mqyDj54yPxi3qPZHyPUUUXmG7+A6jVw7DW7bGMIpYQ4Y+oZLNq8iOVVy3lp00scP+H4Hd5jyWWXkZKdzdab9qJh/B40/vMZ4g0NFJyxYPcnzTgZ2hpg/R66FLz+Jy+pJ8DabQmZeBRs/R8jzvgoRV/4AnUPPUTVz342sGPogwK3ocQ5b8atfB4bGzey8I2FLJi6gPH543c5tfG++5jUsJnR11yd9I2x0j/hk08iJS+P3KOPVnDdHxl5XoLCzvvcNi+D9Fyvu0IAQuFwdwB30UW9BnBt69bT+M9nKDz3nL2qybWD0pledmTNThmtXYkJ/Z9BTFhmuLuo94ELIMAMyKFuxKc+SfEllzD29t8w9f9epOz668g54vDB2Su6r6Ye77V+WvGQNyu5m0zvBVMXELIQ33jhG0RddJfepKkjRnjf8y+8yPYXgmn1VPfIQtLKy8k+/PDdnzTpg97/4VWP932xpfd7s4nlA5yINcHvMvTO/1HylS9TcNaZbPvVr6m5t5dZwUHw7vlfuz9oqITtW2DMPH659JekpqTyxTlf3OW0js2bOfAff+StSXMI91JVX4aGUDjM5L8/xZhf3hZoiYB3ldFzd63ltmmpV4g04K9pKBym5LJLew3gIj/+MZaezohPfKL/L1Da2fpqpwSFug3QUjNwv5xmf9wrrbDT0tpwl5KdTcklF5P7gQ/0b6l7KEnNgJl+sHbct3a7B7Aku4Rjxh5D5fZKxuWNY8aIGbucM+K8c0kbP46tN/1wn8uDtFdU0vzflwgvOL3vn3lpmV7wufqvXv/j3lSvhY0vJa12W5/KD4G0HFj/ImbGqO98x0sOu+EG6p9IrGVXMum3yVBS+SoA0bK5PLPhGU6efDKl2bvu79hw/Q0QjxH5zCX7z9T+u1TqiBH751/0Q8Xog6FxU3d/xnjMyzYMsK/kznoL4LY/8wzhBaeTWlTU/wsXTfX2se28z20gEhN6mnU6fHUVjJw1MK8nyfHBq+DU27yEkz6cNe0sAE6YcEKvvy8sPZ2RV1xB+1tvUfvH3TexT0T9o4+CGQWnn77nk2ec7HXt2Lio98eX3Z/02m27FUqDcUd4pWjwepuOvvlmst/zHjZdeSXNr7468GPqQYHbUFKxGELpvJWVRUu0hUNHHrrLKdv/9S/an3uGB6Z9mDnv0Q9eGeY6g5nOfW7Vb3p7XpIYuHXqCuD++TSjrr2W0i/vmtm9V9IyoWhy74FbKL271luymUGeOqrs98LlMPcTe5yNem/Ze/nekd/j07N2n8CWe8wxZL/3CKp//vN+t4VzsRh1jz1GzpFHkjY6gXprUz8MoQyvBdnO4jGvX/eUDw3e9+rEo7xEKD+rPSUjgzG/vI0R551H5swB+r+6GwrchpLKV2HUQSyr8X6wzy7ZcVNwvKWFLd/9HvWlY/jrzGM4qHzoNsEVCcQoP0Ghc1YqoMSEvREqKKDw7I8H04mkR8/SLpuWeLNfvdQXE9lXZsapU04lnLH73xdmxsgrryLW2Ejkpz/t1+s0/fclops3952U0FNGntc+b9VfvH2ePa3/l7d1aIBqt/Wqc5+bP+sGEMrLY+RVVw56gfukBm5mNt/M1pjZWjO7spfHx5vZM2a23MyeN7Mx/vFjzGxpj49WMzvNf2yimS3yr/lHM0tP5nsYMLGo9wO8fB7Lq5YzInMEY3J37HVX/evf0FFRwX1HfJzZE0q6+pOKDFsZuVB8QPc+t83LvLZbxQcM7rj6q3Qm1KyH9mbvfjzuvbeBWiYV2Y3MaQcw4pOfoO6BB/u1j6vukYWEwmFy99DKbwczTob6jbtmji+5DzILvOLLg6VsDqTnwfoX93zuAEvab34zCwG3AScCM4FzzGzn+cWbgXucc7OB64EbAZxzzznnDnbOHQwcCzQD//CfcxNwi3NuClAL7EXDwCGsahV0NMOYeSyvXs7s4tk77Edoe+sttt15J1kfPYknQmUcPnEf9tqI7E9GH9z9g33zUq/WWWg/LUFZOgNwXgkHgNr10FavwE2GhNKvfY2sQw9l8ze/Seuq3dQc7EW0tpbt/3yG/FNOISV9L+ZSDjjR2/fZc7m0pQ5WPwEHnTVwtdt6E0qF8e/bYcZtqEjmlM1hwFrn3DrnXDvwIHDqTufMBJ71bz/Xy+MAZwJ/c841mxfJHAss9B+7Gzgt8JEPBr/wbn3JNNbXr99hmdQ5x5brriclK4v1Z34W5+CwiSMGa6QiA2v0XGjcDA2bYfPyAV0mDdxOPUsHPDFBpA+Wns6YW28hFA5TccmlCbfDavjLE7iOjsSXSTvlFMGEI3cM3F5/zCsOPZjLpJ0mHgXb1no/e4aQPQZuZnapmfWnbHY5sLHH/Qr/WE/LgM5/6dOBPDPbeSrpbOAB/3YRUOec6+yE3Ns1O8f9eTNbbGaLq6qq+jH8AVa5GLJG8L+Y19S2Z+DW8PjjNL/8MqVf/Sr/rXWkh1KYOy6A/TYi+4PODgmvPwrtjft34FY40duQ3bnPbdMSSM2EkgFo3i6SgNSSEsb87KdEIxE2fe1ruGi0z/Odc15D+Vmzdmwon6gZp3iFqav8Weil90PJjKHxx8yEo7zPQ2zWLZEZt5HAK2b2kL9nLcj6E5cDR5vZEuBooBLoKupiZmXAQcDf9/bCzrnbnXPznHPzSkpKghpv8lS8CuWHsrx6BYZxYLHX+iZWX8/Wm35I5pzZFHzsLBatr2HO2DCZaSoxIe8Sow7yygK8epd3f38O3EKpUHLAjjNuow7yyg+IDBFZc+Yw6trv0PSf/xK55ZY+z219fSVta9ZQ0FtD+URM93uQrvoLVL0BFS8PTu223ow6yCtavb8Fbs65bwJTgTuA84E3zez7ZransuWVwNge98f4x3pee5NzboFzbi5w+Jp93QAAIABJREFUjX+sZy7yx4DHnHOdVQG3AQVm1rnBZZdr7pdaG7y04zHzWFa9jCmFU8hJ86qzR265hVhdHWXXXktTR5z/VdZrf5u8u3QmKFS/4ZXNKNm1iOh+pbNnaTzmJVsMhZkFkZ0UnHEGBeecTc0dd1L/190nK9Q9shDLyCC/t4byicgfDeXzvMBt2f3enrehUhw6JQTjjxxyCQoJ7XFzzjlgi/8RBQqBhWb2wz6e9gow1c8CTcdb8tyhv4WZFZtZ5xiuAu7c6Rrn0L1M2jmO5/D2vQF8GvhzIu9hSNu0BHDERx/CiqoVzC72lklbli2j7o8PMeKTnyBzxgxee6eWWNxpf5u8+3Qul5bOhNT9PJG8dIZX6qDyVWjfDqMHuJ2PSIJGXXUVWYccwuZrvknr6tW7PB5vbaXhib96DeXz8/v/QjNO9hKPXr3Lq++WN7L/1wrahKO8JKL6isEeSZdE9rh92cxeBX4I/Bs4yDn3JeBQYLdzo/4+tEvwljlXAQ855143s+vNrLOx2geBNWb2Bt6S7A09XncC3ozdv3a69BXAV81sLd6etzv2/DaHuEovMeGdcCkN7Q3MKZmDi0bZfO11pJaUUHzpZQC8vL6GUIpx6Pj+bDkU2Y91zkrtz8uknToTFJbe733WjJsMUZaezpif3kooP7/XZIXGp58m3thIwRn9XCbtNONk73NL7dBISuhpor/PbQjNuiWSUz8CWOCce6fnQedc3MxO6uuJzrkngSd3OvbtHrcX0p0huvNz36aXxAPn3Dq8jNXho/I1GDGZ5Y3el3h2yWxq77+ftlWrKL/11q4m8ovWb+PA8jA5GftpKQSR/hpWgZu/1Pu/R71+iMVTB3c8In1ILSlhzM9/xjuf+CSbvnY5Y2//DZbq/Q6qe+RR0saMIfuw9+zbixRNhtJZXnu7A+YHMOoAlc6CrBHePreDzxns0QCJLZX+DajpvGNm+WZ2OIBzLvFCL9I757xSIGPmsaxqGblpuUwMT2Tb7+8i+4gjyPObyLd2xFi2sZ7DtUwq70ZjD4NTfjE4fQuDFh4L6ble/bayOd4+GpEhLGvOHEZ959s0/ec/VN16KwDtGzfS/NJLFJyxoO+G8ok69RfwsXuHXgeRlBSvZMkQmnFL5Kv9K2B7j/vb/WMShIZK2L6lq2PCQcUHEa+rJ7p5M7lHHdVVhHfJhjraY3EFbvLuZAaHfBLScwZ7JPvOrHvWTcuksp8oOPNMCs7+ONt+dwcNTz5Jnd9QPnxaQKVUyw/pXpYcaiZ8AOo3QO3bgz0SILHAzfykAMBbIiWxJVZJhF94t3nkLN6se5PZJbNpW+PVs8mYPq3rtJfX12AG8yYocBPZ7ylwk/3QqKuvJmvuXDZd803qHnqYnPe/n7SyssEeVvINsX1uiQRu68zsMjNL8z++DKxL9sDeNSoXQyid19Mg7uLMLpndlb3Ts5jhovXbmDEqn3CW6j2J7PdGHuR9LldGqew/LD2d8p/eSigvj9i2bXvfKWF/VTIdckqGTD23RAK3LwLvw6uXVgEcDnw+mYN6V6l4FUbNZlmNt11wdvFs2lavIVRSTGqRV6+tPRrntQ21KgMiMlwc8kn49F+8Tdki+5G00lLG/OqXjDj/fPKOPXawhzMwzGDC+70Zt+4FyEGzxyVP51wErwabBC0W9WrXHPIpllctZ0L+BAoyC6hZs4bMad2zbSsq62jtiHPEJAVuIsNCWhZM/MBgj0KkX7JmzSJr1qzBHsbAmnCU10e1Zt2g/8G1x8DNzDKBzwKzgMzO4865zyRxXO8OkZXQ0YwbfSjLV/+SI8uPxHV00L52LblHvq/rtEXrvaTe92h/m4iIyMDr/ENr/QuDHrglslR6LzAKOAGvGO4YoDGZg3rX8Avvbioay7bWbd4y6br1uI4OMnrMuL28voappbkU5Q6xNGkREZF3g6IpkDtqSOxzSyRwm+Kc+xbQ5Jy7G/go3j432VcVr0J2EcvbvWrUXkZpZ2KCl1EajcVZ/Lb2t4mIiAwaMy+7dAjsc0skcOts8F5nZgcCYaA0eUN6F6lcDOWHsrx6BZmhTKYWTqV19RosPZ30iRMBWLW5ke1tUQ6fpMbyIiIig2bC+6EpAtVvDuowEgncbjezQuCbeE3iVwI3JXVU7watDVC1pqvw7qziWaSmpNK2ejUZU6Z0tRRZtH4bAIdpf5uIiMjgmXQMHP4lSE0f1GH0GbiZWQrQ4Jyrdc694Jyb5Jwrdc79ZoDGN3xtWgI42kfPYVXNKmaXzAagdc0aMnao31bD+KJsRoUzd3MhERERSbrC8XDiD6BwwqAOo8/Aze+S8I0BGsu7i5+YsCorh454B3OK5xCtqiK2bVvX/rZ43PHK2zVqcyUiIiJAYkul/zSzy81srJmN6PxI+siGu4pXYcRklje+DcBBJQfRutpvdeVnlL4RaaSuuYPDJmp/m4iIiCTWc/Tj/ueLexxzwKTgh/Mu4Zw34zbpgyyvWk5ZThml2aVsW/M40J1RumidV79NM24iIiICiXVOmDgQA3lXqa+A7Vu9xISNj3Tvb1u9htSyMkLhMODVbxsdzmRMYdZgjlZERESGiEQ6J3yqt+POuXuCH867hL+/rapkMptWb+K8GecB0LZmNZnTvNk25xyL1tdw1NRizGzQhioiIiJDRyJLpe/pcTsTOA54DVDg1l8ViyGUwXKLAl7h3XhbG23r1pN73HEArKtuonp7mwrvioiISJdElkov7XnfzAqAB5M2oneDylehbDbLa1aSmpLKjKIZtK1eC7EYmX4pkJfXa3+biIiI7CiRrNKdNQHa99ZfsQ7YtLSr8O6METPICGXQ1pVR2pmYsI3i3AwmFucM5mhFRERkCElkj9tf8LJIwQv0ZgIPJXNQw1pkJURbiJYfwusrbmbB1AUAtK5ZjWVlkT5uHACvvF3L4RNHaH+biIiIdElkj9vNPW5HgXeccxVJGs/wV/kqAGvzimiJtjC72MsobVu1mowDpmKhEFsbWqmsa+Ez79fEpoiIiHRLJHDbAGx2zrUCmFmWmU1wzr2d1JENVxWvQnYRy9uqAZhTOgfnHK1r1pA/fz4Ar71TC8Ah4woGbZgiIiIy9CSyx+1hIN7jfsw/Jv1RuRjK57GsejlFmUWMzhlNdPNm4g0NZPiFd1/bUEt6agqzRocHebAiIiIylCQSuKU659o77/i305M3pGGstQGq1kD5oSyvWs7sktmYWVerq86M0tc21HFQeZj01P7kjoiIiMhwlUhkUGVmp3TeMbNTgerkDWkYq1oNOOpLpvJ2w9tdHRPa1qwGIOOAabRH46yorGfuWC2TioiIyI4S2eP2ReA+M/uFf78C6LWbguzB9q0ArIhvB2BOyRzAa3WVNnYsodwcVmysoz0a55DxhYM2TBERERmaEinA+xZwhJnl+ve3J31Uw1VTFQDLmjeRYinMKpoFQNvq1V2N5bsTExS4iYiIyI72uFRqZt83swLn3Hbn3HYzKzSz7w3E4IadJm+FeXn9W0wtmEp2Wjbx5mbaN2wgY1rn/rZaRoczGRXOHMyRioiIyBCUyB63E51zdZ13nHO1wEeSN6RhrKmKeGaYFdWvd+9ve+MNcK5rxm3JhjrmaplUREREepFI4BYys4zOO2aWBWT0cb7sTlMVb+cV09jR2BW4dWaUZkyf3lV4V4kJIiIi0ptEkhPuA54xs9/79y8A7k7ekIaxpmqWZecAdd2B25rVpOTmklZezpLXtwAoMUFERER6lUhywk1mthw4zj/0Xefc35M7rGGqqYrl4UzyQnlMyJ8AQNvqNWRMm4aZ8dqGOtJDKcwanT+44xQREZEhKZEZN5xzfwP+luSxDH9NVSwPj2R28RxSLAUXj9O2Zg3h004DvIzSA8vzyUgNDfJARUREZChKJKv0CDN7xcy2m1m7mcXMrGEgBjesxKI0tdSyNtbUtUzaUVFBvLmZjOle4d3llfUqAyIiIiK7lUhywi+Ac4A3gSzgc8BtyRzUsNS8jTfTU4njuuq3ta72OiZkTp/Oys0NKrwrIiIifUqoGaZzbi0Qcs7FnHO/B+Ynd1jDUFMVW0PeEmhZbhng7W8jJYWMqVO7Cu/OHaeMUhEREeldInvcms0sHVhqZj8ENpNgwCc9NFURSfW+3COzRwLQumYN6ePHk5KVxZKNdZSFMykLZw3mKEVERGQISyQA+6R/3iVAEzAWOCOZgxqWmqqJhEJkpKSTn+5ljbatXk1Gj1ZX2t8mIiIifdlj4Oace8c51+qca3DOXeec+6q/dCp7o6mKrakhSrNKMDNijY10VFaSOW06kc7Cu1omFRERkT5oyXOg+EulpTmjAGhb09kxYRqvbfAbyysxQURERPqgwG2gNFURSUunNKcU6G51lTl9ugrvioiISEIUuA0Qt72KSIp1JSa0rVlNKBwmdeRIXnunllkqvCsiIiJ7sMesUjM7APg6ML7n+c65Y5M4rmGnoTlCWzqUZnfPuGVMn05HzLGisp5PHDF+kEcoIiIiQ10i5UAeBn4N/BaIJXc4w9fWlmrwAzcXi9H25psUfvxjrNrcQFs0roxSERER2aNEAreoc+5XSR/JMBdprwfCjMweSfs77+BaW8mYPqNHYoIySkVERKRviexx+4uZXWRmZWY2ovMj6SMbTtqbiBAFvBm3tq5WV9N4bYMK74qIiEhiEplx+7T/+es9jjlgUvDDGab8Gm4AJVkl1K5eA6mppE+ezGt//j8tk4qIiEhC9hi4OecmDsRAhjW/a8KItFzSQmm0rllNxqRJVLfGqaxr4YIjJwz2CEVERGQ/sMelUjNLM7PLzGyh/3GJmaUlcnEzm29ma8xsrZld2cvj483sGTNbbmbPm9mYHo+NM7N/mNkqM1tpZhP843eZ2XozW+p/HJz42x0kfvHdkZlFgNdcPsNfJgWYqxk3ERERSUAie9x+BRwK/NL/ONQ/1iczCwG3AScCM4FzzGzmTqfdDNzjnJsNXA/c2OOxe4AfOedmAIcBkR6Pfd05d7D/sTSB9zC4mqqIhEKUZo8kWltLdOtWMqdNZ8mGWtJDKRxYrsK7IiIismeJ7HF7j3NuTo/7z5rZsgSedxiw1jm3DsDMHgROBVb2OGcm8FX/9nPAn/xzZwKpzrmnAZxz2xN4vaGrqYpIaoiD8sp3bHW1QoV3RUREJHGJzLjFzGxy5x0zm0Ri9dzKgY097lf4x3paBizwb58O5JlZEXAAUGdmj5rZEjP7kT+D1+kGf3n1FjPL6O3FzezzZrbYzBZXVVUlMNzkaW/cQk0oRGnuaFpXeRmlKVMOYHlFvRITREREJGGJBG5fB57z96D9C3gW+FpAr385cLSZLQGOBirxgsJU4Cj/8ffgZbCe7z/nKmC6f3wEcEVvF3bO3e6cm+ecm1dSUhLQcPunavtmAEZmj6Rt9WpCJcW82Z6mwrsiIiKyVxLJKn3GzKYC0/xDa5xzbQlcuxIY2+P+GP9Yz2tvwp9xM7Nc4AznXJ2ZVQBLeyyz/gk4ArjDObfZf3qbmf0eL7gb0iIt3va80uxSWtesIXPadP7tF96dO06Fd0VERCQxu51xM7Nj/c8LgI8CU/yPj/rH9uQVYKqZTTSzdOBs4PGdXqPYzDrHcBVwZ4/nFphZ51TZsfh748yszP9swGnA/xIYy6Da2uoFaSVphbS99RaZ06exZEMdo/IzGV2gwrsiIiKSmL5m3I7GWxY9uZfHHPBoXxd2zkXN7BLg70AIuNM597qZXQ8sds49DnwQuNHMHPACcLH/3JiZXQ484wdor+L1SgW4zw/oDFgKfDGhdzqIIh2NkJnGiEgrVR0dZEybxmsra9XmSkRERPbKbgM359x3/JvXO+fW93zMzBIqyuucexJ4cqdj3+5xeyGwcDfPfRqY3cvxYxN57SEjHicSbyXTMsmobgBg+4hSKmqrOf99EwZ3bCIiIrJfSSQ54ZFejvUabEkvWmqJhFIoTc0l6me3rmz3EmFVeFdERET2xm5n3MxsOjALCO+0py0fyEz2wIYNv09paUYB0a1e4PZaY4oK74qIiMhe62uP2zTgJKCAHfe5NQIXJnNQw4rfNWF2VgnRSIRQQQGLN21n5mgV3hUREZG909cetz8Dfzaz9zrn/juAYxpW3PatREKpjMwdTTRSRai0lOUV9Zx3+PjBHpqIiIjsZxJpebXEzC7GWzbtWiJ1zn0maaMaRuobK2hPMUrzxxKtepPWvEKv8K4ySkVERGQvJZKccC8wCjgB+BdeId3GZA5qONnaUAFAaXgC0UiEbZl5AOqYICIiInstkcBtinPuW0CTc+5uvGK8hyd3WMNHpGkLAKVZpUSrq9lo2Sq8KyIiIv2SSODW4X+uM7MDgTBQmrwhDS+R1moAStoyIBZjdUeGlklFRESkXxIJ3G43s0LgW3gtq1YCP0zqqIaRSFs9BoS3xwF4y2Uzd6yWSUVERGTvJdJk/nf+zX8Bk5I7nOFna6yJEampUF0DQE1mHtNG5Q3yqERERGR/1FcB3q/29UTn3E+CH87wszXeTmmoiI5IBICazHxG5KQP8qhERERkf9TXjFvntNA04D14y6TgFeN9OZmDGjY6WomYY3R6fle7q9qMfMJZaYM8MBEREdkf9VWA9zoAM3sBOMQ51+jfvxb464CMbn/XVEUkNcTBmUVEIxE6cvLpCKVSkK3ATURERPZeIskJI4H2Hvfb/WOyB20NldSFQpRmjyRaVU1LfgGhFCM3I5G6xyIiIiI7SiSCuAd42cwe8++fBtyVtBENI5G69QCU5pYTjbzE9txCCrLSMLNBHpmIiIjsj/Y44+acuwG4AKj1Py5wzt2Y7IENB5GGdwAYGZ5AtKqK+uwwYS2TioiISD/1lVWa75xrMLMRwNv+R+djI5xzNckf3v4t0lgJQEnBJKJVVdSMn0eBEhNERESkn/paKr0fOAl4FXA9jpt/XzXd9iDS4pUAKY7nsyUWI5KeS0G2SoGIiIhI//SVVXqS/3niwA1neNnaWkuWg8y6VgC2pOZqxk1ERET6ra+l0kP6eqJz7rXghzO8RDoaKXUpxPwabhUpOczRHjcRERHpp76WSn/cx2MOODbgsQw7kVgLpamZXcV3K0I5HJ2lpVIRERHpn76WSo8ZyIEMRxGiHJza3e6qNiNfxXdFRESk3xKqBGtmBwIzgczOY865e5I1qOHAxeNEUqA0o8CbcQuH1TVBRERE9skeAzcz+w7wQbzA7UngROD/8Arzym7U1r9Dhxkjs0qIRqqIFxYBqE+piIiI9FsiLa/OBI4DtjjnLgDmAOGkjmoYiNS8CUBpbhnRqio6CrzATeVAREREpL8SCdxanHNxIGpm+UAEGJvcYe3/IvV+u6u8sUQjEVryCwBUDkRERET6LZHAbbGZFQC/xSvG+xrw36SOahjY2rARgNL8CUSrq9meWwigPW4iIiLSb33VcbsNuN85d5F/6Ndm9hSQ75xbPiCj249FmjZjzlGQUkJdNEp9dgEWg7xMBW4iIiLSP30lJ7wB3GxmZcBDwAPOuSUDM6z9X6R1G0WxONZkANRm5pEfSyOUYoM8MhEREdlf7Xap1Dn3U+fce4GjgW3AnWa22sy+Y2YHDNgI91Nb2+oodRCtqQGgKiNPy6QiIiKyT/a4x805945z7ibn3FzgHOA0YFXSR7afi0SbKCWNqF98V31KRUREZF/tMXAzs1QzO9nM7gP+BqwBFiR9ZPu5SLydkanZO7S7CqsUiIiIiOyDvpITPow3w/YR4GXgQeDzzrmmARrbfqs12kq9xSlNzaPjnQihcJiaNseYEs24iYiISP/1lZxwFXA/8DXnXO0AjWdYqGr2ZtlKM4uIRqpILS2lrqVDe9xERERkn/TVZP7YgRzIcLK1sRKA0uyRRKs2Eyotpb6lQ3vcREREZJ8kUoBX9lKkbh0AI/NGE41EcCOKcA7tcRMREZF9osAtCSIN7wBQkjuOaHV1d59SzbiJiIjIPlDglgRbGyvIisfJskKIRmnNV7srERER2XcK3JIg0lLFyGiMWIv35W3K8xvMK3ATERGRfaDALQkirTWUxmJEt0cBqM8KAxDO0h43ERER6T8FbkkQ6WikNO6I1nol72qzvcBNM24iIiKyLxS4BSzu4kRiLZSmZBCt9uq5VaXlARBWcoKIiIjsAwVuAattrSWKozQ1h46I1zWhtgNyM1JJC+nLLSIiIv2nSCJgkWavqfzIjAKiVZ1dE9o12yYiIiL7TIFbwDoDt9LMEq/dVUkJ9c1qdyUiIiL7ToFbwLY2bwWgNHdUjxk3BW4iIiKy7xS4BSzSsJEU5yjKGeMFbiUl1DW3U6BSICIiIrKPFLgFLNK4kaJYDHN5EI2S6jeYD2vGTURERPaRAreARZq2eMV321IBCJWWUNfcoT6lIiIiss+SGriZ2XwzW2Nma83syl4eH29mz5jZcjN73szG9HhsnJn9w8xWmdlKM5vgH59oZov8a/7RzIbUGuTWlmpKozGiXu1dogVFRONOe9xERERknyUtcDOzEHAbcCIwEzjHzGbudNrNwD3OudnA9cCNPR67B/iRc24GcBgQ8Y/fBNzinJsC1AKfTdZ76I9Ie90O7a66+pRqj5uIiIjso2TOuB0GrHXOrXPOtQMPAqfudM5M4Fn/9nOdj/sBXqpz7mkA59x251yzmRlwLLDQf87dwGlJfA97pTXaSkOsjZHRGNGGVgAasvIBtMdNRERE9lkyA7dyYGOP+xX+sZ6WAQv826cDeWZWBBwA1JnZo2a2xMx+5M/gFQF1zrloH9ccNF013Cyd6LYaQuEw9THvS6w9biIiIrKvBjs54XLgaDNbAhwNVAIxIBU4yn/8PcAk4Py9ubCZfd7MFpvZ4qqqqkAHvTtdNdzS8uiIREgtLaG+pQOAgmwtlYqIiMi+SWbgVgmM7XF/jH+si3Nuk3NugXNuLnCNf6wObyZtqb/MGgX+BBwCbAMKzCx1d9fsce3bnXPznHPzSkpKgnxfu9XV7iqryO+aUEpdc2fgphk3ERER2TfJDNxeAab6WaDpwNnA4z1PMLNiM+scw1XAnT2eW2BmnRHXscBK55zD2wt3pn/808Cfk/ge9krXUml26Q59SgH1KhUREZF9lrTAzZ8puwT4O7AKeMg597qZXW9mp/infRBYY2ZvACOBG/znxvCWSZ8xsxWAAb/1n3MF8FUzW4u35+2OZL2HvRVpjpAdd+Rkj+zqmlDf3EFmWgqZaaHBHp6IiIjs51L3fEr/OeeeBJ7c6di3e9xeSHeG6M7PfRqY3cvxdXgZq0PO1qYtlEajxMjv6prgFd/V/jYRERHZd4OdnDCsRLZvYmQsRrQ9E8DrU9rSrv1tIiIiEggFbgGKNEe8rgmt3rJo54yb9reJiIhIEBS4BSTu4lS11VAaixJtcgBd5UAUuImIiEgQFLgFpKa1hqiLezNujV4JkNQSv8G8lkpFREQkAElNTng36arhFosRbWwlFA6TkpHh73FTcoKIiIjsO824BaSrhlscOmrqSS0tobUjRmtHXEulIiIiEggFbgHpCtzSw0Srva4J3e2uFLiJiIjIvlPgFpCtzVtJAYqyiv12VyXd7a5Ux01EREQCoMAtIJHmCMUuhVB2MdHqar8UiNfuSjNuIiIiEgQFbgGJNEcojcWJWSF0dPjFd70ZN+1xExERkSAocAtIpDlCaUc70Y4cwCu+W9+sPW4iIiISHAVuAdnatJXSjjai7d5+ttTSUupaOpdKtcdNRERE9p0CtwC0RFto7GhkZDRGtKWz3ZWXnJCaYuSkhwZ5hCIiIjIcKHALQFcpkFiMaLPf7srf41aQnYaZDebwREREZJhQ4BaArsAtGiXa0E6K3zWhXg3mRUREJEAK3AKwtXkr4M+41beQVloCoHZXIiIiEigFbgHo6lMajXntrkr8wK25gwLNuImIiEhAFLgFINIcIcdSyUnLIbptG6klpYAXuIVVCkREREQCkjrYAxgOzpl+Dh9Y/youO0a0yuuaAFDf0qF2VyIiIhIYBW4BGJ8/nvFt7URTiqBjC6klJXTE4mxvi6r4roiIiARGS6VBaaomGg8DfteEFnVNEBERkWApcAtKUxXRjiygu/guqE+piIiIBEdLpUGIx70Zt1AG0DnjpnZXIiIiEizNuAWhpRZcjGiz9+VMLemecVM5EBEREQmKArcgNFUBEG2Kd3VN6ArctMdNREREAqLALQidgVtjW4+uCZ0zbloqFRERkWAocAuCH7h11DV1dU2ob27HDPIytY1QREREgqHALQhN1QBEaxq6uya0eA3mU1JsMEcmIiIiw4gCtyA0VeGcEa3eRmqp+pSKiIhIcihwC0KsnVjGaIhGd5xxUykQERERCZACtyB8+DqiZzwG0DXjVt/crhk3ERERCZQCt4BEI16CQmeD+bqWDpUCERERkUApcAtINBIBegRu2uMmIiIiAVPgFpBolR+4lZQQizsaWrXHTURERIKlwC0g0UhVV9eExtYOnFO7KxEREQmWAreARKsipJYUA6jdlYiIiCSFAreARCNVpPVITAAFbiIiIhIsBW4B6aiKdLW7qmtuByCsPqUiIiISIAVuAXDOEa2q7soordeMm4iIiCSBArcAxOrqoKOju2tC5x43JSeIiIhIgBS4BaC7hlt3n1KAsAI3ERERCZACtwDs2jWhnbyMVFJD+vKKiIhIcBRZBKBrxq2ks09pB2HtbxMREZGAKXALQLTKn3HrzCpVn1IRERFJAgVuAYhGIl7XhMxMwCsHUqBSICIiIhKw1MEewHBQfOklFJ5zdtf9upYOygqyBnFEIiIiMhwpcAtAamEhqYWFXffrmztUCkREREQCp6XSgDnntMdNREREkkKBW8C2t0WJxZ32uImIiEjgFLgFrKv4rmbcREREJGBJDdzMbL6ZrTGztWZ2ZS+PjzezZ8xsuZk9b2bhx1iiAAAMaElEQVRjejwWM7Ol/sfjPY7fZWbrezx2cDLfw97q6lOqPW4iIiISsKQlJ5hZCLgN+DBQAbxiZo8751b2OO1m4B7n3N1mdixwI/BJ/7EW59zugrKvO+cWJmvs+6KrT2m2lkpFREQkWMmccTsMWOucW+ecawceBE7d6ZyZwLP+7ed6eXy/U9fSDqDkBBEREQlcMgO3cmBjj/sV/rGelgEL/NunA3lmVuTfzzSzxWb2kpmdttPzbvCXV28xs4zeXtzMPu8/f3GV39lgIHTNuGmpVERERAI22MkJlwNHm9kS4GigEoj5j413zs0DzgVuNbPJ/vGrgOnAe4ARwBW9Xdg5d7tzbp5zbl6J34pqIHTucctX4CYiIiIBS2bgVgmM7XF/jH+si3Nuk3NugXNuLnCNf6zO/1zpf14HPA/M9e9vdp424Pd4S7JDRl1zO1lpITLTQoM9FBERERlmkhm4vQJMNbOJZpYOnA083vMEMys2s84xXAXc6R8v7FwCNbNi4EhgpX+/zP9swGnA/5L4HvZaXbOK74qIiEhyJC2r1DkXNbNLgL8DIeBO59zrZnY9sNg59zjwQeBGM3PAC8DF/tNnAL8xszhecPmDHtmo95lZCWDAUuCLyXoP/VHX0kFYy6QiIiKSBEntVeqcexJ4cqdj3+5xeyGwS1kP59x/gIN2c81jAx5moOo14yYiIiJJMtjJCcNOXUu72l2JiIhIUihwC5j2uImIiEiyKHALWH1Lh/qUioiISFIocAtQa0eMtmhcS6UiIiKSFArcAtTdp1QzbiIiIhI8BW4B6upTqnIgIiIikgQK3ALUOeOmPW4iIiKSDArcAtTdYF573ERERCR4CtwCVO8vlWrGTURERJJBgVuAumfcFLiJiIhI8BS4BaiupYO0kJGdHhrsoYiIiMgwpMAtQHXNHYSz0jGzwR6KiIiIDEMK3AJU39KuGm4iIiKSNArcAlTX3KH9bSIiIpI0CtwCpAbzIiIikkwK3AJU3+LtcRMRERFJBgVuAapr1h43ERERSR4FbgFpj8Zpao9pj5uIiIgkjQK3gNS3+MV3NeMmIiIiSaLALSDd7a60x01ERESSQ4FbQNTuSkRERJJNgVtAugI3LZWKiIhIkihwC0hd5x43lQMRERGRJFHgFpC65s49bppxExERkeRQ4BaQ+pYOUgzyMlIHeygiIiIyTClwC0hdcwfhrDRSUmywhyIiIiLDlAK3gNS1dFCgUiAiIiKSRArcAlLX3E5YpUBEREQkiRS4BaS+pUOlQERERCSpFLgFpK65Q8V3RUREJKkUuAWkrrlde9xEREQkqRS4BSAWdzS0RrXHTURERJJKgVsAGlrU7kpERESST4FbAOoUuImIiMgAUOAWgM52V+pTKiIiIsmkwC0AnTNu6lMqIiIiyaTALQD1zf5SqZITREREJIkUuAWga6lU5UBEREQkiRS4BaBzqTQ/M3WQRyIiIiLDmQK3ANQ1d5CXmUpqSF9OERERSR5NEQXggiMnMP/AUYM9DBERERnmFLgFYHxRDuOLcgZ7GCIiIjLMaW1PREREZD+hwE1ERERkP6HATURERGQ/ocBNREREZD+hwE1ERERkP6HATURERGQ/ocBNREREZD+R1MDNzOab2RozW2tmV/by+Hgze8bMlpvZ82Y2psdjMTNb6n883uP4RDNb5F/zj2amBqEiIiLyrpC0wM3MQsBtwInATOAcM5u502k3A/c452YD1wM39nisxTl3sP9xSo/jNwG3OOemALXAZ5P1HkRERESGkmTOuB0GrHXOrXPOtQMPAqfudM5M4Fn/9nO9PL4DMzPgWGChf+hu4LTARiwiIiIyhCUzcCsHNva4X+Ef62kZsMC/fTqQZ2ZF/v1MM1tsZi+ZWWdwVgTUOeeifVwTADP7vP/8xVVVVfv6XkREREQG3WAnJ1wOHG1mS4CjgUog5j823jk3DzgXuNXMJu/NhZ1ztzvn5jnn5pWUlAQ6aBEREZHBkMwm85XA2B73x/jHujjnNuHPuJlZLnCGc67Of6zS/7zOzJ4H5gKPAAVmlurPuu1yTREREZHhKpkzbq8AU/0s0HTgbODxnieYWbGZdY7hKuBO/3ihmWV0ngMcCax0zjm8vXBn+s/5NPDnJL4HERERkSEjaYGbPyN2CfB3YBXwkHPudTP7/+3db+idZR3H8fenn4tGhn+2GuJmKxzUIp0RYuWDNShWSgZFKgYSQiRRi/5t9SSSBtWD/qz2xNIaZJlUmvRAHHOUUKgzN/enrCWTGtNt1KpBWK1vD+5reNif0PY7u++z837B4dzX94z7XIcvu37fc93Xfa5bkhy9S3Q58ESS3wELgLUt/lpgS5JtdIXaF6tqV3ttNfDxJLvp1rzdNq7PIEmSNCTpJrHObEkOAE+N+W3mAwfH/B76/5mf4TI3w2Z+hsvcDNup5OeVVXXCBfpTUbidDkm2tJspNEDmZ7jMzbCZn+EyN8M2rvz0fVepJEmSnicLN0mSpAlh4TZ7bu27A/qfzM9wmZthMz/DZW6GbSz5cY2bJEnShHDGTZIkaUJYuEmSJE0IC7dZkGRlkieS7E6ypu/+TLsktyfZn2THSOz8JBuT/L49n9dnH6dVkkVJNifZlWRnklUtbn56luQlSR5Osq3l5vMt/qokD7Xx7YdtJxz1IMlMkseS/Ky1zc1AJNmTZHuSrUm2tNhYxjULt1OUZAZYD7wDWApcn2Rpv72aet8FVh4TWwNsqqolwKbW1un3b+ATVbUUuAL4cPv/Yn769yywoqouBZYBK5NcAXwJ+GpVXQz8Bbipxz5Ou1V0OxEdZW6G5a1VtWzkt9vGMq5ZuJ26y4HdVfVkVf0TuBO4puc+TbWq+gXw52PC1wAb2vEG4N2ntVMCoKr2VdWv2/Hf6f4IXYj56V11DrfmnPYoYAXwoxY3Nz1JshC4Cvh2awdzM3RjGdcs3E7dhcAfR9p/ajENy4Kq2teOn6bbG1c9SrIYuAx4CPMzCO1S3FZgP7AR+ANwqO09DY5vffoa8GngP609D3MzJAXcn+TRJB9ssbGMa2fNxkmkSVJVlcTfwelRkrOBHwMfq6q/dZMHHfPTn6o6AixLci5wN/CanrskIMnVwP6qejTJ8r77oxO6sqr2JnkFsDHJb0dfnM1xzRm3U7cXWDTSXthiGpZnklwA0J7399yfqZVkDl3RdkdV/aSFzc+AVNUhYDPwJuDcJEe/5Du+9eMtwLuS7KFbjrMC+DrmZjCqam973k/3pedyxjSuWbidukeAJe3unhcD1wH39twnHe9e4MZ2fCPw0x77MrXaupzbgN9U1VdGXjI/PUvy8jbTRpK5wNvo1iBuBt7b/pm56UFVfaaqFlbVYrq/MQ9U1Q2Ym0FI8tIkLzt6DLwd2MGYxjV3TpgFSd5Jt/5gBri9qtb23KWpluQHwHJgPvAM8DngHuAu4CLgKeB9VXXsDQwasyRXAg8C23lurc5n6da5mZ8eJbmEbgH1DN2X+ruq6pYkr6ab5TkfeAx4f1U9219Pp1u7VPrJqrra3AxDy8PdrXkW8P2qWptkHmMY1yzcJEmSJoSXSiVJkiaEhZskSdKEsHCTJEmaEBZukiRJE8LCTZIkaUJYuEmaSkmOJNk68pi1je2TLE6yY7bOJ0lHueWVpGn1j6pa1ncnJOmFcMZNkkYk2ZPky0m2J3k4ycUtvjjJA0keT7IpyUUtviDJ3Um2tceb26lmknwryc4k97fdCEjy0SS72nnu7OljSppQFm6SptXcYy6VXjvy2l+r6vXAN+l2RQH4BrChqi4B7gDWtfg64OdVdSnwBmBniy8B1lfV64BDwHtafA1wWTvPh8b14SSdmdw5QdJUSnK4qs4+QXwPsKKqnkwyB3i6quYlOQhcUFX/avF9VTU/yQFg4ehWQ0kWAxuraklrrwbmVNUXktwHHKbbhu2eqjo85o8q6QzijJskHa9OcvxCjO4ZeYTn1hRfBaynm517JIlrjSU9bxZuknS8a0eef9WOfwlc145vAB5sx5uAmwGSzCQ552QnTfIiYFFVbQZWA+cAx836SdLJ+E1P0rSam2TrSPu+qjr6kyDnJXmcbtbs+hb7CPCdJJ8CDgAfaPFVwK1JbqKbWbsZ2HeS95wBvteKuwDrqurQrH0iSWc817hJ0oi2xu2NVXWw775I0rG8VCpJkjQhnHGTJEmaEM64SZIkTQgLN0mSpAlh4SZJkjQhLNwkSZImhIWbJEnShPgv9hUNqYK++usAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sCnAtK8vSMd"
      },
      "source": [
        "Looking at the plot we can see that activity regularization was exclusively detrimental in this case. For this reason we also won't use it. Regularization ended up not having a major impact in our case. This could be caused by the NN already behing pretty well optmized, but realistically is mostly a matter of further testing, namely alternating apllication for each layer and using different penalties. We're confident however that it still wouldn't have considerable impact in the accuracy rating itself, but could definetly improove convergence speeds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u0vLV8XJ2RZ",
        "colab_type": "text"
      },
      "source": [
        "#####Optimization\n",
        "\n",
        "We've completed all testing in regards to stantard Multi-Layered NN so now it's just a matter of few tweaks or optimizations. We believe 98% is already a pretty good value without the use of Convolutional Neural Networks so we want to mostly increase convergence speed. For this, we will try batch normalization, as it could have a big impact depending on the data, using [4 hidden layers](https://colab.research.google.com/drive/1KnSJmvMyJn0KpTsu216wN7Yiy5hlgKow#scrollTo=Dd7HjISMLGwn&line=6&uniqifier=1) as a baseline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVbOueMxNOUJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "7c29cec9-c7e8-4a9e-a802-864e6230eef0"
      },
      "source": [
        "multi_layer_4_hidden_model = create_multi_layer_multi_hidden_model(4, \"multi_layer_4_hidden_model\") #baseline\n",
        "\n",
        "multi_layer_norm_4_hidden_model = tf.keras.Sequential(name=\"multi_layer_norm_4_hidden_model\")\n",
        "multi_layer_norm_4_hidden_model.add(tf.keras.layers.Input(mnist_info.features['image'].shape))\n",
        "multi_layer_norm_4_hidden_model.add(tf.keras.layers.BatchNormalization())\n",
        "multi_layer_norm_4_hidden_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "for i in range(4):\n",
        "  multi_layer_norm_4_hidden_model.add(tf.keras.layers.Dense(128, activation='relu', name='hidden{}'.format(i)))\n",
        "  multi_layer_norm_4_hidden_model.add(tf.keras.layers.BatchNormalization())\n",
        "multi_layer_norm_4_hidden_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "\n",
        "multi_layer_norm_4_hidden_model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "multi_layer_norm_4_hidden_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"multi_layer_4_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "hidden3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 151,306\n",
            "Trainable params: 151,306\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"multi_layer_norm_4_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_11 (Batc (None, 28, 28, 1)         4         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "hidden0 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "hidden1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "hidden2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "hidden3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 153,358\n",
            "Trainable params: 152,332\n",
            "Non-trainable params: 1,026\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "akbjyetmPAbH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac7ebb2e-9339-4a6f-fa77-4175da32d8be"
      },
      "source": [
        "earlystop4 = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50, verbose=1)\n",
        "earlystop4norm = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=50, verbose=1)\n",
        "checkpoint4 = tf.keras.callbacks.ModelCheckpoint('multi_layer_4_hidden_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "checkpoint4norm = tf.keras.callbacks.ModelCheckpoint('multi_layer_norm_4_hidden_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "multi_layer_4_hidden_train = multi_layer_4_hidden_model.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop4,checkpoint4], epochs=10000, batch_size=256)\n",
        "multi_layer_norm_4_hidden_train = multi_layer_norm_4_hidden_model.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop4norm,checkpoint4norm], epochs=10000, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.4467 - accuracy: 0.8670\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.94675, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4252 - accuracy: 0.8730 - val_loss: 0.1861 - val_accuracy: 0.9467\n",
            "Epoch 2/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.9567\n",
            "Epoch 00002: val_accuracy improved from 0.94675 to 0.96267, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1466 - accuracy: 0.9567 - val_loss: 0.1290 - val_accuracy: 0.9627\n",
            "Epoch 3/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.1003 - accuracy: 0.9699\n",
            "Epoch 00003: val_accuracy improved from 0.96267 to 0.96800, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0992 - accuracy: 0.9702 - val_loss: 0.1109 - val_accuracy: 0.9680\n",
            "Epoch 4/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.0735 - accuracy: 0.9774\n",
            "Epoch 00004: val_accuracy improved from 0.96800 to 0.96867, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0734 - accuracy: 0.9775 - val_loss: 0.1079 - val_accuracy: 0.9687\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.9807\n",
            "Epoch 00005: val_accuracy did not improve from 0.96867\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0607 - accuracy: 0.9807 - val_loss: 0.1103 - val_accuracy: 0.9670\n",
            "Epoch 6/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 0.9845\n",
            "Epoch 00006: val_accuracy improved from 0.96867 to 0.97083, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0481 - accuracy: 0.9846 - val_loss: 0.1007 - val_accuracy: 0.9708\n",
            "Epoch 7/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.9878\n",
            "Epoch 00007: val_accuracy improved from 0.97083 to 0.97192, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0395 - accuracy: 0.9879 - val_loss: 0.1005 - val_accuracy: 0.9719\n",
            "Epoch 8/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.0305 - accuracy: 0.9902\n",
            "Epoch 00008: val_accuracy improved from 0.97192 to 0.97433, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 0.0953 - val_accuracy: 0.9743\n",
            "Epoch 9/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.0266 - accuracy: 0.9916\n",
            "Epoch 00009: val_accuracy did not improve from 0.97433\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9915 - val_loss: 0.0991 - val_accuracy: 0.9731\n",
            "Epoch 10/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9927\n",
            "Epoch 00010: val_accuracy did not improve from 0.97433\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.1019 - val_accuracy: 0.9721\n",
            "Epoch 11/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.0197 - accuracy: 0.9934\n",
            "Epoch 00011: val_accuracy did not improve from 0.97433\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.1219 - val_accuracy: 0.9713\n",
            "Epoch 12/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.0212 - accuracy: 0.9931\n",
            "Epoch 00012: val_accuracy improved from 0.97433 to 0.97550, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.0952 - val_accuracy: 0.9755\n",
            "Epoch 13/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9942\n",
            "Epoch 00013: val_accuracy did not improve from 0.97550\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.1233 - val_accuracy: 0.9700\n",
            "Epoch 14/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9954\n",
            "Epoch 00014: val_accuracy did not improve from 0.97550\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.1305 - val_accuracy: 0.9722\n",
            "Epoch 15/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 0.0150 - accuracy: 0.9948\n",
            "Epoch 00015: val_accuracy did not improve from 0.97550\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.1314 - val_accuracy: 0.9716\n",
            "Epoch 16/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9944\n",
            "Epoch 00016: val_accuracy did not improve from 0.97550\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.1162 - val_accuracy: 0.9752\n",
            "Epoch 17/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0082 - accuracy: 0.9971\n",
            "Epoch 00017: val_accuracy did not improve from 0.97550\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.1244 - val_accuracy: 0.9752\n",
            "Epoch 18/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.0142 - accuracy: 0.9951\n",
            "Epoch 00018: val_accuracy did not improve from 0.97550\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0143 - accuracy: 0.9950 - val_loss: 0.1208 - val_accuracy: 0.9746\n",
            "Epoch 19/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.0080 - accuracy: 0.9973\n",
            "Epoch 00019: val_accuracy did not improve from 0.97550\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1373 - val_accuracy: 0.9748\n",
            "Epoch 20/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0104 - accuracy: 0.9962\n",
            "Epoch 00020: val_accuracy improved from 0.97550 to 0.97608, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.1289 - val_accuracy: 0.9761\n",
            "Epoch 21/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0082 - accuracy: 0.9972\n",
            "Epoch 00021: val_accuracy did not improve from 0.97608\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9972 - val_loss: 0.1298 - val_accuracy: 0.9758\n",
            "Epoch 22/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.0089 - accuracy: 0.9969\n",
            "Epoch 00022: val_accuracy did not improve from 0.97608\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.1528 - val_accuracy: 0.9705\n",
            "Epoch 23/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.0133 - accuracy: 0.9955\n",
            "Epoch 00023: val_accuracy did not improve from 0.97608\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.1250 - val_accuracy: 0.9752\n",
            "Epoch 24/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0074 - accuracy: 0.9976\n",
            "Epoch 00024: val_accuracy did not improve from 0.97608\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1498 - val_accuracy: 0.9745\n",
            "Epoch 25/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.0070 - accuracy: 0.9977\n",
            "Epoch 00025: val_accuracy did not improve from 0.97608\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.1572 - val_accuracy: 0.9711\n",
            "Epoch 26/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.0132 - accuracy: 0.9956\n",
            "Epoch 00026: val_accuracy improved from 0.97608 to 0.97617, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9957 - val_loss: 0.1320 - val_accuracy: 0.9762\n",
            "Epoch 27/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9976\n",
            "Epoch 00027: val_accuracy did not improve from 0.97617\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.1343 - val_accuracy: 0.9752\n",
            "Epoch 28/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.0046 - accuracy: 0.9987\n",
            "Epoch 00028: val_accuracy improved from 0.97617 to 0.97975, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1135 - val_accuracy: 0.9797\n",
            "Epoch 29/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.0130 - accuracy: 0.9963\n",
            "Epoch 00029: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.1583 - val_accuracy: 0.9696\n",
            "Epoch 30/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0122 - accuracy: 0.9954\n",
            "Epoch 00030: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.1222 - val_accuracy: 0.9768\n",
            "Epoch 31/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.0045 - accuracy: 0.9985\n",
            "Epoch 00031: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1181 - val_accuracy: 0.9783\n",
            "Epoch 32/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9964\n",
            "Epoch 00032: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.1188 - val_accuracy: 0.9762\n",
            "Epoch 33/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
            "Epoch 00033: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.1184 - val_accuracy: 0.9789\n",
            "Epoch 34/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
            "Epoch 00034: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1331 - val_accuracy: 0.9765\n",
            "Epoch 35/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 0.0114 - accuracy: 0.9962\n",
            "Epoch 00035: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.1309 - val_accuracy: 0.9765\n",
            "Epoch 36/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9977\n",
            "Epoch 00036: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1209 - val_accuracy: 0.9781\n",
            "Epoch 37/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9980\n",
            "Epoch 00037: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.1444 - val_accuracy: 0.9747\n",
            "Epoch 38/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9980\n",
            "Epoch 00038: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.1598 - val_accuracy: 0.9731\n",
            "Epoch 39/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9962\n",
            "Epoch 00039: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.1345 - val_accuracy: 0.9775\n",
            "Epoch 40/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0048 - accuracy: 0.9984\n",
            "Epoch 00040: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.1512 - val_accuracy: 0.9751\n",
            "Epoch 41/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.0096 - accuracy: 0.9970\n",
            "Epoch 00041: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.1109 - val_accuracy: 0.9793\n",
            "Epoch 42/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9987\n",
            "Epoch 00042: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.1249 - val_accuracy: 0.9778\n",
            "Epoch 43/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998\n",
            "Epoch 00043: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.1314 - val_accuracy: 0.9784\n",
            "Epoch 44/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
            "Epoch 00044: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.1385 - val_accuracy: 0.9782\n",
            "Epoch 45/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0097 - accuracy: 0.9965\n",
            "Epoch 00045: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 0.1497 - val_accuracy: 0.9770\n",
            "Epoch 46/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 0.0055 - accuracy: 0.9982\n",
            "Epoch 00046: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.1540 - val_accuracy: 0.9757\n",
            "Epoch 47/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
            "Epoch 00047: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1748 - val_accuracy: 0.9733\n",
            "Epoch 48/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 0.0090 - accuracy: 0.9971\n",
            "Epoch 00048: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.1491 - val_accuracy: 0.9758\n",
            "Epoch 49/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 0.0059 - accuracy: 0.9982\n",
            "Epoch 00049: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.1525 - val_accuracy: 0.9755\n",
            "Epoch 50/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 00050: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.1521 - val_accuracy: 0.9768\n",
            "Epoch 51/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 0.0058 - accuracy: 0.9980\n",
            "Epoch 00051: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.1570 - val_accuracy: 0.9765\n",
            "Epoch 52/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n",
            "Epoch 00052: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.1690 - val_accuracy: 0.9744\n",
            "Epoch 53/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0096 - accuracy: 0.9971\n",
            "Epoch 00053: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.1353 - val_accuracy: 0.9772\n",
            "Epoch 54/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
            "Epoch 00054: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1308 - val_accuracy: 0.9787\n",
            "Epoch 55/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
            "Epoch 00055: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.1341 - val_accuracy: 0.9796\n",
            "Epoch 56/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 6.7360e-04 - accuracy: 0.9998\n",
            "Epoch 00056: val_accuracy improved from 0.97975 to 0.98100, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.8071e-04 - accuracy: 0.9998 - val_loss: 0.1290 - val_accuracy: 0.9810\n",
            "Epoch 57/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 3.0661e-04 - accuracy: 1.0000\n",
            "Epoch 00057: val_accuracy improved from 0.98100 to 0.98167, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.9182e-04 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9817\n",
            "Epoch 58/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 3.0936e-05 - accuracy: 1.0000\n",
            "Epoch 00058: val_accuracy did not improve from 0.98167\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.0668e-05 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9817\n",
            "Epoch 59/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 2.0259e-05 - accuracy: 1.0000\n",
            "Epoch 00059: val_accuracy improved from 0.98167 to 0.98175, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.9983e-05 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9818\n",
            "Epoch 60/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 1.6023e-05 - accuracy: 1.0000\n",
            "Epoch 00060: val_accuracy did not improve from 0.98175\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5938e-05 - accuracy: 1.0000 - val_loss: 0.1372 - val_accuracy: 0.9818\n",
            "Epoch 61/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 1.3355e-05 - accuracy: 1.0000\n",
            "Epoch 00061: val_accuracy improved from 0.98175 to 0.98183, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.3252e-05 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9818\n",
            "Epoch 62/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 1.1258e-05 - accuracy: 1.0000\n",
            "Epoch 00062: val_accuracy did not improve from 0.98183\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1235e-05 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9818\n",
            "Epoch 63/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 9.6556e-06 - accuracy: 1.0000\n",
            "Epoch 00063: val_accuracy did not improve from 0.98183\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.6496e-06 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9818\n",
            "Epoch 64/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 8.4579e-06 - accuracy: 1.0000\n",
            "Epoch 00064: val_accuracy did not improve from 0.98183\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.3770e-06 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9818\n",
            "Epoch 65/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 7.1825e-06 - accuracy: 1.0000\n",
            "Epoch 00065: val_accuracy did not improve from 0.98183\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.3201e-06 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9818\n",
            "Epoch 66/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 6.5613e-06 - accuracy: 1.0000\n",
            "Epoch 00066: val_accuracy improved from 0.98183 to 0.98200, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.4393e-06 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.9820\n",
            "Epoch 67/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 5.7318e-06 - accuracy: 1.0000\n",
            "Epoch 00067: val_accuracy did not improve from 0.98200\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.6749e-06 - accuracy: 1.0000 - val_loss: 0.1442 - val_accuracy: 0.9820\n",
            "Epoch 68/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 5.0515e-06 - accuracy: 1.0000\n",
            "Epoch 00068: val_accuracy improved from 0.98200 to 0.98208, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.0042e-06 - accuracy: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9821\n",
            "Epoch 69/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 4.4555e-06 - accuracy: 1.0000\n",
            "Epoch 00069: val_accuracy improved from 0.98208 to 0.98217, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.4145e-06 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9822\n",
            "Epoch 70/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 3.7310e-06 - accuracy: 1.0000\n",
            "Epoch 00070: val_accuracy did not improve from 0.98217\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.7343e-06 - accuracy: 1.0000 - val_loss: 0.1491 - val_accuracy: 0.9820\n",
            "Epoch 71/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 2.5098e-06 - accuracy: 1.0000\n",
            "Epoch 00071: val_accuracy did not improve from 0.98217\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.4968e-06 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 0.9818\n",
            "Epoch 72/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 1.2072e-06 - accuracy: 1.0000\n",
            "Epoch 00072: val_accuracy did not improve from 0.98217\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.2210e-06 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9817\n",
            "Epoch 73/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 7.3637e-07 - accuracy: 1.0000\n",
            "Epoch 00073: val_accuracy did not improve from 0.98217\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.3093e-07 - accuracy: 1.0000 - val_loss: 0.1811 - val_accuracy: 0.9818\n",
            "Epoch 74/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 5.3775e-07 - accuracy: 1.0000\n",
            "Epoch 00074: val_accuracy did not improve from 0.98217\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.2951e-07 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9818\n",
            "Epoch 75/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 4.5303e-07 - accuracy: 1.0000\n",
            "Epoch 00075: val_accuracy did not improve from 0.98217\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.4119e-07 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9822\n",
            "Epoch 76/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 3.8483e-07 - accuracy: 1.0000\n",
            "Epoch 00076: val_accuracy did not improve from 0.98217\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.8347e-07 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9822\n",
            "Epoch 77/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 3.1772e-07 - accuracy: 1.0000\n",
            "Epoch 00077: val_accuracy did not improve from 0.98217\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.3460e-07 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9821\n",
            "Epoch 78/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 2.9851e-07 - accuracy: 1.0000\n",
            "Epoch 00078: val_accuracy did not improve from 0.98217\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.0351e-07 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9820\n",
            "Epoch 79/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 2.7332e-07 - accuracy: 1.0000\n",
            "Epoch 00079: val_accuracy improved from 0.98217 to 0.98225, saving model to multi_layer_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.7011e-07 - accuracy: 1.0000 - val_loss: 0.1982 - val_accuracy: 0.9822\n",
            "Epoch 80/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 2.5823e-07 - accuracy: 1.0000\n",
            "Epoch 00080: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.5165e-07 - accuracy: 1.0000 - val_loss: 0.2000 - val_accuracy: 0.9822\n",
            "Epoch 81/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 2.3417e-07 - accuracy: 1.0000\n",
            "Epoch 00081: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.3399e-07 - accuracy: 1.0000 - val_loss: 0.2013 - val_accuracy: 0.9819\n",
            "Epoch 82/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 2.1704e-07 - accuracy: 1.0000\n",
            "Epoch 00082: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.1519e-07 - accuracy: 1.0000 - val_loss: 0.2027 - val_accuracy: 0.9822\n",
            "Epoch 83/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 2.0312e-07 - accuracy: 1.0000\n",
            "Epoch 00083: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.0190e-07 - accuracy: 1.0000 - val_loss: 0.2039 - val_accuracy: 0.9821\n",
            "Epoch 84/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 1.8839e-07 - accuracy: 1.0000\n",
            "Epoch 00084: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.8839e-07 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9822\n",
            "Epoch 85/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 1.8464e-07 - accuracy: 1.0000\n",
            "Epoch 00085: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.7772e-07 - accuracy: 1.0000 - val_loss: 0.2059 - val_accuracy: 0.9819\n",
            "Epoch 86/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 1.6400e-07 - accuracy: 1.0000\n",
            "Epoch 00086: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.6556e-07 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9821\n",
            "Epoch 87/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 1.5484e-07 - accuracy: 1.0000\n",
            "Epoch 00087: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5487e-07 - accuracy: 1.0000 - val_loss: 0.2079 - val_accuracy: 0.9820\n",
            "Epoch 88/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 1.4984e-07 - accuracy: 1.0000\n",
            "Epoch 00088: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.4715e-07 - accuracy: 1.0000 - val_loss: 0.2081 - val_accuracy: 0.9819\n",
            "Epoch 89/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 1.3878e-07 - accuracy: 1.0000\n",
            "Epoch 00089: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.3755e-07 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9819\n",
            "Epoch 90/10000\n",
            "176/188 [===========================>..] - ETA: 0s - loss: 1.2812e-07 - accuracy: 1.0000\n",
            "Epoch 00090: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.2964e-07 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9819\n",
            "Epoch 91/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 1.2421e-07 - accuracy: 1.0000\n",
            "Epoch 00091: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.2228e-07 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9815\n",
            "Epoch 92/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 1.1531e-07 - accuracy: 1.0000\n",
            "Epoch 00092: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1480e-07 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9818\n",
            "Epoch 93/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 1.0762e-07 - accuracy: 1.0000\n",
            "Epoch 00093: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0877e-07 - accuracy: 1.0000 - val_loss: 0.2118 - val_accuracy: 0.9820\n",
            "Epoch 94/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 1.0261e-07 - accuracy: 1.0000\n",
            "Epoch 00094: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0204e-07 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9819\n",
            "Epoch 95/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 9.5345e-08 - accuracy: 1.0000\n",
            "Epoch 00095: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.5098e-08 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9818\n",
            "Epoch 96/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 8.9065e-08 - accuracy: 1.0000\n",
            "Epoch 00096: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.9061e-08 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9818\n",
            "Epoch 97/10000\n",
            "175/188 [==========================>...] - ETA: 0s - loss: 8.6394e-08 - accuracy: 1.0000\n",
            "Epoch 00097: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.3809e-08 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9819\n",
            "Epoch 98/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 7.9183e-08 - accuracy: 1.0000\n",
            "Epoch 00098: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.8335e-08 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9818\n",
            "Epoch 99/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 7.3597e-08 - accuracy: 1.0000\n",
            "Epoch 00099: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.3768e-08 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9818\n",
            "Epoch 100/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 6.8529e-08 - accuracy: 1.0000\n",
            "Epoch 00100: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.8371e-08 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9816\n",
            "Epoch 101/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 6.3710e-08 - accuracy: 1.0000\n",
            "Epoch 00101: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.4018e-08 - accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9817\n",
            "Epoch 102/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 6.2171e-08 - accuracy: 1.0000\n",
            "Epoch 00102: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 6.0558e-08 - accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9816\n",
            "Epoch 103/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 5.5546e-08 - accuracy: 1.0000\n",
            "Epoch 00103: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.5368e-08 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9819\n",
            "Epoch 104/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 5.2004e-08 - accuracy: 1.0000\n",
            "Epoch 00104: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.1868e-08 - accuracy: 1.0000 - val_loss: 0.2195 - val_accuracy: 0.9820\n",
            "Epoch 105/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 4.8862e-08 - accuracy: 1.0000\n",
            "Epoch 00105: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.8205e-08 - accuracy: 1.0000 - val_loss: 0.2205 - val_accuracy: 0.9818\n",
            "Epoch 106/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 4.5657e-08 - accuracy: 1.0000\n",
            "Epoch 00106: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.5518e-08 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9818\n",
            "Epoch 107/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 4.1403e-08 - accuracy: 1.0000\n",
            "Epoch 00107: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 4.2384e-08 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9818\n",
            "Epoch 108/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 3.9754e-08 - accuracy: 1.0000\n",
            "Epoch 00108: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.9148e-08 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9815\n",
            "Epoch 109/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 3.6470e-08 - accuracy: 1.0000\n",
            "Epoch 00109: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.6036e-08 - accuracy: 1.0000 - val_loss: 0.2225 - val_accuracy: 0.9814\n",
            "Epoch 110/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 3.3340e-08 - accuracy: 1.0000\n",
            "Epoch 00110: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.3488e-08 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9817\n",
            "Epoch 111/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 3.0671e-08 - accuracy: 1.0000\n",
            "Epoch 00111: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 3.0984e-08 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9818\n",
            "Epoch 112/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 2.8587e-08 - accuracy: 1.0000\n",
            "Epoch 00112: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.8685e-08 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9817\n",
            "Epoch 113/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 2.6422e-08 - accuracy: 1.0000\n",
            "Epoch 00113: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.6608e-08 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9818\n",
            "Epoch 114/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 2.4431e-08 - accuracy: 1.0000\n",
            "Epoch 00114: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.4592e-08 - accuracy: 1.0000 - val_loss: 0.2262 - val_accuracy: 0.9820\n",
            "Epoch 115/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 2.3179e-08 - accuracy: 1.0000\n",
            "Epoch 00115: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.2781e-08 - accuracy: 1.0000 - val_loss: 0.2269 - val_accuracy: 0.9818\n",
            "Epoch 116/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 2.0680e-08 - accuracy: 1.0000\n",
            "Epoch 00116: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 2.0968e-08 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9818\n",
            "Epoch 117/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 1.9193e-08 - accuracy: 1.0000\n",
            "Epoch 00117: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.9344e-08 - accuracy: 1.0000 - val_loss: 0.2277 - val_accuracy: 0.9819\n",
            "Epoch 118/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 1.7718e-08 - accuracy: 1.0000\n",
            "Epoch 00118: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.7757e-08 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9819\n",
            "Epoch 119/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 1.6335e-08 - accuracy: 1.0000\n",
            "Epoch 00119: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.6299e-08 - accuracy: 1.0000 - val_loss: 0.2296 - val_accuracy: 0.9821\n",
            "Epoch 120/10000\n",
            "174/188 [==========================>...] - ETA: 0s - loss: 1.4837e-08 - accuracy: 1.0000\n",
            "Epoch 00120: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.5018e-08 - accuracy: 1.0000 - val_loss: 0.2305 - val_accuracy: 0.9818\n",
            "Epoch 121/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 1.3935e-08 - accuracy: 1.0000\n",
            "Epoch 00121: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.3928e-08 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 0.9818\n",
            "Epoch 122/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 1.2850e-08 - accuracy: 1.0000\n",
            "Epoch 00122: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.2773e-08 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9818\n",
            "Epoch 123/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 1.1854e-08 - accuracy: 1.0000\n",
            "Epoch 00123: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.1817e-08 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9821\n",
            "Epoch 124/10000\n",
            "173/188 [==========================>...] - ETA: 0s - loss: 1.0678e-08 - accuracy: 1.0000\n",
            "Epoch 00124: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.0816e-08 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9820\n",
            "Epoch 125/10000\n",
            "170/188 [==========================>...] - ETA: 0s - loss: 9.7323e-09 - accuracy: 1.0000\n",
            "Epoch 00125: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.9589e-09 - accuracy: 1.0000 - val_loss: 0.2336 - val_accuracy: 0.9820\n",
            "Epoch 126/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 9.1816e-09 - accuracy: 1.0000\n",
            "Epoch 00126: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.1816e-09 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9821\n",
            "Epoch 127/10000\n",
            "177/188 [===========================>..] - ETA: 0s - loss: 8.3056e-09 - accuracy: 1.0000\n",
            "Epoch 00127: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 8.4142e-09 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9820\n",
            "Epoch 128/10000\n",
            "171/188 [==========================>...] - ETA: 0s - loss: 7.7474e-09 - accuracy: 1.0000\n",
            "Epoch 00128: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.7312e-09 - accuracy: 1.0000 - val_loss: 0.2361 - val_accuracy: 0.9819\n",
            "Epoch 129/10000\n",
            "172/188 [==========================>...] - ETA: 0s - loss: 7.1095e-09 - accuracy: 1.0000\n",
            "Epoch 00129: val_accuracy did not improve from 0.98225\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 7.0656e-09 - accuracy: 1.0000 - val_loss: 0.2371 - val_accuracy: 0.9821\n",
            "Epoch 00129: early stopping\n",
            "Epoch 1/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.3302 - accuracy: 0.8986\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.94492, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.3218 - accuracy: 0.9011 - val_loss: 0.2767 - val_accuracy: 0.9449\n",
            "Epoch 2/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.1071 - accuracy: 0.9674\n",
            "Epoch 00002: val_accuracy improved from 0.94492 to 0.96183, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.1071 - accuracy: 0.9674 - val_loss: 0.1242 - val_accuracy: 0.9618\n",
            "Epoch 3/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0669 - accuracy: 0.9799\n",
            "Epoch 00003: val_accuracy improved from 0.96183 to 0.96617, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0669 - accuracy: 0.9797 - val_loss: 0.1069 - val_accuracy: 0.9662\n",
            "Epoch 4/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0453 - accuracy: 0.9862\n",
            "Epoch 00004: val_accuracy improved from 0.96617 to 0.96967, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0450 - accuracy: 0.9862 - val_loss: 0.0963 - val_accuracy: 0.9697\n",
            "Epoch 5/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9891\n",
            "Epoch 00005: val_accuracy improved from 0.96967 to 0.97267, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0348 - accuracy: 0.9891 - val_loss: 0.0964 - val_accuracy: 0.9727\n",
            "Epoch 6/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9924\n",
            "Epoch 00006: val_accuracy improved from 0.97267 to 0.97333, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 0.0908 - val_accuracy: 0.9733\n",
            "Epoch 7/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9939\n",
            "Epoch 00007: val_accuracy improved from 0.97333 to 0.97400, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.0907 - val_accuracy: 0.9740\n",
            "Epoch 8/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0174 - accuracy: 0.9944\n",
            "Epoch 00008: val_accuracy did not improve from 0.97400\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.1165 - val_accuracy: 0.9707\n",
            "Epoch 9/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9949\n",
            "Epoch 00009: val_accuracy did not improve from 0.97400\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 0.1086 - val_accuracy: 0.9706\n",
            "Epoch 10/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.0175 - accuracy: 0.9939\n",
            "Epoch 00010: val_accuracy did not improve from 0.97400\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0176 - accuracy: 0.9938 - val_loss: 0.1030 - val_accuracy: 0.9726\n",
            "Epoch 11/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9955\n",
            "Epoch 00011: val_accuracy did not improve from 0.97400\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.1020 - val_accuracy: 0.9740\n",
            "Epoch 12/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0144 - accuracy: 0.9952\n",
            "Epoch 00012: val_accuracy did not improve from 0.97400\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0992 - val_accuracy: 0.9739\n",
            "Epoch 13/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9942\n",
            "Epoch 00013: val_accuracy did not improve from 0.97400\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0169 - accuracy: 0.9942 - val_loss: 0.1313 - val_accuracy: 0.9679\n",
            "Epoch 14/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9957\n",
            "Epoch 00014: val_accuracy improved from 0.97400 to 0.97542, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0963 - val_accuracy: 0.9754\n",
            "Epoch 15/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9963\n",
            "Epoch 00015: val_accuracy improved from 0.97542 to 0.97758, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0921 - val_accuracy: 0.9776\n",
            "Epoch 16/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9978\n",
            "Epoch 00016: val_accuracy did not improve from 0.97758\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0951 - val_accuracy: 0.9775\n",
            "Epoch 17/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9977\n",
            "Epoch 00017: val_accuracy did not improve from 0.97758\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.1015 - val_accuracy: 0.9761\n",
            "Epoch 18/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9965\n",
            "Epoch 00018: val_accuracy did not improve from 0.97758\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.1106 - val_accuracy: 0.9756\n",
            "Epoch 19/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9947\n",
            "Epoch 00019: val_accuracy did not improve from 0.97758\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.1059 - val_accuracy: 0.9749\n",
            "Epoch 20/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9970\n",
            "Epoch 00020: val_accuracy did not improve from 0.97758\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.1137 - val_accuracy: 0.9737\n",
            "Epoch 21/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9966\n",
            "Epoch 00021: val_accuracy did not improve from 0.97758\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.1204 - val_accuracy: 0.9728\n",
            "Epoch 22/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9966\n",
            "Epoch 00022: val_accuracy did not improve from 0.97758\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.1022 - val_accuracy: 0.9767\n",
            "Epoch 23/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9980\n",
            "Epoch 00023: val_accuracy improved from 0.97758 to 0.97858, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0985 - val_accuracy: 0.9786\n",
            "Epoch 24/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979\n",
            "Epoch 00024: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0983 - val_accuracy: 0.9768\n",
            "Epoch 25/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0097 - accuracy: 0.9967\n",
            "Epoch 00025: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.0973 - val_accuracy: 0.9771\n",
            "Epoch 26/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9972\n",
            "Epoch 00026: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.1024 - val_accuracy: 0.9764\n",
            "Epoch 27/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0064 - accuracy: 0.9977\n",
            "Epoch 00027: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.1041 - val_accuracy: 0.9780\n",
            "Epoch 28/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9973\n",
            "Epoch 00028: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.1064 - val_accuracy: 0.9766\n",
            "Epoch 29/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0055 - accuracy: 0.9981\n",
            "Epoch 00029: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0999 - val_accuracy: 0.9785\n",
            "Epoch 30/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9962\n",
            "Epoch 00030: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0119 - accuracy: 0.9962 - val_loss: 0.1094 - val_accuracy: 0.9764\n",
            "Epoch 31/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0075 - accuracy: 0.9974\n",
            "Epoch 00031: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0996 - val_accuracy: 0.9783\n",
            "Epoch 32/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 00032: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1128 - val_accuracy: 0.9783\n",
            "Epoch 33/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9988\n",
            "Epoch 00033: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1181 - val_accuracy: 0.9771\n",
            "Epoch 34/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9978\n",
            "Epoch 00034: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.1123 - val_accuracy: 0.9776\n",
            "Epoch 35/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9972\n",
            "Epoch 00035: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.1145 - val_accuracy: 0.9758\n",
            "Epoch 36/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9972\n",
            "Epoch 00036: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.1149 - val_accuracy: 0.9783\n",
            "Epoch 37/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9983\n",
            "Epoch 00037: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1160 - val_accuracy: 0.9773\n",
            "Epoch 38/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0049 - accuracy: 0.9984\n",
            "Epoch 00038: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.1064 - val_accuracy: 0.9783\n",
            "Epoch 39/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9982\n",
            "Epoch 00039: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1240 - val_accuracy: 0.9755\n",
            "Epoch 40/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0048 - accuracy: 0.9984\n",
            "Epoch 00040: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.1151 - val_accuracy: 0.9783\n",
            "Epoch 41/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9978\n",
            "Epoch 00041: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.1134 - val_accuracy: 0.9781\n",
            "Epoch 42/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9985\n",
            "Epoch 00042: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.1131 - val_accuracy: 0.9777\n",
            "Epoch 43/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993\n",
            "Epoch 00043: val_accuracy did not improve from 0.97858\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.1130 - val_accuracy: 0.9780\n",
            "Epoch 44/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988\n",
            "Epoch 00044: val_accuracy improved from 0.97858 to 0.97875, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.1140 - val_accuracy: 0.9787\n",
            "Epoch 45/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989\n",
            "Epoch 00045: val_accuracy improved from 0.97875 to 0.97975, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.1112 - val_accuracy: 0.9797\n",
            "Epoch 46/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9985\n",
            "Epoch 00046: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.1148 - val_accuracy: 0.9791\n",
            "Epoch 47/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9981\n",
            "Epoch 00047: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.1226 - val_accuracy: 0.9780\n",
            "Epoch 48/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9973\n",
            "Epoch 00048: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.1421 - val_accuracy: 0.9745\n",
            "Epoch 49/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9959\n",
            "Epoch 00049: val_accuracy did not improve from 0.97975\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.1094 - val_accuracy: 0.9771\n",
            "Epoch 50/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0052 - accuracy: 0.9984\n",
            "Epoch 00050: val_accuracy improved from 0.97975 to 0.98067, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.1015 - val_accuracy: 0.9807\n",
            "Epoch 51/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
            "Epoch 00051: val_accuracy did not improve from 0.98067\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.1014 - val_accuracy: 0.9803\n",
            "Epoch 52/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
            "Epoch 00052: val_accuracy improved from 0.98067 to 0.98242, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0953 - val_accuracy: 0.9824\n",
            "Epoch 53/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998    \n",
            "Epoch 00053: val_accuracy improved from 0.98242 to 0.98258, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0991 - val_accuracy: 0.9826\n",
            "Epoch 54/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 8.1145e-04 - accuracy: 0.9998\n",
            "Epoch 00054: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 8.1145e-04 - accuracy: 0.9998 - val_loss: 0.1022 - val_accuracy: 0.9822\n",
            "Epoch 55/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
            "Epoch 00055: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1014 - val_accuracy: 0.9814\n",
            "Epoch 56/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 00056: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1266 - val_accuracy: 0.9788\n",
            "Epoch 57/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9971\n",
            "Epoch 00057: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.1177 - val_accuracy: 0.9783\n",
            "Epoch 58/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9965\n",
            "Epoch 00058: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.1242 - val_accuracy: 0.9755\n",
            "Epoch 59/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0066 - accuracy: 0.9976\n",
            "Epoch 00059: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 0.0994 - val_accuracy: 0.9802\n",
            "Epoch 60/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
            "Epoch 00060: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.1005 - val_accuracy: 0.9803\n",
            "Epoch 61/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n",
            "Epoch 00061: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.1087 - val_accuracy: 0.9800\n",
            "Epoch 62/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
            "Epoch 00062: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.1035 - val_accuracy: 0.9800\n",
            "Epoch 63/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9991\n",
            "Epoch 00063: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1152 - val_accuracy: 0.9773\n",
            "Epoch 64/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
            "Epoch 00064: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.1102 - val_accuracy: 0.9782\n",
            "Epoch 65/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9984\n",
            "Epoch 00065: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1280 - val_accuracy: 0.9766\n",
            "Epoch 66/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
            "Epoch 00066: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1301 - val_accuracy: 0.9757\n",
            "Epoch 67/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0049 - accuracy: 0.9983\n",
            "Epoch 00067: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.1154 - val_accuracy: 0.9783\n",
            "Epoch 68/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n",
            "Epoch 00068: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.1127 - val_accuracy: 0.9803\n",
            "Epoch 69/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9995\n",
            "Epoch 00069: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.1115 - val_accuracy: 0.9806\n",
            "Epoch 70/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n",
            "Epoch 00070: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.1069 - val_accuracy: 0.9813\n",
            "Epoch 71/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 9.4269e-04 - accuracy: 0.9997\n",
            "Epoch 00071: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 9.5564e-04 - accuracy: 0.9997 - val_loss: 0.1050 - val_accuracy: 0.9817\n",
            "Epoch 72/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 6.1230e-04 - accuracy: 0.9998\n",
            "Epoch 00072: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 5.8611e-04 - accuracy: 0.9999 - val_loss: 0.1175 - val_accuracy: 0.9812\n",
            "Epoch 73/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992\n",
            "Epoch 00073: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.1201 - val_accuracy: 0.9782\n",
            "Epoch 74/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9976\n",
            "Epoch 00074: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1443 - val_accuracy: 0.9738\n",
            "Epoch 75/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9965\n",
            "Epoch 00075: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.1243 - val_accuracy: 0.9751\n",
            "Epoch 76/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
            "Epoch 00076: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.1095 - val_accuracy: 0.9789\n",
            "Epoch 77/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n",
            "Epoch 00077: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1008 - val_accuracy: 0.9823\n",
            "Epoch 78/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 7.7625e-04 - accuracy: 0.9998\n",
            "Epoch 00078: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 8.0257e-04 - accuracy: 0.9998 - val_loss: 0.1033 - val_accuracy: 0.9823\n",
            "Epoch 79/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n",
            "Epoch 00079: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1032 - val_accuracy: 0.9817\n",
            "Epoch 80/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 7.4872e-04 - accuracy: 0.9998\n",
            "Epoch 00080: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.9459e-04 - accuracy: 0.9998 - val_loss: 0.1081 - val_accuracy: 0.9804\n",
            "Epoch 81/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
            "Epoch 00081: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.1107 - val_accuracy: 0.9791\n",
            "Epoch 82/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
            "Epoch 00082: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.1161 - val_accuracy: 0.9784\n",
            "Epoch 83/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
            "Epoch 00083: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1322 - val_accuracy: 0.9762\n",
            "Epoch 84/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981\n",
            "Epoch 00084: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.1337 - val_accuracy: 0.9754\n",
            "Epoch 85/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9976\n",
            "Epoch 00085: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.1153 - val_accuracy: 0.9792\n",
            "Epoch 86/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9990\n",
            "Epoch 00086: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.1214 - val_accuracy: 0.9782\n",
            "Epoch 87/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n",
            "Epoch 00087: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.1140 - val_accuracy: 0.9788\n",
            "Epoch 88/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9991\n",
            "Epoch 00088: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.1074 - val_accuracy: 0.9809\n",
            "Epoch 89/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n",
            "Epoch 00089: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1130 - val_accuracy: 0.9806\n",
            "Epoch 90/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n",
            "Epoch 00090: val_accuracy did not improve from 0.98258\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.1118 - val_accuracy: 0.9801\n",
            "Epoch 91/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 8.6960e-04 - accuracy: 0.9997\n",
            "Epoch 00091: val_accuracy improved from 0.98258 to 0.98275, saving model to multi_layer_norm_4_hidden_model.h5\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 9.4645e-04 - accuracy: 0.9996 - val_loss: 0.0995 - val_accuracy: 0.9827\n",
            "Epoch 92/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9993\n",
            "Epoch 00092: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.1220 - val_accuracy: 0.9796\n",
            "Epoch 93/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
            "Epoch 00093: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1157 - val_accuracy: 0.9809\n",
            "Epoch 94/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994\n",
            "Epoch 00094: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.1315 - val_accuracy: 0.9773\n",
            "Epoch 95/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9986\n",
            "Epoch 00095: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1184 - val_accuracy: 0.9804\n",
            "Epoch 96/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9981\n",
            "Epoch 00096: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.1198 - val_accuracy: 0.9779\n",
            "Epoch 97/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9985\n",
            "Epoch 00097: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.1092 - val_accuracy: 0.9813\n",
            "Epoch 98/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n",
            "Epoch 00098: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0986 - val_accuracy: 0.9826\n",
            "Epoch 99/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\n",
            "Epoch 00099: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.1063 - val_accuracy: 0.9815\n",
            "Epoch 100/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n",
            "Epoch 00100: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.1062 - val_accuracy: 0.9822\n",
            "Epoch 101/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
            "Epoch 00101: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.1104 - val_accuracy: 0.9803\n",
            "Epoch 102/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\n",
            "Epoch 00102: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.1108 - val_accuracy: 0.9798\n",
            "Epoch 103/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
            "Epoch 00103: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1205 - val_accuracy: 0.9792\n",
            "Epoch 104/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9989\n",
            "Epoch 00104: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.1220 - val_accuracy: 0.9790\n",
            "Epoch 105/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n",
            "Epoch 00105: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1114 - val_accuracy: 0.9813\n",
            "Epoch 106/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9995\n",
            "Epoch 00106: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1140 - val_accuracy: 0.9811\n",
            "Epoch 107/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n",
            "Epoch 00107: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1192 - val_accuracy: 0.9797\n",
            "Epoch 108/10000\n",
            "180/188 [===========================>..] - ETA: 0s - loss: 9.1892e-04 - accuracy: 0.9998\n",
            "Epoch 00108: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.1089 - val_accuracy: 0.9818\n",
            "Epoch 109/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
            "Epoch 00109: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.1126 - val_accuracy: 0.9804\n",
            "Epoch 110/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n",
            "Epoch 00110: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1348 - val_accuracy: 0.9784\n",
            "Epoch 111/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9983\n",
            "Epoch 00111: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.1293 - val_accuracy: 0.9790\n",
            "Epoch 112/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9991\n",
            "Epoch 00112: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1105 - val_accuracy: 0.9806\n",
            "Epoch 113/10000\n",
            "185/188 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
            "Epoch 00113: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.1092 - val_accuracy: 0.9818\n",
            "Epoch 114/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
            "Epoch 00114: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.1276 - val_accuracy: 0.9784\n",
            "Epoch 115/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n",
            "Epoch 00115: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.1146 - val_accuracy: 0.9810\n",
            "Epoch 116/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
            "Epoch 00116: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.1023 - val_accuracy: 0.9821\n",
            "Epoch 117/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 9.8696e-04 - accuracy: 0.9996\n",
            "Epoch 00117: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 9.7202e-04 - accuracy: 0.9996 - val_loss: 0.1241 - val_accuracy: 0.9797\n",
            "Epoch 118/10000\n",
            "182/188 [============================>.] - ETA: 0s - loss: 8.1236e-04 - accuracy: 0.9998\n",
            "Epoch 00118: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 8.8921e-04 - accuracy: 0.9998 - val_loss: 0.1121 - val_accuracy: 0.9819\n",
            "Epoch 119/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\n",
            "Epoch 00119: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.1320 - val_accuracy: 0.9783\n",
            "Epoch 120/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0037 - accuracy: 0.9989\n",
            "Epoch 00120: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.1092 - val_accuracy: 0.9804\n",
            "Epoch 121/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
            "Epoch 00121: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.1240 - val_accuracy: 0.9793\n",
            "Epoch 122/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n",
            "Epoch 00122: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1120 - val_accuracy: 0.9797\n",
            "Epoch 123/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 7.8854e-04 - accuracy: 0.9997\n",
            "Epoch 00123: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 8.0386e-04 - accuracy: 0.9997 - val_loss: 0.1114 - val_accuracy: 0.9816\n",
            "Epoch 124/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 7.1673e-04 - accuracy: 0.9997\n",
            "Epoch 00124: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 6.9862e-04 - accuracy: 0.9998 - val_loss: 0.1117 - val_accuracy: 0.9825\n",
            "Epoch 125/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 2.6212e-04 - accuracy: 0.9999\n",
            "Epoch 00125: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.6352e-04 - accuracy: 0.9999 - val_loss: 0.1043 - val_accuracy: 0.9827\n",
            "Epoch 126/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 3.4042e-04 - accuracy: 0.9999\n",
            "Epoch 00126: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.4563e-04 - accuracy: 0.9999 - val_loss: 0.1113 - val_accuracy: 0.9822\n",
            "Epoch 127/10000\n",
            "183/188 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 00127: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.1181 - val_accuracy: 0.9816\n",
            "Epoch 128/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9987\n",
            "Epoch 00128: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1446 - val_accuracy: 0.9777\n",
            "Epoch 129/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0053 - accuracy: 0.9982\n",
            "Epoch 00129: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.1300 - val_accuracy: 0.9786\n",
            "Epoch 130/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9987\n",
            "Epoch 00130: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 0.1225 - val_accuracy: 0.9807\n",
            "Epoch 131/10000\n",
            "179/188 [===========================>..] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
            "Epoch 00131: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1312 - val_accuracy: 0.9791\n",
            "Epoch 132/10000\n",
            "181/188 [===========================>..] - ETA: 0s - loss: 8.7584e-04 - accuracy: 0.9997\n",
            "Epoch 00132: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 8.5510e-04 - accuracy: 0.9998 - val_loss: 0.1108 - val_accuracy: 0.9825\n",
            "Epoch 133/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 7.4714e-04 - accuracy: 0.9997\n",
            "Epoch 00133: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.4528e-04 - accuracy: 0.9997 - val_loss: 0.1091 - val_accuracy: 0.9825\n",
            "Epoch 134/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 4.0714e-04 - accuracy: 0.9999\n",
            "Epoch 00134: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 4.0613e-04 - accuracy: 0.9999 - val_loss: 0.1151 - val_accuracy: 0.9818\n",
            "Epoch 135/10000\n",
            "184/188 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
            "Epoch 00135: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.1216 - val_accuracy: 0.9815\n",
            "Epoch 136/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 00136: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1157 - val_accuracy: 0.9810\n",
            "Epoch 137/10000\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 00137: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.1139 - val_accuracy: 0.9821\n",
            "Epoch 138/10000\n",
            "178/188 [===========================>..] - ETA: 0s - loss: 0.0033 - accuracy: 0.9991\n",
            "Epoch 00138: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.1764 - val_accuracy: 0.9724\n",
            "Epoch 139/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9982\n",
            "Epoch 00139: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.1148 - val_accuracy: 0.9803\n",
            "Epoch 140/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
            "Epoch 00140: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.1151 - val_accuracy: 0.9807\n",
            "Epoch 141/10000\n",
            "186/188 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 00141: val_accuracy did not improve from 0.98275\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.1144 - val_accuracy: 0.9821\n",
            "Epoch 00141: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IQQzcDdaPAbI"
      },
      "source": [
        "and draw the plots:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ItP5c_2BPAbJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "73fa12d2-fda9-41d0-8c7b-bc101ba23232"
      },
      "source": [
        "  fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "  loss_ax.set_title('Loss')\n",
        "  loss_ax.plot(multi_layer_norm_4_hidden_train.history['loss'], '-r', label='Train norm')\n",
        "  loss_ax.plot(multi_layer_norm_4_hidden_train.history['val_loss'], '-g', label='Validation norm')\n",
        "  loss_ax.plot(multi_layer_4_hidden_train.history['loss'], '-b', label='Train 4')\n",
        "  loss_ax.plot(multi_layer_4_hidden_train.history['val_loss'], '-y', label='Validation 4')\n",
        "\n",
        "  acc_ax.set_title('Accuracy')\n",
        "  acc_ax.plot(multi_layer_norm_4_hidden_train.history['accuracy'], '-r', label='Train norm')\n",
        "  acc_ax.plot(multi_layer_norm_4_hidden_train.history['val_accuracy'], '-g', label='Validation norm')\n",
        "  acc_ax.plot(multi_layer_4_hidden_train.history['accuracy'], '-b', label='Train 4')\n",
        "  acc_ax.plot(multi_layer_4_hidden_train.history['val_accuracy'], '-y', label='Validation 4')\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D5LlQGobPAbK"
      },
      "source": [
        "Looking at the plots it appears normalization did harm convergence, but slightly increased the speed at wich the highest accuracy value is reached, as well as the value itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e1RU1-S8PAbK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "56193f1c-ede0-48e7-c05f-89960374c978"
      },
      "source": [
        "multi_layer_4_hidden_model.load_weights('multi_layer_4_hidden_model.h5')\n",
        "multi_layer_norm_4_hidden_model.load_weights('multi_layer_norm_4_hidden_model.h5')\n",
        "loss, acc4 = multi_layer_4_hidden_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "loss, acc4norm = multi_layer_norm_4_hidden_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for baseline: {}, Accuracy for normalized: {}'.format(acc4, acc4norm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1654 - accuracy: 0.9815\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9837\n",
            "Accuracy for baseline: 0.9815000295639038, Accuracy for normalized: 0.9836999773979187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xScB4ma_PAbM"
      },
      "source": [
        "Just like the validate accuracy, here the normalized did outperform the baseline, reaching 98.4% wich will be our reference going forward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13tVOFWonpZa",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Neural Networks\n",
        "\n",
        "We're now moving on to CNN's, wich we expect to overperform the previous, since the data is composed of pictures. For now, we will consider a single hidden layer with size 128, wich by our tests already performs quite well, while also speeding up the next tests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRphQLawFxAr",
        "colab_type": "text"
      },
      "source": [
        "#### Single Convolutional Layer\n",
        "\n",
        "We will start by testing a single convolutional layer. First we will consider a fixed number of filters, in order to test the impact of the kernel size:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-G0qveY9s_uM",
        "colab": {}
      },
      "source": [
        "def create_single_convolutional_model(filters, kernel_size, name='single_convolutional_model'):\n",
        "  multi_layer_model = tf.keras.Sequential(name=name)\n",
        "  multi_layer_model.add(tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same', name='convolution_{}_{}'.format(filters, kernel_size), input_shape=mnist_info.features['image'].shape))\n",
        "  multi_layer_model.add(tf.keras.layers.MaxPool2D())\n",
        "  multi_layer_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "  multi_layer_model.add(tf.keras.layers.Dense(128, activation='relu', name='hidden'))\n",
        "  multi_layer_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "\n",
        "  multi_layer_model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "  multi_layer_model.summary()\n",
        "  return multi_layer_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAmdVR0xw_FP",
        "colab_type": "text"
      },
      "source": [
        "64 filters is a good start, but generates a lot of params so we will have to sacrifice testing validity here and consider a single test per parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jS38vIibs_uP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f9f1508-457b-4817-a9c4-8c58d90e0822"
      },
      "source": [
        "kernel_sizes = (2, 3, 4, 5, 6, 7, 8, 9)\n",
        "accuracy_lines = test_model_parameter(lambda x: create_single_convolutional_model(64, x), kernel_sizes, 50, tests=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_2 (Conv2D)    (None, 28, 28, 64)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               1605760   \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,607,370\n",
            "Trainable params: 1,607,370\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.3262 - accuracy: 0.9099 - val_loss: 0.1665 - val_accuracy: 0.9554\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.1191 - accuracy: 0.9656 - val_loss: 0.1054 - val_accuracy: 0.9690\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0771 - accuracy: 0.9771 - val_loss: 0.0853 - val_accuracy: 0.9743\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0585 - accuracy: 0.9831 - val_loss: 0.0701 - val_accuracy: 0.9804\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0456 - accuracy: 0.9865 - val_loss: 0.0629 - val_accuracy: 0.9805\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0357 - accuracy: 0.9898 - val_loss: 0.0637 - val_accuracy: 0.9805\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0287 - accuracy: 0.9916 - val_loss: 0.0597 - val_accuracy: 0.9814\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0236 - accuracy: 0.9934 - val_loss: 0.0635 - val_accuracy: 0.9804\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 0.0573 - val_accuracy: 0.9827\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 0.0595 - val_accuracy: 0.9833\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.0704 - val_accuracy: 0.9792\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.0561 - val_accuracy: 0.9838\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.0650 - val_accuracy: 0.9826\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0611 - val_accuracy: 0.9842\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0664 - val_accuracy: 0.9829\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.0661 - val_accuracy: 0.9822\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.0681 - val_accuracy: 0.9833\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0731 - val_accuracy: 0.9822\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0794 - val_accuracy: 0.9817\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0767 - val_accuracy: 0.9815\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0708 - val_accuracy: 0.9835\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0744 - val_accuracy: 0.9837\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 8.3825e-04 - accuracy: 0.9999 - val_loss: 0.0679 - val_accuracy: 0.9851\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.6442e-04 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9849\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.7198e-04 - accuracy: 1.0000 - val_loss: 0.0718 - val_accuracy: 0.9850\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.3632e-04 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9850\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.0155e-04 - accuracy: 1.0000 - val_loss: 0.0731 - val_accuracy: 0.9850\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.7295e-04 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 0.9850\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.5726e-04 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9851\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.4424e-04 - accuracy: 1.0000 - val_loss: 0.0761 - val_accuracy: 0.9846\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.2729e-04 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9851\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.1328e-04 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9849\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.0309e-04 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9847\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 9.3604e-05 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9846\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 8.1594e-05 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9848\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.4692e-05 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9845\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.0208e-05 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9852\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 6.0265e-05 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9847\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 5.5858e-05 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9850\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 4.9874e-05 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9846\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 4.5716e-05 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9847\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 4.3456e-05 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9846\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.7335e-05 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9845\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.2982e-05 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9849\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.0241e-05 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9844\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.7377e-05 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9839\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.4630e-05 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9846\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.2372e-05 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9848\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.9265e-05 - accuracy: 1.0000 - val_loss: 0.0921 - val_accuracy: 0.9847\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.8032e-05 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9844\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_3 (Conv2D)    (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               1605760   \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,607,690\n",
            "Trainable params: 1,607,690\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.2956 - accuracy: 0.9163 - val_loss: 0.1153 - val_accuracy: 0.9691\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0885 - accuracy: 0.9747 - val_loss: 0.0812 - val_accuracy: 0.9750\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0568 - accuracy: 0.9836 - val_loss: 0.0705 - val_accuracy: 0.9788\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0424 - accuracy: 0.9876 - val_loss: 0.0574 - val_accuracy: 0.9831\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0320 - accuracy: 0.9906 - val_loss: 0.0508 - val_accuracy: 0.9845\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0256 - accuracy: 0.9925 - val_loss: 0.0516 - val_accuracy: 0.9849\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 0.0522 - val_accuracy: 0.9856\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.0473 - val_accuracy: 0.9873\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0131 - accuracy: 0.9966 - val_loss: 0.0469 - val_accuracy: 0.9868\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0096 - accuracy: 0.9975 - val_loss: 0.0607 - val_accuracy: 0.9828\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.0540 - val_accuracy: 0.9867\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.0550 - val_accuracy: 0.9868\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 0.0537 - val_accuracy: 0.9862\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0572 - val_accuracy: 0.9862\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0533 - val_accuracy: 0.9869\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0605 - val_accuracy: 0.9860\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0657 - val_accuracy: 0.9843\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0646 - val_accuracy: 0.9842\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0596 - val_accuracy: 0.9860\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0640 - val_accuracy: 0.9855\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0631 - val_accuracy: 0.9862\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 9.3525e-04 - accuracy: 0.9999 - val_loss: 0.0587 - val_accuracy: 0.9877\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 4.3474e-04 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9877\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.1945e-04 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 0.9884\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.5361e-04 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9883\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.2608e-04 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 0.9883\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.0897e-04 - accuracy: 1.0000 - val_loss: 0.0617 - val_accuracy: 0.9888\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 9.7716e-05 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 0.9886\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 8.6429e-05 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9883\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.5715e-05 - accuracy: 1.0000 - val_loss: 0.0637 - val_accuracy: 0.9883\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 6.9426e-05 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9884\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 6.1505e-05 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 0.9882\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 5.6146e-05 - accuracy: 1.0000 - val_loss: 0.0659 - val_accuracy: 0.9882\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 5.1155e-05 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9887\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 4.5160e-05 - accuracy: 1.0000 - val_loss: 0.0672 - val_accuracy: 0.9884\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 4.0487e-05 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9882\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.7447e-05 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9885\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.3306e-05 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9882\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.0114e-05 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9881\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.7472e-05 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9877\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.4830e-05 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9883\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.2027e-05 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9887\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.0338e-05 - accuracy: 1.0000 - val_loss: 0.0722 - val_accuracy: 0.9884\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.8434e-05 - accuracy: 1.0000 - val_loss: 0.0722 - val_accuracy: 0.9885\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.6487e-05 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9885\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.5360e-05 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9881\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.3645e-05 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9885\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.3040e-05 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 0.9883\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.1120e-05 - accuracy: 1.0000 - val_loss: 0.0762 - val_accuracy: 0.9884\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.0365e-05 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9884\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_4 (Conv2D)    (None, 28, 28, 64)        1088      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               1605760   \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,608,138\n",
            "Trainable params: 1,608,138\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.2569 - accuracy: 0.9274 - val_loss: 0.0905 - val_accuracy: 0.9747\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0702 - accuracy: 0.9796 - val_loss: 0.0658 - val_accuracy: 0.9808\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0474 - accuracy: 0.9859 - val_loss: 0.0538 - val_accuracy: 0.9841\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0360 - accuracy: 0.9893 - val_loss: 0.0467 - val_accuracy: 0.9860\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0266 - accuracy: 0.9919 - val_loss: 0.0455 - val_accuracy: 0.9872\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0228 - accuracy: 0.9932 - val_loss: 0.0557 - val_accuracy: 0.9826\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 0.0450 - val_accuracy: 0.9863\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0126 - accuracy: 0.9965 - val_loss: 0.0455 - val_accuracy: 0.9872\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.0451 - val_accuracy: 0.9872\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0424 - val_accuracy: 0.9887\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0456 - val_accuracy: 0.9878\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0470 - val_accuracy: 0.9880\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0461 - val_accuracy: 0.9882\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0467 - val_accuracy: 0.9874\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0460 - val_accuracy: 0.9887\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0494 - val_accuracy: 0.9880\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0538 - val_accuracy: 0.9874\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0654 - val_accuracy: 0.9847\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.0637 - val_accuracy: 0.9854\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.0548 - val_accuracy: 0.9872\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0571 - val_accuracy: 0.9869\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0569 - val_accuracy: 0.9880\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0585 - val_accuracy: 0.9879\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0529 - val_accuracy: 0.9891\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.8789e-04 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9902\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.0146e-04 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9902\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.9771e-05 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9902\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 6.7911e-05 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9901\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 5.9026e-05 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9902\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 5.0805e-05 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 4.4966e-05 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 0.9902\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 4.0479e-05 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 0.9900\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.6689e-05 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 0.9902\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.3131e-05 - accuracy: 1.0000 - val_loss: 0.0568 - val_accuracy: 0.9902\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.1941e-05 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 0.9903\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.6722e-05 - accuracy: 1.0000 - val_loss: 0.0577 - val_accuracy: 0.9902\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.4149e-05 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 0.9903\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.2230e-05 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9902\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.0265e-05 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9902\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.8627e-05 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 0.9902\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.6838e-05 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9900\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.5657e-05 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 0.9902\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.4149e-05 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 0.9902\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.2784e-05 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9905\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.1777e-05 - accuracy: 1.0000 - val_loss: 0.0619 - val_accuracy: 0.9903\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.0947e-05 - accuracy: 1.0000 - val_loss: 0.0619 - val_accuracy: 0.9904\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 9.8093e-06 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 0.9904\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 8.9468e-06 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 0.9905\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 8.1459e-06 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 0.9905\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.6410e-06 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9902\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_5 (Conv2D)    (None, 28, 28, 64)        1664      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               1605760   \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,608,714\n",
            "Trainable params: 1,608,714\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.2590 - accuracy: 0.9250 - val_loss: 0.0956 - val_accuracy: 0.9719\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0712 - accuracy: 0.9791 - val_loss: 0.0616 - val_accuracy: 0.9814\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0485 - accuracy: 0.9854 - val_loss: 0.0523 - val_accuracy: 0.9853\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0364 - accuracy: 0.9888 - val_loss: 0.0555 - val_accuracy: 0.9830\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0278 - accuracy: 0.9918 - val_loss: 0.0463 - val_accuracy: 0.9862\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 0.0452 - val_accuracy: 0.9871\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0472 - val_accuracy: 0.9867\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.0465 - val_accuracy: 0.9860\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.0430 - val_accuracy: 0.9878\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.0521 - val_accuracy: 0.9847\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0473 - val_accuracy: 0.9870\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0518 - val_accuracy: 0.9870\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0445 - val_accuracy: 0.9887\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0453 - val_accuracy: 0.9894\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0474 - val_accuracy: 0.9891\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0531 - val_accuracy: 0.9870\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0583 - val_accuracy: 0.9861\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0654 - val_accuracy: 0.9837\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.0565 - val_accuracy: 0.9877\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0521 - val_accuracy: 0.9880\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0495 - val_accuracy: 0.9895\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 6.3233e-04 - accuracy: 0.9999 - val_loss: 0.0466 - val_accuracy: 0.9908\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.6597e-04 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9902\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.0926e-04 - accuracy: 1.0000 - val_loss: 0.0490 - val_accuracy: 0.9903\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 8.8650e-05 - accuracy: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9905\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.7164e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9902\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 6.7743e-05 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9905\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 6.0094e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9902\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 5.5841e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9900\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 4.8635e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9902\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 4.3578e-05 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9902\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.9714e-05 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9899\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.6765e-05 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 0.9901\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.2636e-05 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 0.9901\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.0506e-05 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 0.9901\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.7192e-05 - accuracy: 1.0000 - val_loss: 0.0558 - val_accuracy: 0.9902\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.4295e-05 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 0.9900\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.2520e-05 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9901\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.9864e-05 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 0.9900\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.8609e-05 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 0.9900\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.6738e-05 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 0.9898\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.5474e-05 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 0.9900\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.3770e-05 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9898\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.2556e-05 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9899\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.1348e-05 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 0.9895\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.0741e-05 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 0.9901\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 9.6891e-06 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 0.9898\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 8.5012e-06 - accuracy: 1.0000 - val_loss: 0.0618 - val_accuracy: 0.9896\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.8128e-06 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 0.9899\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.0350e-06 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 0.9899\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_6 (Conv2D)    (None, 28, 28, 64)        2368      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               1605760   \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,609,418\n",
            "Trainable params: 1,609,418\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.2515 - accuracy: 0.9282 - val_loss: 0.0984 - val_accuracy: 0.9711\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0675 - accuracy: 0.9805 - val_loss: 0.0626 - val_accuracy: 0.9803\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0471 - accuracy: 0.9856 - val_loss: 0.0536 - val_accuracy: 0.9827\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0345 - accuracy: 0.9899 - val_loss: 0.0501 - val_accuracy: 0.9845\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0257 - accuracy: 0.9924 - val_loss: 0.0492 - val_accuracy: 0.9837\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0214 - accuracy: 0.9936 - val_loss: 0.0432 - val_accuracy: 0.9865\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.0442 - val_accuracy: 0.9863\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.0424 - val_accuracy: 0.9874\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.0457 - val_accuracy: 0.9875\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0400 - val_accuracy: 0.9881\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0473 - val_accuracy: 0.9879\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0456 - val_accuracy: 0.9872\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0462 - val_accuracy: 0.9874\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0425 - val_accuracy: 0.9881\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0479 - val_accuracy: 0.9877\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0483 - val_accuracy: 0.9883\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0534 - val_accuracy: 0.9872\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.0551 - val_accuracy: 0.9862\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0500 - val_accuracy: 0.9876\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0494 - val_accuracy: 0.9885\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.2519e-04 - accuracy: 0.9999 - val_loss: 0.0458 - val_accuracy: 0.9894\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.0079e-04 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9896\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.1842e-04 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9896\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 9.0841e-05 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9897\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.4868e-05 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9897\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 6.6643e-05 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9899\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 5.6853e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9899\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 5.0233e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9898\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 4.4412e-05 - accuracy: 1.0000 - val_loss: 0.0527 - val_accuracy: 0.9899\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.9670e-05 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9898\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.6812e-05 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9898\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.3141e-05 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.9322e-05 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9898\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.6766e-05 - accuracy: 1.0000 - val_loss: 0.0554 - val_accuracy: 0.9898\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.4113e-05 - accuracy: 1.0000 - val_loss: 0.0560 - val_accuracy: 0.9898\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.1855e-05 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9898\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.9656e-05 - accuracy: 1.0000 - val_loss: 0.0568 - val_accuracy: 0.9897\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.8070e-05 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9897\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.5843e-05 - accuracy: 1.0000 - val_loss: 0.0579 - val_accuracy: 0.9897\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.4913e-05 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 0.9897\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.3080e-05 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9897\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.1818e-05 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9898\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.0794e-05 - accuracy: 1.0000 - val_loss: 0.0603 - val_accuracy: 0.9896\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 9.7705e-06 - accuracy: 1.0000 - val_loss: 0.0608 - val_accuracy: 0.9897\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 8.9095e-06 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 0.9899\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 8.0029e-06 - accuracy: 1.0000 - val_loss: 0.0617 - val_accuracy: 0.9896\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.3252e-06 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 0.9899\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 6.5409e-06 - accuracy: 1.0000 - val_loss: 0.0622 - val_accuracy: 0.9898\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 5.9110e-06 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 0.9894\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 5.3671e-06 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 0.9897\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               1605760   \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,610,250\n",
            "Trainable params: 1,610,250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.2531 - accuracy: 0.9266 - val_loss: 0.0916 - val_accuracy: 0.9747\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0678 - accuracy: 0.9799 - val_loss: 0.0637 - val_accuracy: 0.9812\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0450 - accuracy: 0.9868 - val_loss: 0.0511 - val_accuracy: 0.9850\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0335 - accuracy: 0.9898 - val_loss: 0.0442 - val_accuracy: 0.9862\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0261 - accuracy: 0.9919 - val_loss: 0.0394 - val_accuracy: 0.9871\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 0.0501 - val_accuracy: 0.9852\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.0397 - val_accuracy: 0.9874\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.0376 - val_accuracy: 0.9876\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0395 - val_accuracy: 0.9881\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0415 - val_accuracy: 0.9879\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.0437 - val_accuracy: 0.9877\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0468 - val_accuracy: 0.9868\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0419 - val_accuracy: 0.9887\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0507 - val_accuracy: 0.9869\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.0462 - val_accuracy: 0.9883\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0438 - val_accuracy: 0.9892\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0450 - val_accuracy: 0.9893\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0454 - val_accuracy: 0.9892\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0459 - val_accuracy: 0.9893\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0526 - val_accuracy: 0.9881\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.6857e-04 - accuracy: 0.9998 - val_loss: 0.0448 - val_accuracy: 0.9905\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.6302e-04 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9908\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.0461e-04 - accuracy: 1.0000 - val_loss: 0.0450 - val_accuracy: 0.9909\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 7.6492e-05 - accuracy: 1.0000 - val_loss: 0.0459 - val_accuracy: 0.9909\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 5.9684e-05 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9911\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 5.7591e-05 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9911\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 4.8883e-05 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9912\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 4.1353e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9911\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.8495e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9909\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.2925e-05 - accuracy: 1.0000 - val_loss: 0.0480 - val_accuracy: 0.9910\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.1137e-05 - accuracy: 1.0000 - val_loss: 0.0488 - val_accuracy: 0.9910\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.7132e-05 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9910\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.6988e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9912\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.2321e-05 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9909\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.1287e-05 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9909\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.8985e-05 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9909\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.7100e-05 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9909\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.5727e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9909\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.4730e-05 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9911\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.3468e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9908\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.1859e-05 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9908\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.0862e-05 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9909\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 9.9097e-06 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 0.9908\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 8.8328e-06 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9912\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 8.4382e-06 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 0.9909\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.6862e-06 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9908\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 6.8134e-06 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9910\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 6.7070e-06 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 0.9910\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 5.6101e-06 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 0.9910\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 5.0988e-06 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 0.9908\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_8 (Conv2D)    (None, 28, 28, 64)        4160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               1605760   \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,611,210\n",
            "Trainable params: 1,611,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.2451 - accuracy: 0.9281 - val_loss: 0.0948 - val_accuracy: 0.9721\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0659 - accuracy: 0.9805 - val_loss: 0.0689 - val_accuracy: 0.9799\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0437 - accuracy: 0.9866 - val_loss: 0.0500 - val_accuracy: 0.9836\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 0.0429 - val_accuracy: 0.9868\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0246 - accuracy: 0.9926 - val_loss: 0.0412 - val_accuracy: 0.9882\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 0.0381 - val_accuracy: 0.9896\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.0378 - val_accuracy: 0.9887\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.0453 - val_accuracy: 0.9867\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.0474 - val_accuracy: 0.9868\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0472 - val_accuracy: 0.9870\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0447 - val_accuracy: 0.9887\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0416 - val_accuracy: 0.9890\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0466 - val_accuracy: 0.9871\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0477 - val_accuracy: 0.9881\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0459 - val_accuracy: 0.9886\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0603 - val_accuracy: 0.9844\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.0472 - val_accuracy: 0.9893\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0546 - val_accuracy: 0.9885\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0578 - val_accuracy: 0.9887\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0506 - val_accuracy: 0.9883\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0453 - val_accuracy: 0.9900\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0531 - val_accuracy: 0.9884\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0525 - val_accuracy: 0.9877\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0546 - val_accuracy: 0.9886\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0506 - val_accuracy: 0.9893\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0532 - val_accuracy: 0.9890\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0500 - val_accuracy: 0.9899\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 5.9861e-04 - accuracy: 0.9998 - val_loss: 0.0498 - val_accuracy: 0.9903\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.4634e-04 - accuracy: 0.9999 - val_loss: 0.0546 - val_accuracy: 0.9896\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.8472e-04 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9902\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.2097e-05 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9908\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.3332e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9907\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.9223e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9907\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.6727e-05 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9907\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.4528e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9908\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.2898e-05 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9908\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.1379e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9908\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.0063e-05 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9907\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 9.1090e-06 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9908\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 8.3382e-06 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9908\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.5613e-06 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9908\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 6.8136e-06 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9908\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 6.1947e-06 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9908\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 5.6514e-06 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9908\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 5.1912e-06 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 0.9908\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 4.7613e-06 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9909\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 4.3561e-06 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 0.9908\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.9701e-06 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 0.9908\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.6537e-06 - accuracy: 1.0000 - val_loss: 0.0569 - val_accuracy: 0.9909\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.3476e-06 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 0.9908\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_9 (Conv2D)    (None, 28, 28, 64)        5248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               1605760   \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,612,298\n",
            "Trainable params: 1,612,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 0.2478 - accuracy: 0.9287 - val_loss: 0.0833 - val_accuracy: 0.9750\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0658 - accuracy: 0.9806 - val_loss: 0.0631 - val_accuracy: 0.9787\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9867 - val_loss: 0.0490 - val_accuracy: 0.9847\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0328 - accuracy: 0.9900 - val_loss: 0.0447 - val_accuracy: 0.9862\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0244 - accuracy: 0.9923 - val_loss: 0.0456 - val_accuracy: 0.9867\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 0.0407 - val_accuracy: 0.9869\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.0386 - val_accuracy: 0.9881\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.0403 - val_accuracy: 0.9895\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.0428 - val_accuracy: 0.9883\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0423 - val_accuracy: 0.9877\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0425 - val_accuracy: 0.9890\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0464 - val_accuracy: 0.9871\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0553 - val_accuracy: 0.9869\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0066 - accuracy: 0.9975 - val_loss: 0.0496 - val_accuracy: 0.9871\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0888 - val_accuracy: 0.9781\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0505 - val_accuracy: 0.9873\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0437 - val_accuracy: 0.9900\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0431 - val_accuracy: 0.9907\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0474 - val_accuracy: 0.9898\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0452 - val_accuracy: 0.9895\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0490 - val_accuracy: 0.9898\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0513 - val_accuracy: 0.9899\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.0505 - val_accuracy: 0.9876\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0538 - val_accuracy: 0.9884\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0578 - val_accuracy: 0.9883\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0565 - val_accuracy: 0.9885\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 6.6901e-04 - accuracy: 0.9998 - val_loss: 0.0522 - val_accuracy: 0.9894\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0528 - val_accuracy: 0.9896\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0661 - val_accuracy: 0.9866\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0635 - val_accuracy: 0.9871\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0590 - val_accuracy: 0.9883\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0573 - val_accuracy: 0.9884\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0552 - val_accuracy: 0.9881\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.9984e-04 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9911\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 9.8848e-05 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9912\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.3803e-05 - accuracy: 1.0000 - val_loss: 0.0501 - val_accuracy: 0.9907\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.7195e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9907\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.4056e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9908\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.1910e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9907\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.0321e-05 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9906\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 9.0546e-06 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9906\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 7.9941e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9905\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 7.1312e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9906\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 6.3998e-06 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9906\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 5.7794e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9906\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 5.2244e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9908\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 4.7442e-06 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 0.9908\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 4.3183e-06 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9908\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.9299e-06 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 0.9908\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.5784e-06 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Us81Hn-Js_uR"
      },
      "source": [
        "With the accuracy values retrieved, we plot the graph:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Eg3WLbCzs_uR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "39ce5f00-644d-4724-880c-4eddc7e0bb86"
      },
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "multiple_line_chart(plt.gca(), \n",
        "                    None, \n",
        "                    accuracy_lines, \n",
        "                    \"Validation accuracy variation per kernel_size of the convolutional layer\", \n",
        "                    \"Epochs\", \n",
        "                    \"Validation accuracy\")\n",
        "plt.show()\n",
        "plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6p6kR3d4s_uT"
      },
      "source": [
        "From the graph we can see that a kernel_size of 7 is a good fit for this dataset, reaching the highest value and converging early. Let us now try to find if we can reduce the numbers of filters, since it has huge impact on performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "scPEEwWnFxxl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8857253-b2fa-4f91-e6e8-f48cccce4976"
      },
      "source": [
        "filters = (16, 32, 64, 128, 256)\n",
        "accuracy_lines = test_model_parameter(lambda x: create_single_convolutional_model(x, 7), filters, 35, tests=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_16_7 (Conv2D)    (None, 28, 28, 16)        800       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               401536    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 403,626\n",
            "Trainable params: 403,626\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.3420 - accuracy: 0.9044 - val_loss: 0.1475 - val_accuracy: 0.9580\n",
            "Epoch 2/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1053 - accuracy: 0.9687 - val_loss: 0.0979 - val_accuracy: 0.9711\n",
            "Epoch 3/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0672 - accuracy: 0.9800 - val_loss: 0.0678 - val_accuracy: 0.9795\n",
            "Epoch 4/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0502 - accuracy: 0.9858 - val_loss: 0.0628 - val_accuracy: 0.9799\n",
            "Epoch 5/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0407 - accuracy: 0.9882 - val_loss: 0.0530 - val_accuracy: 0.9833\n",
            "Epoch 6/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9899 - val_loss: 0.0500 - val_accuracy: 0.9847\n",
            "Epoch 7/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0285 - accuracy: 0.9913 - val_loss: 0.0448 - val_accuracy: 0.9858\n",
            "Epoch 8/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 0.0421 - val_accuracy: 0.9871\n",
            "Epoch 9/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0196 - accuracy: 0.9941 - val_loss: 0.0440 - val_accuracy: 0.9863\n",
            "Epoch 10/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.0383 - val_accuracy: 0.9883\n",
            "Epoch 11/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.0422 - val_accuracy: 0.9862\n",
            "Epoch 12/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9970 - val_loss: 0.0429 - val_accuracy: 0.9856\n",
            "Epoch 13/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.0423 - val_accuracy: 0.9861\n",
            "Epoch 14/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9977 - val_loss: 0.0468 - val_accuracy: 0.9873\n",
            "Epoch 15/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.0404 - val_accuracy: 0.9880\n",
            "Epoch 16/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0455 - val_accuracy: 0.9877\n",
            "Epoch 17/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0461 - val_accuracy: 0.9869\n",
            "Epoch 18/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0459 - val_accuracy: 0.9873\n",
            "Epoch 19/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0460 - val_accuracy: 0.9875\n",
            "Epoch 20/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0446 - val_accuracy: 0.9873\n",
            "Epoch 21/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0497 - val_accuracy: 0.9873\n",
            "Epoch 22/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0588 - val_accuracy: 0.9853\n",
            "Epoch 23/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0505 - val_accuracy: 0.9877\n",
            "Epoch 24/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0518 - val_accuracy: 0.9872\n",
            "Epoch 25/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0472 - val_accuracy: 0.9893\n",
            "Epoch 26/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 9.1039e-04 - accuracy: 0.9999 - val_loss: 0.0447 - val_accuracy: 0.9893\n",
            "Epoch 27/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0492 - val_accuracy: 0.9883\n",
            "Epoch 28/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0737 - val_accuracy: 0.9856\n",
            "Epoch 29/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0552 - val_accuracy: 0.9872\n",
            "Epoch 30/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0543 - val_accuracy: 0.9872\n",
            "Epoch 31/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0620 - val_accuracy: 0.9847\n",
            "Epoch 32/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9973 - val_loss: 0.0597 - val_accuracy: 0.9872\n",
            "Epoch 33/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0504 - val_accuracy: 0.9883\n",
            "Epoch 34/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 5.5718e-04 - accuracy: 0.9999 - val_loss: 0.0509 - val_accuracy: 0.9891\n",
            "Epoch 35/35\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 1.8312e-04 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9902\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_32_7 (Conv2D)    (None, 28, 28, 32)        1600      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_21 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               802944    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 805,834\n",
            "Trainable params: 805,834\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.2855 - accuracy: 0.9178 - val_loss: 0.1042 - val_accuracy: 0.9718\n",
            "Epoch 2/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0782 - accuracy: 0.9773 - val_loss: 0.0691 - val_accuracy: 0.9792\n",
            "Epoch 3/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0526 - accuracy: 0.9843 - val_loss: 0.0545 - val_accuracy: 0.9836\n",
            "Epoch 4/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0392 - accuracy: 0.9883 - val_loss: 0.0498 - val_accuracy: 0.9849\n",
            "Epoch 5/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.0555 - val_accuracy: 0.9833\n",
            "Epoch 6/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.0465 - val_accuracy: 0.9847\n",
            "Epoch 7/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.0420 - val_accuracy: 0.9870\n",
            "Epoch 8/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.0449 - val_accuracy: 0.9853\n",
            "Epoch 9/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.0439 - val_accuracy: 0.9873\n",
            "Epoch 10/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0485 - val_accuracy: 0.9850\n",
            "Epoch 11/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.9971 - val_loss: 0.0424 - val_accuracy: 0.9871\n",
            "Epoch 12/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.0495 - val_accuracy: 0.9867\n",
            "Epoch 13/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0513 - val_accuracy: 0.9854\n",
            "Epoch 14/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0446 - val_accuracy: 0.9877\n",
            "Epoch 15/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0550 - val_accuracy: 0.9858\n",
            "Epoch 16/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0603 - val_accuracy: 0.9841\n",
            "Epoch 17/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0484 - val_accuracy: 0.9868\n",
            "Epoch 18/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0477 - val_accuracy: 0.9892\n",
            "Epoch 19/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0504 - val_accuracy: 0.9885\n",
            "Epoch 20/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0473 - val_accuracy: 0.9897\n",
            "Epoch 21/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0518 - val_accuracy: 0.9874\n",
            "Epoch 22/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 7.0099e-04 - accuracy: 0.9999 - val_loss: 0.0506 - val_accuracy: 0.9895\n",
            "Epoch 23/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 3.0346e-04 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9893\n",
            "Epoch 24/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.0640 - val_accuracy: 0.9839\n",
            "Epoch 25/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0158 - accuracy: 0.9945 - val_loss: 0.0552 - val_accuracy: 0.9869\n",
            "Epoch 26/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0460 - val_accuracy: 0.9890\n",
            "Epoch 27/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 8.5474e-04 - accuracy: 0.9999 - val_loss: 0.0483 - val_accuracy: 0.9893\n",
            "Epoch 28/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 3.4631e-04 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9899\n",
            "Epoch 29/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.5358e-04 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9902\n",
            "Epoch 30/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.0590e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9906\n",
            "Epoch 31/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 8.7483e-05 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9901\n",
            "Epoch 32/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 7.4310e-05 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9903\n",
            "Epoch 33/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 6.5145e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9902\n",
            "Epoch 34/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 6.0782e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9902\n",
            "Epoch 35/35\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 5.1505e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9899\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               1605760   \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,610,250\n",
            "Trainable params: 1,610,250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/35\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.2438 - accuracy: 0.9300 - val_loss: 0.0860 - val_accuracy: 0.9751\n",
            "Epoch 2/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0675 - accuracy: 0.9798 - val_loss: 0.0614 - val_accuracy: 0.9799\n",
            "Epoch 3/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0435 - accuracy: 0.9870 - val_loss: 0.0453 - val_accuracy: 0.9858\n",
            "Epoch 4/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0330 - accuracy: 0.9898 - val_loss: 0.0537 - val_accuracy: 0.9830\n",
            "Epoch 5/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0250 - accuracy: 0.9924 - val_loss: 0.0427 - val_accuracy: 0.9862\n",
            "Epoch 6/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.0451 - val_accuracy: 0.9865\n",
            "Epoch 7/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.0417 - val_accuracy: 0.9875\n",
            "Epoch 8/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0120 - accuracy: 0.9966 - val_loss: 0.0422 - val_accuracy: 0.9875\n",
            "Epoch 9/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0438 - val_accuracy: 0.9877\n",
            "Epoch 10/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0421 - val_accuracy: 0.9887\n",
            "Epoch 11/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0401 - val_accuracy: 0.9876\n",
            "Epoch 12/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0419 - val_accuracy: 0.9884\n",
            "Epoch 13/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0462 - val_accuracy: 0.9872\n",
            "Epoch 14/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0489 - val_accuracy: 0.9871\n",
            "Epoch 15/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0460 - val_accuracy: 0.9886\n",
            "Epoch 16/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0449 - val_accuracy: 0.9880\n",
            "Epoch 17/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0442 - val_accuracy: 0.9892\n",
            "Epoch 18/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0513 - val_accuracy: 0.9877\n",
            "Epoch 19/35\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0599 - val_accuracy: 0.9859\n",
            "Epoch 20/35\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.0506 - val_accuracy: 0.9867\n",
            "Epoch 21/35\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.0487 - val_accuracy: 0.9893\n",
            "Epoch 22/35\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0498 - val_accuracy: 0.9899\n",
            "Epoch 23/35\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.3042e-04 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9904\n",
            "Epoch 24/35\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.0430e-04 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9905\n",
            "Epoch 25/35\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 7.4729e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9904\n",
            "Epoch 26/35\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 6.0419e-05 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9902\n",
            "Epoch 27/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 5.1975e-05 - accuracy: 1.0000 - val_loss: 0.0509 - val_accuracy: 0.9906\n",
            "Epoch 28/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 4.4230e-05 - accuracy: 1.0000 - val_loss: 0.0514 - val_accuracy: 0.9903\n",
            "Epoch 29/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.9488e-05 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9905\n",
            "Epoch 30/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.4663e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9905\n",
            "Epoch 31/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.0591e-05 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9902\n",
            "Epoch 32/35\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 2.7843e-05 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9906\n",
            "Epoch 33/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.5136e-05 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9904\n",
            "Epoch 34/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.2528e-05 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9907\n",
            "Epoch 35/35\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.0313e-05 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9907\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_128_7 (Conv2D)   (None, 28, 28, 128)       6400      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 3,219,082\n",
            "Trainable params: 3,219,082\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.2274 - accuracy: 0.9314 - val_loss: 0.0875 - val_accuracy: 0.9743\n",
            "Epoch 2/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0596 - accuracy: 0.9820 - val_loss: 0.0580 - val_accuracy: 0.9822\n",
            "Epoch 3/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.0393 - accuracy: 0.9883 - val_loss: 0.0467 - val_accuracy: 0.9844\n",
            "Epoch 4/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0287 - accuracy: 0.9914 - val_loss: 0.0437 - val_accuracy: 0.9849\n",
            "Epoch 5/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 0.0391 - val_accuracy: 0.9877\n",
            "Epoch 6/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.0424 - val_accuracy: 0.9864\n",
            "Epoch 7/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 0.0475 - val_accuracy: 0.9859\n",
            "Epoch 8/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.0099 - accuracy: 0.9972 - val_loss: 0.0374 - val_accuracy: 0.9878\n",
            "Epoch 9/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0464 - val_accuracy: 0.9872\n",
            "Epoch 10/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0362 - val_accuracy: 0.9899\n",
            "Epoch 11/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0416 - val_accuracy: 0.9887\n",
            "Epoch 12/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0440 - val_accuracy: 0.9883\n",
            "Epoch 13/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0440 - val_accuracy: 0.9896\n",
            "Epoch 14/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0490 - val_accuracy: 0.9879\n",
            "Epoch 15/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0433 - val_accuracy: 0.9902\n",
            "Epoch 16/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0515 - val_accuracy: 0.9891\n",
            "Epoch 17/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0524 - val_accuracy: 0.9891\n",
            "Epoch 18/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0685 - val_accuracy: 0.9847\n",
            "Epoch 19/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.0553 - val_accuracy: 0.9878\n",
            "Epoch 20/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0553 - val_accuracy: 0.9879\n",
            "Epoch 21/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0493 - val_accuracy: 0.9901\n",
            "Epoch 22/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.0438 - val_accuracy: 0.9904\n",
            "Epoch 23/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0489 - val_accuracy: 0.9897\n",
            "Epoch 24/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 8.4911e-04 - accuracy: 0.9997 - val_loss: 0.0503 - val_accuracy: 0.9902\n",
            "Epoch 25/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0516 - val_accuracy: 0.9898\n",
            "Epoch 26/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 4.5076e-04 - accuracy: 0.9999 - val_loss: 0.0490 - val_accuracy: 0.9908\n",
            "Epoch 27/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 5.0349e-04 - accuracy: 0.9999 - val_loss: 0.0593 - val_accuracy: 0.9890\n",
            "Epoch 28/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.0681 - val_accuracy: 0.9868\n",
            "Epoch 29/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0584 - val_accuracy: 0.9874\n",
            "Epoch 30/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0501 - val_accuracy: 0.9891\n",
            "Epoch 31/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 5.6170e-04 - accuracy: 0.9999 - val_loss: 0.0470 - val_accuracy: 0.9910\n",
            "Epoch 32/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 9.7569e-05 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9909\n",
            "Epoch 33/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 3.5648e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9911\n",
            "Epoch 34/35\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 2.6450e-05 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9911\n",
            "Epoch 35/35\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 2.1230e-05 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9911\n",
            "Model: \"multi_layer_single_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_256_7 (Conv2D)   (None, 28, 28, 256)       12800     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 50176)             0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               6422656   \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 6,436,746\n",
            "Trainable params: 6,436,746\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/35\n",
            "188/188 [==============================] - 3s 17ms/step - loss: 0.1898 - accuracy: 0.9402 - val_loss: 0.0654 - val_accuracy: 0.9797\n",
            "Epoch 2/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0502 - accuracy: 0.9851 - val_loss: 0.0515 - val_accuracy: 0.9833\n",
            "Epoch 3/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0324 - accuracy: 0.9902 - val_loss: 0.0491 - val_accuracy: 0.9844\n",
            "Epoch 4/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0413 - val_accuracy: 0.9875\n",
            "Epoch 5/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0154 - accuracy: 0.9952 - val_loss: 0.0407 - val_accuracy: 0.9885\n",
            "Epoch 6/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.0390 - val_accuracy: 0.9893\n",
            "Epoch 7/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0420 - val_accuracy: 0.9876\n",
            "Epoch 8/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0435 - val_accuracy: 0.9877\n",
            "Epoch 9/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.0457 - val_accuracy: 0.9894\n",
            "Epoch 10/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0493 - val_accuracy: 0.9877\n",
            "Epoch 11/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0429 - val_accuracy: 0.9895\n",
            "Epoch 12/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0540 - val_accuracy: 0.9877\n",
            "Epoch 13/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0616 - val_accuracy: 0.9860\n",
            "Epoch 14/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.0496 - val_accuracy: 0.9897\n",
            "Epoch 15/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0453 - val_accuracy: 0.9896\n",
            "Epoch 16/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0476 - val_accuracy: 0.9904\n",
            "Epoch 17/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0496 - val_accuracy: 0.9893\n",
            "Epoch 18/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0567 - val_accuracy: 0.9883\n",
            "Epoch 19/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0537 - val_accuracy: 0.9866\n",
            "Epoch 20/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0615 - val_accuracy: 0.9876\n",
            "Epoch 21/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0496 - val_accuracy: 0.9885\n",
            "Epoch 22/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0651 - val_accuracy: 0.9879\n",
            "Epoch 23/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0556 - val_accuracy: 0.9894\n",
            "Epoch 24/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0560 - val_accuracy: 0.9907\n",
            "Epoch 25/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0572 - val_accuracy: 0.9897\n",
            "Epoch 26/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 9.9653e-04 - accuracy: 0.9996 - val_loss: 0.0560 - val_accuracy: 0.9893\n",
            "Epoch 27/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 3.0135e-04 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9911\n",
            "Epoch 28/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 4.2074e-05 - accuracy: 1.0000 - val_loss: 0.0573 - val_accuracy: 0.9909\n",
            "Epoch 29/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 1.8491e-05 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 0.9914\n",
            "Epoch 30/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 1.2575e-05 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 0.9915\n",
            "Epoch 31/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 9.9911e-06 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 0.9915\n",
            "Epoch 32/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 8.2910e-06 - accuracy: 1.0000 - val_loss: 0.0568 - val_accuracy: 0.9915\n",
            "Epoch 33/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 7.0796e-06 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 0.9916\n",
            "Epoch 34/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 6.0902e-06 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9915\n",
            "Epoch 35/35\n",
            "188/188 [==============================] - 3s 16ms/step - loss: 5.2787e-06 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 0.9913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yt49PT95Fxxm"
      },
      "source": [
        "With the accuracy values retrieved, we plot the graph:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UBQntcCPFxxn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "1a719dc6-92b3-475b-c331-ea35b1b62636"
      },
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "multiple_line_chart(plt.gca(), \n",
        "                    None, \n",
        "                    accuracy_lines, \n",
        "                    \"Validation accuracy variation per number of filters of the convolutional layer\", \n",
        "                    \"Epochs\", \n",
        "                    \"Validation accuracy\")\n",
        "plt.show()\n",
        "plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx_4zBBVTAtb",
        "colab_type": "text"
      },
      "source": [
        "Looking at the plot, we can see that there is no point in going beyond 64, since the small improvements dont compensate doubling the computations. Below 64 the max values aren't much smaller but convergence appears slower. We will go with 32 since convergence happens only 5 epochs later, which isn't a bad payoff given that it requires half the computations. THis value will also be a better starting point for adding more layers in the next section:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfnL05YiQfzo",
        "colab_type": "text"
      },
      "source": [
        "#### Multiple Convolutional Layers\n",
        "\n",
        "Let us add more Convolutional layers, to improve both performance and accuracy. Each layer of pooling halves the image, so we cant't have indefinite layers. Since the image is 28X28, after 3 pooling layers, only a 4x4 imagine is being analyzed (with padding), therefore there is no point in going further. Since each consecutive layer is working with half the image, we can increase the number of filters to compensate, for instance doubling it. Let us test this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dgKRPm7iUuAr",
        "colab": {}
      },
      "source": [
        "def create_multi_convolutional_model(layers, name='multi_convolutional_model'):\n",
        "  multi_layer_model = tf.keras.Sequential(name=name)\n",
        "  for filters in layers:\n",
        "    multi_layer_model.add(tf.keras.layers.Conv2D(filters=filters, kernel_size=7, activation='relu', padding='same', name='convolution_{}_7'.format(filters), input_shape=mnist_info.features['image'].shape))\n",
        "    multi_layer_model.add(tf.keras.layers.MaxPool2D())\n",
        "  multi_layer_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "  multi_layer_model.add(tf.keras.layers.Dense(128, activation='relu', name='hidden'))\n",
        "  multi_layer_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "\n",
        "  multi_layer_model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "  multi_layer_model.summary()\n",
        "  return multi_layer_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hzYouLj-UuAy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "797c996a-b71e-4ee1-d344-190303e176ea"
      },
      "source": [
        "layers = ((32,), (32, 64), (32, 64, 128), (64,), (64, 128), (64, 128, 256)) #each tuple has the number of filters for each layer\n",
        "accuracy_lines = test_model_parameter(create_multi_convolutional_model, layers, 50, tests=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"multi_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_32_7 (Conv2D)    (None, 28, 28, 32)        1600      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               802944    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 805,834\n",
            "Trainable params: 805,834\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.2993 - accuracy: 0.9152 - val_loss: 0.1199 - val_accuracy: 0.9671\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0818 - accuracy: 0.9762 - val_loss: 0.0803 - val_accuracy: 0.9753\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0542 - accuracy: 0.9840 - val_loss: 0.0645 - val_accuracy: 0.9808\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0396 - accuracy: 0.9881 - val_loss: 0.0526 - val_accuracy: 0.9842\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0307 - accuracy: 0.9912 - val_loss: 0.0466 - val_accuracy: 0.9856\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 0.0454 - val_accuracy: 0.9854\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.0459 - val_accuracy: 0.9859\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.0414 - val_accuracy: 0.9872\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 0.0396 - val_accuracy: 0.9887\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.0430 - val_accuracy: 0.9873\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.0425 - val_accuracy: 0.9887\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0496 - val_accuracy: 0.9865\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0437 - val_accuracy: 0.9872\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0394 - val_accuracy: 0.9894\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0441 - val_accuracy: 0.9878\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.0504 - val_accuracy: 0.9861\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0445 - val_accuracy: 0.9886\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0541 - val_accuracy: 0.9870\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0441 - val_accuracy: 0.9893\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0431 - val_accuracy: 0.9893\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 9.9585e-04 - accuracy: 0.9998 - val_loss: 0.0431 - val_accuracy: 0.9908\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0630 - val_accuracy: 0.9857\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.0475 - val_accuracy: 0.9884\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0565 - val_accuracy: 0.9875\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0467 - val_accuracy: 0.9893\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 9.2575e-04 - accuracy: 0.9999 - val_loss: 0.0461 - val_accuracy: 0.9902\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 2.2499e-04 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 0.9901\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.1946e-04 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9905\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 8.9485e-05 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9905\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 7.5827e-05 - accuracy: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9902\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 6.6660e-05 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9902\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 5.7496e-05 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9903\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 5.1122e-05 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9905\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 4.5653e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9904\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 4.1581e-05 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9905\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 3.7623e-05 - accuracy: 1.0000 - val_loss: 0.0506 - val_accuracy: 0.9908\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 3.3600e-05 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9907\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 3.0145e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9905\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 2.8040e-05 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9908\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 2.6308e-05 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9908\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 2.6314e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9906\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 2.1550e-05 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9904\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.9000e-05 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9908\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.7582e-05 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9906\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.6010e-05 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9903\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.4500e-05 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9907\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.3446e-05 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 0.9906\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.2498e-05 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9904\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.1127e-05 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 0.9902\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 1.0464e-05 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9902\n",
            "Model: \"multi_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_32_7 (Conv2D)    (None, 28, 28, 32)        1600      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "convolution_64_7 (Conv2D)    (None, 14, 14, 64)        100416    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               401536    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 504,842\n",
            "Trainable params: 504,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.2602 - accuracy: 0.9211 - val_loss: 0.0780 - val_accuracy: 0.9758\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0608 - accuracy: 0.9814 - val_loss: 0.0517 - val_accuracy: 0.9849\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0400 - accuracy: 0.9880 - val_loss: 0.0435 - val_accuracy: 0.9868\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0304 - accuracy: 0.9906 - val_loss: 0.0448 - val_accuracy: 0.9864\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 0.0316 - val_accuracy: 0.9901\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0427 - val_accuracy: 0.9868\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0144 - accuracy: 0.9957 - val_loss: 0.0397 - val_accuracy: 0.9872\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0379 - val_accuracy: 0.9883\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.0371 - val_accuracy: 0.9892\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0389 - val_accuracy: 0.9887\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0386 - val_accuracy: 0.9889\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0389 - val_accuracy: 0.9895\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0460 - val_accuracy: 0.9866\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0429 - val_accuracy: 0.9890\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0412 - val_accuracy: 0.9890\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0494 - val_accuracy: 0.9887\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.0412 - val_accuracy: 0.9906\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0391 - val_accuracy: 0.9899\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0374 - val_accuracy: 0.9915\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0499 - val_accuracy: 0.9873\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0563 - val_accuracy: 0.9890\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0458 - val_accuracy: 0.9901\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0477 - val_accuracy: 0.9907\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0521 - val_accuracy: 0.9896\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0493 - val_accuracy: 0.9897\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0551 - val_accuracy: 0.9882\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0504 - val_accuracy: 0.9902\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0524 - val_accuracy: 0.9900\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0520 - val_accuracy: 0.9906\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0644 - val_accuracy: 0.9892\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0645 - val_accuracy: 0.9893\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0585 - val_accuracy: 0.9911\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0569 - val_accuracy: 0.9893\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0439 - val_accuracy: 0.9916\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0516 - val_accuracy: 0.9911\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 4.8134e-04 - accuracy: 0.9999 - val_loss: 0.0538 - val_accuracy: 0.9922\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 6.4820e-05 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9927\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 1.0616e-05 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9927\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 6.3000e-06 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9925\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 5.1842e-06 - accuracy: 1.0000 - val_loss: 0.0515 - val_accuracy: 0.9925\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 4.4560e-06 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 0.9925\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 3.9086e-06 - accuracy: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9924\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 3.4594e-06 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9924\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 3.0756e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9924\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.7410e-06 - accuracy: 1.0000 - val_loss: 0.0531 - val_accuracy: 0.9924\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.4604e-06 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9924\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 2.2118e-06 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9924\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 1.9909e-06 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9924\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 1.7999e-06 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9923\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 1.6240e-06 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 0.9923\n",
            "Model: \"multi_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_32_7 (Conv2D)    (None, 28, 28, 32)        1600      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "convolution_64_7 (Conv2D)    (None, 14, 14, 64)        100416    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 7, 7, 128)         401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               147584    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 652,426\n",
            "Trainable params: 652,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 2s 12ms/step - loss: 0.2675 - accuracy: 0.9161 - val_loss: 0.0725 - val_accuracy: 0.9768\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0574 - accuracy: 0.9824 - val_loss: 0.0451 - val_accuracy: 0.9868\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0331 - accuracy: 0.9899 - val_loss: 0.0330 - val_accuracy: 0.9904\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.0357 - val_accuracy: 0.9898\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.0305 - val_accuracy: 0.9906\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0133 - accuracy: 0.9959 - val_loss: 0.0360 - val_accuracy: 0.9903\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.0369 - val_accuracy: 0.9898\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0350 - val_accuracy: 0.9899\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 0.0346 - val_accuracy: 0.9905\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0400 - val_accuracy: 0.9893\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.0451 - val_accuracy: 0.9883\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0435 - val_accuracy: 0.9893\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0354 - val_accuracy: 0.9906\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0321 - val_accuracy: 0.9915\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0378 - val_accuracy: 0.9915\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0531 - val_accuracy: 0.9893\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0727 - val_accuracy: 0.9832\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0480 - val_accuracy: 0.9900\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0422 - val_accuracy: 0.9902\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0379 - val_accuracy: 0.9912\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.0418 - val_accuracy: 0.9907\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0374 - val_accuracy: 0.9918\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0373 - val_accuracy: 0.9916\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0420 - val_accuracy: 0.9899\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0346 - val_accuracy: 0.9933\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0343 - val_accuracy: 0.9931\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 8.7265e-04 - accuracy: 0.9998 - val_loss: 0.0427 - val_accuracy: 0.9920\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0513 - val_accuracy: 0.9891\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0427 - val_accuracy: 0.9910\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0522 - val_accuracy: 0.9905\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0417 - val_accuracy: 0.9928\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0445 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0448 - val_accuracy: 0.9913\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0434 - val_accuracy: 0.9906\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0358 - val_accuracy: 0.9920\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 2.8638e-04 - accuracy: 0.9999 - val_loss: 0.0371 - val_accuracy: 0.9927\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 9.4309e-04 - accuracy: 0.9997 - val_loss: 0.0389 - val_accuracy: 0.9912\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0426 - val_accuracy: 0.9900\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0408 - val_accuracy: 0.9912\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0465 - val_accuracy: 0.9908\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0438 - val_accuracy: 0.9920\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0522 - val_accuracy: 0.9900\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0457 - val_accuracy: 0.9910\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0488 - val_accuracy: 0.9918\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0473 - val_accuracy: 0.9914\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 8.5144e-04 - accuracy: 0.9997 - val_loss: 0.0473 - val_accuracy: 0.9917\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 9.3787e-04 - accuracy: 0.9997 - val_loss: 0.0452 - val_accuracy: 0.9916\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0583 - val_accuracy: 0.9909\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0486 - val_accuracy: 0.9907\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 2s 10ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0509 - val_accuracy: 0.9911\n",
            "Model: \"multi_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               1605760   \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,610,250\n",
            "Trainable params: 1,610,250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.2545 - accuracy: 0.9249 - val_loss: 0.0927 - val_accuracy: 0.9728\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0685 - accuracy: 0.9795 - val_loss: 0.0580 - val_accuracy: 0.9821\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0456 - accuracy: 0.9863 - val_loss: 0.0503 - val_accuracy: 0.9840\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0346 - accuracy: 0.9894 - val_loss: 0.0447 - val_accuracy: 0.9865\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0259 - accuracy: 0.9924 - val_loss: 0.0388 - val_accuracy: 0.9873\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0209 - accuracy: 0.9936 - val_loss: 0.0416 - val_accuracy: 0.9877\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.0419 - val_accuracy: 0.9863\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.0470 - val_accuracy: 0.9876\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.0445 - val_accuracy: 0.9873\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0404 - val_accuracy: 0.9881\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0415 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0462 - val_accuracy: 0.9886\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0482 - val_accuracy: 0.9875\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0500 - val_accuracy: 0.9866\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0480 - val_accuracy: 0.9865\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.0455 - val_accuracy: 0.9881\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0436 - val_accuracy: 0.9900\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0482 - val_accuracy: 0.9883\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0464 - val_accuracy: 0.9883\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0480 - val_accuracy: 0.9880\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0474 - val_accuracy: 0.9900\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 5.3026e-04 - accuracy: 0.9999 - val_loss: 0.0527 - val_accuracy: 0.9882\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.4826e-04 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9908\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.6247e-04 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9906\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.1809e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9911\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 6.7140e-05 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9914\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 5.2513e-05 - accuracy: 1.0000 - val_loss: 0.0469 - val_accuracy: 0.9911\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 4.5233e-05 - accuracy: 1.0000 - val_loss: 0.0468 - val_accuracy: 0.9912\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 3.9050e-05 - accuracy: 1.0000 - val_loss: 0.0475 - val_accuracy: 0.9913\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.5525e-05 - accuracy: 1.0000 - val_loss: 0.0478 - val_accuracy: 0.9911\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 3.1052e-05 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9912\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.8206e-05 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9911\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.5297e-05 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9914\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.3118e-05 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9912\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 2.1154e-05 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 0.9914\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.9067e-05 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9911\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.7401e-05 - accuracy: 1.0000 - val_loss: 0.0500 - val_accuracy: 0.9912\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.6029e-05 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9911\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.4406e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9912\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.3195e-05 - accuracy: 1.0000 - val_loss: 0.0512 - val_accuracy: 0.9912\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.1949e-05 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9910\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 1.1024e-05 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9911\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 1.0050e-05 - accuracy: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9912\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 9.2524e-06 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 0.9912\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 8.5170e-06 - accuracy: 1.0000 - val_loss: 0.0534 - val_accuracy: 0.9912\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.7083e-06 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9912\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 7.0043e-06 - accuracy: 1.0000 - val_loss: 0.0539 - val_accuracy: 0.9910\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 6.3741e-06 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9913\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 5.7375e-06 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9909\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 5.3077e-06 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9913\n",
            "Model: \"multi_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 14, 14, 128)       401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               802944    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,208,970\n",
            "Trainable params: 1,208,970\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 3s 15ms/step - loss: 0.2185 - accuracy: 0.9331 - val_loss: 0.0700 - val_accuracy: 0.9802\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0512 - accuracy: 0.9843 - val_loss: 0.0571 - val_accuracy: 0.9819\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0322 - accuracy: 0.9897 - val_loss: 0.0435 - val_accuracy: 0.9868\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.0535 - val_accuracy: 0.9838\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0329 - val_accuracy: 0.9909\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0388 - val_accuracy: 0.9892\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0353 - val_accuracy: 0.9888\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.0399 - val_accuracy: 0.9873\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0444 - val_accuracy: 0.9877\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0322 - val_accuracy: 0.9911\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0397 - val_accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0418 - val_accuracy: 0.9893\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0380 - val_accuracy: 0.9908\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0420 - val_accuracy: 0.9904\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.0530 - val_accuracy: 0.9885\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0350 - val_accuracy: 0.9915\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0413 - val_accuracy: 0.9896\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0456 - val_accuracy: 0.9902\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0427 - val_accuracy: 0.9919\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0462 - val_accuracy: 0.9897\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0407 - val_accuracy: 0.9908\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0516 - val_accuracy: 0.9900\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0438 - val_accuracy: 0.9897\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0439 - val_accuracy: 0.9911\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0430 - val_accuracy: 0.9902\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.0509 - val_accuracy: 0.9902\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0475 - val_accuracy: 0.9906\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0535 - val_accuracy: 0.9896\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0513 - val_accuracy: 0.9898\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0489 - val_accuracy: 0.9905\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 5.4125e-04 - accuracy: 0.9998 - val_loss: 0.0502 - val_accuracy: 0.9920\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 7.8107e-05 - accuracy: 1.0000 - val_loss: 0.0482 - val_accuracy: 0.9924\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 1.0501e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9925\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 7.3246e-06 - accuracy: 1.0000 - val_loss: 0.0491 - val_accuracy: 0.9925\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 5.7398e-06 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 0.9925\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 4.6580e-06 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9925\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 3.8984e-06 - accuracy: 1.0000 - val_loss: 0.0503 - val_accuracy: 0.9925\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 3.3108e-06 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 0.9924\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 2.8415e-06 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9925\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 2.4522e-06 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9924\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 2.1432e-06 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9926\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 1.8809e-06 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9927\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 1.6557e-06 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9927\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 1.4671e-06 - accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9927\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 1.3051e-06 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9927\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 1.1611e-06 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9928\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 1.0369e-06 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9929\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 9.2778e-07 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 0.9929\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 8.3209e-07 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9930\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 3s 14ms/step - loss: 7.4816e-07 - accuracy: 1.0000 - val_loss: 0.0544 - val_accuracy: 0.9930\n",
            "Model: \"multi_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 14, 14, 128)       401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "convolution_256_7 (Conv2D)   (None, 7, 7, 256)         1605888   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,306,954\n",
            "Trainable params: 2,306,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/50\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.2254 - accuracy: 0.9271 - val_loss: 0.0542 - val_accuracy: 0.9837\n",
            "Epoch 2/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0455 - accuracy: 0.9862 - val_loss: 0.0455 - val_accuracy: 0.9865\n",
            "Epoch 3/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0279 - accuracy: 0.9916 - val_loss: 0.0401 - val_accuracy: 0.9873\n",
            "Epoch 4/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0345 - val_accuracy: 0.9890\n",
            "Epoch 5/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0327 - val_accuracy: 0.9902\n",
            "Epoch 6/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.0332 - val_accuracy: 0.9912\n",
            "Epoch 7/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.0324 - val_accuracy: 0.9903\n",
            "Epoch 8/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0308 - val_accuracy: 0.9917\n",
            "Epoch 9/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0282 - val_accuracy: 0.9918\n",
            "Epoch 10/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0396 - val_accuracy: 0.9888\n",
            "Epoch 11/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0328 - val_accuracy: 0.9922\n",
            "Epoch 12/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0337 - val_accuracy: 0.9910\n",
            "Epoch 13/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0354 - val_accuracy: 0.9913\n",
            "Epoch 14/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0381 - val_accuracy: 0.9913\n",
            "Epoch 15/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0380 - val_accuracy: 0.9898\n",
            "Epoch 16/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0312 - val_accuracy: 0.9926\n",
            "Epoch 17/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0505 - val_accuracy: 0.9898\n",
            "Epoch 18/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.0373 - val_accuracy: 0.9914\n",
            "Epoch 19/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0527 - val_accuracy: 0.9889\n",
            "Epoch 20/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0290 - val_accuracy: 0.9934\n",
            "Epoch 21/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0406 - val_accuracy: 0.9920\n",
            "Epoch 22/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0358 - val_accuracy: 0.9921\n",
            "Epoch 23/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0372 - val_accuracy: 0.9922\n",
            "Epoch 24/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0324 - val_accuracy: 0.9941\n",
            "Epoch 25/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0274 - val_accuracy: 0.9937\n",
            "Epoch 26/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 8.6744e-05 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 0.9938\n",
            "Epoch 27/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 2.2249e-04 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9941\n",
            "Epoch 28/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.9571e-05 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 0.9945\n",
            "Epoch 29/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 5.9828e-06 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9943\n",
            "Epoch 30/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 4.2806e-06 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9942\n",
            "Epoch 31/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 3.3106e-06 - accuracy: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9942\n",
            "Epoch 32/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 2.6616e-06 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9943\n",
            "Epoch 33/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 2.2018e-06 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 0.9942\n",
            "Epoch 34/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.8571e-06 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 0.9942\n",
            "Epoch 35/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.5819e-06 - accuracy: 1.0000 - val_loss: 0.0331 - val_accuracy: 0.9942\n",
            "Epoch 36/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.3578e-06 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9942\n",
            "Epoch 37/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.1754e-06 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9942\n",
            "Epoch 38/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.0233e-06 - accuracy: 1.0000 - val_loss: 0.0341 - val_accuracy: 0.9942\n",
            "Epoch 39/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 8.9547e-07 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9942\n",
            "Epoch 40/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 7.8816e-07 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9943\n",
            "Epoch 41/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 6.9480e-07 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9943\n",
            "Epoch 42/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 6.1467e-07 - accuracy: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9943\n",
            "Epoch 43/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 5.4382e-07 - accuracy: 1.0000 - val_loss: 0.0356 - val_accuracy: 0.9942\n",
            "Epoch 44/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 4.8241e-07 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 0.9942\n",
            "Epoch 45/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 4.2832e-07 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9941\n",
            "Epoch 46/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 3.8119e-07 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9942\n",
            "Epoch 47/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 3.3995e-07 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9942\n",
            "Epoch 48/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 3.0293e-07 - accuracy: 1.0000 - val_loss: 0.0370 - val_accuracy: 0.9942\n",
            "Epoch 49/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 2.6996e-07 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9942\n",
            "Epoch 50/50\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 2.4122e-07 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 0.9942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JqbKTS9ZUuA0"
      },
      "source": [
        "With the accuracy values retrieved, we plot the graph:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LMuVbwEvUuA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "56fde5be-7b62-4c98-b981-e0556a27ef16"
      },
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "multiple_line_chart(plt.gca(), \n",
        "                    None, \n",
        "                    accuracy_lines, \n",
        "                    \"Validation accuracy variation per convolutional layers\", \n",
        "                    \"Epochs\", \n",
        "                    \"Validation accuracy\")\n",
        "plt.show()\n",
        "plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm4AAAG5CAYAAAA3e7gZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd1hUx/rHP7NLX+rSRAER7L2X2FBjicaYmGJ6L8b0xOSm3yQ3+d2ba4rXGKMpJtEUS3qx9y4KgiJ2QEDpvcOy8/vjLEhvgmgyn+fZZ8+eae8pe/a777wzI6SUKBQKhUKhUCguf3RtbYBCoVAoFAqFonEo4aZQKBQKhUJxhaCEm0KhUCgUCsUVghJuCoVCoVAoFFcISrgpFAqFQqFQXCEo4aZQKBQKhUJxhaCEm+JviRBCCiE6W7YXCyFea0zeZrRzhxBiQ3PtVLQsQoiXhRCfX0T5o0KI4BY06W+HECLA8p2yamb5S/KdEkJ8JYR4u460e4UQu1rbBoWiNpr1xVEo2hohxDogREr5erX9M4AlgK+U0tSYuqSUs1vIpgAgBrAub1tK+S3wbUvUr7h4pJT/19i8QoivgAQp5auVyvdqDbsUtaO+UwpFTZTHTXGl8jVwpxBCVNt/F/BtY0Wbonk011vSllyJNjcVoaGe639B/g73r6JxqC+44krlF8AdGF2+QwjhBlwLLBNCDBVC7BVCZAkhEoUQC4UQNrVVVL1LRAjxvKXMeSHE/dXyThNCHBJC5Agh4oUQb1RK3mF5zxJC5AkhRlTvUhFCXCWEOCCEyLa8X1UpbZsQ4l9CiN1CiFwhxAYhhEcdNrsJIf4QQqQKITIt276V0o1CiC8tx5AphPilUtoMIUS45RjOCCGmWPbHCiGurpTvDSHEN5bt8u6tB4QQccAWy/7VQogky/HsEEL0qlTeXgjxvhDirCV9l2Xfn0KIJ6odz2EhxA21HOdaIcTj1fZFCCFmWrb/Z7kOOUKIUCFE5fvhDSHED0KIb4QQOcC9lY+pPvuFEA8DdwAvWK7l79XPkRDCVggx33KOz1u2bS1pwUKIBCHEc0KIFMv9dF9t19KSf5sQ4t9CiBDLsfwqhDBWSh8uhNhjuZ8jRKXuWkvZd4QQu4ECILCW+v2EED9Z7pd0IcRCy36dEOJVyzVKEUIsE0K4VLvm9wgh4oQQaUKIVyxp7YUQhdVsHGDJY11fvbXYVud9Ryt/p+q7f5tCXfehEKKdEKJACOFeKe9Ay3Wwtny+XwhxTGjf0/VCiI6V8kohxGNCiFPAKaHxoeWc5gghjgghejfHZsWVixJuiisSKWUhsAq4u9LuW4DjUsoIoAx4BvAARgATgDkN1Ss0ETMXmAh0Aa6uliXf0qYrMA14VAhxvSVtjOXdVUrpKKXcW61uI/AnsABNdH4A/Fn5oQ7cDtwHeAE2FltqQwd8CXQE/IFCYGGl9OWAA9DLUteHFhuGAsuA5y3HMAaIret81MJYoAcw2fJ5Ldp58gLCqNqF9R4wCLgKMAIvAGYs3tLyTEKIfkAHtHNTne+B2yrl7Wk55vK8B4D+lvq/A1YLIewqlZ8B/GA51tq612q1X0r5qWX7v5ZrOb2Wsq8Awy3t9wOGAq9WSm8HuFiO7QHgY6H9uaiLu4H7AR/AhHafIIQoPzdvW45zLvCjEMKzUtm7gIcBJ+Bs5UqFEHrgD8v+AIs9KyzJ91pe49AEnyNV7yOAUUA3tO/Q60KIHlLK88Be4MZK+W4HfpBSljay3sbQ2t+p+u7fplDrfSilTAK2oT2byrkLWCGlLBVaaMfLwEzAE9iJds9X5npgGNATmIR2Trqi3Vu3AOnNtFlxpSKlVC/1uiJfaD8oWYCd5fNu4Jk68j4N/FzpswQ6W7a/At62bC8F/lMpX9fKeWupdz7woWU7wJLXqlL6vcAuy/ZdaHF5lcvvBe61bG8DXq2UNgdY18hz0R/ItGz7oAkkt1ryLSm3t5a0WODqSp/fAL6pdmyB9djgasnjgiYsC4F+teSzAzKBLpbP7wGL6qjTCU0sd7R8fgdYWo8NmeVtWuzfUS294pjqs7/6fVHbOQLOAFMrpU0GYi3bwZbjr3wvpADD62h7W7X7ridQAuiBfwDLq+VfD9xTqexb9ZyTEUBqZVsqpW0G5lT63A0oRYt/Lr/mvpXSQ4BbLdsPAlss2wKIB8Y0oV6rJtx3rf6dasz1r82GRtyHs4Ddlm09kAQMtXxeCzxQqZwOzWtafr9LYHyl9PHASbQ/DLq62levv/ZLedwUVyxSyl1AGnC9ECIIzePxHYAQoqvQug+ThNZN9n9o3reGaI/2A1ROde/FMCHEVktXRzYwu5H1ltd9ttq+s2gekHKSKm0XoHkqaiCEcBBCLLF0ReWgdSm5WrwrfkCGlDKzlqJ+aIKjuVScGyGEXgjxH6F1t+ZwwXPnYXnZ1daWlLIIWIkWo6hD86gtr60xKWUumkflVsuu26jkFRFCzLV0M2ULIbLQRGPl61H5WlahAfsbQ/Xredayr5x0WTXWss7rWYutZwFriy0dgZuF1k2aZTnOUWgCvbay1fEDzsra4z5rOwYrwLvSvrruyR+BEUIIHzQvkBnNY9TYeluCZn+nWuD6V9DAffgr0FMI0QnNk58tpQyxpHUE/lfpumagieDK9ldcWynlFjTP5cdAihDiUyGEc1PtVVzZKOGmuNJZhtbFdCewXkqZbNn/CXAczavjjNYdUX0gQ20kov3QleNfLf074DfAT0rpAiyuVK9soO7zaA/qyvgD5xphV3WeQ/NiDLMcX3mXUrnnwyiEcK2lXDwQVEed+Wjdq+W0qyVP5WO8Ha0r8mq0H6qASjakAUX1tPU1WgzZBKBAVusCq8b3wG1CiBFoYnArgCWO6AW07iI3KaUrkE3V61zfNanP/obKQs3r6W/Z11yq33elaOcxHs3j5lrpZZBS/qdS/vpsjQf8Re3B7bUdgwlIriVvFSx/DDageZRuR+v+K7ejKfXWd9+15neqoevfKBq6Dy1/VFahPaPuouqflHjgkWrX1l5KuadSnirnQEq5QEo5CM0r2xUt7EHxN0IJN8WVzjK0B+9DaGKgHCcgB8gTQnQHHm1kfavQgth7CiEcgH9WS3dC82YVWeLFbq+UlormdagRHG5hDdBVCHG7EMJKCDEL7eH7RyNtq25HIVrQtrGynVLKRLQumEVCG8RgLYQoF3ZfAPcJISYILYC8g+X8AIQDt1ryDwZuaoQNxWgxNg5oXs1yG8xo3c4fCC2QXS+0wHJbS/petHP1PnV42yqxBu3H+S1gpaXu8vZNWLoBhRCvA03xPtRpv4Vk6r6WoAnKV4UQnpaA99eBb+rJ3xB3Vrrv3kKLFyuz1DldCDHZch7thDb4wbf+6ioIQftD8h8hhMFSfmSlY3hGCNFJCOGIdg5W1uGdq43v0P443WTZLqcp9dZ337Xmd6qh699YGnMfLkPrXr2Oqvf7YuAlcWFQjIsQ4ua6GhJCDLF4/a3RBG8R2vlR/I1Qwk1xRSOljAX2AAY0T1g5c9FEVS7wGVrXXGPqW4sWt7YFOG15r8wc4C0hRC7aD/WqSmUL0GKwdlu6PoZXqzsdbdTrc2g/Fi8A10op0xpjWzXmA/ZoHpl9wLpq6XeheWyOo8VWPW2xIQQtUPtDNK/Adi54LF5D85BlAm9S9Ye4NpahdUudA6IsdlRmLnAELXA7A3iXqs+cZUAfGhA7Uspi4Cc0gV7ZpvVox33SYkcR9XcZNtX+L9C6uLJEpVG5lXgbOAgcRjvOMMu+5rIcLa4qCc2z+CSAlDIezTP0Mpo4iEfzsjTq+W0Rf9OBzkAckIDmJQNNXC9H62qPQTuHT9RSTV38hhbcnyS1QUHlNKXeOu+7Vv5ONXT9G0uD96GUcjeawAqTUp6ttP9ntO/FCkt3bSRwTT1tOaM9zzItbaUD85ppt+IKRVzwbCsUCsWlQwhxN/CwlHJUW9vS1gghtqEF5Dd7VQfF5Y0QYgvwnbrGiotFTeinUCguOZbuwDnAora2RaFobYQQQ4CBaJ5TheKiUF2lCoXikiKEmIzW5ZdMw92xCsUVjRDia2AT8LRllLRCcVGorlKFQqFQKBSKKwTlcVMoFAqFQqG4QvhbxLh5eHjIgICAtjZDoVAoFAqFokFCQ0PTpJSetaX9LYRbQEAABw8ebGszFAqFQqFQKBpECFF9RZAKVFepQqFQKBQKxRWCEm4KhUKhUCgUVwhKuCkUCoVCoVBcISjhplAoFAqFQnGFoISbQqFQKBQKxRWCEm4KhUKhUCgUVwitKtyEEFOEECeEEKeFEC/Wkt5RCLFZCHFYCLFNCOFbKe1dIUSk5TWr0v6vhBAxQohwy6t/ax6DQqFQKBQKxeVCqwk3IYQe+Bi4BugJ3CaE6Fkt23vAMillX+At4N+WstPQFuTtDwwD5gohnCuVe15K2d/yCm+tY1AoFAqFQqG4nGhNj9tQ4LSUMlpKWQKsAGZUy9MT2GLZ3lopvSewQ0ppklLmA4eBKa1oq0KhUCgUCsVlT2sKtw5AfKXPCZZ9lYkAZlq2bwCchBDulv1ThBAOQggPYBzgV6ncO5bu1Q+FELa1NS6EeFgIcVAIcTA1NbUljkehUCgUCoWiTWnrwQlzgbFCiEPAWOAcUCal3ACsAfYA3wN7gTJLmZeA7sAQwAj8o7aKpZSfSikHSykHe3rWutyXQqFQKBQKxRVFawq3c1T1kvla9lUgpTwvpZwppRwAvGLZl2V5f8cSwzYREMBJy/5EqVEMfInWJatQKBQKhULxl6c1hdsBoIsQopMQwga4FfitcgYhhIcQotyGl4Cllv16S5cpQoi+QF9gg+Wzj+VdANcDka14DAqFQqFQKBSXDVatVbGU0iSEeBxYD+iBpVLKo0KIt4CDUsrfgGDg30IICewAHrMUtwZ2atqMHOBOKaXJkvatEMITzQsXDsxurWNQKBQKhUKhuJwQUsq2tqHVGTx4sDx48GBbm6FQKBRNJj8rExs7e6zt7NraFIVCcYkQQoRKKQfXltZqHjeFQqFQNJ/0hHj2/vAdJ/btQiAwdvClXVAXvAM74x3YBc+ATljb1DqoXqFQ/IVRwk2hUCguIzLOn2Pfj99zbPd2rG1sGTJ9JlY2NiRHnyYmPJSj2zcDIHQ6PPw64h3YhXZB2svo69cmYq7MZMJsLlNCsgUoLSnGVFLSonUKIbB1MGAJP1Jc4SjhplAoFJcBWclJ7PtxBVE7tqC3sWbI9JkMnj4TB2eXijxSSvIy0kmKPkXymdMkR5/i9MF9RG7dUJHHzuCIwc2Io9EdRzejtu1mxNHN3bLfiIOzK0LX8Ng0KSVFuTnkZWaQl5lBfma6tp1RaTszg8KcbABsDQatHVc3rW2LDZod2raDqys6nb7lT+BljjSbKcjJspy7DPIs5y/fcg7zMtLJz8ygKD+vVdq3d3ahXWBnvIO6aGI/sDOORvdWaUvRuqgYN4VCoWhDslOS2f/zSiK3bUKvt6LfpKkMue5GDK5ujSovpSQnNYWkM6fISjqvCYKMC4IgPysDc1lZwxU1EiF0OLi6XhCFrtq73sqK/KzMqoIkIwNzmanhSv+m6PR6DK7GC+fSaMTgasTG3r5F2zGbTKQlxJEcfZr0+DikNANgcDPiHdiZdoFd8A7S3h1cXFu0bUXzUDFuCoVCcZmRk5ZKyC+rOLJlI0JA/8nTGDrjZhzdjE2qRwiBi5c3Ll7etaZLs5nCCq+ZJuoKc7Jp7J92eyenCm+Zo5sRBxdXdPrGecyk2UxhXu4Fr1JmOgVZWY1u+6+EEAJ7ZxccjZr309HNiL2Tc6M8ny1JaXERKbExJEefIvnMKZKiTxMddgAs10RvZQWN6FLV6fQY3NwueFiNxir3icHNHUejERs7e8xlZeRnZ5KfkVHTe5uZQX6Gtl1SVNjah98i3PrGu7Tr3LXN2lceN4VC8bfk9IF97FqxjG4jRtNn/KRL0m2Un5VJdNgBzoTuJzY8FCmhz4TJDLv+ZpzcPVq9fYWiNkoKC0iJiSYp+hQFlm7vhjCbSsnPyiIvU+vizc1Ix1RcXCOfta0dpSXFFcKwHCF0GFxdKwSeo5sRG3uHRonGtqb/pGk4e7Tuikz1edyUcFMoFH87pJQsf/EpshLPU1pchNDp6Dx4OH0nXkPH3v1azAsipSQ9IY4zB/dzJnQ/iadPgpQ4e3rRecgIBk2bgbOHV4u0pVC0JVJKSgoLK4RcRdxeViY29g6aJ854IdbSwcXlbxnr2FhUV6lCoVBU4tzxo6TGRjPxocfx692XI5vXE7l1I6dC9uDq7UPfq6fQK/jqKgMDGkuZycS541GcCdXEWnZyEgDtgrow8uY7CBo8DA//ADXCT/GXQhu56oCtgwPuHfwaLqBoNsrjplAo/nb8/uF/iDsSzsOLvqqY2NZUWsqpkD0c3riWhGOR6K2s6DJsJP0mXkOH7r0qhFaZyURBdtaFIPwMbQBAuYch8fQJivPz0Vtb07FPf4IGDSNw4BA1gk+hUDQa5XFTKBQKCzlpqZwK2cOgaddXWY3AytqaHiPH0mPkWNIT4ojYtJao7Vs4vns7bj4dsLa104Lrc7JrxuvodBhc3TC4Guk8ZARBg4cR0GeAWu1AoVC0OEq4KRSKvxWHN60FqQUY14W7rz/j732E0bfdw4k9Ozm+Zwd6Kyu8gzpXnRPNMl+avbOzitdRKBSXBCXcFArF3wZTSQmHN60jaPDQOqfPqIy1rR29x02k97iJl8A6hUKhaJhLO4GMQqFQtCHH9+ygMDeHAVOmt7UpCoVC0SyUcFMoFC1ObHgoKbHRbW1GFaSUHFr7O+6+/vj16tvW5igUCkWzUMJNoVC0KFJK/lz4Pr++906LL5Z9MZw/cYyU2DMMvOa6Jk/FsT52PYdSDlFmbrmloxQKhaI5qBg3hULRouRlpFOUm0NRbg4H//iZ4TNntbVJAISt+x1bg4Eeo4KbVO5U5inmbp8LgJutG2N8xzDObxwj2o/AwdqhFSxVKBSKulHCTaFQtCipcTEAuLbzYf8vq+gVPAEnY9su55Sbnsap/btrTAHSGA4ma3NAvjT0JSJSI9gSv4Vfz/yKjc6GYT7DCPYLJtgvGC8HtQKCQqFofVRXqUKhaFFSYzXhNv2Zl5BmMzu/+7qNLYKIjWuRUtJ/0tQmlw1LDsPLwYvbut/Gu2PeZfus7Xwx6Qtu6XYL0dnR/Gvfv5iwegK3/nEriyMWk5iX2ApHoFAoFBrK46ZQKFqU1LMxOHt64xUQyOBrb2D/z6voP2kq7bv2aBN7tClA1hI0aBguXu2aVFZKSVhyGIPaDaqIi7PWWTPUZyhDfYbywpAXOJN1hm0J29gav5VF4YtYfWI1q6avwt1erZSgUFzOSLOkMK+U/KxiSopMjS7n6eeEjX3byScl3BQKRYuSGheLZ8dOAAy9/maObtvE1q8+5fa332+xxdubwom9Oy1TgFzb5LIJuQmkFKYwyGtQrelCCDq7daazW2ce7PMgUelR3L32bl7c+SKLr16MXk3Kq1C0GGVlZgpzSijMLW1UfiklRXml5GcXk59VYnkvJj+7hILsYgqySzCbm77s503/GIx3J+cml2splHBTKBQtRmlJMZnnz9F1+EgAbOzsGX3Hfaxd+D5Hd2yhd/DVl9QeKSVha3/D3dcf/979mlw+NCUUgEHetQu36vR078lLQ1/ijb1v8OmRT3m036NNbvNyoqC0AFu9rRKgilbFbJYU5pZQkF1iEVYXBFbl7cLcEriI5dVtDVYYXGwxuNpi9HGo2Da42GJjr4dGjjZ3a9e2g5KUcFMoFC1GenwcUporPG4APUaOJXz9H+z87iu6DL0KW4dL99A7f/I4KTFnuPrBx5o8BQhAaHIoLrYuBLoGNrrMzC4zCU0O5ZPwTxjgNYDhPsOb3O7lQEFpAVN+nMI9ve7hgT4PtLU5LUKpuRRrnXXLVWgqBrMJbAwtV+dfCCklRfmlVbxdBbV5v3JKkNU9XwLsnWwwuNhgcLXFq6Nzxba9ow2ikc57O4M1BldbHFxssLL+a/wBUcJNoVC0GKlntYEJlYWb0OkYd+/DfPfKc+z/ZRVjbr/3ktlzaO1v2BoM9Bw9rlnlw5LDGOg1EF1jfyXQuk9fHf4qUelR/GPHP1g9ffUVOeJ0a/xWMosz2RK/5S8h3L499i3zQ+czf9x8RnYYWX/mMhPkJUFuEuQm1v1emAlCDx2vgm5Tods1YOxUf91tQFmpuVldgvXWaTJrHrLsqh6yggqPWQn5OcWYTTXb1cSUDQYXW4wdHDVB5mJ7wQPmaoO9sw16vRo/WRtKuCkUihYjNS4Ga1s7XKsNAvDp3I1eY68m7M9f6DN+Em7t2re6LbkZaZwK2cOAa65r8hQgAKkFqcTlxnFLt1uaXNbB2oH3g9/ntj9v44UdL/D5pM+x0l1Zj9u1MWsBiEyLJLckFycbpza2qHlIKVkYvpBPD3+KXuiZd2Aew3yG1X49pISjP8P6VyD3fNU0oQdHb3BqB26dwH8EOPlAaT6cXA/rX9Jenj00AddtKnQYBK0Y11lWaiY/p7haF2PNWK7igsYH3l8Mtg5WODhrXrH2XVwxuNrg4FwuxmwxuNj8pTxfbcWV9SRRKP7mpMbF8vN/3uTm197GzadDW5tTg9SzMXj4d6x1EMKo2+7m5P7dbF/+Bdc//1qr23J441rMZjP9J01rVvmmxrdVJ8g1iNeGv8bLu17m4/CPeWrgU82qpy3IKspi97nd9PXsy+HUwxxIOsB4//FtbVaTKTOX8fb+t/nh5A/M7DKTEe1H8Pz25/ntzG/M7DKzaua007BmLkRvhXZ9YcxccO6gCTUnHzB4QF2xfle/ARkxcHIdnFgDu/8Huz4Agxd0nayJuMBgsGl+mEBJkYm0+DxSzuaQcjaX1LhcspILauTT6QUOFg+WWzsHfLu54eBsg86q6aEC9aHX6yraMbja4OBii7WNEmSXAiXcFIoriGO7tpGbnsrJfbsZdkPTPUGtiZSS1LMxdBsxutZ0Rzcjw2fOYud3XxEbEUZAv4GtZouppISITesIGjQUV++mTQFSTmhSKPZW9nQ3dm+2HdODphOaHMrnRz5ngNcAxviOaXZdl5INZzdgkiZeHPIiD2x4gH2J+xol3EwlZVUCyqt4gizeoMLcEmTL9trVgaTQVISTeRCP6K/CNtyWeODB0v9y9oDkM+vtgACkFqtmKgYeAOvHINsGm7jyQHY9BpdsDK6FFd15DpZuPlsHK4QQmufL3I58z9spsLmR/HZZ5J89RX7iefK3FpK/MYVC8wZsdQUY9FkY9JkYrLIs29pnB8u2ta6EUrMN6aV+pBR3IqUkgJSSTmSW+lA+9aqjPh0vmxi6uJ7H0bEMg7Meg6sDBg8n7Nw9EM4+mth0MoKjF+hbMK5P0eYo4aZQXEFEh4YAcCZ0/2Un3HLT0yjOz8fTv+4Yn4FTZ3Bk83q2Lfucu95dgN6qdR5BJ/bupDAnmwFTpje7jrCUMPp59rvoLs4Xh75IZFokL+96mR+m/0A7Q/OE5KVkTcwaAl0C6e3Rm0Heg9iXuK/OvOnn8zjwRywJxzNq7ZLTW+kq4pncOzji4GSN0Les96c6pWWlbE/YTlJ+EoO8B9HDvWNFWmpBKutj19Pfqz+99c4QuxOKc8CnC/hfpXnFJBQXmsjPKiYzqYBzJzJrPzZrHVY2Oorza6bp9A44uPTE0M4GN5tc2pvOU1wsyC/yJrnIn/w8W8rMNT1UNlallJbpkVITafa2xXgbc+jsGo2Xaw6erjkY7CxrAJuAvHQt3i41CWKSQVZfT1eAgztY2Tb7fF7R2LtZvKYWz2n1d4MX6K8sKXRlWatQ/I3JTkkiPSEOR3cPEk+fpCA7CwcX17Y2q4LaBiZUx8ramrF3P8iv8/5FxMY1DLzmuha3Q0rJoXW/N3sKEIDs4mxOZZ5iTv85F22PnZUd7we/z6w/ZvHc9uf4avJXWF/GHpCk/CRCk0N5vP/jCCEY7jOc9w6+R1J+UhXRmZmUz4E/YjgVmoK1rZ4ug71x9rCr0yt1qUgrTGPOpjmc8j7FWyPfYnpQdfHelR0blvF14pv8eTYO9w6dYep7EDi23npLS8pqjIgsyC6htLhM6zJ0ta3oNjS42GJnsEbo6j5uKSUlhaYL9VWKS7Ox0+PV0VkbSelq0/jzZy6D/LSaAynykrTRr383JFCYoZ2H5KOQlwzSXC2T0LySdi7admO4aSm0693CxjYeJdwUiiuEM6EHAAi+60H+mP8fog8dvOTzotVHuXDz8A+oN1/QoKF07DuAPau/pfvIsTg4u7SoHYmnjpMcfZqrH5zTbMEQnhKORDY7vq06HZ078uZVbzJ3+1zmh83n+SHPt0i9rUH5oISpnbTlwcqnM9mfuJ8ZnWeQlVzAgTUxnApJRm+jZ+Dkjgy42h87x7YXowm5CTyy8RFSClJYMH4Bo32rdduXlcLej3nq0J9s83ZlSZ+JvDz9G7CyabBuaxs9Lp4OuHi2zHQ2QghsHayxdbDG2L6FphPR6cHJW3spamIug/zU2kcIF+U0vh5r+9azsREo4ab4SyPNZjYvXUz3UWPx7d6rrc25KKLDQnBr70vX4SNxdDMSHRZyeQm3uFhcvLwbnKdNCEHw3Q+y7IUn2LPqW65+sOleLWk2U5ibQ15mBnmZ6eRnZlreM4iPisTWwUCPZk4BAtr8bVY6K/p49Gl2HdWZHDCZ0ORQlkUtY6DXQCZ0nNBidbcka2LW0NejL37OfgB0ceuC0c5IyMlwHPd05cS+JPRWgv4T/Rkw0R97p4ZFz6XgRMYJZm+aTUlZCZ9N+oz+Xv2rZsg+B9/cCKnH6NRtGje192P12Q3cUZBIR+eOtVeq+Guh01/oNr2CUcJN8ZcmNS6WiI1rOH1wH/fMW4i9U9stU3IxlBQWkBB1hP5TpiOEIHDgUI7t3k6ZqRS9Vdt7OkDzuNXXTVoZD7+O9J80jfD1f9Jv4jUV5bQJO/PIz0i3iLIM8i3iLC+jfDuD/KwMzGXVY3nA3tkFRzcj4+59GBu75v8rDk0Jpbd7b+ysmj6NSH3MHTyXw6mHeW33a3Q1dsXPya9F6/kkFO8AACAASURBVL9YzmSd4XjGcV4c+mLFvryMYq6Jux9DdHtOWSXTd7wvAyd1xMH58hBsoAntJzY/gb21PV9P+ZrObp2rZigrhR/uh+x4uPV76D6V2YVp/Jawlf+F/Y8Pgj9oG8MVimaghJviL03CsUgACrKz2PjpQqY/+9IljbdpKc4eDqfMZCJo0FAAAgcN5fDmdcRHRRLQd0AbWwelxUVkJZ6n+1W1jyitjatuvoNju7fz6/vvYHA1kp+pibWy0prrENoZHDG4GXE0uuPfwVfbdjPi6OZu2W/E4OrWIiK2oLSAqLQo7ul1z0XXVR0bvQ3vjX2PW/64hee2Pcd30767rOZ3WxOzBp3QMTlgMlJK9vx0hsNb4nHClyPeO3j8vtvo3bFLW5tZhb3n9/LElifwMfjw6cRP8XH0qZlp81sQvw9u/AK6a13AHvYe3Nf7PhaFLyI8Jbymh+4y51TmKTad3cTsfrOvyGeaovlcPk8MhaIVSIiKxNnTi34Tp7Lzu684un3zZdW92FjOhIVgazDQvmsPAPx798XK2obosJBLJtxKS8qI2BxP32BfbOyrPjoqlrqqZ0RpdewcHRl/78Ps+2kler0eny7dcTS64+hmrCrMjEasbS7diLgjaUcwSRMDvVtnuhJfJ1/+MeQfvLr7VQ6nHm61dpqKlJI10WsY1m4YHvYexBxOI3xjHN2GtaPTREcWb36akfmd6U3zp0dpaQpNhby+53V8HX1ZOmUpRjtjzUzH18CeBTD4AehzU5Wke3rew6oTq/gg9AO+nvL1FSOAisuKmbt9LtHZ0Qz0Hsgwn2FtbZLiEqKEm+Ivi5SShGORdBowmMHTbyAm/CBbvlyCb4/ezZ7bqy2QZjMxhw4S0G9QxfQZ1rZ2+PfpR3RoCOPuefiS/OBEbj/H/l+j0et1DJjkXyUtpREjSmujx6hgeowKbjBfaVkp3x//ngCXAIb5DMNW33pCLjQ5FIFggFfrCeLx/uPR79Gz69yuy0a4HUk7QkJeAo/0ewRzmZm9P53G1duBcXd3R6/X0dG5I/sS93FXz7va2tQKvor8iqT8JL6c/GXtoi3zLPwyG3z6weT/q5HsYO3AnP5zeGvvW2yJ38IE/8sz7rA6SyKWEJ0djZ3ejpUnVl5y4ZaUn8T62PVMD5pe+3lXtCpqITBFm2IqLSU7JZlzJ45xct8uwtb+xvmTx1uk7vSEOApzc/Dt2RudTs81jz2LTqdj7cL3a42PulxJOnOKguysim7ScgIHDiU7JZmMc/GtbkNZqZmITXEAnNifVCM99WwM1nb2uHi1zmi2RRGLmHdwHo9tfozRK0bzzNZn+PX0r2QUZbR4W2HJYXQzdmvVJZ6cbJzo59mP3ed3t1obTWVNzBpsdDZM8J/AsT2JZCYVMOKGoIr1Iof7DOdA0gFKzTW7stuCxLxElkYuZXLAZAa3G1wzg6kYVt+rTQlx89dgXXu84g2db6CTSyfmh86/bI6tPqLSo1gauZTrgq5jVrdZbI3bSmpB6iVrPzEvkXvX3ct7B99jyo9TmB86n6yirEvWvkJ53BSXACklp/bvJiU2pmLkX3ngeVFuzSHYbj7tuX/+pxfdbkKUFt/m10MbGejs4cWEBx5lzUfvEfLLaobfeOtFt3EpiA4LQeh0BPSvOjVF4MAhAJwJDcHd17+2oi3GiZAk8rNLCOzvSXR4KmkJuXj4XhA2aXGxdS51dbGEJofyxZEvuL7z9UwOmMy2+G1sjd/KprhN6ISO/p79CfYLJtgvmE4uF7fAd2lZKRGpEdzY9cYWsr5uRnUYxYJDC0gvTMfd3r3V26sPk9nEuph1jPUbi510IOT3CHyCXOjUz6MizwifEaw8sZIjqUcuCy/hB6EfIJE8O+jZ2jNseA3Oh8Gsb+pd+N1KZ8UzA5/hya1P8vOpn5u1Nu2lorSslNd2v4abnRsvDHmBrOIsvo76mh9P/cjsfrNbvf2k/CQe2PAAOcU5vDf2PTbHbWZp5FJWnFjBHT3u4O6ed+Ni2/TpfYpMRYQkhZBWmIanvSdeDl54OnjiauuKTij/UnWUcFO0Oif37eKP+e8idDoMrm44uhlx8WpHh249tXgmoxbL5Gh0Jzo0hF0rlpGVnHTR3ZnxxyJxNLrjUqmeHqOCiQ47wJ4fvqNjvwH4dO52sYfX6pwJDaFDt57YO1b1ADm5e+AVEER0WAhDZ9xUR+mLx2yWHNoQh6e/E8F3diP2cBon9iXhcZNmT/lSV91HtvxyTrkluby882V8nXx5aehLOFg7MKrDKF4Z9grHMo6xLX4b2+K38UHoB3wQ+gEBzgEE+wUzq9ssfJ18m9xeVEYURWVFDPRqfWEyssNIFhxawJ7ze2qZJPbSEpIUQnpROlM7TSV8UxwFOSVcM7tPlS74we0GoxM69ibuvTTCLTEC7I3gWnPkbWhyKOti1/Fov0dp79i+ZtmjP0PIEhj+GPRo+NwG+wUz0GsgH4d/zLTAaRisW2hetRbmi8gvOJl5kvnj5uNi64KLrQsjfEbww8kfeLDPg6060CWlIIUHNzxIRlEGn078lL6efZkcMJmH+zzMJxGf8OnhT/n+2Pfc1esu7uxxZ4Me6/TCdHYk7GBb/Db2Ju6l0FRYI4+VzgpPe088HTzxstfEnJeDFx2dOzLBf8LfVtQp4aZoVYoLCtj69Wd4dQri9rffb3CJIytra3atWEZsRBj9J01tdrtSShKijuDfu1+N+K8JDzzKueNRrF34Pnf9ZwHWdi075UNljmccJyE3oVF5O7l0Isg1qMq+nLRUUs/GMOaO+wDtuJJjcvDu5KxNCzJoCPt/WkVhbk6rTXUSE55KVnIBkx/qhX1mBP693Tl5IJkRMzuj0wly01IpLshvcnxbY/j3/n+TXJDM19d8jYP1hfnhhBD0dO9JT/eezOk/h8S8RLYnbGdb/Da+OfYNOxN28tOMn5r8YA9N1haWvxTCpLuxO0Y7I7vO7Wpz4bYmeg2O1o4Mch7G6g1hBA3wpF1gVc+Ji60Lvdx7se/8Ph7r/1jrGlSUDV9MBqS22PtVT1Ys2VRmLuPdkHfxdvDmvt731SybfgZ+fQJ8h2iLvzcCIQTPDX6OO9bcwddHv26RFTNamlOZp1hyeAlTAqZUicWb1W0WT297mh0JOxq1nmxzSCtM44H1D5BakMqSiUvo69m3Iq2zW2feD36fExkn+CTiExaFL+KbqG+4t9e93N7j9goRLKUkJjuGrfFb2Ra/jYjUCCSSdoZ2zAiawTi/cfg7+5NWmEZqYSopBSmkFKSQWpBKSmEK0dnR7E/cT25pLgDBvsH8e/S/cbRxbJVjvpxRwk3RquxetZz8rEyun/tqo9aldG3XHhfvdsRGhF6UcMtMPEdBdhZ+PWtOoGpncOSax55h1b9eYdvyz5n40OPNbqc+Np/dzDPbnkHSuBW1XW1d2XLzlirLIUWHaaslBA7U4ttiItJYu/gI1zzSh8ABngQOHMK+H1cQGx7a7AlnS4oKKczJxsWrpodTSknourO4eNkTaLUTvniA7oNXE3vYioTjGfj3dCc1rnzFhJYVbuti1vF79O/M6TeHfp71L13l4+jDrd1v5dbut7IuZh3P73iejWc3MjlgcpPaDEsOI8A5AA97j4Yz10LpuXMAWHfo0GBendAxsv1Idp7bSZm5DL2u5rqVl4IiUxGb4jYxseNEDq87T1mpmeHXB9Wad7jPcJZGLiWvJK9ZP5jmkhKKo6Kw7tgRKze3ujMe/QVMhRAwGra8DRErtGWpgsbxy+lfOJZxjP+O+S92OluKY2LAZMK2SxcoLYRV92hrT970ZaNWRCinr2dfJnWcxFdHv+Lmrjfj6eDZ5ONrLUxmE6/vfh0naydeGvZSlbSxfmPxcvBi1YlVrSLc0gvTeWD9AyQXJLP46sV1TpvSzdiN+ePmE5UexSfhn7Dg0AKWRS3jzh53klOSw7b4bcTlanGyPd178mj/RxnnN45ubt2q/LluyFNeUFrAz6d/Zt6Bedyx5g4WjF/wt5tAWQk3RauRHH2a8HV/0m/iVNp17tqoMkIIAvoNImr7ZkylpVhZN29ervL4Nt+eta8n59erL0Omz+TAbz8SOHAIQYMaPyrLXFZGSmx0vQMcTmSc4N2QfzPMpQfPTvsnugZ+lCPTInlj7xvsOLejyr/p6LAQXL19MHbQHmZxR9MBiNgST+AAT9oFdsHBxZUzoSHNFm7rFn1IXGQEsxcvx8qm6g9dwvFMUuNyGXd7F3TbNS9EgO1BbB1GcWJfkibcYi0jSv1b7uGZlJ/EW/veoq9HXx7q+1CTyk7sOJFOLp1YcngJEztObLTXzSzNhKWEMbHjxCa1J00mcrduJWvFSvJ3a4MNDCNH4nrrLJzGjUPU84dlZIeR/B79O8cyjtHbo/lrH0opMZ0/Dzod1j61zGNWDzvP7SS/NJ/xTlM4uvM8vUe3x9W79tUvhvsM57Mjn3Ew+SDBfsGNbqMkPp6sVavI+vEnyjK0ASXW7dtj17s3dr17Y9+7F3a9eqF3sXj5Dq8E9y5wz+9wejOsmYtcdj1Z7SezOy6G5zI86Ll5BSejXseclweAXe/euHU340wkurtX1drF2hBPDXyKLXFb+CTiE14f8XqTy7cWy6OWE5keybwx82qM4rTSWXFTl5tYFLGI+Jz4ihUvWoKMogwe3PAgifmJLJqwqFGe6J7uPflowkccST3CoohFLAxfiLXOmmE+w7in1z2M8R1TZc3bpuJg7cAdPe6gi2sXntv+HLf9eRvzxsxjZIeRNfKWnj+P3mhE10K9KtJsJn/3HgyjRrbp1DFKuClqUFpUhM5Kf1GTmZrNZWz6/GPsnZ0ZdWvTpg/o1H8gERv+5PyJqGYvEh4fdQQHF1fcfOr2fFx1y53EHj7E+sULuGfeQgyu9XgAgNz0NA5vXk/klvXkZTY8mnEyHkA+CSVbGvTqBbkGseDQAv4480eFcCstKiIuMoJ+V1+DEAIpJXFRGeitdJw/lUVaQh4evo4EDhzCqf17KDOZGuXVrExy9GlO7d8DQOzhQ3QeXFXAhq0/i4OLDd3stkBGNFjZoU8JJ2jQTE7uT6KkyETq2RhcvX2wsW+ZNRzN0syru17FZDbx79H/bnLcjl6n5+G+D/PSzpfYGre10UtLnco8RW5JbqPXJy1NTCRr9Q9k/fADppQUrNq1w+MJ7Tpnrf6Bc088iZWXF6433YTrzTfVKqhGtB+BQLDr3K5GCzcpJabkZIqOHqUwMpKiyKMURUZSlpkJgG23bjiOH4fT+PHY9erV4ICRNdFr8LD3oHCPE1bWmQyedmEVC1NiInoXF3QGrburn1c/7PR27Evc16BwkyYTedu2kbliJfm7doFeT/6wnnzqmcUUw2CGZrlTFHmU3A0bKspY+/tj37UTdmnh2I2/lbINGymKjKToSH8KD0vMBUd4CJBWBZh7eOJy3XTsevXGXFBA1tefkvhDKsl2/rjYhuA6KwC7ro37w1iOv7M/t3S7hZUnVnJnjzsJdA1sUvk6z0VZGaXx8chaJpeuDSsfH/SOmkczJjuGhYcWMt5vfJ0e5JldZrLk8BJWn1zNs4PrGKzRRLKKsnhow0Mk5Cbw8YSPax+5Ww99PPvwydWfEJ8bj9HO2OJxg0N9hvL9tO95autTzNk8h2cHPcvdPe9GFheTs24dWStWUhgejpWnJ+4PP4zrLTejs23eNEJSSnI3bSLto4UUnzyJ/5dLMYwY0aLH0xSUcFNUoSAnm+9eeRZrO3tmvfEf7AzNix84vHEdSWdOMfWJuU2uw69XX3R6K2LCQ5sl3Mrnb/Pt2afef0VW1tZMe2Iu37z4NBuWLOD6F16vkd9sLuNsxCEiNq0lOvQAEkmnfgMZc9cDtR5XZlEm8w7+lzKzmReGPE/aoSiObN7AgCnT8fCr2yNlpbNiaqeprDyxkuzibFxsXTgbGUFZaWlFN2l2aiG56UUMuy6Q0LWxHNkaz7i7ehA4cAiRWzdy/kQUfr361tlGbexauRw7RyeQklP7dlURbsmxOSQcz+Sq6wPQ73oEOgzSvCDRW+l+fTuidp4nOjyV1LjYGgvLF5cVYyWsmtX9tzxqOfuT9vPmVW/i79y80bJTAqawOGIxiw8vZrz/+Eb9Ow5LCQOod2CCLCsjf/duMlesJG/bNpASw+hRtHvjnziOGVPhXfN45BHyduwgc8UK0j75hLTFi3EMDsbt1lkYRo5E6LXzYrQz0su9F7vP7a51VKA0mTClplJ0/HiFQCs8epSytDQtg16PbefOOI4fh33v3pgLCsnbupX0JZ+S/slirDw9cRw3Dsfx4zAMH17D85BTksOOhB3c6nIfMeFp9OtZRt7nH5NmacecnQ1CYBMUiH0vzTs2rbAzobF7YGgNcwEoTUrSBO3q1VUErePMGczc8xAZRY7sNYVx3fjreOO9P9DlFlhEqOX4QveQk+4C4WuBtWBlhV3XrohJE/iseCP+7Rx4Ku84or0bXDsX/IZCynHczj5Pobk7mbmDyVq1isxvv8V+0CDcbp2F06RJjf7RfrjPQ2w5/DMfbH+bBdM/R9fEkdLSbKYk9ixFRyO144k8SlFUFLKwZvB9nVhbYxg6FMO4YN7X/Y6tlS2vDn+1zvvY2+DNOL9x/Hz6Zx4b8Fiz5jmUUlKWlYUsLCSnJJd/7HiBvNx4PrrqLQZIX0rPn29ynQDt0ENuNqVkN5hX5+yC3rHxAs/XyZfl1yzn1d2v8u36eTh+spreIamYc3KwCQjA86knyd+9h+R33iH988/xmP0ILjfeiM6mcV3oUkrytm4jdeFHFEcdwyYggPbvvYfD0Dpu/kuEEm6KCspMpfz+wb/Jy8xAmiW/znubG19+q0b3WUPkZ2Wya8Uy/Hv3o/vIsU22w8bOHt8ePYmNCGPsnffXmc9sluh0NR9k2clJ5GWk49ejYQ+Gu68/o++4j61fLSFi49qKuLr8rEwit27k8Ob15KQm4+DiypAZN9J3wuRaY8FA+xF8du09JBpz+GrKV3Q3dqew9whOH9jHzu++4oZ//LNeW6YHTeebY9+wPnY9t3S7heiwEGzs7fHt2QuA+CjNy9dliBe5mUWc3JfEiBs607HvAPRWVpwJDWmScEs4fpTY8FBG334vGecTOB2yt0r39KH1Z7F1sKKXYTPkJMCMhZB6HA6voJ1XIc4edhzbHUdm0vkq1zkpP4m71t6Fnd6Ol4e9zIj2jf9neiLjBP8L+x/j/cZzQ+cbGl2uOlY6Kx7q8xCv7n6V7Qnb6/QOSbNEWO6h0ORQvB286eBY00trSksj68efyFq1itJz59C7u+P+4IO43nIzNr41Y3KElRVO48fjNH48JQkJZK1aTdaPP5K3ZQvWHTrgesstOE+ZjLmggOtSOrA/ch0Jpz5An5GDKSXlwis9HcxmS6WagHIcOdLSxdgLu+7d0dlXXZPV/YH7MWVmkr9jB7lbtpLzxx9krVqFsLfHMPIqnMaNx37AAEpiY4nY8QPPHChEGg0UWWXhuvhN0nVmbLt2wXnSJGx7dKcsI5OiyEjydu8m+9dfmQWUCTi5/Foc+/bDvndv7Hr1oiwzk8xVq8nburVWQbv65GoS8jTvzdH0oywKX0R2cTbzxs7DcNVVGK66CqSEhYMx6TpS1O819C7O2Hbtis7Wljmb5nAoxZFXrv8dEbsb1r4IX0yEgXdDfAjCxgGH2d/h4OyD6eWXyf75FzJXruD88y+gf+f/cJk5E5frZyCEoDQlBVNKatVznZJCaWoKptQ0FpSWAns59np/bNv5YO3phZVX9Zcn1l5eIARFUVEUHtGEWtHRo5jz87VLZmeHXY8eFE8dzZfFW/DxCGRywBQCXeuJBzWbKYqKInfLVlLefofHgKJOPpD6PYXjxmPXq2etXtRbut3CprhNbIjdUGWwi5QSc35+zWOtfA6SkzGlpiJLSirKPVe+8dHznK7b2pZFCGw6dcKudy/tvurdW7vHHWr35suSEkxbdvDUigwK9pVh0p3hSG8Xhj36Pr7BWk+F++zZFOzfT+qCj0h68y3SPvsMj9mzcb3hBkQdoThSSvJ37iR1wUcURUZi7e9P+3f/g/O0aSQUJuKib5t41HKUcFMA2o26ZekSEo5FMvWJuSAEaxbMY+3C95n29AsNxmhVZtuyzzGVFDPhgUebHQcQ0G8QO779ktyMNJyMNQPFYyJS2fTVMWY+PxD39lU9X/HHjgB1x7dVZ8DkacQcOsD25V9ga2/P6dAQTofsxVxmwq9XX8bccS+dhwyvt+u4uKyYJ7c8SWxOLJ9c/QndjdqyQPZOzgy9/mZ2fvcV8UcP1yusehh7EOQSxO9nfufmLjcRHXaAgL4DK9qNP5aBs4cdLp4O9A32JWrneaJ2n2fg5I749epLdNgBgu9+sFHHLKVk94rlOLi4MmDytcQfO8LRbZuIiwwncMAQMpPyOROeyqCJ7bHZ9wB0HAWBwRUj+0RiBF2HdSXkt70gJZ4B2g9RdnE2szfOJr8kH2s7ax7e+DBTAqbw/JDn8XLwqtem4rJiXtz5Ii62Lrxx1RsXHUMyNXCq5nWLWMxY37E16ju8NZ4Df8YybU5fvDs5E5YcxuB2g6vkMxcXk/7Z56R/+imypASHYcPwmvscThMmIBr5h8bG1xevZ5/B8/HHyN28mcyVq0j98ENSP/wQgP6WVy6foTcaK0SBbY/uWFtEgm3nztj16FHRZdkQVm5uuMyYgcuMGZhLSijYH0Le1i3kbtlK3qbNFfmMAtKDBnLO0JGhXbIJemY5tt261eqdklJiSknh9N51/PLbu0wptoLNW8j+8aeKPHp3Y62CtrismCURS+jn2Y/RHUYzxncMRlsj7+x/h0c2PsJH4z/S5v86Fwbpp7G67mkcB16IWdqRsIOd53Yyd/Bc3B08oOcMCBoP29+FvYtAmuGun8HZp+L43e+/D+O991Cwfz+ZK1aSsWwZGUuX1jgunbNzhQgzBAzFytsbvacHK44spzQlhekunSE9h8KjkZi2pCCLimo958LaGtsePXCZcR12Fu+kbVAgOWX5PPjbjQjRjvCybL4pWsQI3Qjm9J9TZ6C/89SplDxyK09/eT3XJnozOd5I2uIlpC36BCsvLxzHjcNp/Djs+/enLCsLU0oKPZLTuSvChbS973POsL2SGE1FFhTUPG6DoUKE2g8ciLW3FyajC8tjfyAx/zy3d7+drsamdTVfFFJSmpJCUeRRCvbtJ+e33y2G6rANCqr4s2Lfuzc6Z2eyf/mVrB9/pCwtDev27fF8+mkih3sx7+h/sE/5Lx+m+jDAawBCCAzDh+MwbBj5u/eQ+tECkl7/J+mffobHo4/iMuO6Ck+5lJL8PXtIW/ARhRERWHfogM87b+Ny3XWczovlzV0vsPHsRr6b+h19PGsOfLtUKOGmACBiwxoOb17H0Bk3VSxBlJ+ZwfblX2D4+nPG3du4ZZXOHgnn+O7tDL/xVoztmz6PVjkB/TXhFhsRRp9xk2qkR0ekUVJoYsuy49z4wqAqnreEqEjsnZwbPSmt0OmYPPspvn7hCdYsfB9bg4H+k6fR9+opuHdoONC3zFzGSztfIjQ5lHdHv8twn+FV0gdcM53w9X+y/ZsvueOd9+uMORJCMD1oOvPD5nP46B7yMzMItKyWUFZmJuFEJl2Hat4+9w6OdOjmypHtCfS/2o/AQUPZsnQxGefPYWzf8IjGs0fCSTgWybh7H8Hazg7/3v2xdTBwct9uAgcM4dDGOPRWOvo6b4T8FJi1HISAdn0AAYkRdBs2hn0/aTO2e/p3oshUxJNbniQuN65iyoClkUv5/PDn7Dy3k8f7P86t3W+tM2Ztfuh8Tmed5pOrP8HNrv54w8ZgrbPmob4P8c89/2TXuV2M9h1dkZafXcy+X6IpLS7j9wXhDH3Qh9TCVAZ7X4jjydu5i6R//YvSuDicp16Dx+OPYxvY/JgnYWOD8zXX4HzNNRRHx1AQEoLezQ3haeS2kMcZ3ONq3hj7drPrf3vf24Qmh/LCkBeqeDl1NjY4jh6F4+hReL/2GsXHjlF49CiFHdy5IfJZ7j5zJ24OBgY9HYxOX3e3oBACa29vus24iw1FX1DQoSfvjPoZ06kICv87FSjD6Ym3Ef1qTl68+sRqkguSeWfUOxXPkVndZ+Fq58qLO1/k3nX3smTiErwivgcrO02YWSgtK2XegXkEOAdwe/fbL1Rq6wST3ob+d0JekvbHorrNOh2GESMwjBhBaUoKedu3o68kWKw8PWt4LMu5NmcMN/52I2d8dCwYv6wiztScl1fFcyVLS7Hr2RPbzp1rFfPv7HmHtMI0vpn6DUGuQaw6sYqlkUu5a+1djOowisf6P1YjvlFKyRt73iDVw4rr7v8cH0efql7U338na+XKGm1NB0qsIMc7FHufDtj16omjp/ZHwMrLu+JPgZWnV40uydKyUh7c8CCHrVP4MPgjhjZh8ElrUJqcQtHR8vCASPK2byf7558vZNDpcBw7Vgs/GDUKodcTDHzbsQ9Pbn2S+9ffz6vDXq2YTFsIgeOokRhGXkX+jh2kLviIxFdeIe3TJXjOmYOVtzepCxdSeDAUKx8f2r35Jq43XE9MQQLv7HmZ9bHrcbB2YHa/2XR0adtRrEq4/U0oyi/lx/+GEnxHNzp0rfqjGBcZwZavlhA4cAgjKw0kGHztDeRlpBP65y84Gt0bnOTVVFrK5i8+wdXbh6HX33xR9nr4dcTRzUhseO3C7fzJTBycbUiJzSFiczwDJl4QaQnHIvHt0btJHhtHozs3vvQmmYnn6Dx0RKMXNZdS8t8D/2Xj2Y3MHTyXqYE1pzCxtrFl5Kw7WbfoQ07s3Vlv9/G0wGn8L+x/bNv2IwhBpwGakEiOyaG0qAz/HhdGlPUN9mPtkiPEHk4ncMAQtrCY6LAQjO3r72LUvG3LcHL3pO/VUwAt3i9oSAO0mAAAIABJREFU0FDOHNhH9s35nNiXRK8RHjiEvg+dJ4K/RYzaOoF7Z0iMwDXYAXtDNnlFNhiMRubueJ5DKYeYN3YeQ9ppqzo82u9Rru10Le+EvMO7B97ll9O/8OrwV2t4Gvac38M3x77htu63MarDqIZPfCOZHjidJRFLWByxmFEdRlXcE/t+PkPZ/7N33uFRlPsX/8y2bMqm915J70AooYciRRCVqIAgdpRrvdYL9s4VO9hARBFBqdIhQOg1IaSRRnrvve3O748JCTEBAsrV+7uc5+FJmPLOOzubmTPfco5Wx7SnQolZlcLhr/Ow7OdImHUYbcXFlLzzLnU7d6JydcV5+bdSGu9PhJ67G3ruXeky79qhHCw5iiiK1xVpLGko4Ze0X5AJsitGOQVBQO3nh9rPj63JP+BaNQhq9Bgy0+OKpO1SyAQZEXYRHCs6BoAybzNKx0bQ2MHxTyFoukTyO9DY1sjX574mwjaih6fmeNfxGKuMeXLfk8zeNosvszNw9Z4I6i5NwtWpq8muzebzMZ93k8rphLWP9O8qUFpbY3Zn3+9LLsYuLAhdwOJTi9l+YTsT3SciCAJyjQa5RoOeR++SKZdia9ZWtl/YzuMhj3eSszn+c7iz352sOb+GFYkruHvr3Yx0HMn8kPn4WvgC8Gv6rxwvPs7CQQuxM+qKIv4+itqSdh65hUVnZLbRRM3YHVOZ6jmahYMX9vlcRVHkzeNvcqb0DO8Pf/+aOoZvFJQ21ihtrNGMlrrlRVGkvbiYpsRE2otL0IwZjdK+p/iyp5knP036iedin+PVo6+yPmM9o5xGMdppNG4mbhKBGzECw+HDqd+3j7JPPqXw+RcAUFhbY7NoIaZ33EFuUyHvHV/EtqxtqBVqHgh8gDn+c67LGeLPxv+m7PD/ICoLG6guaeT45qxuy6uLi9iy5F3M7R2ZuOCfPVKiI2bNw2foCA6u/o7k2JgrHuPk5l+oKipgzLxH+kx8LgdBEHANCSfnXFwP2Y36qmZqy5sJHeeMW7AlxzdnUV0ipQJqy0qpLSvtc5r0Uth6eOEbOfKqcy/OquGn148TtyuXb+NWsDp1NbP9ZjPHf85l9/EdNhIrFzcOrfme9it0ltka2jLQbiCVSWnYeXpjYCzdJPKSKxFkAg7epp3bugZZoDFXk7AvDxNrGyydXDp1366EzNMnKM5MZ9Dtd3WTW/EaFElzQz2H1sQgihBishuaqmD0y90HsA+BongA5IoqECxZvOtzYvJieH7g8z0635yMnVg6ZilLRi6huqWa2dtn8+qRVzv9Daubq1l4aCHuJu48Ff7UVed/NRS99hrZd91N+ZdfocvK5v6AeSSUJ3C06CggkeDUY8WEjHHCwduMaU+H0aZo5taUxxB/OEbmxEnU79+P1ZNP4LZ5059O2npDpEMkpU2lpFenX9f+a9PWohN1/DLlF+aHzCcmN4ZbN97KD8k/0K5r73Wfnem7GVQwGXsvU1wCr81ya5DdIMqaysgqT4JTy8F3Mox8Hgrj4MKBbtuuTl1NZXMlj4f23lk92H4wy8cvp7mlljnmapI8uoh7RVNFJ+ke7nj9zhyZZfW88VsyIz/Yx6xvjvPejlS2nysiv6oRUby8zuIs31kEWgbyzol3qGiquKZjFtYX8taxtwixCuH+wPu7rTNQGjAvYB47bt/BP0L/wZnSM8z4bQZP7nuSQwWHWHxqMQNtB3JHv95fli9GUS3uvx/TadMwHDIEPU9PzKwcGe82gd+yfqOhraHPc12dupr16eux1k5i2TZjPtmbTnJh7RU/m/80BEFAaWeH8dixmM+e1StpuwgTPRM+H/M5z4Q/Q5u2jY/PfMzUTVOZvGEyH5z8gJPFJ9GKWjSjR+O2/lccP/8Mu7fexGP3LhomD2PhideYumkqMbkxzA2YK12nsH/8LUgb3Iy4/c+grlKqyyjKqKEooxo7T1NaGhvZ+MEbIIpM++dC9HopABVkMsY/+iSNNVXsXPYxBsYmPTwzAaqKCzm+YS39Bg/rdf31wDU4nMR9uynKSMPB27dzeUGa9MB36GeGV38bfnr9ODGrUrjt6TDykjvq2/rQmHA9EEWRw79kUF3ayJH1GTQqzZkR8AhPBj10xf1kMjnDZ97Hr28v4uyubYRPmnrZbW+xHE121Wr0I7tSzbnJldi4GqNn0EW0ZHIZASMdOLo+k4qCetzDB3Jqy3qaG+ov28kr6nQc+XkVprZ2+I/oLpPhGhSKUk9N5qmj+A65E+NzH0p2Qfah3QexC4Zz6xDrSmmsLkSm8CT7VBX3Tb6Pmb4zez2uIAhEuUQxxH4Iy84uY1XyKvbm7mVi0+M0nG+l2bOdT297B31F72mrvkJbU0P12nXITUw668hCnRx51FGPbTXvE/HQzxxcm4aBsYrwW1wB0JiruWD9DX5ps4iJN2bogCj6LVzQa9PBjcIQe4kcHi44TD+za6sratG28EvaL4x0Gom7qTuPml49yplbm4vinA2qVgOGTPe85ijfIHspAnvs9FI8mqpg8OPS92TfO3BoSWfasra1lhWJKxjuOPyy9VwA/pb+rJQ58TDJzEv5ik/sAoiwi+DTuE9pbm/muQHPXdP8AFrbdexKLubHY7kczapAIROI9LKkvL6Fr2OzaNdJpMTcUEWggwlBjiYdP02xMdaTomsyOa8PeZ0Zv83gnRPvsHjE4j4dW6vT8vKhl9GKWu5w/idvbT3PkYwKmtt70370RCa8jL7+fmKy97M3dy+CqMKiaSab44sIdDTBzcKw10as3hDtHc3mzM38lvkb0T7RV91+ZdwuFp99n7Z6P2prRqMxhSV70vhwdxoOpvpE+VoT5WdDhJsFKsV/T6xHIVMwN2AucwPmUtxQzIG8A+zP389PqT/xffL3GKuMGeY4jJFOI4kcFklDaw1LTr/NpoxNKGQKZvrOZF7AvOsW476RuEnc/kdQXyURNz0DBWd25TLR3Zhtny2msjCf2196HVPby4t2KpRKbn3mX/z86vNs/vAdol99Fxt3z871oiiy99ulyBUKRvWxOL4vcAkMQRBkZJ893Y24FaZXo9JXYOFohEwmMPQOL2K+TyExtoDC1ETUhkZY/U6e4s9CTmIFxVk1OE6UszT3I0aW3Il5nC8/Zh0nfIIr/pH2yJW939xcg8NwCQrl2Po1+I8cc1ly5VxuRDaQaFLMbUhp7tKcWgZM6tmJ5jfUnpNbLpCwL59+AwZyYuM6ss+ewWdI79GJ80cPUpabzcQFz/bQfFOoVJjZ+1OanUyI6U4orIdRL/ccxE56ANemHKS1qZFqyxb8q4YxP/jqwrUGSgOe7v80Uzym8MG2zzE8YYaxqODu1Jewb3e96v5XQ/3ubaDV4vTwMBQTnqZ+/37qY2IYceQQsqPnObD1cUrc7mZIaBvytibaG9vIfecNHt6SSrX9N6QGP8tx+WTsBFP+k7bvNoY2eJl5cbjgcO82TlfAjgs7qGyu5B7frvqvi1HOvbl7effEu8zePpvbvW7nybAnMVWbsjVxJ8GFo3AMMcbG7dqt0hyMHHDSOHEs/yAzHfqDU4SUHh08H3YvkpoMHML4Pul7altrWRC64MoDNlXhmrGfVaEzeVibw6N7HuWhoIdYn76e2X6zcTPpuytHXmUjP53IZe2pPMrrW3E00+ef472Z0d8JK40UTW9u03K+uI6EghrO5VeTkF/DF/vL0XaQOSuNHkEOJgQ6SoRuts8DLE9eygTXCUS5RF3x+DVNbbxx8HNOlZyCsmieOJeHnkLGIHcLzAwu1+BkCtxNm3gr+dq9NDdasfl0C2uPSZFtIz0FAQ7GBDmadpJMZ3ODXgl3oGUgvua+/Jz2MzO8Z1yWlJ/JreLd3QdJFt5EprPmyaBFzB3sg1opp7SumX2ppexOLuXnU3msPJqDRk/BcG8rxvraMNLbClODa1MbuBxEUeRkdhWrj+eQV9WEjbEe1ho1NsZqbIz1On9aG6vR6Cmuq5TA1tCWaJ9oon2iaWhr4GjhUfbl7SM2P5atWVulultResGM9o7m/sD7r9pM9VfiJnH7H0FJSSVavVaafEvIPt3O7m++Jev0CUbf9zAugZd/E74IPQMDpr/4Gj8tfJb1777K3a9/0En20o4dIichjlFzH8LI/M973KmNjLDz8iY7/jRDZ8zqXF6YXo2dp0nnG6jPYFsyTpVwZEMmsvYEHHyvLjp6PRBFkeObs9A3l/N2zfM4OTvy+EO3UpPdxoktFzj4cxpxu3IIv8UV3yF2yHt5Ox12z1x+ePFJTmz6heH3zO31OAVnz6LVKNleF8vz2lbyU6tBBGc/8x7bqg2V9IuwJe14MRFTB6GvMSbrzEmJuO1+BcxcIPw+EAR0Wi1H1q3GwtEZ7yHDeozV1qqlvtYJxNM0nfkWBtwJ1r49tpMaFGB/3HYAtJ5y5Of1KEitwSWgb9ffWc+VgNPTaJQ1scfmGHdWjWD94tNMfjwYa5fr9Fy9EEvd8teRq7Wos5YiVA7FLHoGZtEzaKqr5qXF0+hXNAnjxnz0lrxL2mcKZCoV2pZmNg4WuPX1N7hN5cfGD8+w6aM4pj0Vhrn9n2823ljbSsqRQsrz6xlxtzdqQ+lhHmkfyaqUVTS2NXbzZb0SRFFkdepqPEzciUjdBxmHYZgk5HC5KOdT4U+RE9OIg6hg5O1+130eg/Tt2SbPoa3/IygvPkzD74PYf8Phj6i69WNWJa9inMu4zi7ryyJpI2hbsQ6by3cWbiyIWcDn8Z9jrjbn4eCHrzqXdq2OfefL+PF4DgfSyhCA0T42zBzkzHAvK+S/i1aplXKCnUwJdjIFpELzplYtyUW1nUTuXEENMedLkbKFjph4OvDc/le4x96cAS5OBDqYYG4okZe8ykb2pJSwJ6WEEwXn0HP5DnlTEONdpjB2oi2Rnpboq/ramR/ZeU4ZZfXSXPJrSCio4bvD2bRqJXkYY7VCInKOJp0k08FUH0EQmOE9g9eOvkZ8WTyh1t0j5gn51SzZnca+9Dw07kvRVyn4adI3eJp3Fdxba9RED3AmeoAzTa1aDmeUd5xfKVsTipDLBAa4mhHla8NYPxtcLK7976SmqY0NZ/L58Xgu6aX1aNQK/OyMOV9cR2xaOfUtPVP8+ko5NsZ62Jno429v3EGsTXExN+hzRNJQaUiUSxRRLlFodVrOlp1lf95+dKKOWX6z/pCrw38KN4nb/wDSqtI4knYSlcKArbKlRLdFc27vbloDLKnx09Dc3oxacXVLECMzc25/6XV+WvQcv769iLvf+AC5UtVpIh8ybtIfmmebro2VSSsxVhkzw3sGAK4hYRxZt5rG2hoMjE1oqGmhuqQR36FdEUJBEBg5y4cfF+2htryE0Fsm/6F5XA5ZcWWU59WTErwXtUqPL6K+wEhlhFE/mPa0KfnnqzixOYsDq89zZkcO/Se64j3YFvklRd82bh74RY7kzLZNhIybiLFl97e6ttYWcs7FY98/kLq2DA7kH0CR7IhKX4G1i6bXeQWNciT5UCGpR0twC+1P1pmT6LKPITv8kbRBwWmY9CHJB2OpKirg1mde6lXeJeVwEVqtE3K5jLRqE5xHvtD7B6FvyjlLVzbknScAE56Z8082vJXC+WNFfSJuoiiy+etz0KilKMCMjPxw9MbbIYstZ+OHcUx8NBBHn54k9bJob4V9b6GL/ZiGPDuMo0Yj2KfAxsfAJgDM3dDXmOLv9BQtJRocH7PB9ckfqI+Job2sjHUROjY2HeA5hxAUMgVTnwpl44dxbPwojtueDsXM9o+TN1EUKUirJim2gKz4MnRaEUGAloY2Jj8ejEwuY6jDUFYkreBE8YnO4vDEghqWH75AdWPvdZF1ZJAqJDO/SoFQvR+Ak6I/AYPGdhKFS6Ocbx57k893fsu0/KcwCm3FxOr63S4GFaWzTi4jycqNzlc/tTEMfAAOfshyO2eatc3MD55PQXVTJyHKKmvA1ECJ9cWIikbN4JM/oGfhjWAThIlcxpdjv+Sj0x8x1GEoxiqJyDe3aSmtbaGkrpmS2mZKalsorZV+P36hkqKaZqw1eiwY7cVdA5ywN722tLu+Sk64ixnhLl3NWw0t7SQV1pKQX82RvEc42foK3yR/zGd7pfuTo5k++ko56aWS7ZantQobj18R5GZsiv4Mc/3r745WyGX42BrjY2vMjP5Sd3tru460kjrOFdSQkF9DQn51r2lfX3sv1HIDVp5bTcjoEARBILGgho/2pLMnpQQTAzkBIb+R31zO51FfdSNtvX0uUX42RPnZoNOJnM2vlkhccilvbk3hza0p9LMxIspX2ibE0fSyJEoURRLya/jxeA6bzxbS3KYj2MmU9+8IYkqQfTdyW9/S3nF9Wyi95JqX1DaTV9XE98dyaG2XSKxGrSDwYoTUwZQgRxMczfSvGp2Ty+SE2YT1ycrr74SbxO1vio0ZG5ELcia7T/5DelZxpXE8tvcxJjcvwNPZhZlDv2DjnlcQFPbstctl9b4FqOVqBtsPZpTTKIY5DrtiTt/c3pHbnlvEujdeZv27r2Ht5t5pIi/7A6KEObU5vBD7AokVicgEGd7m3gRbBeMWHM6RtT+SkxCHb+RICtM76tu8ut8QNeZq3EPaOLcb2tr+/DcmnU6KtglmrcTqb2FxxOJuoXRBEHDyMcfR24y85EqOb7nAvh9SOb0jm3H3B3RLRw2Nns35Y4c4svZHJszvXoyfl5RAe0sLgyInY5lxkC0ZWwhPicbRx+yyXX8WDkY49DMlcX8BAycPIDk2hsJtH+OoNoH+8+DQEtpLznM03gEbdy88B/QUxNVqdcTvzsXeVYMyq4z0JgdGm7n22r2UXZPNYxoZg9IUGNvYYGFuhVd4JSlHi2htakelf+Xbytm9eZSmVHNco+OTuaHEfLCfzOZWXngunM2fxLPls7OMvc8fz/A+pCrK0+HX+6HoLI0mk9G1ncFo6l0Q7ArLhsO6uXD/LmqqdLTHG5Njc5b4miRGjfsagzDpZn1g83RCrEI6ZUrMbA07yNsZNi6J47anwy7r3Xk1NDe0kXq0iKSDhVSXNKJnoCBwpCP+w+wpyqxh36pUjvyaSeQML0KtQ9FX6HOo4BC2yjA+2p3OjqRiNGoFrr1FNEQRud5KjJQ6pteW84HRs8yuW45qz4uE7dYy1NOGsX7WjPaxwUqjh5eZF2+6LmHL9jhaDZqYfOcfaLooOE1EfgKCiyNHi08ScokdUpnfXNqPf8GPmZsxZTAzPsuioiEVAIVMwNnCgLrmdsrrWxBFcBJKOKh3ivfa7uLLf23HSiOlx6w1USQn6niz9gAltS3UNPUkryqFDBtjPXztjHllij9jfK1R9rE7ti8w1FMw0M2cgW7mPIA7n8bl8VXCVzw15E5o9CWhoIbapjaiBzgR5WvDT5mfsDq1gC9Hf/mHSNvloFLICHAwIcDBhLs7xPt7S/seyihHYRXMnrbdDHh3E04mVsTlVmOsVvDsuH40Gm1hVcopXo54mYF2fXcBkMkEQp3NCHU245/jfcit6Io0fhmbxRf7M7E0UjHGRyJxFyONDS3tbD5byI/Hc0gsqMVAJee2UEdmRjgT4NB7wb+RngIjKyPcrXovKWnT6kgvqedcQVeEdPmhC7RpJRJraqC8pHZRInN2Juq/1GP0z8JN4vY3RLuunbePv01TexN7cvbw6pBXr0vX6kDeAZ458Ax2hnZY6uywMFGx5+MlGJmaoWUq/zL0QDWikv15+9mft599efsQEAi0CuQu77suSxrt+/kw+cnn2PTBW5RkpRM8blKfTeR/D1EU2ZixkXdOvINSpuTNoW/yWfxnLDq8iHVT1mHj7om+xpjs+NMScUurRqknx8q5lz9mXT4yuR7n9jcTOLIFI7M/1tl6KdJPllBV3EiM9xqiXKMY59pTogQkAufsb4GTnzk5iRXs+yGVw7+mM/3ZroYNYytrQidM4dRvGwibOBVr1y5tsKzTJ1HqqXENCGGSdhK/ndmFd2UL4ROuHIEKGiVJgwhyT2QyGVmJKThOnwdRr4JdCInfLKK2Qs3Y6RN7vaYZp0qpq2xmuNsRWioqScuzoDA1pUd3bnlTOY/seQRkCjyqZNgGSTIs3oNsSYwtIDOuFN8hl+/2Ks6q4fD6DNIVWkbf6oGFkR4e1kZklNZjaKrHbc+Ese2LBHZ+k0hzgzcBwy+jSSeKcPo72PEiKPUh+kfq1p5G0E/BcNAgUKvhtqWw5h7Y+TJH8ucgyAR8J1ryYeox4kvjCbEOoaalhvSqdMaFdL+e5naGXZG3JXHc9kxon6NToihScqGWxNgCMk6Xom3TYetuzJi5vniGWaPoiCqY2RpSUVDP2Zg8zB0M8Rtqj79ZOJvOx/DNxhA0ekqeGOPFvEg3TPR/VxvVUEHJpkeY0JrPPYIZNk/u4Z/GdrTHeWG76WHedk5kcZE+e1JKEIRzhDiZEmWkQThegZm1EVP+EXndfx9NrVq0+z/GUG6Ig9qDjef3U1U4kqyOtF5pXQvD7LzQUYVV9UAG+lhLD09HU3xsNaiV0vm3a3WU17fCgfcQzwh4Rs3jsTbTzshKflUTaqUcN0tDBrlbdJC5izVPUrTORF/5H30QPxz0MDG5MazL/ogNUzfwsKpLEuRQwSFWp65mlu+szmaT/wQul/bdnWHLyyeP4uycSHvVyM7v0qGiXbxwcAV39ruTaO+rNy9cCc4WBsyLdGNepBs1jW3sTytlT0op284V8fMpqbYv3MWMhPwa6lva8bHV8Ma0AKaF2KNRX78XNoBSLsPP3hg/e2OiJfUhWtq1pBXXk1BQzbn8Gs7m17DsQFZn7aKlkaojMmdKUAepszb+cwzo/5O4Sdz+hjhfdZ6m9iZGOo0ktiCW2zffzpuRb17TzWBz5mYWHV6Ej7kPH0d+yrod8WSdXklzQz13v/4B52JbOH+kmHsnD2FIxBBeHPgiaVVp7Mvbx66cXbx06CX25e3jlcGv9NoC7REewfhHnyBp/55rNpG/iJqWGl47+hq7c3Yz0HYgb0W+ha2hLeZqc+bvnc+ys8v4R9g/cAkKJTshDlGnoyC9GjsPk16jT/kpSTj4+FFVJnBgdSoT5wf9KTd1rVbHiS1Z1JuUU2KbyZcRV+8sEwQB10BLQqKcOfJrBmW5dVg5d6U6I6bNIDFmFwdXf8ftL70OSA/8rDMncQkKQaFSMcVjCqf3SvItvdW3XQrXIAuMzPVIOVKOo40+WZXmDB8o1Qa1eU7gWP3POGjKcDmyACx1EHJ3576iTuTMzhzMbZS4FCyhbfh9KNZmkXb8cCdxa9O2cbL4JEvOLKGyuZIvvR8m5rcNWJlIN18bN2NMrPQ5f6z4ssStub6NHV8nUi+D8y5KPhjiCoCntREH0iQhX7WhkilPhLDz60QOrD5PU10r/Se6dr+ODRWweQGc3wruo2DaUkSNLfUxizGKHNrlx+kzCQY/Tv7+A2RVTSTiVnf8wgay4sJXLEtYxrKoZcSVxgH0aixvYW/E1CdD2bQkjo0fxuHRhwhgYVUTZZk1UN2GQk+O72A7/IfbY+nYe5p76O2eVBY2sH/1eVaeK+BQjQVq2zLuHWbE06OG9F4AnrEXNj7KWlUbWhMj7pq2ussxICQaTn/LbRXfMO3JR0ipFNiTUkLq4ULEhDIK5DrWqxo4tz8NA+XVI+Q6EaobWzvSk1KaStNcTKzeFpZrbyEz3wKVRSwrE1NxNjMn0ssSF+tmVuTWMb22kUV+F2Dc/b2OrZDLsDXWgwsbwG0Yt4+K6HW7vxNUchWvD3mdWdtn8eHpD3llsGRjV9VcxcLDC/E09eTJ8Cf/4llK6c1b/cJYnxtOScNhtj72EjJBRmJ5Iq8ceYVwm3BeHPjin0p6TQyUTA1xYGqIA63tOk5mV7I7uYQjmeWM87dhZoQLYc6mN5Ro6ynkBDpKKVM6vk7NbVpSimo708vn8ms4kJZOB5fDxliPQAdTXCwM6OvM7ot0w+EaU/F/Jm4ocRMEYQLwMSAHvhFF8d3frXcBlgNWQCUwSxTF/I517wEXi6beEEXx547lbsAawAI4DcwWRbGV/0eIL5U6iV6OeJnqlmqej32eh3c/zL1+9/JE2BOo5Ffu5lmZtJLFpxYTYRfBx6M+prlMRNt8gtrqC0x+8gWsXd0J1Wsg9WgRCfvyibjVHUEQ8Db3xtvcmwcDH2Rl8ko+jfuUs2VneTvy7R7CmQD+I8b0kJToK44XHeelQy9R2VzJ0+FPM8d/DjJBImPDHIdxq8etLE9czliXsbiFhJN6+AB5yeepKmrAO8Kmx3gN1VVUFeYTMDIKbyMPDq1LJ+1ECd4RfzxtmnqkiNryZmJ9fuWFiOevqT3cd4gdJ7ZkkbA/nzH3dhX6q42MiJgezYFV35KdEIdrUChlOReoqyhj8B0SqfI298a7MZwmwxqMLa98k5DJZQSOcOTohkwClcWcbNFQ3SRgagzxu7bRUFvH5OdfQ0h4BzY+AiWJEPUayBVkxpVRWdhAVMARhGolqlH/xDXtG84fP0R9pB0HCg5wuPAwDW0NGCgMWDxiMTZVamAjVmqptkcQBLwH2XJiywVqK5owtug+X1Ensue7ZBpqWlhv0Mz7Uwd0prS8rI345XQ+NY1tmBgoUark3PJIIPtWpXJiywWa6toYNsNL8hTtIC00VcH4tyHiUZDJaE5Mor2kBKPR3R+aulGvcHDHejTyMkJCnVAoDZjjP4ePznzEubJznC45jUKmINCyd/saS0cjbn0yhB1fJZJ88Mom21qdSHOblkq5yFn9dlJUWhwKCgk82NhZPO5vbyxFGhoq4OxPlOm5cNrUCJWoxfJsLXePjmJD4ya83Qt6kra2Ztj7Ghz7glYrb34xVzLCJgwnk0scQgQBbnkXvh6NcPDf+Ea9RmN8BfJCLbY+ZpgOMKMorYwtZwvR6fqm0WVqoMLGWA8vayMiPS2ZVroZWYFA6G1kd9StAAAgAElEQVQv8I6qgldP7uerh8wZ4SQJSy88vBC5IOchm6FwaoXULHG5tGH+Sai6AMP/2ae5/B0QaBXIHL85rEhawXjX8UTYRvDqkVepaalhWdSy6zJ4v1GI9o7mudjnOFJ4BG8zb56IeQILtQUfjvywdzHjPwkqhYyhnpYM9fzrpTTUSnlnevciGlvbSS6s7UyxJuRXczSzvM9j3hpi//+TuAmCIAc+B8YC+cBJQRA2i6KYfMlmi4HvRVFcKQjCaOAdYLYgCJOAMCQLPz1gvyAI20VRrAXeA5aIorhGEIRlwP3A0ht1Hn8F4kvjsTW07fy3ZvIa/n3q33yf/D3Hi47z3vD38DDtqdotiiJLzixhReIKxrmM451h76CSq8hIjaO9+Tiunp5495dqUcztDHEPtuLc/nxCxzmjUnd9FeQyOfMC5hFhF8ELsS/w4K4Hmes/lwWhC/7wH3ubto1P4z7lu6TvcDF24dOJn+Jn0bOz7bkB0s1m4eGFfBspXd7EA0cBV+y9ej4E8lMSAXDyC8TGw5GM0yUcXJuGk685BsbX37be3qbl2G+ZlGpycAuwYpLbtTVgqA2VeEfYknq0mCHTPdA36ppLyPjJxO34jdgfV+ASENwpnuseJsX9te06rKpcSDQ/THZNKK4mrlc8ll+kPSc3p9NIGJBO1pkTBIyM4sSmX3AJCsUxbCgEb4CdL8PRz9AVJ3PG7G1O7ijGzFKOZ9kScgfNZV/uDuL0E3GqquOjra8j2muY4DqBUU6jiLCLQK1QczZF6ii10uV1Hr/fQIm4pZ0oof8t3ecatzuXnMQKYjVaAgOsGNHPqnOdp7WU9s4oqyPcRYosyuUyxtzri76Rkvg9eTTXtzDGfg3yE5+BlQ/M+rWzuxWgPmavZIEzsrsrRdKRUiqbrJlg/TmKDR/Dg3u5y+cuViSt4MuEL6lqriLQMvCKzTlWThpmv9GzLvBSnMmt4p6vj+FlrWHZ7HAulDWQUFBNQl4NZ3Kq2HJWIn2CAO6WhixSrGJE1S/YAK8DuTYh7Ch9EeczTcQH2nE4b393TbySZPj1AShNgoEPscMjgspjr3W3gLoIh3AImYl4ZCkHC6dw7mgd/SJsGH2vL3K5jFlD+y6t0QPNtbBkM/jfxoCQIIK0LbxzRo9jRccY4TSCCzUX2Jy5mZm+M7F1mghJm+HkN5cnZmfXgEIf/G69/jn9BZgfMp+YvBhePfIqs/1mE5MXw7P9n8Xb3Puvnlo3RDlHYa4254eUH6hrqaOurY5Vt6zCXH0NzT//D2GgUtDf1Zz+rv+dn8ONVNMbCGSIopjVERFbA/xeddQPuCjHv++S9X5ArCiK7aIoNgAJwARBirGOBn7p2G4lMO0GnsNfgrjSOEKsuiQ69BX6/GvQv/hs9GeUNZUR/Vs0a1LXdFO1bte1s+jIIlYkriDaO5r3h7+PSq5Cp9VyYv3XIKgZIW6FuFWd+4SOd6alsZ3kQ71HEvwt/Pl58s/c0e8OViStYOa2mWTVZPW6bV+QVZPFzG0zWZEk1VesnbK2V9IGkvL1vwb9i/NV51mTtx5rNw/ykuJRKGW9dlfmJSei1FNj7eaBTCYw+l5f2lt0xK45f93zBUiMLaC5pp2zrntYOHjhdYX5A0c5om3X9ficFUolkXfNpiw7i5TDB8g6fQJbDy8MTSViWpxVA20yCszS2JK15arHUauhn+FRcrQTMLNzIH3/Xk6uXU1zXS1DozvkVORKmPg+taO+YOPpMRzfVoS9t0CJ53tMd7JhUukuFp9aTIFtM8gF5qtvZ++de3l1yKuMcBrRSXDKci6gUoBxTWLn8U2s9LHzNCHteHG372ZhehXHNmXRYK3ijLKNlyd1XfP2qircCiW3gIyOzryLEDo0+gZP9yD9VBlbd5hTH/AYPLS/G2kDqNsbg35YKAqzLlLf3NDG8S1ZOHib4j7rEYn0bPsnhkpD7vW7lwP5B0isSCTM+o91lGWW1XP/dyexMVazfO4AHEz1ifSyZP5IT5bNDufwC6M59a8oVtw3gKei+uFtriC0ajs7dQNZ2e9z6ka8irO/B+Psv6e8Ss3o+NGczD9Cy8fBsO4+2PESfDVS8oy9Zx3iLe/zY/o63E3ce/jiXoR2xEJ21zzBuaN1BEc5ETXHr1t383UjbhW01MLgxwDQk+sRah3aaX+1NH4penI97g+4H2wDwGscHFsKrT1NzmlvgcRfJdcFvd5TyX9XqBVqXh/yOoX1hbx74l0G2g5ktt/1lYzcSCjlSqZ7TedwwWESyhN4O/Ltvx25vIlrx40kbg5A3iX/z+9YdinOAtM7fr8N0AiCYNGxfIIgCAaCIFgCowAnpPRotSiK7VcYEwBBEB4SBOGUIAinysrK/pQT+k+guKGYksaSXlXGRziN4Ndbf6W/bX/eOv4Wj8c8TkVTBc3tzTy1/yk2Zmzk0eBHeTniZeQdcg+nfttAbVkuKsNRmCvL4UJs53i2biY4eJsSvzsXbZuu1/kYKA1YNHgRH4/6mKKGIqK3RLP2/No+W6GIokhBfQGrklcRvSWa4oZiPhn1CQsHL7yqSv4Y5zFMcJ3AsoRlmHi7U19xASsXvV710fKTz2Hv7dspKmtma8iAya5knikj43Rpn+b6e7S1aDmyNY184zTuHXc7NoY9U7R9gYW9EY4+ZiQeKECn7f45+wwZjrWbB7E/rqAoMw33sK4Or4s2V/ZeJmzN2opO7P0adSJpA4HKdbTrlBiaeFJwIYNT2zbh0X8Qdp5dN+v0kyX8vNGJcvyIsl7OOfmDfEcuVhoHXhj4Atunb2fd7RtwDxlAZUIaQi+VH2W52VhZGSNUZUFzTedy7whbqoobKcutAyTNsp3fJKE2VfF1Sw3zIt1ws+zqkCx9911aHn8Il+ZK0kvqexwHIMwjk9HGn5LfFsz3MWPZ/m0GuckViB2pvtb8fFrOn0czunva/sSWC7Q2thN5Zz+EfmOllF3cKoj/ibt97kaj0qATdb3Wt/UVpbXNzFl+ApkgsPK+gZ0Cr7+HpZEeo7yt+ccYL74IvoAxDUTd9wpz7pmFZtRTcMdyXF9ezeDJjihrB+JXNJ7TVm6QfwqOfQ7uI+DRI9BvHGfLzpJckcw9Pvf0+iLR2tzO1lUlpDcOYbDRSoYG50pp5j8KbTscWwYuQ8Ghi+wOshtERnUGRwqOsD17O7N8Z2Gh3yELE/kUNFZA3A89x0vfBc3VEHzXH5/bX4AwmzDm+s/FQm3BW5FvdZZ6/N1wZ787MdEzYUHogquKB9/Efwf+6m/as8AIQRDigBFAAaAVRXEXsA04AvwEHAV68wq5LERR/EoUxf6iKPa3srK6+g5/E1wslv69aOJFWOpbsnTMUl4Y+ALHCo8xffN07ttxHwfyDvBSxEvMD5nfeTOvKMjjyLofMbEJxNjIAZmgg+xDoOsiAGHjXWioaeX8ieIrzmu082jW37qeMJsw3jj2Bv+I+QeVzZXdthFFkeKGYvbm7OWTM5/w8O6HGf7zcCb8OoH3T75PuE0466euZ5TzqD5/Hi9GvIhGqWFb6wlARN+g5zwba2uoyM/Fya97FCZ0rDNWzhpiV6fQWN3U52NexOEdyYiNMhpDs7nN88rG7VdD4EhH6qtayIrvXkchyGSMmDWPhqpKEEXcwy8hbimV2LobM8nnFgrqCzq/G71CFOHoZ1ja6WHvZUJNsQWiINAu6ggPkohJa1M7e1Yks+vbJMztDIheOBjvZ94j31CDT7vIN1N/ZabvTBw1ktVTv4ih1FWUUZyZ1v1QOh3luRewcu5IuRUldK7zCLNGrpCReqwYnU5k9/IkWhrb2W+hw0Sjx+Ojuxw32quqqN22HUSRmQXHyCjrhbjVFsKvD+LrUsTMf4USOtaJwoxqtnxylh8WHeXMzhzKd+4HQDNmdOduFQX1JMYW4D/cAUvHjg7kkS+BSyRsfRpNdT7zAuZhqDS8ohXTlVDX3MbcFSepqG9l+dwBuFr2Ue/t1Ldg5YvcdWiPVaGTvHHvb8nAvMkcU02Ep87BS0Uwcx0YSc0Rq1NWo1FqmOIxpcf+TfWtbPoonvyUSkbN9CTM6SzCrpdAe3l/3D4jZTPU5HZG2y7iov3VcwefQ6PUdPfsdR4suSoc+bTnHM6uASMbcBv5x+f2F+Hp/k+z+47df2vRVnsje/bN2MdDV7Hlu4n/HtxI4laAFCW7CMeOZZ0QRbFQFMXpoiiGAi93LKvu+PmWKIohoiiOBQQgDagATAVBUFxuzP92xJXGoa/Qv6JfoSAIzPSdyZrJa7DQtyC1KpX3h7/P3T5dnYI6nZadyz5GqafG1H4CGlkxKA2hqRLKUjq3c/I1x8pZQ9yu3KsWK1sZWLE0ainPDXiOw4WHmb5pOmvPr+Xz+M+Zv2c+I9eOZOwvY3ly/5MsT1xOZXMlY5zHsHDQQtZMXsPSqKXX7PtmrjbnxYgXKazXAipaGjJ7bFOQkgT09CeVyWVEjjGmua6FtS/uofhCTY99L4fmhlYS9hSQZ57Cc1MW/OFOKNcgSzQWkiH87+EcEIx72ABMrG06pUGa6lspza3DydecMc5j0FfosyXzCunS7ENQdBYGP0bgcHtacUaJAofGVsR16ynKrOHnt06QdqKYAZPduO2ZMEys9MHEgSIzJ+zcRkniqZfAIzwCmVxB2rHD3ZbXlJXS2tSElXewtKDobOc6taES1yALMk6VcPK3C+SnVqEZYkVsWS3PTfDuJgFQs349Ylsb+mFhDEo9TGHe7yKj2nb4ZR60NcGMlZg4WDD4Nk/mvjOUsff7YWSm5uiGTDadsCFl4ALKW40RRRFRFDm0Lh2VWk7ElC6pFeQKuONbUBnC2jnc7xXNrjt2oVFde5qutV3HIz+cJq2kjqWzwjqkGPqAgjOSEXv/eVLB2+8gCAJj7/Wn0awC+T5nKgrqQdUlQ1LaWMrunN3c5nVbN3cFUSdSUVDPhsVnqMivZ8LDgfgNc5YaOMpS4eS313yO3dDxYoC5O/S7pdsqHzMfTPRMqGmpYY7/nO5d6IIgRd1qciFxfdfyxkpI2wmBd0rX5b8YN7LI/8+CUvb3n+NN9B038i/mJODV0QVaANwFdKuk7UiDVoqiqANeROowvdjYYCqKYoUgCEFAELBLFEVREIR9wB1INXNzgE038Bz+44gvjSfIMqhTDPRK8DLz4udJP1PVUtXDVy1+x28UpaVyy+PPcHq7DBuxEPrfJ918LxwEG39AelCEjXdh59eJXDhbhkfolSUPZIKM2X6zGWg7kBcOvsAbx95AJshwN3FnmMMw/C398bfwp59Zvz65MfQFE1wncErIQ1AmUZh5FlEUuxGpvJRzKFR62Hp69dhX+O0HQs/GkeQ7l/Xvn2bgFDfCJrhe1R5l7bq9yNv08J9gjYPRZbTErgEymUDgCEeOrM+gLK8OK6fuZGHyUy/Q3tLSeV75qVUggpOfOQZKA6Kco9iVvYsXI17svWvt6GdgYAlB0Vju2o+6pQFjjwcY7lLA6Q1p5Cw+jcZCzW3PhmPn0fVgFUWRooaiXqVm1EZGuAQGk378MMNn3tc5t7LcCwBY9QuGVHsoiu+2n3eELZlnyji1LRuPAda8klVEoIMJd4R1mbaLOh1VP69FPzwc20ULaZo6jeD4fTS2TsBA1fHdj3kDco/C9G/AqivVK1fK6DfAln4DbClLK+bIM19Q4hTJhn/HYWZrgIO3GfmpVQyL9kJt9LsHlsYWbv8Wvp+KsPVpjKd/deULJ4oSyWiqBHMPkMnQ6UT++ctZDmdUsPjOYEZ6X4On4alvQWkAwZfXz1Ko5FhOa6HsBwWbP4vjrpcjOpta1p5fi1anZYr17WScLqU0p5bSnDrKcusk8WO1nFufCO5q4PG+RZJM2f+2RJIMr9OSLveY5MAxcTH8zk5OLpMz1H4ox4qOMctvVs99vcaDla9kPh94p7R/0nrQtf3Xpklv4ib+Stww4iaKYrsgCI8DO5HkQJaLopgkCMLrwClRFDcDI4F3BEEQgVjgYgxeCRzseFDUIsmEXKxrex5YIwjCm0Ac8AdfJf8+aGxrJK0qjfsDe9c96g1KubIHaasuLuLgT9/jHjYAnyEjOPDTPjz1yyHgPkj9DbIPwqBHOrd3D7XCxEqfMztycA+x6lN0ydvcmzWT15BVnYWLsUufvRWvB4Ig4NEYQKZxLmJFJuX5OVg5uXauz09OxL6fN3JF94d0W0kJ1Rs34TL1VswTfibRMJLjmyE3uZKo+/x6SFZcRF5pIZUnodY+m0eHzf3TzsN3qB0nfsvi3L58Rt/b3QNUqdJDqeoiZHnJlegZKDp9O6d4TGFL1hb25+1nvOv47gOXp0PaDhjxAij1qV79I86t7qRXjuSAOphyVy8cddnc8vK9PVwNalpqaGpvwt6od+01r0FD2bXsE0ovZGLjLqU5y7IvgCBg6eQC9iHdIm4Azv4W6BurUBsqSbKTU5LewhezwrqR5YbDR2jLzcVqwQLU3t40BYZza/ohsgqrCXC1hPM74PBHkvdl0J2X/UxV50/SL30doxfdRn6bLUkHC0g8UICZneHlxXvdR8Col2DfW1IBvW0Q1BVDXdHvfhZDfTFoO9SGol6FyKd4d0cqm+IL+ed4b+4Id+z9GL2hqQrO/QpBM0Ddu1r8RQz3HsxD3k8wPeUpdnyZSPBoJ4qyqyg5oeKBhvfZeywbAJlCwNLBiH4DbLBy0eDka47G/JIXJkGACe/C0iHS+U7+sO/zvRRHP5MkPUJ66WIFFg5aSGN7I4bKXtLFMhlEPgkbHpbq2rwnSGlSa/8eTSY3cRM3cXXc0Bi1KIrbkGrVLl226JLff6GrQ/TSbZqROkt7GzMLqWP1/x0SyhPQitrL1rf1BaJOx66vPkUmlxP1wGM01beh0wkYKWukB5RrJKT8JtW5dbw5y2QCoeOc2f/jeQrOV/XZJ1JProevRS8m5H8yWpraqS5oxjE4iMp98WzY9S0P3f8GAM319ZTlZjPkjp4PlMqV34NOh+Ujj2BWVY02OhrHSY9yNj+Qn984wYiZ3vQb0L02RdRqWfHDFsy0Hky/e9ifWnDcKQ1yrJjBv5MG6TYHUSQvpVKyueogOwNtB2Ktb82WzC09idvRz0GuBwMeoCkpiabTpwl4ZhwXEmTUVrUy2KUI/ZUfoM2MgAD/brsWNkidrvaGvRM3z/6D2C37jLTjh7uIW84FzGztUKrVYBcM57dDS11nZ6BcIePOF/pT1tzKhC8OMy3EvlPm4yKq1qxBbm6OZrzkWGA4+170n3uCos2/wb2jpYe8baBEOq6Aur0xyK0sMQoPxlcmw3eIHRWF9agNlZe1CANg2LNSNG/3ou7L9UykqJzGFlyGdPxuJ73wxP6bH1uH81VsMfcOdmH+yJ6SPFfE2TXQ3gQDrv5i5m7ijsy2hRLDeDgeKlm9yUQUajXW/voE+Hpi7aLBwt4IufIq31FrHxj4IJz4SkrR2gZcefvfoyITUrfCsKelNHMvMFIZYaTq3ZoIgIDbIeZNKepm6SXpt419/drmcRM3cRPAX9+ccBOXIL40HgGBIKug6x4jYe9O8pISGHnvA2gsLKmvbAHAyMpEkoJwHS51cpUkdtvPZ5AdBiYqzuzM+UPncCNQlFGNKELUiChaTBWkxx0nvy4fgPzUJBDFHtZM2poaqteswfiWW1A5OqIfGIDl/fMw3vI5UybIMbc3Yve3yexekURLUzuUJMHSoWxZPh2TdBdUPk0EePVMvf5RBI50RNvWUxrkUlQVN1Jf1YKTbxfZkcvkTHKfxOGCw92bQjqEXAmOBiMrqn74EcHAAJvoadz+fH/ueSWC4AVTkRkbU760p9xhUX0RALZGvRdX62uMcQ4IJu3Yoc5O4rJLGxPsQgARirt/nzTmaj6ISUcuCDx/i0+3dW1FRdTv24fp7dORqSTy6nrLGHI0Nhhs+hlx7VwQdXDnSlBePt2ua22l4eBBNCNHIVySvrOwN8LQ5CoiqDIZRP8Ad62GudtgwRl4qRBezIXHT8CczTD9Sxj7mhSdnvRvxNYGWmPe45YAW16Z4n9tdY+iCKeWg0N/iexeBYIgMNR+KLv1fmHyE4Hc/lwYh8Z/y5nhvxL90HAChjtg7WJ8ddJ2ESNfALUp7HhBmsu14Pgy6d4x8A8Ut8uVMGQB5B2Dbc+CIIPAGdc/3k3cxP8wbhK3vxHiS+PxMPXAWGV89Y17QW15KbE/Lsc5MISAUWMBqC+XZBk0zh19Iq6R0s/sg932lStlBI9xIi+litKc2us7gRuEwrRqZHIBWw8TggeOwqpCyWuxixBFkfzkc8iVym5yFwBVP/2ErrERiwcf6Fxm+dhjqNzcaHj/FaY+4s3AKW6SNMbCPRR9+jAVZSnE5IUiQ86Me/re+Xo5tLRrGfHBPpYd6GqosHAwwsG7d2mQi8hLlojZpcQNpHRpu9jO9gvbuxae+hbam2HQY7RXVlK7dSum06YiNzbG0tEIQ1M95EZGmM+5l/q9e2lOSek2ZlGDRNwuF3EDqbu0uriI8txsWpsaqSkpxsrlInG72KDQvc7tSGY52xOLmT/SAzuT7inp6nXrQBQxje6q89JTyjkYMhaTgmwa487B1M/A4soRrcbjJ9A1NGB0STfpNUFlKNliuQ6VjnWZaBLAkRoLftaOYrZiDx+NNUZ+rfIa2QehPK1P0baLiHSIpL6tnnLzXIqNskmsPndZCZCrQt8MRr8szSNlc9/3a6yUpDwC75Sij38EobPBwAIyY8BtRKdN103cxE1cG24St78JtDotZ8vOXneaVBRFdn/9OaJOZNxDXV2QdTmSYK6RV0dEysRB6gzLPtRjjIBhDqj0FZzZmXt9J3GDUJBejY2rMUqVHP8Bw5HrBPKSz7E+fT35KYnYeXqjUHWlHXVNTVR+vwrDEcNRe3cROplajd1bb9JWVET5xx8xYLg+0/1/QWiqZEP5qyxVvYp72RCcvWows75C2qeP2JdaRk5FI5/uTaeyocuVLWiUJA1y4WzvFit5KZWY2hj0sLnyMvPCx9ynq7u0rVlKf3mOBWsfqteuQ2xtxWzmzB5jms+ejczIiPKly7otL2woRF+hj6ne5bsiPQcMQhBkHI/Zx4RX1gLwcmwFHi9tw+PdOEpFU9Zv3Sr9v+PfPV8fx9FMnweHu3cbS2xro3rdLxgOi0Tl2L0+zDlIhVxPS2WJP/j9Xqu7J+pi9iLo60um8jcQ5fUtPLzqNBtNZyNX6qEX+9a1D3LyWyni5d93WZkIuwjkgpzDBYdZnXp5CZA+I2yuVFe2619Sp25fcHoFtDXCoPnXf9yLUBlAREdt7c2mhJu4ievGf3cf9v8jZNZkUt9Wf92aUkkH9pIdf5rR8x7BxLpLKLY+vwiFYIiex4CujV2HQdJG0GlB1mU0rdJXEDjCgdM7c6guacTU5sY1HPQVrc3tlOXWETZO8mN09PFHoVIR1ujKR0f/zbQLFgya3r1Dr3r9erSVlVg++GCP8QzCwjCbPYuq71dhXLUCW/MGomcO4LuTTZilBIDQxhibWKTG5T+G9WfyMVYrqG9p58sDmbw4UaoHdA2yRGOuJmFfPh5h3RtLtG06CtKqLmvUPsV9Ch+c+oCc2hxcMmKhoQyGPI7Y1kbVmjUYDhmCnkfPSJXc2Bjze2dT/sVSmtPSUPeT5GaK6ouwM7S7YhTHwMQUR78AUo8dwkghpT1vGR4GRlJEsD7Fn2EthTwa0v24U0PsUf/OyLxubwztZWXYvvZa94NUZjG3eglpnhZok0poyczs9TwuQhRF6mP2dTeVv0H4/mgOdS3tvDk7CiFpARx4DwY/Do79+zZAXbFUIxfxCCj77m+oUWkItgpm+4XtFDcUc7fv3X+sCUiukHxMV06Rmg0in5a+P3VFUFvUe3NGeZrUlXqtdXGXw+DHpOif//Srb3sTN3ETveJmxO1vgovG8qFW1x5xq6+sYP/3X+Pg40/I2Ind15XXoVHWIGguIQiuw6ClBorP9RgraLQTcoWM3cuTyIovu2w674ZAp4XN/4AfZ0Ce5NtZnFmDqBOx7ydFhBQqFU7+QbhWaLCp0gNRxMKr6wEvtrVR+e1y9END0Q/vRRG/tRFr7yKUhu0UHlGjm7ObFK8wlpotIj/yGLcEHcWo4LduIsXXg6qGVvadL2VGfyemhTiw8mg2pbXNQIc0yEhHCtOrKc+v67ZfUVYN7a06nPx6bxAZYCsR8LTK81JTgk0AuI2gbu9e2ouLMZvVixxDB8zvvReZgQEVy7qiboUNhdgZXj1l5RUxBKG6lHBtNnoGhjwzfRDPjvfm2fHeuAcN4f/YO+/wKOr8j79ma5LdTdn0RgoJEDoovYjSFEQRG6goqOjdeafenf5sp3fq2cvpWVBR7IieYqN3VARpCS0BEhLSNskm2bTdZPv8/phUsikgVef1PHkSZr4zO7MJmU8+5f0Ot+dx38Xxzdvum9qb1Mj2+mhVS5eiiolGf9H4lo0uO3xxC4JCyf0JfwSNFssHH3Z6PfaDmY2m8hM7Xfdrsbs8fLI9n0lpEaREGKQ+LV24NNTQ3V6xPR+D1y0NBpwgY2PHUmQtwiN6mNN7TtcHdEXSeEi7AjY9DU+GwUu9JTutpXNgxd/gxxche50U0AXFwZAb4fL//PrXbUKjkwYlVCfvHywj83tHDtzOETLMGYT6hTar1ncXURRZ/96beJwupv7h7jZN2ogidXUCesNxD5ikcdLn4/rcAAICNUy4sTe2Gier3trPR49sY8f3uVir7Cd6SyeGKMLqh2DPh9K033uT4NNrKd5zCEEhEJXcIp+QOOgC6srMzGgYhkcQed38ER6vZKxRu3o1LpOJ0AUL2meRTBnw9ngU+z8mev5EXNVeij7+hvu33E+kLpIHr72L5DF9JYue43q2TpTl+0tweUSuGhrLPZNScXtEXt+U07w/bUw0KrWCfZuK2hxXmHGll4AAACAASURBVGlBoRCI7eW7dNn081F0bLMkpDzqzyAIWD7+BHV8fNuA6DiUwcGE3HQTtatW4zgq9d2V2kqJ1ncduDXE9EME9FUFhPVIbPveRg+WhgnKDnZ6DkduHvXbtxNy3fUIylaZuDUPQek+TBe/wiFNAnXjJ1Pz7be4LZYOz9WRqfypZtmeYiw2J7ePayz5ag1So3/+VkmCpSu8Htj9ASRP6LJnzxdjYiV3hfFx44kPjO9idTe57Dm48DZpsnb6yzD7M1iwCf52CP5RDvcdhju3wA1LpaDN+CtM6WVkZE45cuB2jpBuTmdwxOATbjw+sn0rR3f9wpjrbyIk+jjdquoC6lxBGEKPa7o2REFoqiTE64M+I6O5+alRTPvjAEJj9exceYyPHv6ZlQv3kX+wxSPylLL1FdjxNoy8C/6WJWlmFe3EtCODCF0pmqqWoCBpsOSTWJGRiX9cBFtKf+K/6f9FFEUq31mENjWl7QPd64Wtr8K7k8Bpg5u/Rffntwi6/jrqPl5CYE4ZL170oqT43vMSQICcDb/qdpbtKaJ3hJ6+Ox4k4esr2Rj8b67aPQ/HW5fAu5Pw++wyegXt5sjPBdjfmiFd22dzKNydTVSiPxo/310MBo2BYG0whflbQB8F/a/GnplJw+7dhNxwQ9uAyAfG+fMQ/P2peOttGtwNWOyWTgcTmliTa6PUTwrwmgcTmuhgQOF4qj9fCmo1wddc3bIx81tp2nLMPURcKPW17R81DdHppGrJZx2ey5ep/KnG6xV596dcBsQGMSKpVQZ06C0QmgLr/im5O3TGkTVQWyQFSidBH2MfFgxYwL1D7z2p430SGAPTX5SGFYbdBn2mSd6jgdHnvYuBjMzvATlwOweoaKigyFp0woMJXq+HrV98QliPRIZOb9/M7Tm2gwZvCPoYH+boiWOlzFYHDx6FUkHSoHBm/GUQc58cxZCpCZTm1rD8NckjcvfqY9TXOn0ee8LsXQrr/yVpPU35N2j1MPavuP6YjtnTmxhhF7w9Hj6/CcoOEhwVQ1CkNOE2+IIJXNfrOhYfWMymz1/EkZ1N6O23I9RXSA/Nzc/Ce5Ol0lbvy+CPWyUBVmDd9Cgsenh4QyB9AxstxnRhkqhszvqTvp28ChvpBdXckVqLkLEEPC4iw8Ox4s8xq0LK2mgNDIzLwiOqyawaDloDDcV5lFdoiDcvgkWXwA8vSFms40pycX6hFDWUwYg7QKXB8smnCP7+BF/ddd+QKiSEkDmzqV2xguKsXQBd+iy6PV6W7ytBnSL9fLYL3ILipGnBTgI3b0MD1V9/Q+DkSajCGm3PvB5Y/7hU7r3kUQI0KmKD/dmrCEZ/0UVULVmC1+Fod66OTOVPNZuPmMktt3H7uKS2f1Ap1dIfFhWHIcOHeXprdr0n6cD1ntb5ug5QCAruHno3KSEpXS+WkZH5XSAHbucATf1tJzqYcGTbT1SZihh19WwUivaZFmuOpK2lj/NRYkkaB45aKN3bft9xBIb5M2pmT255ZgxTbu+HIdSP7d/k8uFDW9nwUdav64PLWQ/f3iX13c1c2MZOp9Qk4vUqiLn+bskVIHcLLByN8OV8EntJpav4vgN4sP8CLgzsSe277yMGqQjMfhBeTIUl10mBm9MGV74B130EAVLmZHfZbv5z6G123XIh/oUVbTXOUiZB0Q5J6f4k+Dq9WBKs52dQqOHmb9DO/5ZNw95mmuVv5F76Mcz9mtA/vEts72D2116C94avKBz/jXRPY6SMIhv/LSnevzoQVj0AuZvB4yK+vpZCtQYumC9JgCxfTtCVV6AM7J6MTOj8+QgaDdZFHwB06JrQxNajlVTanIy9dDK9Ro4leeiwtgsEQcq6lXT8s1S7chXe2lqCZ7eaJjywDCxH4aIHpGAISInQk2O2Ypw/H4/FQs137aUrrBs3Am1N5U8Hi37IIzrIj2kDfJSS+1wumadvelr6+fKFJU/K3A69Rc5kycjInDLkwO0cIN2cjkahIc3YfRcC0etl+7LPCY3rQerw9j6TAHX5xwAwhPmYREto1HProFzqC6VKQeqFkcz861Bu+NcI0kZHc+jnEg5tL+32OdpgSofPb5Z8DGd/Cqq2oqmmI9UIAsT0jYWLH4J79kp9OdnrGFj0BskRELt+HuqXevPMhp/pXSTy5TAv5QnDJHPt+avwPljIa30+Jid2ZrOpd2VDJf+35f+I1cey4I6FBM2cSeU7i7BnZkovnDJJ6tnK3XLCtySKIl+nFzEmORRdzvdS6dVfKuf9cUJPNEoFr6zPbl4/8OJ4SRpkXwWFWRa0OhXhV/4JFmyEvx+GGa9CRF+pT+qjK+H5nsRV5FKiUuH2C6T6f18iOp0YOxlKOB5VWBgh11+PZv12IqvELkul32YUY/BTMWlIMjP++iD6EB+DE9GDwJwlDRr4oGrpUjQpPQkY1hj0eT1SRjGirxQENZIaoedouRXtsGFo09KwfPBhs/BvE3UbN6FJ6YkmIaHb93yiHCiuYVtuJfNGJ6L25cAgCDD5SbCWSUMivtj9viQ0e8Etp+06ZWRkfn/Igds5QIY5g/5h/dEouz9plb3jZyqLChg56/q2AwlNOG1YyyUhXb3Rh1yCIRLCevvUc+sOIVE6LrqhN1HJgez4LheXw3NiJ7DkwqfXSiW2m75s9m78OaeCH7PLATBlVxMWb2jx1wwwwsRH4Z59REy8navSKlH3GAqTn8BVOwGCDKy9MIB7A9w4ht8OCaNZdrCGl9Yd4b8bpGDJ4/Xw4I8PUu2o5uUJL6PX6Il88AGUxhBMDz+C6HJJ6vbaoJMql+7Kr6LQ0sDtSRVQU9hGtyvcoGX+mES+32fiUKn0vWmWBtlYRGGmhfg+xhZPT0MUXDAPbvgc/i9XUvnvO4P4gCg8iJhqiqj67DMCRo1Em3JipTTjbbfiVQrM2iYSHhDe4Tq7y8OaA6VM6x+NVtVJ/1z0YGly0pzZblfDgYPY9+8n5PrZLSXHzG+lUuP4+9tkWVMi9DjcXkzVdkLnz8N59Ci2H1v+uPDU1FC/cyeGi09vtu29n/LQaZTMHt6j40U9RkDaDKl/0mpuu8/tkIRr+0yTespkZGRkThFy4HaWsbvtZFoyGRTRtQ1OE6LXy/avlhISE0evUWN9LzKlY/VImRF9SAf2P0njGvvcXCd62YBkyzN6Vgq2Gid7N5yAaK+1HD65WnrQz13WrMheaXVwx8e7WfDRLo6VWSnLq22WAWmDLlSyIvrTNrj2A+xhl2HdsZ+wW+bx+MXPsr9iP4///Dh1dhfPrT4EwNrMUqwON+/sf4ftJdt5eMTD9DZK4rzK4GCi//UvHIcOUbFokVTW6jlBKnOdoD3Qsj3F+KuVjLH/AEqN9OBuxR3jk9FrVLy09gggSYP0nxCLKbsaW42zQxmQZpX/K98g7vLXADCv/h53aSnGuXN9HrL6QAnZZXU+96kjIjgyLoHx+714TR1nTDdkmbE5PVw5uIvgo5MBhaqlnyH4+xM0s7EP0+uVsm1hvdsJ7aY0Ch/nlNcReOmlqCIiqHz//eb91h9+AI/ntJZJS2oa+H6vieuH9SDIX9354on/ksRstzzXdnvmt9J08kkOJcjIyMh0hBy4nWUOVh7E7XWfkH5bzu5fKC84xshZ1/vsbQOgcAd1nnD89SpU6g7WJI4Fp1WSyThJolOCSR4czp41Bd0bVnBYpd6z2hK44QvJcLqR1zbm0ODyICDw8uf78bi9xKZ2rOjfROV77yIEBGC84QYmJkzkrsF38X3u99y1/GXK6xz8c0Zf7C4vb2xbxcKMhcxInsGs1LaN/IaJEwmcPp2KN96kfs8eqVxaZ5LKf93E7vKwfJ+Jy/pFoD78neRo4BfUZk1wgIYF45NZl1nG3sJqAPqOiUHV6Dl5vM2VL+INjT2L/1uBOi4O/UXtJTGqbE7uWpLO3Usz8HYwBbxpfCCiIFD5zqIOX+vbjGIiDFpGJId2flEhidK9Htfn5qmtpXb5CoIun47S0Kjrdmi5lJkbf38bAWhoFbiZrQgaDSFzb6J+23bsh6QAvMlU3m/gyfv5dsWHP+fjFUXmj0nsenFYClw4H3a9DxUtJXB2vgfGnpK1k4yMjMwpRA7czjLp5nSg+4MJoiiy/culBEdF02d0x5pdFO3EquyBIbQTpfYE376lJ8rImcm4XV52rcjrfKHHBf+7RcrKXLMY4oc37zpWYeOT7flcPyyev0/pRXmuVEqMTuk8cHMWFVO7YiUh112HMlhae+fAOxkTPZE91k8ZP6iCeaMT6RHu4rNjz5AclMw/Rv7Dp+xK1L/+iTo2luK//g23sVG89wTKpRsPmamzu7klrlGFvr/vKc9bxyYREqDmxbWHAfDTqek/IY6Y1GAMvsraxxHuH06KWYkuM79DCZB1WWV4vCJZJbWsOuA7o3ZEZeHouESqv/4al6m96X1NvYvNh8uZMSima2/OpgGF4/4IqPnmW0S7vWUoQRRhy/OSnIaP9yc4QEOYXkt2mRWAkOuuQwgIwPL+Bx2ayre7r7I6jlV0MDDQBTaHmyW/5HNZ/2jijd10KbjoAckRYUOjG0TZQclM/cJb25SBZWRkZE4F8m+Vs8xe814SAxMJ8eueHlXunp2Yjx1lxFXXo+hIs0sUofAX6sRo9CGdBAL6cGkw4FcGbiFROvqNjeHgjyaqy+o7vqbv7pYCocv/066E+MKaw2hUCu6dlMq80Yn0VmiwqEU8qs4DBsv774NCgXH+vOZtgiDgLLkWnNEc8S4kpzoHbcxS3KKdB4Y+1aFtkNJgIO6V/+CpqsL071cQw9NOKHBbtqeYyEAtA2o2gcofel3qc51eq+KPE3ryY3YFv+RWAjDm6hSu+vvQbr2OUqFk5l4NLo2yQwmQVftLiAvxJzVCz8vrDuM5Luvm9ropqy/DPEsSeC174QXqd+3CWVCAt0HysVx9sASnx9t1mbSJ6EFSJs0tZV5FUaTq88/xGzgQ/379pDWHV0HZfmnIpINscUqEjpxyKXBTBgURPGsWNStXUrt8RZem8qIoMm/xDq54/SeOdFAm7owvdhVSa3dz27gTEJ3VR8CYeyDreyj4Rcq2qfxg8A0n/PoyMjIyXSEHbmcRURTJKM84sWzbV58RFBFJ2tgJHS+05CLaKrE6DeiNHfS3NZE0Dgq2Nz9sT5ZhlyehUCvY/s1R3ws2Pgl7l0iyHhfMa7MrvaCKFftLWDAumQiDH4IIkU7IEzy8sv5Ih6/prqyk+ssvCbryCtSRLVp1P2aXszGrmpuTH0er0nLDihsodR7EXjKL9NzO3w+/vn2JfOQRbD/9RGVunNQD6LB2ef+VVgebD5uZOSgKRea30GuKpEfXATePSiTCoOWltUfaTU12hbuqiqEZVjKGBqIMCmq3v6bBxU85FUwbEM3fJvfiaLmNr9OL26wpry/HI3oISexFyJzZ1K1aTf5Nczk6ZSqHhwzl8PARRN87n5d3vEvoa89ifullLB9/Qt369Xiqq31fWPRg8DihXCpr1u/YifPoUULaZNuek8qqA67t8P6aJEGa3hfjLTeD203pv//dpal8Zkktpho7NqeHWxbvwFTdTTN1wOMVWbw1jwsSQhja4wSFfUfdBfpIWP0g7Ptc8uIM6LrsLSMjI3OiyIHbWeRY7TGqHdUMDu9e4HZs7x5Kj2YzfOZ1KFWd6EIV7cQpBuByKTrPuIGkn+aql6Q5fgUBgRqGTunB0fRySnNr2u5M/xR+fAmG3izZBbVCFEWeWXmIML2WBeMlbTbzsVq8bpGEtBAWbz1GVkmtz9e0fPIJotNJ6K0tDeAuj5cnvs8kITSAeyYM45WLX8Erermm1zUMMV7Csj3FXQZKwdddS+CMGZSvysRmoluTt8v3leD2itwYVQg2c5cm2n5qJX+5JIUdxyz8kF3R5flbU/2/L1G5Rb4d7PZ5LxuyynB5RC7rH8Wl/aPoFxPIqxuO4HS36O2V2EoAiNHFEPnQQyR//x3x771L9DPPEP7Xv6KeehlHtKFEa0Tqd+6g8oMPKHvqKYr+/BeOjBlL/tybqXz/A5zHjrW8cHTjz3HjgELV0s9QBAUROO0yaXv2OmnfuPs61TVLjTBQZ3djrpPEdzXx8RgmTUKsr+/SVH5DlhlBgA/mD6PO7mbe+zuoqe/e8M3ag6XSRPDYk7B40ujg4ofBtEfqGx0mDyXIyMicHuTA7SzSbCzfDccEURTZ9uUSDGHh9Luoi4m6wh3UKRIBuu6ZSpBKZRz7octr6IpBE+MJCNTw81c5LQFF4Q5Yfq/UpD39P81aak2szzKz45iFeyelotdKD/PibCmjc+fVfQnyV/PI1/vbNdh7rDaqPl2CYfJktMktD9pPt+eTbbbyyLQ0tColQyKGsPG6jTw28jGuGhJHjtnKgWLfgWATgiAQ/a9/oklIpHibEfee5V3e+7L0YtKiA+lhWg1qHaRO6fKY64f1IDbYn5fWHu521k10u6lasoTaAQkcCWmg2tE++7VyfykxQX4Mjg9GEATum9KbQksDX+wqbF5jskk9bdH6aARBQJuain7MGIKvmknYnXewccrN/Hv4LUR8/AmpGzfSZ28GqT9vJeGzJYTesQBPbS3m557j6KWXcXTadMwvvkj9sWpElQFK9uIuL6du3XqCZ86UAq2mbFtQDxg0u901t6b1gEITxlvnA2CYMrXTYzccMjM4PphxqeG8M/cC8ipsLPh4F3ZX13I17/6URw9jAFP6de4k0SGDb5JaD2KGQOwFJ3cOGRkZmS6QA7ezSLo5nSBtEIlBiV2uLdi/l5Lsw4yYeS1KVRcSBYU7sAZLjf9dlkp1oZLl0AkI8XaExk/F8BlJlBytIW9vBdQUw9IbITAWrv2gXZbF7fHy7KosksN1XD+sxd3BlF2NMUZHVISOh6elsaegms9bBR1ehwPTgw/gra0ldMHtzdstNicvrzvC2JQwJvdtKZ0GaYMQBIHpA6LRKBUsS29r7O4LhU5H3H9fxetWUrxoI6Kn4wf/0XIrewuruXpQBGR+J1lrabpubNeoFNwzKZV9RTWszSzrcj1A7apVuEtL8cySApiiurb3Umd38UN2OZf2j24ewJjQO5wLEkJ4bWN2cwBTYpUybtE63wbz3+01MSA2iJ7hUhAlKBSojEYChgwh4p57SP72G3quX0/kI4+gjoqk8oMPyb9pLtlfBWFavImyF14At5vg2dc3vkkboXgXjPtbs0tCR/gK3AKGDKHnurUEXj69w+PMdXb2FlYzsU8EAKNTwnjpusHsyLPw188z2vX5tWZPQRW786u4dUxi14MYHaFUwfyVcNOydn+gyMjIyJwq5MDtLJJRnsGg8EEohM6/DaIosu2rJeiNofSbMLnzkzrqwHwQq06SSzB0VSoFqVxauEMSDf2VpI2OJiQqgG3LsvF8dpOkcTXnM5/9Pp/vKuRouY0HLu3TrE7v8XgpOVpDTKMMyNVDYxmRZOTZVYeotDrw1NVRePsCrOs3EPnII/gPGNB8vpfXHcbm9PDYjL4+p0aDAtRM6hvBdxkmXN2w6dKmphI1fwr1JpHy55/scN3Xe4pRCHCNMRcaLB1Ok/pi1pBYksN0vLz2SKeBBYDoclH++utoe/cmfIoUwBTWFbZZs/GQGafby7QBLVmjpqxbWa2DT7bnA1LGLUQbgr+q/dRxbrmVfUU1XQ4laOJiMc69iR6LF9Nr28/EvvwSur4x1GXbqP3ue3SjR6FNSmrJtgXGdathP8KgxeCnahO4gVQy9fV9bWLzIUm4+ZI+LUH7FYNi+Mf0NFYdKOXx7w92mNl898dcAv1UXHuhD3u4EyHAKPe2ycjInFbkwO0sUW2vJq8mr1tl0qLM/RQfymT4ldegUneRbSveA6KXOmUiCqVAQGA33BgSx4K7AYp3d/PqO0ahVDDqqp5Um+1k5YbD1Ysgor2Vl83h5j/rshmWGMKUVtmx8oI63A5Pc+AmCAJPXdWfeqeb/3y+nfy5N1Ofnk7Miy9inNti85RVUsuSXwqYOzKBXpGGDq/vqiFxVNqcze4MXRE8/26CkmxUfvQ51h/b97p5vSJfpxczNjWc4NzloA2UNOC6iUqp4N7JvThcVsfyfe0lOVpT8+23uPILCL/nbuKCpACjyNo247ZqfykRBm275vpRPUMZkxLKws1HsTnclNhKiNZ3nG0TBLh8YPcV/5UGA4HTphH7f7fTa2YpCf99gpjnGkVp836Awl9g7L3tbM18IQgCKRF6ss0nNhW64VAZMUF+pEW3/f7fPi6ZBeOS+GhbPm9ubj88U2ipZ/WBUm4YkYBOK3uKysjInNvIgdtZIqO80Vi+G4MJ275aii7EyIBLOu/vAaTMGWD1GNGHaBG6U/ZJGA0IJ21/dTyJNR8Roz7IDudtOBN8ZwgX/ZhLhdXBQ9PS2mRRTEeknq2YVsK7KREG7knz55I3HsGed4z4hQsJalUyE0WRJ77PJNBfzb2TWgR9fXFRr3BCAtR8tae403XNGJOJmmREG+6H6f/+D1dpW020HccsFFc3cPWgcDj0veRu0I3gpDWXD4imT5SBV9Znd5h18zqdlL/5Jn4DB6K/+GL8Vf6E+4e3ybjZHG42HTZzWf+oFtusVtw3pTeVNifvb82jxFri06NUFEW+yzAxMimUqKBuZGuPJ3oQggICIlyowhuttLY8D4YYaTilm6SE68kxd1+Lze7y8GN2BZekRfjMyj10WRpXDo7hhTWH+XJ322B38dY8FILALaNPn/epjIyMzKlCDtzOEhnmDFSCin5h/TpdV5R1gMKD+xh+xdWoNN3InhXtgPA+1NV4u54obSLACFH9pczIr+XQSoSNTzJ6cCENdjUZ69pbYZnr7LzzQy7TBkQ1Z4ZEr0jObjP7txQRHBmALqgl+LFnZTF54aMYPHZeuuweNKNGtznf6gOlbMut5O+TexEc0Pl7pFEpuGJQDOsyy6i1d2/aUJE2mdiRZkSHg+K//V3yM23k6z3F6DRKpvplgr2my2lSn+dXCNw9MZW8ChtrDvoWy63+/AvcphLC77m7OTCJM8S16XHbfLgch9vLZQN8Z9KG9AhhUloEb/9wFJPVRJSufRP+/uIacits3dduO56wVFAHtDgoHPsJ8n/qdratidRIPRVWB9X13ZOp+SXPQr3Tw8S0SJ/7FQqBF64ZxNiUMB74ah+bD0veojUNLr7YWciMQTFEB3UiVi0jIyNzjiAHbmeJdHM6aaFpPnuMWrN92ecEBAUzYGI3sm1eLxTthLhhWC2OrgcTWpM4Hs/RnVg+eJ/cmVdR8vjj3T+2CXMWLFsA0YOIvPlxUi6IIH19Ibaatr1zr67Pxun2cv/UPoiiSG56OZ8/tYM1iw6g1iiZcGPv5rW2HTvIn3szCrWahhffZAPhvPtTbvN+u8vDUyuz6BNlYE5nhuCtuGpoHE63l1X7S7p3XymT0AZYif7LbBr27MH8yivNr71yfwmX9o/G7/C34BcMyRO6d87jmNoviqQwHQs3H23Xh+VtaKDi7bcJGDYM3eiWoDXeEN8m47byQAlheg3DEjvusfrr5F5YXbXYPXZi9O2Ds28zTKiVApf19x38dYlCCVEDWhwUtjwv6ZudQLYNfA8odMaGrDL81UpGdWLNpVEpWHjTUHpHGvjTp3vYW1jN0h0F2JwebjsZCRAZGRmZs4AcuJ0FXB4XBysPMii8c2N505Es8velM2zGLNTabmTPKnOgoQpv7HBs1Y5uDSaIokjD/v2YlheTvSyYsmefx1NVRfVnS7Fu3drdW4J6C3w2W9Kzmr0E1P6MnJmM1+3lly+zyJt1NYV//jNHPljCqh8zuXF4PJga+OLpnax6ez8et8jk2/oy+7ERxPaSsnB1GzZQePsCVBERJH62hPGTh3Npvyj+uyGbQovk0PDuj7kUVTXw2OV9USm79+M8KC6I5DBd98uliWNBqSEwppqQG+ZgeW8xdRs3si6zjDqHm6sHhcGhlZB2Oai6kRX1gVIhcOf4ZPYX17A1p7LNvqpPP8VTUUH4vfe0KQPG6eMw15txeBw0OD1sOmRmar+oTqci+8UEMa6v1MelV4a32efxiny/18SE3hEEBXTRS9kZ0YOhdD/k/wx5WyRXAfWJZbNSwqU+te4EbqIosiHLzJiUMPw68uVtxOCn5oNbh2HUabj1g52891Meo5JD6R/bXshYRkZG5lxEDtzOAlmWLBweR5eDCdu+Woq/IZBBk6d1uq6ZIqm/rT7kQrxeEX0nGm5em42qz7/g2NXXcOza66jdup+gRDuJD02n59o1qBN6UPbEk3gd3Zg09bjgi5sl4/jrP4WgWACCwgPoNz6WQzsrsBTVYj+YifvZJ3ll+/9IWZ7Jyjf34ayzM3FeGnMeG06vYS29WdVffknRX+5Gm9aHhE8/QR0tZYAem9EXhSDwz+8OUlLTwBubjnJpvyhGp4R17z1Can6fNTSWHXmW5gCwUzQ6qQ8wZwMRDz6IX79+mB58iM0bdhEd5McIz25w1p1UmbQ1Vw2NJcKgZeGWnOZtnro6Khe9i27cOAIuaKsNFmeIQ0Sk2FrMliPl1Ds9TOugTNqaKQOk4PLHLHeb7b/kVmKuc5x8mbSJ6EHgskkWZ7pwuGD+CZ8iNsQfP7WiW4HbkTIrxdUNTEqL6Na5Iwx+fHTrcLyiiLnOwYLxcrZNRkbm/EEO3M4C3TGWL8k5zLGM3Vw4YxbqTpTi21C4A/yCsIrSw1sf0r5Uaj98mJLHHyd7/EWU/vOfiG43Uf98jNQffyD6ikT8vZkotFqiHnsMZ34+lYve7fp11zws+Z3OeBXih7XZ1ccvF4XbQcHFd5P/6GK+nPAS+wf+CZegpc+hjxn67R9R/3M+5S++SP3OnYhuNxXvLKLkH4+iGz2ahMWLUYW0TEjGBPvzt8m92HjIzC2Ld+ARRR6Z3n5qtSuuHCwFl99mdDPrljIJyrNQvXU04wAAIABJREFUNJiJffUVRKWSyz95juuSA1Ae/BoCQiWR4V+BVqXk9nFJbM2pZG+hNKRh+fAjPDU1hN9zT7v18YbGydK6IlYdKCEkQM2IpK6lKERVFQDL99gprbE3b/82w4ROo2RiH999Yt0mujGTXJkNo//SLU2741EqBJLD9GR3I3BbnyVp4F3Sp3uBG0ByuJ6PbxvB/VN7M6FX94+TkZGROdvIgdtZYG/5XmL1sUQE+H5geD0efvrsI/z0BgZP6Wa2DZr72+qqpYbu1q4JrtJSjt10E3lXzqTmq2UYJk0i4bMlJH37DSFz5qDU66WSYNFOcDWgHzOGwGnTqHznnba2Rsez633Y8Y70gB48p80ud1UV1c89SU/7Xkw1Og5/kYtWqWXM7F7csvAKxi99hpjH/oG6Rw+qPvmE/Lk3c2TESMpffpnA6dOJf/MNFDpdu5ecNzqRPlEGjpRZuWNcMvHGEw8M4o0BjEgydssCC2iR+MjZgCYujr13/ZMgh5VLP34Gz4HVkHZFpzZO3WXO8B4E+ql4a8tR3FVVWN5/H8Pkyfj3bz/EEmeIAyCvuoANWVKZtDvlYpPVhFbph+jx57WN2QA43B5WHihhar8o/DWdlxu7JLyPZLLub4QLT976qcmztCs2HjIzMC6IiMATm4LtHxvEXRen+JzAlZGRkTlXkQO3M4woiqSb0zvMtnm9Hla98TIFB/YydvZcNP7dDErsNdJwQPwIrBapvNlUKnWVmSm4ZR6OrENEPPAAqT9sIea5ZwkYMqStdELSeMkkvFFSJOLBBxA0GkqfeLJ9cONxw+4PYeV9UlAzqf0wQ9lTT+Opq2PUg7PQ9w5inb+ThLkpDJ4Qh1KlQB0VRcicOfRY9A6p27YR++qrGKZMIfzee4l54XmEDqZoVUoF/7l+MHOG9+CPE3p27/3xwayhseRW2NhbVNP14vA+kgNEznoAPqnS8ellf4C8oxRt9kfsfcVJX0drDH5qbh6VyOqDpRx97S289fWE3/0Xn2tD/ULxV/mzoygbq8Pd4TTp8ZTaSonVx3D9sB58vrOQQks9mw+XU2d3c8WvLZOCFMCOvw+mvwha/UmfJjVCT3F1A/VOd4drKq0O9hRUnVC2TUZGRuZ8Rg7czjBF1iIqGip86rd5vR7WvPkKh7ZuYeycW7rf2wZQtAsQpYxblR2NnxKtvwp3eTkF8+bhLi8nftEiQufPQxkc7PscPUaBoJDKnoA6IoLwe+/F9vPP1K1aJa3xuCHjM3j9Qvj+bogZCle/J00TtqJu4yZqly8n7M470fTpxQeeOup7+HPNMN/K9Eq9jsCpU4h55mnC/nAngqLzH8206ECemTXgVwmmXjYgGq1Kwdd7urbAQhAgZSLkbib9mJn9xTX0nXkp0Vf0oL5Mi+ntlYjert0YusO8MYlEuKw4/7eUwMsvR5vqW5tOEATiDHFklucR5K9mdM+OJypbY7KZiNZH8+eLU1EqBF5Zn813GSZCdRrGnECvYKeMvx/6X/2rTtE0WXq0Ez23zYfLEUV+fXlXRkZG5jxBDtzOMB0Zy4teL2vffo3MHzcx5rqbGDHz2hM7cdFOQIDYC7Ba7OiNfrgrK8mfNx9XWRnxi94hYGgXLg1+gdJEYCsh3pA5s/Hr14/Sp5/Bs/1jeHMEfPMHKZMyZyncthb82waCntpaSv/1L7S9ehF2xwJe35RDXoWNh6aldXvy80wQ6Kdmct9IvttrwunuRtCVMgkctby0eAkRBi0z+wYSrNtD+LQ+1K5YgfnFl07JdYXptTxk+QXB7YZbbu90bYwulgq7icl9I5ttw7qixFpCtC6aqCA/5o5M4Ov0ItZllTF9YHS3z3EmaJYEKe/YQWHjITORgVr6xwaeqcuSkZGROaucO7+lfydkmDPQqXWkBKc0bxO9XtYtep2Dm9cz6po5jLx69omfuPAXiOgLfoFYqxzo9AoK5s3HVVxM/FsL200kdkjSOCl755SmLQVBIGrueDwVFZQ/9bDUu3T9J3Dnj5KZug+V+rLnn8ddWUn000+TVWHnzU05XDUklot7n3vlrFlDY6mqd7HlSOcWWF6vyMKCeNyigiv0mXz357GEFm0Et53Qu+8n5IYbsCxejOXDD3/1NblMJnrvXM+6hOF8kN9xmRBA4Q5DVFVyWf/uZZzqXfVUOaqaXRP+OKEnfmolTrf310+TnmISQnWoFEKHfW5Ot5ctR8q5pI9vtwQZGRmZ3yJy4HaGSS9PZ2DYQJSNpUVRFNmweCH7N65lxFXXM+qark242+H1QtFuiB8OQF1lA6T/jLOggPi3FqIbPrz750ocB14XFGyDzO/grTH4ZzxKyAA1VUcNNIx9C9Jm+AzYAKxbt1Lz5VeE3norqrQ07v9yL8EBah67vO+J39cZYFxqOKE6Dcs6KZfaHG7+9OkenttcQkFAP64JPCzZQR1cBoYYhB4jiXzkYQxTplD2zLPUrFjxq66pYuFCBKBy5g0s+aWgU/eAskodgsJN79huDFgApfWSM0OTT2moXsvfJvdiZLKxnb/p2UajUpAQGkB2me/AbecxC1aHu42pvIyMjMxvHTlwO4PUOevIqcppLpOKosjG999m77pVDLvyGsZcf9PJZQ4qDoOjBuKH4yi3YLe5UVcUEPfmG+hGjjyxc/UYCYJS0mX7Yq6k0Xb1e4S/+wPK0FBKH38C0ePxeajHaqP00cfQJCUR9ue7eOeHXA6aannyyv6E6E5OmPZ0o1YquGJwDBuyzNTUt7fAKqisZ9abP7M2s5RHL+9L0sgrUZRmQOVRaVCh31WgUCAolcS88Dz+F16A6cGHsG3fflLX4zx2jOplXxM8ezY3zRyBzenh4235Pte6PF6yiqT31dzQPReIEqu0rrVP6e3jkll6x6hzMmuVEqEnp9x34LYhy4xWpWDsqerLk5GRkTkPkAO3M8jR6qOIiPQL64coimz+cBEZa5ZzweVXMW7OLW0enBUZu7Ee2tO9EzdOgXqC+nLkrvsBiJl9BfoxY078IrUGSJ0s2RRd9Q7c9QsMuAZlUDCRDzyI/cABqpYu9Xlo+csv4yopIfqpp8itcfLq+mymDYjq9rTj2WLWkDicHi8rjrPA2ppTwRVv/ERprZ0Pbx3ObWOTEFIbZUFW/E2awO3fIrqr0GqJf+MNtIkJFN31Z+yHDp3wtZS//gaCRkPYHQvoExXIJX0ieP/nYzQ42wfL245WUlcnKf63tr7qDJPNBEC07tz+njSRGmEgv7K+XQ+iKIpsOFTG6J6hv16+REZGRuY8Qg7cziCVdsnKyOhnZMsni9mz6juGTruSi266tW22w17LikW5bF64Ht6+SJLdcHY8WUfhDjxKIwUPPE2tSZK2CBs18OQv9IbP4e49MOj6NtOigdOnoRs9ivL/vIK7vG1PWP3OnVQtWYLx5rloBw/m/i/3EaBV8vgV/U/+Os4Q/WMDSY3QN5dLRVHk/a153Lx4B+F6Ld/eNYZxqY32UFGDICAMcjdDUA+Ibds7qAwKIv6dd1Do9RQuuANnUTcFfgH7kSPUrliB8aYbUYVLr/fHCT2x2Jx8sat9YLbqQAkBQigKQUGRtRuTsUgZN6WgJDwgvOvF5wApEXo8XpH8yrY//0fLbeRX1ndoKi8jIyPzW0UO3M4gVfYqEKFw+WZ2L/+awVMvZ8LNt7crUdm3L8HqCaXYPQS3yyvJbrzUB1bcB2WZ7c7ryf2Fws1G7JlZBMz/EwD6bviUniiCIBD56KOIDgdlzz7XvN3b0IDpH/9AHR9P+D338P7WPNILqvnXjH6EG07A6P4sIQgCVw2NZVd+FTnmOu7/ch+Pf5/JxD4RfH3XGBLDWokAKxSSLAhAv5k+e/3U0dHEL3oHr8NB4YIF1O/Zg8tkQnR23KsGUPHaayh0OkJvaxGtHZZo5MKEEN75IReXpyXr5PZ4WXOwjIlpsUQFRHU741ZiKyEyIBKV4teLBZ8JmiZLj3dQ2HASbgkyMjIyvwXOj9/evxGq7FUMyQ4iM2c1gyZP45L5d7bvK/K4sWxdBfTC7VFiuvgbehhyYNdi2PMR7FwE8SPhwluh75V4ayooXGahweJH7KuvcsiRBEIe+uDTEzBpk5IIveMOKt54g+CrZ6EbPZry/76GK7+AHh98QEG9yItrDzMpLeKcm1LsjJmDY3lhzWFmvvEzVoebeyamcs/EVN+q+n2mw/7/wcDrOjyfX69exL/xOgW33U7+DTc2b1cajagiIlBFhKOKiEAdEYEqIgIQqFu3nrC//Lmdzt4fJ/Tktg93sXyfiauGSG4JO/IsWGxOpg2IwlYcR1Fd9zJuJqupeTDhfKBnuB5BaG82v+GQmbToQGKCT8y8XkZGRuZ8Rw7cziBVuccYlBPMgEumMPHWP/huBs/6DktNY9AlQEGmhR7XjoAeI+DSZyDjU8lm6us7YPUDVBxJoKFSQ+xDCwicPBnrR1kEBGpQqk9fMjX0jgXULP+e0sefIOrJJ7B8+CHBs6/Hf/hwHli0HbVSwb9nDjgnm907IibYn7EpYezOr+Ktm4Zyaf9Ogpu0K+De/RAU1+k5A4YNo+ea1TiOHMFlNuM2m3Gbyxs/m3FkHcJdWSlNBQPKkBCMt9zS7jwX946gd6SBhZuPcuWgWBQKgZUHSvBXK7moVwTba+PZVLipW/dZYivhgshuSsOcA/hrlMQG+7cJ3KrrnezOr+JPv8I1Q0ZGRuZ8RQ7cziCOwyb8BJGL5t7m2xlAFGHb61iUE1BrlUQlB1JwsBKubVTODzBKnqAj74JjPyDuXEztF9vRRXsInH0HANYq+2kpk7amyYS+8LbbKbx9AarISCLuu49PdxTwS56F568eKMllnGe8fsNQnG5v1+VdQegyaGtCHR2NOrrjIFB0u3FXWnCbzShDQiTP2ONQKAT+MCGZv36+l02HzUzoHcHqA2Vc0icCf42SOEMcFruFelc9AeqOLdLcXjfmevN5M5jQREpEW7P5LUfK8XhFuUwqIyPzu0TucTuDKI9VY41QoQ1ob5wOSCK6xbuxaC/AGKOjR79Qqkrrqa1saLtOoYDkCdj7P4DLpiRw7l9BI52zzuLAYDz9fWVNJvSi00n0E49T4lLw7MosxqWGce2F3QtqzjWC/NVnvCdPUKlQR0bgP6A/mrjYDtfNGBhDXIg/CzcfZdcxCxVWB5cNiAJazOa76nMrry/HI3qI0Z8/JWyQPEtzy614vJJW3YYsM2F6DYPiOrBuk5GRkfkNIwduZ4i6ygq0FhfOxE5Mt7e9Dv4hWKyG5sANoDDT4vuca9aCUol+ptRDJYpis93VmSD6qX+T+MXn6MaO5aFl+wF4Ztb5VSI9X1ApFdwxPpld+VU8s+oQWpWi2YkiXi/5v3Y1WXq+SYE0kRKhx+H2UlzVgMvjZfNhMxf3jvDdfygjIyPzG0cO3M4Qeem7AFClRPleYMmFrOXU97+TBqsbY7SOkKgA9EYtBQfbB26iKFK7ZjW6ESNQhUiK9w6bG7fLi+E0l0qbUPj74z9wIP/bXcSP2RU8eFkf4kI6LtXJ/DquvSCeUJ2GjMJqJvQOR6eVOh2aMm5dDSiYrI2B23k0nACtJ0vr2J1fRa3dzcQ0uUwqIyPz+0QO3M4Quek7sfp7CIrqIHDbvhAUKiwx0qRiaIweQRDo0S+UwkMWPJ62AqSOI0dw5RdgmDq1eVudxQ6A/gyUSpsoq7Xz5PJMhicZuXFEwhl73d8j/hol88ckAjCtlahxkDYIg8bQZam0xCYJDJ93GbdwAyBNlm48ZEajVDA29fzQoZORkZE51cjDCWcAt8tF/v4MiiLrGelvbL+goQrSP4EB12KploIuY4zUs5bQN5TMH02U5dYQk9riJVm3Zg0oFBgmTWzZ1hi4Gc5QqVQURR75ej8uj5fnrx4ol67OALeNTcbgp+ay46Ze4w3xXWbcSmwlGP2M+KvOLwmNoACp9zDHbGV3QRUjko3otfKvLhkZmd8ncsbtDFCcdRC3w0FReANGPx+B2673wVUPo+7CYrKiDVARECR5UMb2CUGhEMg/rlxau2YtAcOGoQoNbd5mrXIAp0d893ganB6eXXWI9Vlm7pvSu61Ircxpw1+j5JbRiWhUbf/rxhviu864WUuI0nWQ8T3HSQnXs+VIObnlNibK06QyMjK/Y+TA7QyQl7EThUpFaaidEL+QtjvdTtjxDiRPgKj+WEpsGGN0zQ3+Wn8VUT2DJFmQRhw5OTiPHsUwdUqbU1ktdpQqBf569Wm9nw1ZZUz+zxbe/iGXay+IY/6YpNP6ejJdE6ePw2Q14fG29zRtwmQztTGXP59IjdRjrpP+MJFtrmRkZH7PyIHbGSA3fTf6nvG4VSLB2uMkDA4ug7oSGPUXRFHEYrJhjG6bverRz0hFoRVbjfTgql2zBgQBw6RJbdbVVdnRh2gRTlPJsqiqngUf7eK2D3fhr1ay9I6RvHDtIJRyifSsE2+Ixy26Ka0v9blfFEVKbaXn3WBCE00DCr0i9cQb5QEYGRmZ3y9y4HaaqS4tocpUhCZVKlG1KZWKIvz8OoT3gZSJ1Nc4cdS7Mca0lQzp0bdRFiRLKpfWrVmL/wVDUUe0LRlZLY7TMpjgdHt5c3MOk17ewk+N06Mr7h7HyOTQrg+WOSN0NVla7aimwd1w3mbcUsKl/xNytk1GRub3jtzhe5rJbZQBcScEQR5tS6V5P0DZfrjiNRAELCYb0DKY0ERYnB7/QA0FBy0kRdhxHDlC5MMPt3sta5WduN4h7bYD1DvdPLPyEEadhoFxQQyICyLC0HUv3M9HK3j0mwMcLbcxtV8kj83oR6zsD3nOEW+QtNwK6woZET2i3f7zVcOticE9gpk+MJrZw+LP9qXIyMjInFXkwO00k5exi5DoWGp0LlQKFXp1q2zattdBFw4DJAmQSpNk6xN6XOAmKAR69DWSv7+SGudPABimTG6zxuvxYqt2dCi+u3DzUT7eno9CgEYBeqIC/RgQF8TA2CD6N34O1UsZO3OdnadXZPFNhokexgDenzeMi+Wm8HOWyIBIVApVhxm3EmujFMh5WioN0Kh444ahZ/syZGRkZM46cuB2GnE57BQe3MegydPYZC/EqDW2uAqUH4bstTDhYVBLwZalxIa/QY2/QdPuXD36GTm8vZSiTekYBw9GfZwenK3GiSiCPqR9qbTQUs/bP+Qyc3AMT101gMySWvYV1bC/qJr9xTWszypDbAzmYoP9SYsO5JfcShxuL3dPTOVPE3rip1ae2jdH5pSiVCiJ1cd2OFnapOF2vpZKZWRkZGQk5MDtNFJ4cD8el4ukIReyrHxf2zLptjdA5QfDbmveZDHZ2pVJm4hPk3rjSmsCSJg9st3+zjTcnl6ZhVIQeOCyPui0KoYlGhmW2NJrV2d3cdBUy/6iGvYV13CguIZhSUYevbwvSbLMx3lDnD6uQ9srk9WEv8qfIG3QGb4qGRkZGZlTiRy4nUZy03eh0mqJS+uPpchCsF/jRKm1HPYuhcFzQBcG0DxR2meU71KWv16DUWen0tiXwOPKpCBJgUB7Dbefj1aw6kApf5/ci+gg371pBj81I5ND5WGD85w4Qxz7Kvb53FdiKyFaFy37yMrIyMic55zWqVJBEC4VBOGwIAg5giA86GN/giAIGwRB2CcIwmZBEOJa7XteEISDgiBkCYLwX6HxidO47rAgCBmNH+dk45UoiuSl7yJhwGBUajVV9iqM2sYs1673wOOAkXc1r6+z2HE5PB1m3ACM5QeoDUzEE9z+lpvFd1tNlbo9Xp74PpO4EH8WjE8+RXcmc64Sb4inzllHjaOm3T6T1XTe9rfJyMjIyLRw2gI3QRCUwBvAZUBfYI4gCH2PW/Yi8JEoigOBJ4BnGo8dDYwBBgL9gWHARa2Ou1EUxcGNH+bTdQ+/BktxEbXlZSQNvhCAKnuVVCp1NcCORdDrUgjv1bK+g4nSJlzFxQQd2gyColkWpDV1FjvaABUav5Yk6mc7CzlUWscj09LkHrXfAZ1JgpTaSuX+NhkZGZnfAKcz4zYcyBFFMVcURSewFLjyuDV9gY2NX29qtV8E/AANoAXUQNlpvNZTTm76TgCShlyIy+PC6rJKgdu+L6C+Akbd1WZ9c+AW7Ttwq127DkNdPlo/BQWZ7QM3q8XepkxaXe/k5bWHGZls5NL+56fNkcyJEaeXArdCa9sBhXpXPVWOqvNWCkRGRkZGpoXTGbjFAq2fIEWN21qzF5jV+PVVgEEQhFBRFLchBXIljR9rRFHManXc+41l0keFDpp2BEG4QxCEXYIg7CovLz8V93NC5KXvIqxHIoFh4VQ5qgAwaoOloYSogZA4rs16S4kNXZAGP51vu6q61avxT+tNfL8wCg5WIjaNgTbtr3JgaFUmfWV9NjUNLh67vJ/c1/Q7oUnL7fiMW6lNclOQS6UyMjIy5z9n2znhPuAiQRDSkUqhxYBHEIQUIA2IQwr2LhEEoSnSuVEUxQHAuMaPub5OLIriO6IoXiiK4oXh4eGn+z7a4Kivp/jQQZKGtJRJAUIaaqHiMIy4E44LpjqbKHWVlNCwdy+BU6bSo5+R+honlcW2NmusFnuzhlt2WR0fb89nzvAe9I0JPNW3J3OOEqAOwOhnbBe4NYnvyqVSGRkZmfOf0xm4FQOtZc7jGrc1I4qiSRTFWaIoDgEeadxWjZR92y6KolUURSuwChjVuL+48XMdsASpJHtOUbA/A6/HQ3Jjf5vFLpU2g13SAAERbVv9RK9IVYmtndVVE3Xr1gFgmDql2f6qtem80+7GUe9GH6JFFEWeWJ6JTqPk71N6n9L7kjn3iTfEt9Nya9Zw08uBm4yMjMz5zukM3HYCqYIgJAmCoAFmA9+1XiAIQpggCE3X8BCwuPHrAqRMnEoQBDVSNi6r8d9hjceqgcuBA6fxHk6K3PRdaAN0RPfqA7Rk3Iwup7RA33YqtLayAbfL22HGrXbNWrS9eqFNSkIXrCU0Vk9BZkvg1jRRajD6sT7LzI/ZFfx1ci+MuvZCvjK/beIN8e0ybiXWEpSCkjD/sLN0VTIyMjIyp4rTFriJougG/gysAbKAL0RRPCgIwhOCIFzRuGwCcFgQhCNAJPBU4/YvgaPAfqQ+uL2iKH6PNKiwRhCEfUAGUgZv0em6h5NBFEXyMnaRMHAISpU04dnU4xbiqJcW6dqWbpvKnr4CN1eZmYY9ezBMndK8rUc/IyU5NTjtbqBFw00bpOHfKzJJjdBz08iEU3tjMucFcYY4SutLcXlczdtMNlOzJZaMjIyMzPnNaf1NLoriSmDlcdsea/X1l0hB2vHHeYA7fWy3ARec+is9dZTn52GrsjT3t4GUcRMQCGqoAb8gULW1pbKUdDxRWrd+HYgigVOnNm/r0S+U9LUFFB+uImlQeLNrwoqccvIr6/n4tuGolWe7fVHmbBBviMcreim2FpMYlAhIGTd5MEFGRkbmt0GXT3dBEP4iCEJIV+tkJPLSdwGQNLglvqyyVxGsDUZpK2+XbQNpMMFg9GujwdZE3Zq1aHr2RJuS0rwtumcQKq2SgoNS75y1ygECLNyex6S0SMalntlhDJlzhyZJkNbWVyW2EnkwQUZGRuY3QnfSMpHATkEQvmh0QpC1JTohd89OIpNT0QW3xLpVjkbxXVs56Nq7HnQ0UequqKB+1y4CW5VJAZQqBXG9Q8hvlAWxWuy4NQrsXi//mJ526m9K5ryhSRKkaUDB7XVjrjcTpZO1/GRkZGR+C3QZuImi+A8gFXgPmAdkC4LwtCAIPU/ztZ13NNTVUpJ9uE2ZFKSp0mBtMFjNoG+bDfN6vFSV2Took24ArxdDqzJpEwn9jNRV2qkxN1BSYqXM7eLWsUkkyqbwv2vC/MPwU/o1DyiY6814RI88USojIyPzG6FbjVCipPZa2vjhBkKALwVBeP40Xtt5x7F96Yiil+TjArcqexVGPyPYzO0ybjXlDXjdIsZYH4Hb2jVoEhLQ9urVbl98oyzIsQOVlJTYcGoU/OWS1FN4NzLnI4IgEGeIa864mayyhpuMjIzMb4nu9LjdIwjCbuB5YCswQBTFPyINCVx9mq/vvCIvfRf+hkAie6a02V5lryJEEwj2mnZSIB1ZXbmrqrD9sgPD1Kk+nQ+Cwv0Jjgxg93YTGqeXfikh6LXy1KCM1OfW1OPWpOEmDyfIyMjI/DboTsbNCMwSRXGqKIr/E0XRBSCKohdJR00G8Ho9HMvYTeLgC1AoWgzdPV4PNc4aQhSNk6THS4GYbCBAyHGBm3XDBvB42siAHE+PvkYaCm2oEBjaRx5IkJGIM8RRVFeEKIrNgZvc4yYjIyPz26A7gdsqoNnVXBCEQEEQRgAc5x/6u6bsaA4NdbXt+ttqnbV4RS/GprfaR8YtMMwftUbZ9rjVa1DHxeHXt63LQmvi+xppysUZQv06XCfz+yLOEEeDu4FKeyUmqwmjnxF/lf/ZviwZGRkZmVNAdwK3hYC11b+tjdtkWpGbvgtBUJA4aGib7c0+pU2e8LrjAzcrocdNlDqLirD9/DOB06d3ahDvCFHjRjqxwSgHbjISrc3mS2wlROvkMqmMjIzMb4XuBG5C43AC0FwilZupjiMvfSfRvfrgrze02d7iU9qoZN9qqtTj8lJjbmjX31a15DMQBELmzO70NXcVV1Oo8kqnNWo7XSvz+yHOIGm5FdYVyoGbjIyMzG+M7gRuuYIg3C0Igrrx4x4g93Rf2PmErbqKstycdtOk0GJ3ZXRJ7gatM27V5nq83rYTpd76eqq//BLD5MmoozrvS/ol18KxIIH4vkb8dOpTcCcyvwXi9HEICFLGTXZNkJGRkflN0Z3A7Q/AaCRf0CJgBHDH6byo8428jN0A7frboFWp1GEDjR40Ac37WiZK9c3bar5fjre2FuNNN3b6mqIo8kteJdH9Q7ni7sGdllRlfl9olBoidZHsq9iH3WOXpUBkZGQEU0cXAAAgAElEQVRkfkN0WfIURdEMdF6z+53z/+3de3zU5Zn//9eVSQIJAZIA4RQwsFAh4WSEqt/SYuRgJS1l0WL5FbstVvdrsdQV8PBdbbtt6cGfGtrq1rUtqxWp37ZbWnGldVfRBX4IolBUQOQQIIRTzsdJmMn9+2MmQ0JOA8yQBN7PxyOPzOd0zz3MNnt5H67r1KED9EpJZcBVI1pcCwVuNeWt7CitwmKMlIGBYM45R+nq1fQYO5aEa9svyXq4uIaTFXVcNyI1Qp9CLifpSem8d/I9QKlAREQuJx0GbmbWE7gTyAJCK+Cdc4ui2K9u5aav/SM33Lag1VGv0rpSkuKSiK8pahG4lRRWk5yWgCcuMPBZs3UbdR9/zOAVKzocQdt6qBiA60cqcJOWhvUexvaTgbq5WuMmInL5CGeq9AVgEHAz8BaQDlRGs1PdUULvPq2eL/GWBOqUVp1umQrkePNSVyWrX8CTnEyf3Nkdvt/WgyX0T4rn7wYkdXivXHkaNyiAqiaIiFxOwgncRjnnHgWqnXPPA7kE1rlJGEq9paT0SAmWuzo74uar91N+ujZUXL6+4BhVb2wgef58Ynp2nNpj66ESPjkiVWvbpFWNKUESYhPo26NvJ/dGREQiJZzALZjHgjIzGwf0BdLauV+aCARuyVBT0mzErfREDThIHRIYMSv97ZqwUoAAHC2p4VhZLdeN6Be1fkv3lp4UGHEb0muIgnsRkctIOIHbs2aWAjwCvAzsBn4S1V5dRkq9paTEJgCu2YhbSWEgp3HqkF401NZS9of/oPeMGcQN7ng90tZDgdxw12l9m7ShccRtUJJKXYmIXE7a3ZxgZjFAhXOuFPgfYOQl6dVlwjlHaV0pKRbMsdZkxK3keDUxHqNvWgLl//EHGsrLSb1jYVjtbj1YTHJiHJ9I693xzXJF6tujL6k9UxnRp+VOZxER6b7aDdyccw1m9gDwu0vUn8tK9ZlqzjScOVuntEny3eLCalIGJRITY5S+sJoeY8Z0mAKk0dZDJXwyI5WYGE2BSevMjN/c8pvAxhgREblshDNV+t9mtszMhplZauNP1Ht2GQjlcPMHylI1G3ErDOwordn2DnUff0zqHQvDWot0vLyWIyU1XDdS69ukfVf1uYo+8a3vdhYRke4pnJqjtwd/L25yzqFp0w6V1AXWoqX4gvs7gmvc6r0+Kou9ZH5qCKWr/y2YAiQ3rDa3Hgyub1PiXRERkStOOJUTtEjmAoVG3OprIbYn9AisSSs9XgNA3x5eKl9/g3533hlWChAIJN7t3TOWsYM1kiIiInKlCadywldaO++c+03ku3N5CQVu3qrA+rbgVGjJ8cCO0pit/xV2CpBGWw8G1rd5tL5NRETkihPOVOmUJq97AtOB9wAFbh0orQsEbqk1ZZB0NhVIcWE1njjD9+c19J4+nbgh4WW2P1Xh5WBRNV/65LCo9FdERES6tnCmSr/Z9NjMkoGXotajy0ipt5Qenh4kVBZB37MliEoLq+nT8wwN5WVhpwCBJvnblHhXRETkihTOrtJzVQNa9xaGxjqlVn26WfLd4sJqEk5+TI+rryZh8uSw29t6qJikHrFkDdH6NhERkStROGvc1hHYRQqBQC8T5XULS6jcVfW7oVQgdTVnqC6rY9Dxj0j9x/BSgDTaerCEa69KIdZzIfG2iIiIdHfhrHF7vMlrH3DYOVcQpf5cVkq9paTEJYHzh5LvlhRWA9Cbcvp87nNht1VcVcfHp6r4++yhUemriIiIdH3hBG5HgOPOOS+AmSWYWYZzLj+qPbsMlNaVclV8cFY5uDnh9J5CAIZMnxx2ChCAbVrfJiIicsULZ87t90BDk2N/8Jx0oNRbSooFY+PgiNvxzbvw+LwMvWPeebW19VAJCXEeJqT3jXQ3RUREpJsIJ3CLdc7VNx4EX8dHr0uXhzp/HTW+GlJdcA1bUhoNXi8lRyvpHVdD/NDzm/J8+2Ax116VQpzWt4mIiFyxwokCTpvZnMYDM/sCUBS9Ll0eWtQp7TUA74cfUtVjAP0zzq9cVVlNPR+drFSZKxERkStcOGvc/jfwopk9FTwuAFqtpiBnlXgb65TWQUwcJKRQVfAO9fF9SB12fuk8th0qwTlUWF5EROQKF04C3gPA9WaWFDyuinqvLgOhEbe62kAONzOOHqgGkhk46vwCsK2HSugRG8PEYVrfJiIiciXrcKrUzH5oZsnOuSrnXJWZpZjZDy5F57qz0IibtwKSBuAaHLsP96RXVSHp16R38HRzWw8Vc83wZHrEeqLRVREREekmwlnjdotzrqzxwDlXCsyOXpcuD2V1gX+y1OpS6JXG4Q+KqajryYiSzcTExYXdToX3DLsLK5QGRERERMIK3Dxm1qPxwMwSgB7t3C8Epko95qF3dTH0GsB7fz1MItUM9Rw7r3a255fQ4OC6kdqYICIicqULZ3PCi8DrZvbvweOvAc9Hr0uXhxJvCck9komp/pBC7yiOHygnq3Yncf3Ob+Ts7YMlxHtiyB6eEqWeioiISHcRzuaEn5jZLmB68NT3nXN/jW63ur9Sbykp8X3AX897+0eR0DuOwYfeJnbc2PNqZ+vBYiYO60vPOK1vExERudKFM+KGc249sD7KfbmslNaVkhKbSNGZqzh8ojfXzRkGr5/A0+9TYbdRVefjg8IK7pn2d1HsqYiIiHQX4ewqvd7M3jGzKjOrNzO/mVVcis51Z6XeUlI8PdhR/ffExUHWdf1oqKkhtl//sNvYnl+Cv8FpfZuIiIgA4W1OeApYAHwMJABfB56OZqcuB6V1pfSr7sPH3qlkTUnEUxuIdWP7h7/GbeuhEmJjjGuv0vo2ERERCS9wwzm3H/A45/zOuX8HPhvdbnVvvgYf5XXl9N2fhdHApOnD8RcHqoR5UsMfPdt6sJjx6X1JjA9rRltEREQuc+EEbjVmFg/sNLPHzOyfwnzuilVWV0ZCfW84OpIxCW/Sa/BAfMXFAMT2D2+qtKbex66CcuVvExERkZBwArA7gvfdC1QDw4Bbo9mp7q7UW8r4E5+BBg/X9P8fiPGcDdzCTAfy3uEyfFrfJiIiIk2Ekw7kcPClF/iX6Hbn8lBUXkLWiamk9P+Y5GDc5Q8Gbp4wA7eth4qJMZis9W0iIiISpCnPKMjfWk4PfyKjB7wZKDAP+IqKiUlKIqZHeEUnth4qYdzQvvTuGX55LBEREbm8KXCLMN8ZP6VbjYK+HzGCDyEpLXC+uCjsaVLnHHuOVzAxPTmaXRUREZFuRoFbhH309glcjYcdQ/+bvpWnQyNu/uISPGFuTCiurqfS62PkgF7R7KqIiIh0Mx2ucTOzTwDLgaua3u+cuymK/eqWGhocO147gq9fFZX9jxNXUnt2qrS4mB4jR4bVTn5RNQAZ/RW4iYiIyFnhJAj7PfAM8EvAH93udG8Hd5ym/HQtxVP3kRLfO3AyOFXqLyrC88kp4bUTDNxGKnATERGRJsIJ3HzOuV9EvSfdnHOO9/56mOSBibzXfy8ptQmBC73ScGfO4C8vD7vc1aGiauI8xtDkhCj2WERERLqbcNa4rTOzb5jZYDNLbfyJes+6mYI9pZw+Usk1s4ZTUldMSkx84ELSAHwlpUD45a7yi6oZlppIrEdLEEVEROSscEbc/iH4e3mTcw4Ib8HWFeLdvx6mV994rv7kIMrWljGxx8DAhV5p+AvOr9zVoaJqTZOKiIhICx0O6TjnRrTyE1bQZmafNbOPzGy/mT3UyvWrzOx1M9tlZm+aWXqTa4+Z2YdmtsfMfmZmFjx/rZm9H2wzdL4znTxUwbGPSpk4YzgxsUaZt4yUhuDFXv3xFZcA4ZW7amhw5BdXk9FPgZuIiIg012HgZmZxZrbEzP4Q/LnXzDrMCmtmHuBp4BYgE1hgZpnn3PY48Bvn3ATge8CPgs/+L+BTwARgHDAFmBZ85hfAXcDo4E+nF7z/YOMxeiTGkvXpIVTUV+BzPlJ8ZyAhFTxx+IIF5sPJ43aiwov3TAMjlApEREREzhHOIqpfANcC/xr8uTZ4riOfBPY75w465+qBl4AvnHNPJvBG8PWGJtcd0BOIB3oAccBJMxsM9HHOve2cc8BvgLlh9CWqpi34BHO+NYn4nrGUegPr2VLO1J7dUXoe5a4OBXeUjtBUqYiIiJwjnDVuU5xzE5scv2FmfwvjuaHA0SbHBcB159zzN2Ae8FPg74HeZtbPObfFzDYAxwEDnnLO7TGzycF2mrY5NIy+RFVsnIe0q/oAUFoXDNy81c3KXVmPHsT06jgYU+AmIiIibQlnxM1vZn/XeGBmI4lcPrdlwDQz20FgKvRY8P1GAWOBdAKB2U1m9unzadjM7jaz7Wa2/fTp0xHqbsdKvIH1bCk15WdH3EqKie3Xj3CW4x0qqiYhzsPA3j2j2k8RERHpfsIZcVsObDCzgwRGv64CvhbGc8eAYU2O04PnQpxzhQRG3DCzJOBW51yZmd0FvO2cqwpeWw/cALwQbKfNNpu0/SzwLMDkyZNdGP2NiDJvGQCp1cXQK1intKg4rGlSCKQCuapfIjExnb7nQkRERLqYcHaVvk5gE8AS4JvA1c65DWG0/Q4w2sxGmFk88CXg5aY3mFl/M2vsw8PAquDrIwRG4mKDGyGmAXucc8eBCjO7Prib9CvAn8PoyyVzdqq0EpLOlrsKt8D8oaJq1SgVERGRVrUZuJnZTcHf84BcYFTwJzd4rl3OOR9wL/BXYA/wO+fch2b2PTObE7ztRuAjM9sHDARWBM//ATgAvE9gHdzfnHPrgte+AfwK2B+8Z33Yn/YSKPGWkODpSU/nmhSYL8YTRvJdn7+BIyU1Wt8mIiIirWpvqnQagR2fn2/lmgP+2FHjzrlXgVfPOfftJq//QCBIO/c5P/CPbbS5nUCKkC6p1FtKSlww8OqVhmtowFdSEla5q4LSWnwNTjncREREpFVtBm7Oue8EX37POXeo6TUzGxHVXnVjpd5SUjzBGqNJA/CXl4PfT2y/jqsmNO4o1VSpiIiItCacXaX/0cq5FqNkElDiLSGlMT9xrzT8RcFyV2GscTsYSgWSFLX+iYiISPfV5oibmY0BsoC+56xp60MgOa60oqyujNEWHHHrNQDf3kDKu3CmSvOLqunTM5aUxA4LU4iIiMgVqL01blcDnwOSab7OrZJAySlpRam3lJT4ntCjL8T1bFLuKryp0hEDksLK9yYiIiJXnvbWuP0Z+LOZ3eCc23IJ+9Rt1Zypwev3kuKrD6UCCZW7CqPA/KGiaqZkpES1jyIiItJ9hZOAd4eZLSYwbRqaInXOLYpar7qpUA63utqzyXeLS8DjwdO3b7vPes/4KSyvZUT/Ye3eJyIiIleucDYnvAAMAm4G3iJQraAymp3qrkIF5psl3y3Ck5qCxbT/T324uAbnYIR2lIqIiEgbwgncRjnnHgWqnXPPE0jGe26xeKFpndKy0Iibv6g4rI0JoeLyyuEmIiIibQgncDsT/F1mZuOAvkBa9LrUfZXVBeuU1p4tMB9IvttxKpDGwC2jf2L0OigiIiLdWjiB27NmlgI8SqDW6G7gsaj2qpsKTZX6/WfLXRUVERtGuatDRVUM6N2D3j2VCkRERERa1+HmBOfcr4Iv3wJGRrc73VuJt4RY85AUrFPqnMNXXIwntePALb+oRtOkIiIi0q72EvDe396DzrknI9+d7q3UW0pKbC8MICmNhupqXF1dWCNuB4uqmT5GM9AiIiLStvZG3HoHf18NTCEwTQqBZLzbotmp7ipQp7RH4KDXgLM53DpY41bpPUNRVR0Z/TXiJiIiIm1rLwHvvwCY2f8A2c65yuDxd4H/vCS962ZK6kpIseA/aVIavvyPADrcnJBfVAPACAVuIiIi0o5wNicMBOqbHNcHz8k5yrxlpDYYxPWC+F74ihrLXbUfuB0sqgJgpHK4iYiISDvCqZzwG2Cbma0NHs8Fnotaj7qxUm8pKSSeLXdVEsjr5ukgj1t+UQ1mMDxVqUBERESkbeHsKl1hZuuBTwdPfc05tyO63ep+zvjPUHmmkhQ8Z8tdFQXWuMWmtl9/9FBRFUP6JtAzzhP1foqIiEj31d6u0j7OuQozSwXygz+N11KdcyXR71730axOaZ/hQLDcVd++WFz7udkOFVVrfZuIiIh0qL0RtzXA54B3AdfkvAWPldOtiVDy3doKGNyYfLcYT//2p0mdcxwqquYLk4ZGvY8iIiLSvbW3q/Rzwd8jLl13uq9QndLzLHdVUl1PhdenETcRERHpUHtTpdntPeicey/y3em+QnVK/b5m5a56ZI5t97n84mBxeQVuIiIi0oH2pkqfaOeaA26KcF+6tdCIm7/h7IhbcTG9OthRevC0AjcREREJT3tTpTmXsiPdXam3FMPo29AAvdJoqKujoaqqw3JXh4qqiY0x0lMSLlFPRUREpLsKJ48bZjYOyAR6Np5zzv0mWp3qjkq9pSR7EvBA83JXqantPpdfXM3w1ERiPeHkQhYREZErWYeBm5l9B7iRQOD2KnALsIlAYl4JKq0rJTkmPnCQNADfx0cAiO1gV+nB00oFIiIiIuEJZ5jnNmA6cMI59zVgItA3qr3qhkq8JaSYBzw9oEcffMERt/Z2lTY0OPKLq1VcXkRERMISTuBW65xrAHxm1gc4BQyLbre6n0CdUgIbE8zOTpW2sznhZKUX75kGjbiJiIhIWMJZ47bdzJKBXxJIxlsFbIlqr7qh0rpSsn1nU4GEyl31a3uN26HgjtKRCtxEREQkDO3lcXsaWOOc+0bw1DNm9hegj3Nu1yXpXTfR4Booqysj5UwcJKUDgXJXMYmJxCS0vVv0UDCHm6ZKRUREJBztjbjtAx43s8HA74Dfqrh868rrymlwDaTWVcOAYPLd4pIOy10dOl1Nz7gYBvXp2e59IiIiItDOGjfn3E+dczcA04BiYJWZ7TWz75jZJy5ZD7uBxjqlybUVzZLvxnaQCuRQUTUZ/XoRE2NR76OIiIh0fx1uTnDOHXbO/cQ5dw2wAJgL7Il6z7qRUNUEnw96BQI3f3ERno6S7xYrFYiIiIiEr8PAzcxizezzZvYisB74CJgX9Z51I6E6pQ1+SApuTiguIbadHaU+fwNHimsUuImIiEjY2tucMJPACNtsYBvwEnC3c676EvWt22hWp7RXGs7nw19a2m4Ot2NltfganDYmiIiISNja25zwMLAGWOqcK71E/emWGte4pfj9kJSGv7QUnMPTTiqQg0VKBSIiIiLnp70i8zddyo50Z6V1pSTFxBMP0GsAviOnANqdKm3M4aapUhEREQlXWEXmpX23X307nzl1GGLyoWcyvuLA3o3YdjYn5BdX07tnLKm94i9RL0VERKS7U+AWASP6jmCEPyZQNSEm5my5q9S2A7dDRdWM7N8LM6UCERERkfCEU6tUwlF1umW5q3ZG3A6eVnF5EREROT8K3CKl+lQo+a6/pBiLiyOmd+9Wb/We8VNYXqv1bSIiInJeFLhFStXpUPJdX1Exnn792pwGPVJSg3PamCAiIiLnR4FbJDgXHHFrTL5b3G4Ot0NF2lEqIiIi50+BWyR4y8Ff36TcVXG75a4aAzetcRMREZHzocAtEqpPB343LTDfQQ63/knx9OkZdyl6JyIiIpcJBW6RUBVIuEuvATjn8JWUENtO1QQVlxcREZELocAtEqqDgVtSGg3l5XDmDJ4O1rgpcBMREZHzpcAtEqqCU6W90vCVBArOtzVVWuk9w+nKOq1vExERkfOmwC0Sqk+DxUBiKr6iIoA2p0oPF9cAKi4vIiIi50+BW6SkjoQYz9lyV22MuB0MpQJJumRdExERkcuDArdIuOmf4ZvvAuArDk6VtpEOJD8YuF3VL/HS9E1EREQuGwrcIsxXXAQxMXiSk1u9fqiomqHJCfSM81zinomIiEh3p8AtwvxFxXhSUjBP64HZwaJqMvprtE1ERETOnwK3CGuv3JVzjkOnq5QKRERERC6IArcI8xcXt7m+rbTmDBVenzYmiIiIyAVR4BZhvuJiPKmtB26Hi4M1SrUxQURERC5AVAM3M/usmX1kZvvN7KFWrl9lZq+b2S4ze9PM0oPnc8xsZ5Mfr5nNDV57zswONbk2KZqf4Xy1N1V6ssILwKC+PS9ll0REROQyERuths3MAzwNzAQKgHfM7GXn3O4mtz0O/MY597yZ3QT8CLjDObcBmBRsJxXYD7zW5Lnlzrk/RKvvF6qhpgZXW4unjanSU5V1AKT1VuAmIiIi5y+aI26fBPY75w465+qBl4AvnHNPJvBG8PWGVq4D3Aasd87VRK2nEeILJt+NbWOq9GSFF0+M0a9X/KXsloiIiFwmohm4DQWONjkuCJ5r6m/AvODrvwd6m9m5Uc+XgN+ec25FcHo1z8x6tPbmZna3mW03s+2nT5++sE9wnkLlrtoYcTtZUUda7x7ExNgl6Y+IiIhcXjp7c8IyYJqZ7QCmAccAf+NFMxsMjAf+2uSZh4ExwBQgFXiwtYadc8865yY75yYPGDAgSt1vzh8sMN9WuauTFV7S+miaVERERC5M1Na4EQjChjU5Tg+eC3HOFRIccTOzJOBW51xZk1vmA2udc2eaPHM8+LLOzP6dQPDXJfiKglOlbYy4na6sY1iqdpSKiIjIhYnmiNs7wGgzG2Fm8QSmPF9ueoOZ9Tezxj48DKw6p40FnDNNGhyFw8wMmAt8EIW+XxBfcWCq1JOa2ur1kxVeBvZpdWZXREREpENRC9yccz7gXgLTnHuA3znnPjSz75nZnOBtNwIfmdk+YCCwovF5M8sgMGL31jlNv2hm7wPvA/2BH0TrM5wvf1ExMX36EBPfcvNBnc9Pac0ZBmpHqYiIiFygaE6V4px7FXj1nHPfbvL6D0CraT2cc/m03MyAc+6myPYycnwlJW3mcDvdmApEI24iIiJygTp7c8JlxV9UhKdfW9OkjYGbRtxERETkwihwi6BA1YTWd5SeClZN0FSpiIiIXCgFbhHU3lRpY7krbU4QERGRC6XALUJcfT0N5eVtTpWeqqwjNsZISVTVBBEREbkwCtwixBdMvtvWVKmqJoiIiMjFUuAWIR0l3z1VqaoJIiIicnEUuEWIvyQQuHnaWON2KjjiJiIiInKhFLhFSGjEra3NCZVeBmrETURERC6CArcIaSx31Vrg5j3jp6zmjHaUioiIyEVR4BYh/uISLCGBmF69Wlw7WzVBI24iIiJy4RS4RYivuJjYNorLn6oM5HDTGjcRERG5GArcIsRfXISnjR2ljeWutMZNRERELoYCtwjxFZe0k8OtsWqCAjcRERG5cArcIiRQp7TtAvNxHiMlMe4S90pEREQuJwrcIsD5/fhLStrO4VbpJa13T8xUNUFEREQunAK3CPCXlUFDQ5tTpacq6khTKhARERG5SArcIsBX3H65q5MVXgb21vo2ERERuTgK3CLAHwzcPKltTZVqxE1EREQuXmxnd+By0F6Bee8ZP+W1Z7SjVEREOlV9fT0HDhygpqams7si7UhMTGTo0KFt7mZU4BYBjQXmWyt3dSqYw03Jd0VEpDMdOHCA5ORkrr76amJiNOHWFTU0NHDixAmeffbZsXPmzOn78ssvl597j765CPAVFUNsLDF9+rS4drJSOdxERKTz1dTUMHDgQAVtXVhMTAyDBg0iLS0tDlg+Z86chBb3dEK/Ljtx6en0njkDa+V/DKERN61xExGRTqagreuLiYlpTB82GEg/97qmSiMg5fb5pNw+v9VroaoJ2lUqIiIi4XNAi7VuCr2j7GSll3hPDMmqmiAiIkJtbS3Tpk3j8OHDZGdnM2nSJLKysnjmmWeAwJRubm4uY8aMISsri4ceeqjVdl555RW+/e1vX8qudwkK3KLsdEUdA3r3UNUEERERYNWqVcybN4/BgwezZcsWdu7cydatW/nxj39MYWEhAMuWLWPv3r3s2LGDzZs3s379+hbt5Obmsm7duitul6ymSqPsZKWXgVrfJiIiXci/rPuQ3YUVEW0zc0gfvvP5rA7ve/HFF1mzZg3x8fGhc3V1dTQ0NACBdBg5OTkAxMfHk52dTUFBQYt2zIwbb7yRV155hfnzW1+udDnSiFuUnayo045SERERArnkDh48SEZGBgBHjx5lwoQJDBs2jAcffJAhQ4Y0u7+srIx169Yxffr0VtubPHkyGzdujHa3uxSNuEXZyQovU0e1XsNURESkM4QzMhYNRUVFJCcnh46HDRvGrl27KCwsZO7cudx2220MHDgQAJ/Px4IFC1iyZAkjR45stb20tLTQ9OqVQiNuUVRb76fS62OAku+KiIiQkJCA1+ttcX7IkCGMGzeu2ejZ3XffzejRo7nvvvvabM/r9ZKQ0CLV2WVNgVsUnVLyXRERkZCUlBT8fj9er5eCggJqa2sBKC0tZdOmTVx99dUAPPLII5SXl7Ny5cpmz69du5aHH344dLxv3z7GjRt36T5AF6DALYpOBpPvanOCiIhIwKxZs9i0aRN79uzhuuuuY+LEiUybNo1ly5Yxfvx4CgoKWLFiBbt37w6lC/nVr34FBMp29WlSpWjDhg3k5uZ21kfpFFrjFkWNyXfTlHxXREQEgMWLF5OXl8cLL7zArl27WlxPT0/HOdfqszt37iQvLw+AkydPUltby/jx46Pa365GgVsUnarUiJuIiEhT2dnZ5OTk4Pf78Xg85/Xs6tWrQ6+PHDnCE088EenudXkK3KLoVIWX+NgY+iaoaoKIiEijRYsWXXQbU6ZMiUBPuh+tcYuikxWB5LuqmiAiIiKRoMAtik5V1ml9m4iIiESMArcoahxxExEREYkEBW5RdKpCI24iIiISOQrcoqSm3kdlnU/Jd0VERIJqa2uZNm0afr+fw4cPh/K0ZWVl8cwzzwBQU1NDbm4uY8aMISsri4ceeiistnft2sUNN9xAVlYW48ePb1GhYc6cOc2S9S5btow33ngjcsfMc2gAAB+rSURBVB/uEtGu0ig5FUy+m6ZyVyIiIgCsWrWKefPm4fF4GDx4MFu2bKFHjx5UVVUxbtw45syZQ3JyMsuWLSMnJ4f6+nqmT5/O+vXrueWWW9ps1+fzsXDhQl544QUmTpxIcXExcXFnMzr88Y9/JCkpqdkz3/zmN7nrrru46aabovZ5o0GBW5Q0Jt/ViJuIiHQ56x+CE+9Hts1B4+GWH7d7y4svvsiaNWsAiI+PD52vq6ujoaEBgMTERHJyckL3ZGdnU1BQ0G67r732GhMmTGDixIkA9OvXL3StqqqKJ598kmeffZb58+eHzl911VUUFxdz4sQJBg0adB4ftHNpqjRKTir5roiISEh9fT0HDx4kIyMjdO7o0aNMmDCBYcOG8eCDDzJkyJBmz5SVlbFu3TqmT5/ebtv79u3DzLj55pvJzs7mscceC1179NFHWbp0KYmJiS2ey87OZvPmzRf3wS4xjbhFySmVuxIRka6qg5GxaCgqKiI5ObnZuWHDhrFr1y4KCwuZO3cut912GwMHDgQC058LFixgyZIljBw5st22fT4fmzZt4p133iExMZHp06dz7bXX0q9fPw4cOEBeXh75+fktnktLS6OwsDBin/FS0IhblJyqrKNHbAx9EhQbi4iIJCQktNgw0GjIkCGMGzeOjRs3hs7dfffdjB49mvvuu6/DttPT0/nMZz5D//79SUxMZPbs2bz33nts2bKF7du3k5GRwdSpU9m3bx833nhj6Dmv10tCQsJFf7ZLSYFblARyuPVU1QQREREgJSUFv98fCt4KCgqora0FoLS0lE2bNnH11VcD8Mgjj1BeXs7KlSubtbF27VoefvjhFm3ffPPNvP/++9TU1ODz+XjrrbfIzMzknnvuobCwkPz8fDZt2sQnPvEJ3nzzzdBz+/bta7bTtDtQ4BYlSr4rIiLS3KxZs9i0aRMAe/bs4brrrmPixIlMmzaNZcuWMX78eAoKClixYgW7d+8OpQv51a9+BcCBAwfo06dPi3ZTUlK4//77mTJlCpMmTSI7O5vc3Nx2+3LmzBn279/P5MmTI/9Bo0jzeFFyqrKOsYNa/h+XiIjIlWrx4sXk5eUxY8YMZs6cya5du1rck56ejnOu1ed37txJXl5eq9cWLlzIwoUL23zvjIwMPvjgg9DxK6+8wm233UZsbPcKhTTiFiWnKupI04ibiIhISHZ2Njk5Ofj9/gt6fvXq1QwYMCAiffH5fCxdujQibV1K3SvM7Caq6nxUqWqCiIhIC4sWLersLgDwxS9+sbO7cEE04hYFZ1OBaMRNREREIkeBWxScCiXf1YibiIiIRI4Ctyg4W+5KI24iIiISOQrcoiBUYF4jbiIiIhJBCtyi4FSll55xMfTuob0fIiIijWpra5k2bRp+v5/Dhw+H8rRlZWXxzDPPAFBTU0Nubi5jxowhKyuLhx56KKy2d+3axQ033EBWVhbjx49vUaVhzpw5YSXb3bt3LzfccAM9evTg8ccfD50/evQoOTk5ZGZmkpWVxU9/+tPQtZ07d3L99dczadIkJk+ezLZt24BAypFvf/vbYfU/XFEN3Mzss2b2kZntN7MW//JmdpWZvW5mu8zsTTNLD57PMbOdTX68ZjY3eG2EmW0Ntvl/zSw+mp/hQpysqFPVBBERkXOsWrWKefPm4fF4GDx4MFu2bGHnzp1s3bqVH//4x6G6ocuWLWPv3r3s2LGDzZs3s379+nbb9fl8LFy4kGeeeYYPP/yQN998k7i4uND1P/7xjyQlJYXVx9TUVH72s5+xbNmyZudjY2N54okn2L17N2+//TZPP/00u3fvBuCBBx7gO9/5Djt37uR73/seDzzwAAC5ubmsW7eOmpqasP+NOhK1ISEz8wBPAzOBAuAdM3vZObe7yW2PA79xzj1vZjcBPwLucM5tACYF20kF9gOvBZ/5CZDnnHvJzJ4B7gR+Ea3PcSFOVngZqOLyIiLSRf1k20/YW7I3om2OSR3Dg598sN17XnzxRdasWQNAfPzZcZe6ujoaGhoASExMJCcnJ3RPdnY2BQUF7bb72muvMWHCBCZOnAhAv379Qteqqqp48sknefbZZ5k/f36HnyMtLY20tDT+8z//s9n5wYMHM3jwYAB69+7N2LFjOXbsGJmZmZgZFRUVAJSXlzNkyBAAzIwbb7yRV155Jaz3Dkc0R9w+Cex3zh10ztUDLwFfOOeeTOCN4OsNrVwHuA1Y75yrscAQ1k3AH4LXngfmRrznF+lUpZLvioiINFVfX8/BgwfJyMgInTt69CgTJkxg2LBhPPjgg6GAp1FZWRnr1q1j+vTp7ba9b98+zIybb76Z7OxsHnvssdC1Rx99lKVLl5KYmBixz5Kfn8+OHTu47rrrAFi5ciXLly9n2LBhLFu2jB/96EeheydPnszGjRsj9t7RXIQ1FDja5LgAuO6ce/4GzAN+Cvw90NvM+jnnipvc8yXgyeDrfkCZc87XpM2hrb25md0N3A0wfPjwi/gY5+9UhZecq9Mu6XuKiIiEq6ORsWgoKioiOTm52blhw4axa9cuCgsLmTt3LrfddhsDBw4EAtOfCxYsYMmSJYwcObLdtn0+H5s2beKdd94hMTGR6dOnc+2119KvXz8OHDhAXl4e+fn5EfkcVVVV3HrrraxcuTJUN/UXv/gFeXl53Hrrrfzud7/jzjvv5L//+7+BwAhe4xRwJHT25oRlwDQz2wFMA44BoToYZjYYGA/89Xwbds4965yb7JybHKnyGOGoqvNRXe9XKhAREZEmEhISWmwYaDRkyBDGjRvXbGTq7rvvZvTo0dx3330dtp2ens5nPvMZ+vfvT2JiIrNnz+a9995jy5YtbN++nYyMDKZOncq+ffu48cYbL/gznDlzhltvvZUvf/nLzJs3L3T++eefDx1/8YtfDG1OAPB6vSQkJFzwe54rmoHbMWBYk+P04LkQ51yhc26ec+4a4J+D58qa3DIfWOucOxM8LgaSzaxxpLBFm53tbA43rXETERFplJKSgt/vDwVvBQUF1NbWAlBaWsqmTZu4+uqrAXjkkUcoLy9n5cqVzdpYu3YtDz/8cIu2b775Zt5//31qamrw+Xy89dZbZGZmcs8991BYWEh+fj6bNm3iE5/4BG+++SYATz31FE899VTY/XfOceeddzJ27Fjuv//+ZteGDBnCW2+9BcAbb7zB6NGjQ9f27dsX1m7WcEVzqvQdYLSZjSAQXH0J+H+a3mBm/YES51wD8DCw6pw2FgTPA+Ccc2a2gcC6t5eAfwD+HLVPcAFCOdxU7kpERKSZWbNmsWnTJmbMmMGePXtYunQpZoZzjmXLljF+/HgKCgpYsWIFY8aMITs7G4B7772Xr3/96xw4cCA0PdlUSkoK999/P1OmTMHMmD17Nrm5ue32Ze/evXzqU59qcf7EiRNMnjyZiooKYmJiWLlyJbt372bXrl288MILjB8/nkmTJgHwwx/+kNmzZ/PLX/6Sb33rW/h8Pnr27Mmzzz4bam/Dhg3N1rxdrKgFbs45n5ndS2Ca0wOscs59aGbfA7Y7514GbgR+ZGYO+B9gcePzZpZBYMTurXOafhB4ycx+AOwAfh2tz3AhTlUG65RqxE1ERKSZxYsXk5eXx4wZM5g5cya7du1qcU96ejrOuVaf37lzJ3l5ea1eW7hwIQsXLmzzvTMyMvjggw9Cx/n5+Tz55JMt7hs0aFCru1inTp3aZr+mTp3Ku+++2+L8yZMnqa2tZfz48W3263xFNUOsc+5V4NVzzn27yes/cHaH6LnP5tPKxgPn3EECO1a7JJW7EhERaV12djY5OTn4/X48Hs95P7969eqI9eWVV16JWFttOXLkCE888URE21Rq/wg7WVFHYryHJFVNEBERaWHRokWd3YVLZsqUKRFvs7N3lV52TlXWkda7h6omiIiISMQpcIuwkxVerW8TERGRqFDgFmGnKrxKBSIiIiJRocAtgpxznKyoUyoQERERiQoFbhFUVeej9oyqJoiIiLSltraWadOm4ff7OXLkCLNmzWLs2LFkZma2KEu1ZMkSkpKSWm3nlVde4dvf/nar1y5nCtwi6GQw+a6mSkVERFq3atUq5s2bh8fj4Stf+QrLly9nz549bNu2jbS0s3W+t2/fTmlpaZvt5Obmsm7dOmpqai5Ft7sM5ayIoFPBHG5pvRW4iYhI13Xihz+kbs/eiLbZY+wYBv2f/9PhfS+++CJr1qxh9+7d+Hw+Zs6cCdBsZM3v97N8+XLWrFnD2rVrW23HzLjxxht55ZVXmD9/fmQ+RDegEbcIOlUZLHelqVIREZEW6uvrOXjwIBkZGezbt4/k5GTmzZvHNddcw/Lly/H7/UCgjuicOXMYPHhwu+1Nnjy5WWH6K4FG3CJIBeZFRKQ7CGdkLBqKiopITk4GwOfzsXHjRnbs2MHw4cO5/fbbee6557jlllv4/e9/HyoG3560tDQKCwuj3OuuRYFbBJ2sqKOXqiaIiIi0KiEhAa83MMiRnp7OpEmTGDlyJABz587l7bffZtCgQezfv59Ro0YBUFNTw6hRo9i/f3+L9rxeLwkJCZfuA3QBmiqNoJOVSr4rIiLSlpSUFPx+P16vlylTplBWVsbp06cBeOONN8jMzCQ3N5cTJ06Qn59Pfn4+iYmJoaBt7dq1PPzww6H29u3bx7hx4zrls3QWBW4RdFo53ERERNo1a9YsNm3ahMfj4fHHH2f69OmMHz8e5xx33XVXu88eOHCAPn36hI43bNhAbm5utLvcpWhOL4JOVnqZmJ7c2d0QERHpshYvXkxeXh4zZsxg5syZ7Nq1q937q6qqQq937txJXl4eACdPnqS2tpbx48dHtb9djQK3CAlUTfAq+a6IiEg7srOzycnJwe/34/F4zuvZ1atXh14fOXKEJ554ItLd6/IUuEVIZZ0P75kG5XATERHpwKJFiy66jSlTpkSgJ92P1rhFSCj5rkbcREREJEoUuEWIyl2JiIhItClwixAl3xUREZFoU+AWIaFyV0oHIiIiIlGiwC1CTlZ4SeoRSy9VTRAREWlVbW0t06ZNC9UkPXLkCLNmzWLs2LFkZmaSn5/f7P4lS5Y0Kz7fluLiYnJyckhKSuLee+8Nna+pqSE3N5cxY8aQlZXFQw89FLp25MgRcnJyuOaaa5gwYQKvvvoqAO+//z5f/epXL/7DRokCtwg5VVGnjQkiIiLtWLVqFfPmzQulAfnKV77C8uXL2bNnD9u2bSMtLS107/bt2yktLQ2r3Z49e/L973+fxx9/vMW1ZcuWsXfvXnbs2MHmzZtZv349AD/4wQ+YP38+O3bs4KWXXuIb3/gGAOPHj6egoIAjR45c7MeNCg0PRcipSq+mSUVEpFvY+Lt9FB2t6vjG89B/WBKfnv+Jdu958cUXWbNmDQC7d+/G5/Mxc+ZMgGYja36/n+XLl7NmzRrWrl3b4Xv36tWLqVOntqhnmpiYSE5ODgDx8fFkZ2dTUFAAgJlRUVEBQHl5OUOGDAk99/nPf56XXnqJBx54oMP3vtQ04hYhJyvqtDFBRESkDfX19Rw8eJCMjAwgUGc0OTmZefPmcc0117B8+fLQFOpTTz3FnDlzGDx4cMTev6ysjHXr1jF9+nQAvvvd77J69WrS09OZPXs2P//5z0P3Tp48mY0bN0bsvSNJI24RcLZqggI3ERHp+joaGYuGoqIikpPPloX0+Xxs3LiRHTt2MHz4cG6//Xaee+45brnlFn7/+9/z5ptvRuy9fT4fCxYsYMmSJYwcORKA3/72t3z1q19l6dKlbNmyhTvuuIMPPviAmJgY0tLSKCwsjNj7R5ICtwioqPVR52vQVKmIiEgbEhIS8Hq9oeP09HQmTZoUCqTmzp3L22+/zaBBg9i/fz+jRo0CAhsMRo0a1WIa9HzcfffdjB49mvvuuy907te//jV/+ctfALjhhhvwer0UFRWRlpaG1+slISHhgt8vmjRVGgGnKhurJmjETUREpDUpKSn4/f5Q8DZlyhTKyso4ffo0AG+88QaZmZnk5uZy4sQJ8vPzyc/PJzExMRS0rV27locffvi83veRRx6hvLyclStXNjs/fPhwXn/9dQD27NmD1+tlwIABQGAad9y4cRf1eaNFI24REKqaoBE3ERGRNs2aNYtNmzYxY8YMPB4Pjz/+ONOnT8c5x7XXXstdd93V7vMHDhygT58+rV7LyMigoqKC+vp6/vSnP/Haa6/Rp08fVqxYwZgxY8jOzgbg3nvv5etf/zpPPPEEd911F3l5eZgZzz33HGYGwIYNG8jNzY3sh48QBW4RoKoJIiIiHVu8eDF5eXnMmDEDgJkzZ7Jr1652n6mqOrv7defOneTl5bV637k54Bo551o9n5mZyebNm1ucr6urY/v27S1G6LoKBW4RcLJSBeZFREQ6kp2dTU5ODn6/P5TL7XysXr06Cr1q7siRI/z4xz8mNrZrhkhds1fdzKmKOnr3iCUxXv+cIiIi7Vm0aFFnd6Fdo0ePZvTo0Z3djTYp0oiARZ8awc1Zgzq7GyIiInKZU+AWAcP7JTK8X2Jnd0NEREQuc0oHIiIiItJNKHATERER6SYUuImIiMglUVtby7Rp00I1SY8cOcKsWbMYO3YsmZmZLVJ6LFmypFnx+bYUFxeTk5NDUlIS9957b+h8TU0Nubm5jBkzhqysLB566KHQtSNHjpCTk8M111zDhAkTePXVV9t9j6NHj5KTk0NmZiZZWVn89Kc/DV377ne/y9ChQ5k0aRKTJk1q1tauXbu44YYbyMrKYvz48aEExDNmzKC0tLTDz3YuBW4iIiJySaxatYp58+aFUoF85StfYfny5ezZs4dt27aRlpYWunf79u1hBzY9e/bk+9//Po8//niLa8uWLWPv3r3s2LGDzZs3s379egB+8IMfMH/+fHbs2MFLL73EN77xjXbfIzY2lieeeILdu3fz9ttv8/TTT7N79+7Q9X/6p39i586d7Ny5k9mzZwOBGqkLFy7kmWee4cMPP+TNN98kLi4OgDvuuIN//dd/DevzNevHeT8hIiIi3dqG557l1OGDEW0z7aqR5Hz17nbvefHFF1mzZg0Au3fvxufzMXPmTIBmI2t+v5/ly5ezZs0a1q5d2+F79+rVi6lTp7aoZ5qYmEhOTg4A8fHxZGdnU1BQAICZUVFRAUB5eTlDhgxp9z0GDx7M4MGDAejduzdjx47l2LFjZGZmtvnMa6+9xoQJE5g4cSIA/fr1C12bM2cOn/70p/nnf/7nDj9fUxpxExERkairr6/n4MGDZGRkAIF6oMnJycybN49rrrmG5cuXh6ZQn3rqKebMmRMKlCKhrKyMdevWMX36dCAwvbl69WrS09OZPXs2P//5z8NuKz8/nx07dnDdddeFzj311FNMmDCBRYsWhUYK9+3bh5lx8803k52dzWOPPRa6PyUlhbq6OoqLi8/rc2jETURE5ArT0chYNBQVFZGcnBw69vl8bNy4kR07djB8+HBuv/12nnvuOW655RZ+//vf8+abb0bsvX0+HwsWLGDJkiWMHDkSgN/+9rd89atfZenSpWzZsoU77riDDz74gJiY9se0qqqquPXWW1m5cmWobuo999zDo48+ipnx6KOPsnTpUlatWoXP52PTpk288847JCYmMn36dK699tpQ8JiWlkZhYWGzkbiOaMRNREREoi4hISG0MB8gPT2dSZMmMXLkSGJjY5k7dy7vvfceO3bsYP/+/YwaNYqMjAxqamoYNWrURb333XffzejRo7nvvvtC5379618zf/58AG644Qa8Xi9FRUXttnPmzBluvfVWvvzlLzNv3rzQ+YEDB+LxeIiJieGuu+5i27Ztoc/4mc98hv79+5OYmMjs2bN57733Qs95vV4SEhLO67MocBMREZGoS0lJwe/3h4K3KVOmUFZWxunTpwF44403yMzMJDc3lxMnTpCfn09+fj6JiYmhtWtr167l4YcfPq/3feSRRygvL29RNH748OG8/vrrAOzZswev18uAAQM4duxYaESsKeccd955J2PHjuX+++9vdu348eOh12vXrmXcuHEA3Hzzzbz//vvU1NTg8/l46623QmvinHOcOHEiNHUcLk2VioiIyCUxa9YsNm3axIwZM/B4PDz++ONMnz4d5xzXXnstd911V7vPHzhwIDQ9ea6MjAwqKiqor6/nT3/6E6+99hp9+vRhxYoVjBkzhuzsbADuvfdevv71r/PEE09w1113kZeXh5nx3HPPYWYcP3681QLzmzdv5oUXXmD8+PFMmjQJgB/+8IfMnj2bBx54gJ07d2JmZGRk8G//9m9AIFi9//77mTJlCmbG7Nmzyc3NBeDdd9/l+uuvP+9i9grcRERE5JJYvHgxeXl5zJgxA4CZM2eya9eudp+pqqoKvd65cyd5eXmt3nduDrhGzrlWz2dmZrJ58+YW599++20WL17c4vzUqVPbbOuFF15o9TzAwoULWbhwYavPdJSCpDUK3EREROSSyM7OJicnB7/fH8rldj5Wr14dhV411zSBbzSNGzeu1SnZjihwExERkUtm0aJFnd2FLqGjaeG2aHOCiIjIFaKhoaGzuyAdaGhoaHNKFhS4iYiIXBESExM5ceKEgrcurKGhgRMnTnD69GlfW/dcEVOl7777bpGZHY7y2/QH2k8AI51J30/Xpe+ma9P303Wd13czdOjQuGeffXZMWlpavJlFsVtyoZxznD592rdixYozqampsUDFufdcEYGbc25AtN/DzLY75yZH+33kwuj76br03XRt+n66rgv5bubMmZMELAWGA23Px8lFKyws/MKQIUP+fCHPpqameoCXgWPnXrsiAjcRERGBl19+uWrOnDk/BoYA8Z3dn8vZxx9/fN2QIUP+3wt8vBI4/vLLL7cIrhW4iYiIXEFefvnlOuBQZ/fjcmdmdS+//PJHkW5XmxMi59nO7oC0S99P16XvpmvT99N16bvp2qLy/Vh7W05FREREpOvQiJuIiIhIN6HATURERKSbUOAWAWb2WTP7yMz2m9lDnd2fK52ZrTKzU2b2QZNzqWb2X2b2cfB3Smf28UplZsPMbIOZ7TazD83sW8Hz+n46mZn1NLNtZva34HfzL8HzI8xsa/Dv2/81M+1E7CRm5jGzHWb2SvBY300XYWb5Zva+me00s+3Bc1H5u6bA7SKZmQd4GrgFyAQWmFlm5/bqivcc8Nlzzj0EvO6cGw28HjyWS88HLHXOZQLXA4uD/3vR99P56oCbnHMTgUnAZ83seuAnQJ5zbhRQCtzZiX280n0L2NPkWN9N15LjnJvUJLdeVP6uKXC7eJ8E9jvnDjrn6oGXgC90cp+uaM65/wFKzjn9BeD54OvngbmXtFMCgHPuuHPuveDrSgL/T2go+n46nQuoCh7GBX8ccBPwh+B5fTedxMzSgVzgV8FjQ99NVxeVv2sK3C7eUOBok+OC4DnpWgY6544HX58ABnZmZwTMLAO4BtiKvp8uITgVtxM4BfwXcAAoc8411k3U37fOsxJ4AGgsNNoPfTddiQNeM7N3zezu4Lmo/F1TAl654jjnnJkpD04nMrMk4D+A+5xzFU3rJur76TzOOT8wycySgbXAmE7ukgBm9jnglHPuXTO7sbP7I62a6pw7ZmZpwH+Z2d6mFyP5d00jbhfvGDCsyXE6rdQWk0530swGAwR/n+rk/lyxzCyOQND2onPuj8HT+n66EOdcGbABuAFINrPG/8jX37fO8SlgjpnlE1iOcxPwU/TddBnOuWPB36cI/EfPJ4nS3zUFbhfvHWB0cHdPPPAlAoVhpWt5GfiH4Ot/AC6o8K9cnOC6nF8De5xzTza5pO+nk5nZgOBIG2aWAMwksAZxA3Bb8DZ9N53AOfewcy7dOZdB4P/HvOGc+zL6broEM+tlZr0bXwOzgA+I0t81VU6IADObTWD9gQdY5Zxb0clduqKZ2W+BG4H+wEngO8CfgN8Bw4HDwHzn3LkbGCTKzGwqsBF4n7Nrdf4PgXVu+n46kZlNILCA2kPgP+p/55z7npmNJDDKkwrsABY65+o6r6dXtuBU6TLn3Of03XQNwe9hbfAwFljjnFthZv2Iwt81BW4iIiIi3YSmSkVERES6CQVuIiIiIt2EAjcRERGRbkKBm4iIiEg3ocBNREREpJtQ4CYiVyQz85vZziY/EStsb2YZZvZBpNoTEWmkklcicqWqdc5N6uxOiIicD424iYg0YWb5ZvaYmb1vZtvMbFTwfIaZvWFmu8zsdTMbHjw/0MzWmtnfgj//K9iUx8x+aWYfmtlrwWoEmNkSM9sdbOelTvqYItJNKXATkStVwjlTpbc3uVbunBsPPEWgKgrAz4HnnXMTgBeBnwXP/wx4yzk3EcgGPgyeHw087ZzLAsqAW4PnHwKuCbbzv6P14UTk8qTKCSJyRTKzKudcUivn84GbnHMHzSwOOOGc62dmRcBg59yZ4Pnjzrn+ZnYaSG9aasjMMoD/cs6NDh4/CMQ5535gZn8BqgiUYfuTc64qyh9VRC4jGnETEWnJtfH6fDStGenn7JriXOBpAqNz75iZ1hqLSNgUuImItHR7k99bgq//P+BLwddfBjYGX78O3ANgZh4z69tWo2YWAwxzzm0AHgT6Ai1G/URE2qL/0hORK1WCme1scvwX51xjSpAUM9tFYNRsQfDcN4F/N7PlwGnga8Hz3wKeNbM7CYys3QMcb+M9PcDqYHBnwM+cc2UR+0QictnTGjcRkSaCa9wmO+eKOrsvIiLn0lSpiIiISDehETcRERGRbkIjbiIiIiLdhAI3ERERkW5CgZuIiIhIN6HATURERKSbUOAmIiIi0k38/+ZL1YEl/e00AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "77BalqVjUuA1"
      },
      "source": [
        "From the graph we can see that 3 layers, with 64, 128 and 256 filters respectively is clearly superior, both in convergence speed and accuracy. This however comes with the heavy price of high compution, namely from the huge number of params (2,306,954). Let's run it for convergence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sh4qtH_Dd-ly",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "00dcdc60-37b2-42e8-f8b4-9102e3f86ef5"
      },
      "source": [
        "multi_convolutional_model = create_multi_convolutional_model((64, 128, 256))\n",
        "\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('multi_layer_single_hidden_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "multi_convolutional_train = multi_convolutional_model.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"multi_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 14, 14, 128)       401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "convolution_256_7 (Conv2D)   (None, 7, 7, 256)         1605888   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_47 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,306,954\n",
            "Trainable params: 2,306,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.2449 - accuracy: 0.9230\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.97892, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.2444 - accuracy: 0.9231 - val_loss: 0.0730 - val_accuracy: 0.9789\n",
            "Epoch 2/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0423 - accuracy: 0.9868\n",
            "Epoch 00002: val_accuracy improved from 0.97892 to 0.98425, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0423 - accuracy: 0.9869 - val_loss: 0.0506 - val_accuracy: 0.9843\n",
            "Epoch 3/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9912\n",
            "Epoch 00003: val_accuracy improved from 0.98425 to 0.99000, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.0322 - val_accuracy: 0.9900\n",
            "Epoch 4/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9935\n",
            "Epoch 00004: val_accuracy improved from 0.99000 to 0.99067, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.0323 - val_accuracy: 0.9907\n",
            "Epoch 5/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9963\n",
            "Epoch 00005: val_accuracy did not improve from 0.99067\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0395 - val_accuracy: 0.9883\n",
            "Epoch 6/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9961\n",
            "Epoch 00006: val_accuracy did not improve from 0.99067\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0338 - val_accuracy: 0.9898\n",
            "Epoch 7/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9966\n",
            "Epoch 00007: val_accuracy improved from 0.99067 to 0.99233, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.0272 - val_accuracy: 0.9923\n",
            "Epoch 8/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9981\n",
            "Epoch 00008: val_accuracy did not improve from 0.99233\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0382 - val_accuracy: 0.9906\n",
            "Epoch 9/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9973\n",
            "Epoch 00009: val_accuracy did not improve from 0.99233\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.0316 - val_accuracy: 0.9917\n",
            "Epoch 10/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9980\n",
            "Epoch 00010: val_accuracy did not improve from 0.99233\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.0357 - val_accuracy: 0.9916\n",
            "Epoch 11/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9975\n",
            "Epoch 00011: val_accuracy did not improve from 0.99233\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0066 - accuracy: 0.9975 - val_loss: 0.0403 - val_accuracy: 0.9902\n",
            "Epoch 12/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9976\n",
            "Epoch 00012: val_accuracy did not improve from 0.99233\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.0385 - val_accuracy: 0.9906\n",
            "Epoch 13/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981\n",
            "Epoch 00013: val_accuracy did not improve from 0.99233\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0311 - val_accuracy: 0.9914\n",
            "Epoch 14/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979\n",
            "Epoch 00014: val_accuracy did not improve from 0.99233\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0327 - val_accuracy: 0.9920\n",
            "Epoch 15/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9989\n",
            "Epoch 00015: val_accuracy improved from 0.99233 to 0.99275, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0353 - val_accuracy: 0.9927\n",
            "Epoch 16/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9990\n",
            "Epoch 00016: val_accuracy did not improve from 0.99275\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0470 - val_accuracy: 0.9909\n",
            "Epoch 17/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992\n",
            "Epoch 00017: val_accuracy did not improve from 0.99275\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0439 - val_accuracy: 0.9905\n",
            "Epoch 18/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n",
            "Epoch 00018: val_accuracy did not improve from 0.99275\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0335 - val_accuracy: 0.9922\n",
            "Epoch 19/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9982\n",
            "Epoch 00019: val_accuracy did not improve from 0.99275\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.0409 - val_accuracy: 0.9914\n",
            "Epoch 20/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9976\n",
            "Epoch 00020: val_accuracy did not improve from 0.99275\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0370 - val_accuracy: 0.9918\n",
            "Epoch 21/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9987\n",
            "Epoch 00021: val_accuracy did not improve from 0.99275\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0357 - val_accuracy: 0.9927\n",
            "Epoch 22/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995\n",
            "Epoch 00022: val_accuracy improved from 0.99275 to 0.99292, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0367 - val_accuracy: 0.9929\n",
            "Epoch 23/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n",
            "Epoch 00023: val_accuracy did not improve from 0.99292\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0417 - val_accuracy: 0.9912\n",
            "Epoch 24/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n",
            "Epoch 00024: val_accuracy improved from 0.99292 to 0.99350, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0361 - val_accuracy: 0.9935\n",
            "Epoch 25/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 9.6472e-04 - accuracy: 0.9997\n",
            "Epoch 00025: val_accuracy did not improve from 0.99350\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 9.6215e-04 - accuracy: 0.9997 - val_loss: 0.0343 - val_accuracy: 0.9931\n",
            "Epoch 26/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9990\n",
            "Epoch 00026: val_accuracy did not improve from 0.99350\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0369 - val_accuracy: 0.9935\n",
            "Epoch 27/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9982\n",
            "Epoch 00027: val_accuracy did not improve from 0.99350\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0644 - val_accuracy: 0.9876\n",
            "Epoch 28/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9983\n",
            "Epoch 00028: val_accuracy did not improve from 0.99350\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0331 - val_accuracy: 0.9911\n",
            "Epoch 29/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
            "Epoch 00029: val_accuracy improved from 0.99350 to 0.99358, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0341 - val_accuracy: 0.9936\n",
            "Epoch 30/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
            "Epoch 00030: val_accuracy improved from 0.99358 to 0.99417, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0299 - val_accuracy: 0.9942\n",
            "Epoch 31/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 3.3359e-05 - accuracy: 1.0000\n",
            "Epoch 00031: val_accuracy did not improve from 0.99417\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 3.3272e-05 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9937\n",
            "Epoch 32/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 5.2795e-06 - accuracy: 1.0000\n",
            "Epoch 00032: val_accuracy did not improve from 0.99417\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 5.2669e-06 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9940\n",
            "Epoch 33/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 2.3520e-06 - accuracy: 1.0000\n",
            "Epoch 00033: val_accuracy did not improve from 0.99417\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 2.3458e-06 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9940\n",
            "Epoch 34/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 1.5008e-06 - accuracy: 1.0000\n",
            "Epoch 00034: val_accuracy did not improve from 0.99417\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.4988e-06 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9942\n",
            "Epoch 35/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 1.0897e-06 - accuracy: 1.0000\n",
            "Epoch 00035: val_accuracy improved from 0.99417 to 0.99433, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.0901e-06 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 0.9943\n",
            "Epoch 36/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 8.4126e-07 - accuracy: 1.0000\n",
            "Epoch 00036: val_accuracy did not improve from 0.99433\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 8.4885e-07 - accuracy: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9943\n",
            "Epoch 37/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 7.0366e-07 - accuracy: 1.0000\n",
            "Epoch 00037: val_accuracy did not improve from 0.99433\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 7.0208e-07 - accuracy: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9942\n",
            "Epoch 38/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 6.0200e-07 - accuracy: 1.0000\n",
            "Epoch 00038: val_accuracy improved from 0.99433 to 0.99442, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 6.0043e-07 - accuracy: 1.0000 - val_loss: 0.0402 - val_accuracy: 0.9944\n",
            "Epoch 39/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 5.1017e-07 - accuracy: 1.0000\n",
            "Epoch 00039: val_accuracy did not improve from 0.99442\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 5.1025e-07 - accuracy: 1.0000 - val_loss: 0.0407 - val_accuracy: 0.9944\n",
            "Epoch 40/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 4.4837e-07 - accuracy: 1.0000\n",
            "Epoch 00040: val_accuracy did not improve from 0.99442\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 4.4724e-07 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 0.9942\n",
            "Epoch 41/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 3.9413e-07 - accuracy: 1.0000\n",
            "Epoch 00041: val_accuracy improved from 0.99442 to 0.99450, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 3.9308e-07 - accuracy: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9945\n",
            "Epoch 42/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 3.5038e-07 - accuracy: 1.0000\n",
            "Epoch 00042: val_accuracy improved from 0.99450 to 0.99458, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 3.4945e-07 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9946\n",
            "Epoch 43/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 3.0907e-07 - accuracy: 1.0000\n",
            "Epoch 00043: val_accuracy did not improve from 0.99458\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 3.1036e-07 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 0.9943\n",
            "Epoch 44/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 2.7395e-07 - accuracy: 1.0000\n",
            "Epoch 00044: val_accuracy did not improve from 0.99458\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 2.7334e-07 - accuracy: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9945\n",
            "Epoch 45/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 2.3381e-07 - accuracy: 1.0000\n",
            "Epoch 00045: val_accuracy did not improve from 0.99458\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 2.3403e-07 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9946\n",
            "Epoch 46/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 2.0860e-07 - accuracy: 1.0000\n",
            "Epoch 00046: val_accuracy did not improve from 0.99458\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 2.0914e-07 - accuracy: 1.0000 - val_loss: 0.0422 - val_accuracy: 0.9946\n",
            "Epoch 47/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 1.8943e-07 - accuracy: 1.0000\n",
            "Epoch 00047: val_accuracy did not improve from 0.99458\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.8894e-07 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9946\n",
            "Epoch 48/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 1.6409e-07 - accuracy: 1.0000\n",
            "Epoch 00048: val_accuracy did not improve from 0.99458\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.6383e-07 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9946\n",
            "Epoch 49/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 1.5179e-07 - accuracy: 1.0000\n",
            "Epoch 00049: val_accuracy improved from 0.99458 to 0.99467, saving model to multi_layer_single_hidden_best.h5\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.5138e-07 - accuracy: 1.0000 - val_loss: 0.0431 - val_accuracy: 0.9947\n",
            "Epoch 50/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 1.3297e-07 - accuracy: 1.0000\n",
            "Epoch 00050: val_accuracy did not improve from 0.99467\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.3268e-07 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9947\n",
            "Epoch 51/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 1.2154e-07 - accuracy: 1.0000\n",
            "Epoch 00051: val_accuracy did not improve from 0.99467\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.2237e-07 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9946\n",
            "Epoch 52/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 1.0956e-07 - accuracy: 1.0000\n",
            "Epoch 00052: val_accuracy did not improve from 0.99467\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.0931e-07 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9945\n",
            "Epoch 53/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 1.0010e-07 - accuracy: 1.0000\n",
            "Epoch 00053: val_accuracy did not improve from 0.99467\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 9.9951e-08 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9947\n",
            "Epoch 54/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 9.1022e-08 - accuracy: 1.0000\n",
            "Epoch 00054: val_accuracy did not improve from 0.99467\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 9.0799e-08 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9946\n",
            "Epoch 55/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 8.3694e-08 - accuracy: 1.0000\n",
            "Epoch 00055: val_accuracy did not improve from 0.99467\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 8.3565e-08 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9945\n",
            "Epoch 56/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 7.5740e-08 - accuracy: 1.0000\n",
            "Epoch 00056: val_accuracy did not improve from 0.99467\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 7.5620e-08 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 0.9946\n",
            "Epoch 57/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 6.9358e-08 - accuracy: 1.0000\n",
            "Epoch 00057: val_accuracy did not improve from 0.99467\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 7.0124e-08 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9946\n",
            "Epoch 58/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 6.3823e-08 - accuracy: 1.0000\n",
            "Epoch 00058: val_accuracy did not improve from 0.99467\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 6.3767e-08 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9946\n",
            "Epoch 59/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 5.8217e-08 - accuracy: 1.0000\n",
            "Epoch 00059: val_accuracy did not improve from 0.99467\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 5.8067e-08 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9945\n",
            "Epoch 00059: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2cO4MCVVd-l5"
      },
      "source": [
        "and plot the loss and accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yGJ1geEid-l6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "1eb85233-6336-4876-b80f-54706a5ce843"
      },
      "source": [
        "plot_loss_accuracy(multi_convolutional_train.history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ua-4JuYHd-l7"
      },
      "source": [
        "And evaluate the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6bIumyoXd-l7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8e0e75e9-81e5-4927-b0e6-6f18c2946383"
      },
      "source": [
        "multi_convolutional_model.load_weights('multi_layer_single_hidden_best.h5')\n",
        "loss, acc = multi_convolutional_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy: {}'.format(acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9945\n",
            "Accuracy: 0.9944999814033508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdDQ8qUVfSBS",
        "colab_type": "text"
      },
      "source": [
        "99.45% is already a great accuracy, greatly surpassing the values obtained with a feed-forward arquitecture. Let us see if drop out could have a n impact here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbjRx-v-QPQI",
        "colab_type": "text"
      },
      "source": [
        "#### Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5kqb6szirP4",
        "colab_type": "text"
      },
      "source": [
        "##### Dropout\n",
        "\n",
        "This is pretty straight forward, just a matter of adding a dropout layer in each level, and testing different vlues:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v9-NsG_qgQq9",
        "colab": {}
      },
      "source": [
        "def create_dropout_convolutional_model(rate, name='dropout_convolutional_model'):\n",
        "  multi_layer_model = tf.keras.Sequential(name=name)\n",
        "  for filters in (64, 128, 256):\n",
        "    multi_layer_model.add(tf.keras.layers.Conv2D(filters=filters, kernel_size=7, activation='relu', padding='same', name='convolution_{}_7'.format(filters), input_shape=mnist_info.features['image'].shape))\n",
        "    multi_layer_model.add(tf.keras.layers.MaxPool2D())\n",
        "    multi_layer_model.add(tf.keras.layers.Dropout(rate))\n",
        "  multi_layer_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "  multi_layer_model.add(tf.keras.layers.Dense(128, activation='relu', name='hidden'))\n",
        "  multi_layer_model.add(tf.keras.layers.Dropout(rate))\n",
        "  multi_layer_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "\n",
        "  multi_layer_model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "  multi_layer_model.summary()\n",
        "  return multi_layer_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bVu_HFuEgQq_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50ccddff-46ff-4cde-a4da-7d169bed1979"
      },
      "source": [
        "dropout_rates = (0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)\n",
        "accuracy_lines = test_model_parameter(create_dropout_convolutional_model, dropout_rates, 35, tests=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"dropout_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_51 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 14, 14, 128)       401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_52 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "convolution_256_7 (Conv2D)   (None, 7, 7, 256)         1605888   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_53 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,306,954\n",
            "Trainable params: 2,306,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.2257 - accuracy: 0.9272 - val_loss: 0.0673 - val_accuracy: 0.9801\n",
            "Epoch 2/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0470 - accuracy: 0.9853 - val_loss: 0.0513 - val_accuracy: 0.9843\n",
            "Epoch 3/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0293 - accuracy: 0.9910 - val_loss: 0.0394 - val_accuracy: 0.9876\n",
            "Epoch 4/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.0422 - val_accuracy: 0.9866\n",
            "Epoch 5/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0322 - val_accuracy: 0.9903\n",
            "Epoch 6/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0329 - val_accuracy: 0.9916\n",
            "Epoch 7/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0331 - val_accuracy: 0.9910\n",
            "Epoch 8/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.0375 - val_accuracy: 0.9904\n",
            "Epoch 9/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0369 - val_accuracy: 0.9913\n",
            "Epoch 10/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0337 - val_accuracy: 0.9914\n",
            "Epoch 11/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0385 - val_accuracy: 0.9902\n",
            "Epoch 12/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0478 - val_accuracy: 0.9891\n",
            "Epoch 13/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0385 - val_accuracy: 0.9918\n",
            "Epoch 14/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0390 - val_accuracy: 0.9902\n",
            "Epoch 15/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0324 - val_accuracy: 0.9931\n",
            "Epoch 16/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0319 - val_accuracy: 0.9932\n",
            "Epoch 17/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0394 - val_accuracy: 0.9915\n",
            "Epoch 18/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.0392 - val_accuracy: 0.9925\n",
            "Epoch 19/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0489 - val_accuracy: 0.9898\n",
            "Epoch 20/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0355 - val_accuracy: 0.9918\n",
            "Epoch 21/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0368 - val_accuracy: 0.9932\n",
            "Epoch 22/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0372 - val_accuracy: 0.9933\n",
            "Epoch 23/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0475 - val_accuracy: 0.9902\n",
            "Epoch 24/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0459 - val_accuracy: 0.9891\n",
            "Epoch 25/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0308 - val_accuracy: 0.9944\n",
            "Epoch 26/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 4.8643e-04 - accuracy: 0.9998 - val_loss: 0.0324 - val_accuracy: 0.9941\n",
            "Epoch 27/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 5.2134e-05 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9937\n",
            "Epoch 28/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.3306e-05 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 0.9941\n",
            "Epoch 29/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 5.5623e-06 - accuracy: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9941\n",
            "Epoch 30/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 3.5463e-06 - accuracy: 1.0000 - val_loss: 0.0365 - val_accuracy: 0.9941\n",
            "Epoch 31/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 2.8291e-06 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 0.9941\n",
            "Epoch 32/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 2.3335e-06 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9941\n",
            "Epoch 33/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.9602e-06 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 0.9940\n",
            "Epoch 34/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.6702e-06 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9941\n",
            "Epoch 35/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.4380e-06 - accuracy: 1.0000 - val_loss: 0.0381 - val_accuracy: 0.9941\n",
            "Model: \"dropout_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 14, 14, 128)       401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_55 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "convolution_256_7 (Conv2D)   (None, 7, 7, 256)         1605888   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,306,954\n",
            "Trainable params: 2,306,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.2826 - accuracy: 0.9098 - val_loss: 0.0603 - val_accuracy: 0.9808\n",
            "Epoch 2/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0509 - accuracy: 0.9845 - val_loss: 0.0367 - val_accuracy: 0.9884\n",
            "Epoch 3/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0348 - accuracy: 0.9890 - val_loss: 0.0376 - val_accuracy: 0.9874\n",
            "Epoch 4/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0267 - accuracy: 0.9918 - val_loss: 0.0291 - val_accuracy: 0.9912\n",
            "Epoch 5/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.0330 - val_accuracy: 0.9899\n",
            "Epoch 6/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.0335 - val_accuracy: 0.9915\n",
            "Epoch 7/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.0309 - val_accuracy: 0.9907\n",
            "Epoch 8/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.0304 - val_accuracy: 0.9918\n",
            "Epoch 9/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.0286 - val_accuracy: 0.9915\n",
            "Epoch 10/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0303 - val_accuracy: 0.9914\n",
            "Epoch 11/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0320 - val_accuracy: 0.9912\n",
            "Epoch 12/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0326 - val_accuracy: 0.9923\n",
            "Epoch 13/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0322 - val_accuracy: 0.9923\n",
            "Epoch 14/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.0328 - val_accuracy: 0.9909\n",
            "Epoch 15/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0325 - val_accuracy: 0.9916\n",
            "Epoch 16/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0292 - val_accuracy: 0.9927\n",
            "Epoch 17/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0480 - val_accuracy: 0.9895\n",
            "Epoch 18/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0329 - val_accuracy: 0.9928\n",
            "Epoch 19/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0512 - val_accuracy: 0.9893\n",
            "Epoch 20/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0348 - val_accuracy: 0.9919\n",
            "Epoch 21/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0405 - val_accuracy: 0.9918\n",
            "Epoch 22/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0455 - val_accuracy: 0.9909\n",
            "Epoch 23/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.0418 - val_accuracy: 0.9920\n",
            "Epoch 24/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0415 - val_accuracy: 0.9911\n",
            "Epoch 25/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0387 - val_accuracy: 0.9918\n",
            "Epoch 26/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0346 - val_accuracy: 0.9934\n",
            "Epoch 27/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0372 - val_accuracy: 0.9918\n",
            "Epoch 28/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0441 - val_accuracy: 0.9912\n",
            "Epoch 29/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0418 - val_accuracy: 0.9923\n",
            "Epoch 30/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0346 - val_accuracy: 0.9925\n",
            "Epoch 31/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0499 - val_accuracy: 0.9912\n",
            "Epoch 32/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0313 - val_accuracy: 0.9935\n",
            "Epoch 33/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 8.4501e-04 - accuracy: 0.9998 - val_loss: 0.0392 - val_accuracy: 0.9930\n",
            "Epoch 34/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0412 - val_accuracy: 0.9918\n",
            "Epoch 35/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0312 - val_accuracy: 0.9936\n",
            "Model: \"dropout_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_57 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 14, 14, 128)       401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_58 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "convolution_256_7 (Conv2D)   (None, 7, 7, 256)         1605888   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_59 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,306,954\n",
            "Trainable params: 2,306,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.2642 - accuracy: 0.9155 - val_loss: 0.0562 - val_accuracy: 0.9831\n",
            "Epoch 2/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0570 - accuracy: 0.9830 - val_loss: 0.0370 - val_accuracy: 0.9888\n",
            "Epoch 3/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0410 - accuracy: 0.9876 - val_loss: 0.0338 - val_accuracy: 0.9901\n",
            "Epoch 4/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 0.0288 - val_accuracy: 0.9916\n",
            "Epoch 5/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.0291 - val_accuracy: 0.9917\n",
            "Epoch 6/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0197 - accuracy: 0.9937 - val_loss: 0.0258 - val_accuracy: 0.9920\n",
            "Epoch 7/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.0306 - val_accuracy: 0.9912\n",
            "Epoch 8/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.0291 - val_accuracy: 0.9916\n",
            "Epoch 9/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.0300 - val_accuracy: 0.9918\n",
            "Epoch 10/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.0300 - val_accuracy: 0.9920\n",
            "Epoch 11/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.0293 - val_accuracy: 0.9926\n",
            "Epoch 12/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.0297 - val_accuracy: 0.9926\n",
            "Epoch 13/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0334 - val_accuracy: 0.9912\n",
            "Epoch 14/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0299 - val_accuracy: 0.9926\n",
            "Epoch 15/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0319 - val_accuracy: 0.9931\n",
            "Epoch 16/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.0445 - val_accuracy: 0.9894\n",
            "Epoch 17/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0357 - val_accuracy: 0.9919\n",
            "Epoch 18/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0365 - val_accuracy: 0.9907\n",
            "Epoch 19/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0341 - val_accuracy: 0.9923\n",
            "Epoch 20/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0327 - val_accuracy: 0.9927\n",
            "Epoch 21/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0409 - val_accuracy: 0.9900\n",
            "Epoch 22/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.0335 - val_accuracy: 0.9933\n",
            "Epoch 23/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0503 - val_accuracy: 0.9908\n",
            "Epoch 24/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0308 - val_accuracy: 0.9927\n",
            "Epoch 25/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0438 - val_accuracy: 0.9918\n",
            "Epoch 26/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0397 - val_accuracy: 0.9922\n",
            "Epoch 27/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0357 - val_accuracy: 0.9930\n",
            "Epoch 28/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0400 - val_accuracy: 0.9924\n",
            "Epoch 29/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0418 - val_accuracy: 0.9916\n",
            "Epoch 30/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0273 - val_accuracy: 0.9933\n",
            "Epoch 31/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0338 - val_accuracy: 0.9931\n",
            "Epoch 32/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0446 - val_accuracy: 0.9914\n",
            "Epoch 33/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0354 - val_accuracy: 0.9933\n",
            "Epoch 34/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0387 - val_accuracy: 0.9936\n",
            "Epoch 35/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0371 - val_accuracy: 0.9936\n",
            "Model: \"dropout_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_60 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 14, 14, 128)       401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_61 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "convolution_256_7 (Conv2D)   (None, 7, 7, 256)         1605888   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_62 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,306,954\n",
            "Trainable params: 2,306,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.3108 - accuracy: 0.8994 - val_loss: 0.0666 - val_accuracy: 0.9803\n",
            "Epoch 2/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0698 - accuracy: 0.9796 - val_loss: 0.0398 - val_accuracy: 0.9872\n",
            "Epoch 3/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0472 - accuracy: 0.9861 - val_loss: 0.0331 - val_accuracy: 0.9901\n",
            "Epoch 4/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 0.0281 - val_accuracy: 0.9913\n",
            "Epoch 5/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.0458 - val_accuracy: 0.9870\n",
            "Epoch 6/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0279 - accuracy: 0.9919 - val_loss: 0.0321 - val_accuracy: 0.9901\n",
            "Epoch 7/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.0291 - val_accuracy: 0.9913\n",
            "Epoch 8/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.0282 - val_accuracy: 0.9925\n",
            "Epoch 9/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.0308 - val_accuracy: 0.9905\n",
            "Epoch 10/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.0252 - val_accuracy: 0.9938\n",
            "Epoch 11/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.0242 - val_accuracy: 0.9932\n",
            "Epoch 12/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 0.0261 - val_accuracy: 0.9927\n",
            "Epoch 13/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.0245 - val_accuracy: 0.9933\n",
            "Epoch 14/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.0254 - val_accuracy: 0.9930\n",
            "Epoch 15/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.0306 - val_accuracy: 0.9918\n",
            "Epoch 16/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.0268 - val_accuracy: 0.9932\n",
            "Epoch 17/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0241 - val_accuracy: 0.9941\n",
            "Epoch 18/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.0279 - val_accuracy: 0.9932\n",
            "Epoch 19/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0276 - val_accuracy: 0.9925\n",
            "Epoch 20/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0289 - val_accuracy: 0.9929\n",
            "Epoch 21/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.0310 - val_accuracy: 0.9934\n",
            "Epoch 22/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0278 - val_accuracy: 0.9942\n",
            "Epoch 23/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0339 - val_accuracy: 0.9923\n",
            "Epoch 24/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0369 - val_accuracy: 0.9927\n",
            "Epoch 25/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.0386 - val_accuracy: 0.9927\n",
            "Epoch 26/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0293 - val_accuracy: 0.9941\n",
            "Epoch 27/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0405 - val_accuracy: 0.9925\n",
            "Epoch 28/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0311 - val_accuracy: 0.9939\n",
            "Epoch 29/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0335 - val_accuracy: 0.9924\n",
            "Epoch 30/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.0283 - val_accuracy: 0.9942\n",
            "Epoch 31/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0327 - val_accuracy: 0.9941\n",
            "Epoch 32/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0313 - val_accuracy: 0.9945\n",
            "Epoch 33/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.0366 - val_accuracy: 0.9931\n",
            "Epoch 34/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.0284 - val_accuracy: 0.9938\n",
            "Epoch 35/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0359 - val_accuracy: 0.9923\n",
            "Model: \"dropout_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_63 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 14, 14, 128)       401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_64 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "convolution_256_7 (Conv2D)   (None, 7, 7, 256)         1605888   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_65 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,306,954\n",
            "Trainable params: 2,306,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.3796 - accuracy: 0.8792 - val_loss: 0.0723 - val_accuracy: 0.9782\n",
            "Epoch 2/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0853 - accuracy: 0.9754 - val_loss: 0.0452 - val_accuracy: 0.9847\n",
            "Epoch 3/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0602 - accuracy: 0.9826 - val_loss: 0.0403 - val_accuracy: 0.9877\n",
            "Epoch 4/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0463 - accuracy: 0.9863 - val_loss: 0.0337 - val_accuracy: 0.9881\n",
            "Epoch 5/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0408 - accuracy: 0.9880 - val_loss: 0.0301 - val_accuracy: 0.9907\n",
            "Epoch 6/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0360 - accuracy: 0.9891 - val_loss: 0.0281 - val_accuracy: 0.9913\n",
            "Epoch 7/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.0270 - val_accuracy: 0.9928\n",
            "Epoch 8/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.0261 - val_accuracy: 0.9921\n",
            "Epoch 9/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0245 - accuracy: 0.9929 - val_loss: 0.0265 - val_accuracy: 0.9928\n",
            "Epoch 10/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0228 - accuracy: 0.9939 - val_loss: 0.0270 - val_accuracy: 0.9920\n",
            "Epoch 11/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 0.0250 - val_accuracy: 0.9929\n",
            "Epoch 12/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0215 - accuracy: 0.9935 - val_loss: 0.0241 - val_accuracy: 0.9929\n",
            "Epoch 13/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.0294 - val_accuracy: 0.9920\n",
            "Epoch 14/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.0262 - val_accuracy: 0.9924\n",
            "Epoch 15/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0264 - val_accuracy: 0.9932\n",
            "Epoch 16/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0156 - accuracy: 0.9958 - val_loss: 0.0261 - val_accuracy: 0.9928\n",
            "Epoch 17/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.0252 - val_accuracy: 0.9937\n",
            "Epoch 18/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.0253 - val_accuracy: 0.9939\n",
            "Epoch 19/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.0327 - val_accuracy: 0.9918\n",
            "Epoch 20/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0302 - val_accuracy: 0.9931\n",
            "Epoch 21/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.0282 - val_accuracy: 0.9931\n",
            "Epoch 22/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.0251 - val_accuracy: 0.9941\n",
            "Epoch 23/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.0270 - val_accuracy: 0.9933\n",
            "Epoch 24/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.0293 - val_accuracy: 0.9938\n",
            "Epoch 25/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0271 - val_accuracy: 0.9937\n",
            "Epoch 26/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0275 - val_accuracy: 0.9934\n",
            "Epoch 27/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.0288 - val_accuracy: 0.9929\n",
            "Epoch 28/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.0315 - val_accuracy: 0.9933\n",
            "Epoch 29/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.0279 - val_accuracy: 0.9941\n",
            "Epoch 30/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0321 - val_accuracy: 0.9937\n",
            "Epoch 31/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0130 - accuracy: 0.9960 - val_loss: 0.0278 - val_accuracy: 0.9939\n",
            "Epoch 32/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0313 - val_accuracy: 0.9928\n",
            "Epoch 33/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0123 - accuracy: 0.9965 - val_loss: 0.0323 - val_accuracy: 0.9928\n",
            "Epoch 34/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.0328 - val_accuracy: 0.9937\n",
            "Epoch 35/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.0310 - val_accuracy: 0.9947\n",
            "Model: \"dropout_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_66 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 14, 14, 128)       401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_67 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "convolution_256_7 (Conv2D)   (None, 7, 7, 256)         1605888   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_68 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,306,954\n",
            "Trainable params: 2,306,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.4675 - accuracy: 0.8445 - val_loss: 0.0672 - val_accuracy: 0.9797\n",
            "Epoch 2/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1036 - accuracy: 0.9704 - val_loss: 0.0444 - val_accuracy: 0.9867\n",
            "Epoch 3/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0776 - accuracy: 0.9784 - val_loss: 0.0369 - val_accuracy: 0.9886\n",
            "Epoch 4/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0621 - accuracy: 0.9820 - val_loss: 0.0319 - val_accuracy: 0.9905\n",
            "Epoch 5/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0515 - accuracy: 0.9856 - val_loss: 0.0318 - val_accuracy: 0.9900\n",
            "Epoch 6/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0471 - accuracy: 0.9868 - val_loss: 0.0340 - val_accuracy: 0.9898\n",
            "Epoch 7/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0459 - accuracy: 0.9869 - val_loss: 0.0265 - val_accuracy: 0.9925\n",
            "Epoch 8/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0388 - accuracy: 0.9890 - val_loss: 0.0264 - val_accuracy: 0.9929\n",
            "Epoch 9/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0369 - accuracy: 0.9893 - val_loss: 0.0291 - val_accuracy: 0.9910\n",
            "Epoch 10/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0363 - accuracy: 0.9899 - val_loss: 0.0244 - val_accuracy: 0.9938\n",
            "Epoch 11/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0310 - accuracy: 0.9908 - val_loss: 0.0246 - val_accuracy: 0.9927\n",
            "Epoch 12/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0318 - accuracy: 0.9907 - val_loss: 0.0212 - val_accuracy: 0.9941\n",
            "Epoch 13/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0285 - accuracy: 0.9914 - val_loss: 0.0241 - val_accuracy: 0.9935\n",
            "Epoch 14/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0293 - accuracy: 0.9916 - val_loss: 0.0248 - val_accuracy: 0.9933\n",
            "Epoch 15/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.0226 - val_accuracy: 0.9939\n",
            "Epoch 16/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0281 - accuracy: 0.9915 - val_loss: 0.0223 - val_accuracy: 0.9934\n",
            "Epoch 17/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0258 - accuracy: 0.9925 - val_loss: 0.0212 - val_accuracy: 0.9939\n",
            "Epoch 18/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0221 - accuracy: 0.9933 - val_loss: 0.0205 - val_accuracy: 0.9944\n",
            "Epoch 19/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.0186 - val_accuracy: 0.9950\n",
            "Epoch 20/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.0234 - val_accuracy: 0.9934\n",
            "Epoch 21/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0257 - accuracy: 0.9925 - val_loss: 0.0225 - val_accuracy: 0.9947\n",
            "Epoch 22/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.0215 - val_accuracy: 0.9945\n",
            "Epoch 23/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0238 - accuracy: 0.9928 - val_loss: 0.0217 - val_accuracy: 0.9944\n",
            "Epoch 24/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0218 - accuracy: 0.9935 - val_loss: 0.0220 - val_accuracy: 0.9937\n",
            "Epoch 25/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0210 - accuracy: 0.9935 - val_loss: 0.0211 - val_accuracy: 0.9939\n",
            "Epoch 26/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.0199 - val_accuracy: 0.9948\n",
            "Epoch 27/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0229 - val_accuracy: 0.9941\n",
            "Epoch 28/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.0235 - val_accuracy: 0.9944\n",
            "Epoch 29/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0206 - val_accuracy: 0.9948\n",
            "Epoch 30/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0204 - accuracy: 0.9941 - val_loss: 0.0220 - val_accuracy: 0.9936\n",
            "Epoch 31/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 0.0240 - val_accuracy: 0.9946\n",
            "Epoch 32/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0188 - accuracy: 0.9946 - val_loss: 0.0255 - val_accuracy: 0.9943\n",
            "Epoch 33/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0204 - accuracy: 0.9935 - val_loss: 0.0212 - val_accuracy: 0.9945\n",
            "Epoch 34/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0257 - val_accuracy: 0.9947\n",
            "Epoch 35/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0208 - val_accuracy: 0.9950\n",
            "Model: \"dropout_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_69 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 14, 14, 128)       401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_70 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "convolution_256_7 (Conv2D)   (None, 7, 7, 256)         1605888   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_71 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,306,954\n",
            "Trainable params: 2,306,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.6559 - accuracy: 0.7767 - val_loss: 0.0903 - val_accuracy: 0.9734\n",
            "Epoch 2/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1441 - accuracy: 0.9594 - val_loss: 0.0539 - val_accuracy: 0.9841\n",
            "Epoch 3/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.1037 - accuracy: 0.9719 - val_loss: 0.0433 - val_accuracy: 0.9858\n",
            "Epoch 4/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0865 - accuracy: 0.9763 - val_loss: 0.0385 - val_accuracy: 0.9881\n",
            "Epoch 5/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0776 - accuracy: 0.9789 - val_loss: 0.0310 - val_accuracy: 0.9908\n",
            "Epoch 6/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0681 - accuracy: 0.9816 - val_loss: 0.0309 - val_accuracy: 0.9895\n",
            "Epoch 7/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0635 - accuracy: 0.9827 - val_loss: 0.0260 - val_accuracy: 0.9912\n",
            "Epoch 8/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0624 - accuracy: 0.9835 - val_loss: 0.0273 - val_accuracy: 0.9920\n",
            "Epoch 9/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0562 - accuracy: 0.9844 - val_loss: 0.0307 - val_accuracy: 0.9909\n",
            "Epoch 10/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0529 - accuracy: 0.9857 - val_loss: 0.0259 - val_accuracy: 0.9918\n",
            "Epoch 11/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0565 - accuracy: 0.9852 - val_loss: 0.0263 - val_accuracy: 0.9921\n",
            "Epoch 12/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0477 - accuracy: 0.9871 - val_loss: 0.0235 - val_accuracy: 0.9924\n",
            "Epoch 13/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0540 - accuracy: 0.9854 - val_loss: 0.0235 - val_accuracy: 0.9929\n",
            "Epoch 14/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0473 - accuracy: 0.9868 - val_loss: 0.0258 - val_accuracy: 0.9919\n",
            "Epoch 15/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0491 - accuracy: 0.9861 - val_loss: 0.0233 - val_accuracy: 0.9931\n",
            "Epoch 16/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0441 - accuracy: 0.9877 - val_loss: 0.0220 - val_accuracy: 0.9935\n",
            "Epoch 17/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0444 - accuracy: 0.9873 - val_loss: 0.0215 - val_accuracy: 0.9941\n",
            "Epoch 18/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0431 - accuracy: 0.9876 - val_loss: 0.0218 - val_accuracy: 0.9925\n",
            "Epoch 19/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0441 - accuracy: 0.9882 - val_loss: 0.0211 - val_accuracy: 0.9938\n",
            "Epoch 20/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0425 - accuracy: 0.9882 - val_loss: 0.0240 - val_accuracy: 0.9934\n",
            "Epoch 21/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0405 - accuracy: 0.9890 - val_loss: 0.0217 - val_accuracy: 0.9940\n",
            "Epoch 22/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0421 - accuracy: 0.9886 - val_loss: 0.0211 - val_accuracy: 0.9947\n",
            "Epoch 23/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0385 - accuracy: 0.9890 - val_loss: 0.0209 - val_accuracy: 0.9944\n",
            "Epoch 24/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0393 - accuracy: 0.9888 - val_loss: 0.0211 - val_accuracy: 0.9937\n",
            "Epoch 25/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0406 - accuracy: 0.9887 - val_loss: 0.0223 - val_accuracy: 0.9942\n",
            "Epoch 26/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0378 - accuracy: 0.9894 - val_loss: 0.0230 - val_accuracy: 0.9924\n",
            "Epoch 27/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0392 - accuracy: 0.9890 - val_loss: 0.0235 - val_accuracy: 0.9941\n",
            "Epoch 28/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0358 - accuracy: 0.9898 - val_loss: 0.0208 - val_accuracy: 0.9939\n",
            "Epoch 29/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0359 - accuracy: 0.9896 - val_loss: 0.0218 - val_accuracy: 0.9943\n",
            "Epoch 30/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0394 - accuracy: 0.9888 - val_loss: 0.0217 - val_accuracy: 0.9935\n",
            "Epoch 31/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0330 - accuracy: 0.9905 - val_loss: 0.0213 - val_accuracy: 0.9942\n",
            "Epoch 32/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0363 - accuracy: 0.9898 - val_loss: 0.0207 - val_accuracy: 0.9943\n",
            "Epoch 33/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0359 - accuracy: 0.9903 - val_loss: 0.0197 - val_accuracy: 0.9946\n",
            "Epoch 34/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0321 - accuracy: 0.9907 - val_loss: 0.0195 - val_accuracy: 0.9947\n",
            "Epoch 35/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0343 - accuracy: 0.9909 - val_loss: 0.0205 - val_accuracy: 0.9943\n",
            "Model: \"dropout_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_72 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 14, 14, 128)       401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_73 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "convolution_256_7 (Conv2D)   (None, 7, 7, 256)         1605888   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_74 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,306,954\n",
            "Trainable params: 2,306,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 1.0983 - accuracy: 0.6115 - val_loss: 0.1233 - val_accuracy: 0.9645\n",
            "Epoch 2/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.2449 - accuracy: 0.9329 - val_loss: 0.0785 - val_accuracy: 0.9765\n",
            "Epoch 3/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.1734 - accuracy: 0.9519 - val_loss: 0.0606 - val_accuracy: 0.9826\n",
            "Epoch 4/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1456 - accuracy: 0.9611 - val_loss: 0.0516 - val_accuracy: 0.9840\n",
            "Epoch 5/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1243 - accuracy: 0.9663 - val_loss: 0.0417 - val_accuracy: 0.9878\n",
            "Epoch 6/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.1195 - accuracy: 0.9669 - val_loss: 0.0436 - val_accuracy: 0.9870\n",
            "Epoch 7/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.1125 - accuracy: 0.9705 - val_loss: 0.0371 - val_accuracy: 0.9896\n",
            "Epoch 8/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1029 - accuracy: 0.9744 - val_loss: 0.0366 - val_accuracy: 0.9885\n",
            "Epoch 9/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1037 - accuracy: 0.9732 - val_loss: 0.0343 - val_accuracy: 0.9903\n",
            "Epoch 10/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0928 - accuracy: 0.9756 - val_loss: 0.0311 - val_accuracy: 0.9902\n",
            "Epoch 11/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0977 - accuracy: 0.9741 - val_loss: 0.0327 - val_accuracy: 0.9902\n",
            "Epoch 12/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0970 - accuracy: 0.9744 - val_loss: 0.0362 - val_accuracy: 0.9901\n",
            "Epoch 13/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0916 - accuracy: 0.9757 - val_loss: 0.0285 - val_accuracy: 0.9912\n",
            "Epoch 14/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0898 - accuracy: 0.9769 - val_loss: 0.0294 - val_accuracy: 0.9911\n",
            "Epoch 15/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0855 - accuracy: 0.9769 - val_loss: 0.0287 - val_accuracy: 0.9912\n",
            "Epoch 16/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0821 - accuracy: 0.9781 - val_loss: 0.0296 - val_accuracy: 0.9909\n",
            "Epoch 17/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0809 - accuracy: 0.9787 - val_loss: 0.0282 - val_accuracy: 0.9916\n",
            "Epoch 18/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0856 - accuracy: 0.9774 - val_loss: 0.0284 - val_accuracy: 0.9927\n",
            "Epoch 19/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0797 - accuracy: 0.9787 - val_loss: 0.0250 - val_accuracy: 0.9923\n",
            "Epoch 20/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0792 - accuracy: 0.9782 - val_loss: 0.0268 - val_accuracy: 0.9923\n",
            "Epoch 21/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0744 - accuracy: 0.9797 - val_loss: 0.0270 - val_accuracy: 0.9925\n",
            "Epoch 22/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0776 - accuracy: 0.9790 - val_loss: 0.0255 - val_accuracy: 0.9928\n",
            "Epoch 23/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0755 - accuracy: 0.9803 - val_loss: 0.0261 - val_accuracy: 0.9927\n",
            "Epoch 24/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0805 - accuracy: 0.9785 - val_loss: 0.0247 - val_accuracy: 0.9927\n",
            "Epoch 25/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0809 - accuracy: 0.9792 - val_loss: 0.0257 - val_accuracy: 0.9923\n",
            "Epoch 26/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0747 - accuracy: 0.9798 - val_loss: 0.0252 - val_accuracy: 0.9926\n",
            "Epoch 27/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0779 - accuracy: 0.9789 - val_loss: 0.0250 - val_accuracy: 0.9933\n",
            "Epoch 28/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0668 - accuracy: 0.9822 - val_loss: 0.0261 - val_accuracy: 0.9931\n",
            "Epoch 29/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0761 - accuracy: 0.9806 - val_loss: 0.0271 - val_accuracy: 0.9924\n",
            "Epoch 30/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0721 - accuracy: 0.9809 - val_loss: 0.0241 - val_accuracy: 0.9932\n",
            "Epoch 31/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0733 - accuracy: 0.9807 - val_loss: 0.0266 - val_accuracy: 0.9924\n",
            "Epoch 32/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0695 - accuracy: 0.9814 - val_loss: 0.0254 - val_accuracy: 0.9937\n",
            "Epoch 33/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0705 - accuracy: 0.9807 - val_loss: 0.0313 - val_accuracy: 0.9913\n",
            "Epoch 34/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0741 - accuracy: 0.9796 - val_loss: 0.0242 - val_accuracy: 0.9933\n",
            "Epoch 35/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0730 - accuracy: 0.9801 - val_loss: 0.0245 - val_accuracy: 0.9927\n",
            "Model: \"dropout_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_75 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 14, 14, 128)       401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_76 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "convolution_256_7 (Conv2D)   (None, 7, 7, 256)         1605888   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_77 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,306,954\n",
            "Trainable params: 2,306,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 2.0480 - accuracy: 0.2279 - val_loss: 1.0179 - val_accuracy: 0.7987\n",
            "Epoch 2/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.7570 - accuracy: 0.7527 - val_loss: 0.2058 - val_accuracy: 0.9507\n",
            "Epoch 3/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.4183 - accuracy: 0.8765 - val_loss: 0.1135 - val_accuracy: 0.9685\n",
            "Epoch 4/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.3371 - accuracy: 0.9060 - val_loss: 0.0954 - val_accuracy: 0.9756\n",
            "Epoch 5/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.2959 - accuracy: 0.9199 - val_loss: 0.0819 - val_accuracy: 0.9773\n",
            "Epoch 6/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.2716 - accuracy: 0.9260 - val_loss: 0.0753 - val_accuracy: 0.9796\n",
            "Epoch 7/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.2509 - accuracy: 0.9310 - val_loss: 0.0758 - val_accuracy: 0.9786\n",
            "Epoch 8/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.2388 - accuracy: 0.9352 - val_loss: 0.0723 - val_accuracy: 0.9803\n",
            "Epoch 9/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.2235 - accuracy: 0.9405 - val_loss: 0.0611 - val_accuracy: 0.9829\n",
            "Epoch 10/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.2255 - accuracy: 0.9389 - val_loss: 0.0629 - val_accuracy: 0.9820\n",
            "Epoch 11/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.2145 - accuracy: 0.9421 - val_loss: 0.0664 - val_accuracy: 0.9820\n",
            "Epoch 12/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.2151 - accuracy: 0.9438 - val_loss: 0.0596 - val_accuracy: 0.9835\n",
            "Epoch 13/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.2109 - accuracy: 0.9450 - val_loss: 0.0567 - val_accuracy: 0.9843\n",
            "Epoch 14/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1972 - accuracy: 0.9475 - val_loss: 0.0539 - val_accuracy: 0.9850\n",
            "Epoch 15/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1926 - accuracy: 0.9493 - val_loss: 0.0561 - val_accuracy: 0.9850\n",
            "Epoch 16/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.2037 - accuracy: 0.9470 - val_loss: 0.0512 - val_accuracy: 0.9858\n",
            "Epoch 17/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.2017 - accuracy: 0.9476 - val_loss: 0.0562 - val_accuracy: 0.9843\n",
            "Epoch 18/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.1893 - accuracy: 0.9493 - val_loss: 0.0537 - val_accuracy: 0.9853\n",
            "Epoch 19/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1876 - accuracy: 0.9511 - val_loss: 0.0531 - val_accuracy: 0.9858\n",
            "Epoch 20/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1885 - accuracy: 0.9514 - val_loss: 0.0523 - val_accuracy: 0.9859\n",
            "Epoch 21/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.1805 - accuracy: 0.9522 - val_loss: 0.0514 - val_accuracy: 0.9864\n",
            "Epoch 22/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1885 - accuracy: 0.9492 - val_loss: 0.0502 - val_accuracy: 0.9863\n",
            "Epoch 23/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1828 - accuracy: 0.9501 - val_loss: 0.0516 - val_accuracy: 0.9865\n",
            "Epoch 24/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1861 - accuracy: 0.9503 - val_loss: 0.0532 - val_accuracy: 0.9858\n",
            "Epoch 25/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1726 - accuracy: 0.9544 - val_loss: 0.0514 - val_accuracy: 0.9854\n",
            "Epoch 26/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1768 - accuracy: 0.9529 - val_loss: 0.0461 - val_accuracy: 0.9879\n",
            "Epoch 27/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.1776 - accuracy: 0.9538 - val_loss: 0.0495 - val_accuracy: 0.9867\n",
            "Epoch 28/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.1765 - accuracy: 0.9543 - val_loss: 0.0468 - val_accuracy: 0.9877\n",
            "Epoch 29/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.1684 - accuracy: 0.9551 - val_loss: 0.0464 - val_accuracy: 0.9872\n",
            "Epoch 30/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.1723 - accuracy: 0.9539 - val_loss: 0.0448 - val_accuracy: 0.9883\n",
            "Epoch 31/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.1713 - accuracy: 0.9559 - val_loss: 0.0443 - val_accuracy: 0.9880\n",
            "Epoch 32/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.1597 - accuracy: 0.9570 - val_loss: 0.0423 - val_accuracy: 0.9883\n",
            "Epoch 33/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.1683 - accuracy: 0.9561 - val_loss: 0.0444 - val_accuracy: 0.9872\n",
            "Epoch 34/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.1684 - accuracy: 0.9554 - val_loss: 0.0443 - val_accuracy: 0.9883\n",
            "Epoch 35/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.1586 - accuracy: 0.9570 - val_loss: 0.0427 - val_accuracy: 0.9887\n",
            "Model: \"dropout_convolutional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_78 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 14, 14, 128)       401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_79 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "convolution_256_7 (Conv2D)   (None, 7, 7, 256)         1605888   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_80 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,306,954\n",
            "Trainable params: 2,306,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "TEST 1/1\n",
            "Epoch 1/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 2.3841 - accuracy: 0.1177 - val_loss: 2.3012 - val_accuracy: 0.1128\n",
            "Epoch 2/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 2.2962 - accuracy: 0.1346 - val_loss: 2.3013 - val_accuracy: 0.1128\n",
            "Epoch 3/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 2.1724 - accuracy: 0.2046 - val_loss: 2.5462 - val_accuracy: 0.1128\n",
            "Epoch 4/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.8536 - accuracy: 0.3106 - val_loss: 3.5544 - val_accuracy: 0.1128\n",
            "Epoch 5/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.6484 - accuracy: 0.3910 - val_loss: 3.9164 - val_accuracy: 0.1140\n",
            "Epoch 6/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.5244 - accuracy: 0.4484 - val_loss: 3.8983 - val_accuracy: 0.1288\n",
            "Epoch 7/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.4206 - accuracy: 0.4890 - val_loss: 4.6655 - val_accuracy: 0.1155\n",
            "Epoch 8/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.3503 - accuracy: 0.5119 - val_loss: 4.1922 - val_accuracy: 0.1303\n",
            "Epoch 9/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.3171 - accuracy: 0.5316 - val_loss: 3.4290 - val_accuracy: 0.1691\n",
            "Epoch 10/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.2607 - accuracy: 0.5499 - val_loss: 3.9607 - val_accuracy: 0.1459\n",
            "Epoch 11/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.2297 - accuracy: 0.5688 - val_loss: 3.3446 - val_accuracy: 0.2286\n",
            "Epoch 12/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.1717 - accuracy: 0.5875 - val_loss: 3.7776 - val_accuracy: 0.1922\n",
            "Epoch 13/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.1522 - accuracy: 0.5960 - val_loss: 3.6062 - val_accuracy: 0.2113\n",
            "Epoch 14/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.1212 - accuracy: 0.6114 - val_loss: 2.9100 - val_accuracy: 0.2607\n",
            "Epoch 15/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 1.0866 - accuracy: 0.6223 - val_loss: 2.9324 - val_accuracy: 0.2869\n",
            "Epoch 16/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 1.0855 - accuracy: 0.6265 - val_loss: 2.3122 - val_accuracy: 0.3568\n",
            "Epoch 17/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.0700 - accuracy: 0.6312 - val_loss: 2.2659 - val_accuracy: 0.3600\n",
            "Epoch 18/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.0490 - accuracy: 0.6377 - val_loss: 2.1147 - val_accuracy: 0.3824\n",
            "Epoch 19/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 1.0225 - accuracy: 0.6485 - val_loss: 1.8418 - val_accuracy: 0.4632\n",
            "Epoch 20/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.9941 - accuracy: 0.6607 - val_loss: 1.9842 - val_accuracy: 0.4446\n",
            "Epoch 21/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.9939 - accuracy: 0.6630 - val_loss: 2.0660 - val_accuracy: 0.4393\n",
            "Epoch 22/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.9772 - accuracy: 0.6687 - val_loss: 1.4064 - val_accuracy: 0.5907\n",
            "Epoch 23/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.9781 - accuracy: 0.6691 - val_loss: 1.8714 - val_accuracy: 0.5161\n",
            "Epoch 24/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.9567 - accuracy: 0.6745 - val_loss: 1.4856 - val_accuracy: 0.5738\n",
            "Epoch 25/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.9436 - accuracy: 0.6776 - val_loss: 1.5519 - val_accuracy: 0.5553\n",
            "Epoch 26/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.9500 - accuracy: 0.6819 - val_loss: 1.3878 - val_accuracy: 0.6002\n",
            "Epoch 27/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.9304 - accuracy: 0.6892 - val_loss: 1.3951 - val_accuracy: 0.5956\n",
            "Epoch 28/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.9097 - accuracy: 0.6916 - val_loss: 1.2023 - val_accuracy: 0.6635\n",
            "Epoch 29/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.9087 - accuracy: 0.6975 - val_loss: 1.4867 - val_accuracy: 0.5777\n",
            "Epoch 30/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.8941 - accuracy: 0.6985 - val_loss: 1.1246 - val_accuracy: 0.6794\n",
            "Epoch 31/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.8926 - accuracy: 0.7009 - val_loss: 1.1178 - val_accuracy: 0.6630\n",
            "Epoch 32/35\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.8972 - accuracy: 0.7020 - val_loss: 1.1785 - val_accuracy: 0.6727\n",
            "Epoch 33/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.8669 - accuracy: 0.7117 - val_loss: 0.9459 - val_accuracy: 0.7297\n",
            "Epoch 34/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.8708 - accuracy: 0.7136 - val_loss: 1.0882 - val_accuracy: 0.6813\n",
            "Epoch 35/35\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.8670 - accuracy: 0.7113 - val_loss: 1.1622 - val_accuracy: 0.6828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6LhT9xdxgQrB"
      },
      "source": [
        "With the accuracy values retrieved, we plot the graph (0, 0.9 and 0.8 were removed to cleanup the graph):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J6_X8nb7gQrC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "9058e412-b370-4efc-f499-5923fdb35611"
      },
      "source": [
        "fig = plt.figure(figsize=(10, 7))\n",
        "multiple_line_chart(plt.gca(), \n",
        "                    None, \n",
        "                    accuracy_lines, \n",
        "                    \"Validation accuracy variation per dropout rate\", \n",
        "                    \"Epochs\", \n",
        "                    \"Validation accuracy\")\n",
        "plt.show()\n",
        "plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QtS6b5ZMgQrD"
      },
      "source": [
        "From the graph it appears that 0.5 maximizes the accuracy, so it must be correcting a slight overfit of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OTDXO3ihfnOZ"
      },
      "source": [
        "#### Optimization\n",
        "\n",
        "Like the feed-forward NN's, lets see if we can improve performance by adding BatchNormalization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WYLgPB3xkGVz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9801cf52-39fd-4e2a-ce42-669b3b5b9959"
      },
      "source": [
        "dropout_convolutional_model = create_dropout_convolutional_model(0.5, \"multi_layer_4_hidden_model\") #baseline\n",
        "\n",
        "multi_layer_norm_model = tf.keras.Sequential(name=\"multi_layer_norm_model\")\n",
        "for filters in (64, 128, 256):\n",
        "  multi_layer_norm_model.add(tf.keras.layers.Conv2D(filters=filters, kernel_size=7, activation='relu', padding='same', name='convolution_{}_7'.format(filters), input_shape=mnist_info.features['image'].shape))\n",
        "  multi_layer_norm_model.add(tf.keras.layers.MaxPool2D())\n",
        "  multi_layer_norm_model.add(tf.keras.layers.BatchNormalization())\n",
        "  multi_layer_norm_model.add(tf.keras.layers.Dropout(0.5))\n",
        "multi_layer_norm_model.add(tf.keras.layers.Flatten(name='flatten'))\n",
        "multi_layer_norm_model.add(tf.keras.layers.Dense(128, activation='relu', name='hidden'))\n",
        "multi_layer_norm_model.add(tf.keras.layers.BatchNormalization())\n",
        "multi_layer_norm_model.add(tf.keras.layers.Dropout(0.5))\n",
        "multi_layer_norm_model.add(tf.keras.layers.Dense(mnist_info.features['label'].num_classes, activation='softmax', name='output'))\n",
        "\n",
        "multi_layer_norm_model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "multi_layer_norm_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"multi_layer_4_hidden_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_90 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_54 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 14, 14, 128)       401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_91 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_55 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "convolution_256_7 (Conv2D)   (None, 7, 7, 256)         1605888   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_92 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_56 (Dropout)         (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "dropout_57 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,306,954\n",
            "Trainable params: 2,306,954\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"multi_layer_norm_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_64_7 (Conv2D)    (None, 28, 28, 64)        3200      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_93 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_58 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "convolution_128_7 (Conv2D)   (None, 14, 14, 128)       401536    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_94 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "dropout_59 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "convolution_256_7 (Conv2D)   (None, 7, 7, 256)         1605888   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_95 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 3, 3, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_60 (Dropout)         (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 128)               295040    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_61 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,309,258\n",
            "Trainable params: 2,308,106\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lbAVvAvdkGV3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92d90cb1-1176-4a2c-d8f0-b5f5bebf15a6"
      },
      "source": [
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "earlystop_norm = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('dropout_convolutional_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "checkpoint_norm = tf.keras.callbacks.ModelCheckpoint('multi_layer_norm_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
        "\n",
        "dropout_convolutional_train = dropout_convolutional_model.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop,checkpoint], epochs=10000, batch_size=256)\n",
        "multi_layer_norm_train = multi_layer_norm_model.fit(mnist_train_x, mnist_train_y, validation_split=0.2, callbacks=[earlystop_norm,checkpoint_norm], epochs=10000, batch_size=256)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9951\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.99425, saving model to dropout_convolutional_model.h5\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.0287 - val_accuracy: 0.9942\n",
            "Epoch 2/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9954\n",
            "Epoch 00002: val_accuracy did not improve from 0.99425\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0162 - accuracy: 0.9954 - val_loss: 0.0272 - val_accuracy: 0.9942\n",
            "Epoch 3/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9954\n",
            "Epoch 00003: val_accuracy improved from 0.99425 to 0.99492, saving model to dropout_convolutional_model.h5\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0293 - val_accuracy: 0.9949\n",
            "Epoch 4/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9953\n",
            "Epoch 00004: val_accuracy did not improve from 0.99492\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.0308 - val_accuracy: 0.9944\n",
            "Epoch 5/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9953\n",
            "Epoch 00005: val_accuracy did not improve from 0.99492\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.0259 - val_accuracy: 0.9948\n",
            "Epoch 6/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9948\n",
            "Epoch 00006: val_accuracy improved from 0.99492 to 0.99525, saving model to dropout_convolutional_model.h5\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.0251 - val_accuracy: 0.9952\n",
            "Epoch 7/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9951\n",
            "Epoch 00007: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.0261 - val_accuracy: 0.9941\n",
            "Epoch 8/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9967\n",
            "Epoch 00008: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.0277 - val_accuracy: 0.9952\n",
            "Epoch 9/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9950\n",
            "Epoch 00009: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0182 - accuracy: 0.9950 - val_loss: 0.0256 - val_accuracy: 0.9938\n",
            "Epoch 10/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0169 - accuracy: 0.9952\n",
            "Epoch 00010: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0168 - accuracy: 0.9952 - val_loss: 0.0263 - val_accuracy: 0.9945\n",
            "Epoch 11/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9960\n",
            "Epoch 00011: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0147 - accuracy: 0.9960 - val_loss: 0.0247 - val_accuracy: 0.9944\n",
            "Epoch 12/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9962\n",
            "Epoch 00012: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 0.0275 - val_accuracy: 0.9943\n",
            "Epoch 13/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9962\n",
            "Epoch 00013: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.0282 - val_accuracy: 0.9943\n",
            "Epoch 14/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9957\n",
            "Epoch 00014: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.0272 - val_accuracy: 0.9942\n",
            "Epoch 15/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9964\n",
            "Epoch 00015: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.0288 - val_accuracy: 0.9946\n",
            "Epoch 16/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9953\n",
            "Epoch 00016: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 20ms/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 0.0284 - val_accuracy: 0.9939\n",
            "Epoch 00016: early stopping\n",
            "Epoch 1/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.3197 - accuracy: 0.9019\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.11275, saving model to multi_layer_norm_model.h5\n",
            "188/188 [==============================] - 4s 23ms/step - loss: 0.3190 - accuracy: 0.9022 - val_loss: 6.2245 - val_accuracy: 0.1128\n",
            "Epoch 2/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0879 - accuracy: 0.9732\n",
            "Epoch 00002: val_accuracy improved from 0.11275 to 0.29783, saving model to multi_layer_norm_model.h5\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0878 - accuracy: 0.9732 - val_loss: 4.2804 - val_accuracy: 0.2978\n",
            "Epoch 3/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0631 - accuracy: 0.9811\n",
            "Epoch 00003: val_accuracy improved from 0.29783 to 0.84508, saving model to multi_layer_norm_model.h5\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0630 - accuracy: 0.9811 - val_loss: 0.4832 - val_accuracy: 0.8451\n",
            "Epoch 4/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9841\n",
            "Epoch 00004: val_accuracy improved from 0.84508 to 0.98717, saving model to multi_layer_norm_model.h5\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0533 - accuracy: 0.9841 - val_loss: 0.0395 - val_accuracy: 0.9872\n",
            "Epoch 5/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9849\n",
            "Epoch 00005: val_accuracy improved from 0.98717 to 0.99208, saving model to multi_layer_norm_model.h5\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0494 - accuracy: 0.9849 - val_loss: 0.0258 - val_accuracy: 0.9921\n",
            "Epoch 6/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0423 - accuracy: 0.9867\n",
            "Epoch 00006: val_accuracy did not improve from 0.99208\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0425 - accuracy: 0.9866 - val_loss: 0.0265 - val_accuracy: 0.9920\n",
            "Epoch 7/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9887\n",
            "Epoch 00007: val_accuracy did not improve from 0.99208\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0367 - accuracy: 0.9887 - val_loss: 0.0299 - val_accuracy: 0.9914\n",
            "Epoch 8/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9895\n",
            "Epoch 00008: val_accuracy did not improve from 0.99208\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0329 - accuracy: 0.9895 - val_loss: 0.0258 - val_accuracy: 0.9919\n",
            "Epoch 9/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0305 - accuracy: 0.9907\n",
            "Epoch 00009: val_accuracy did not improve from 0.99208\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0305 - accuracy: 0.9906 - val_loss: 0.0259 - val_accuracy: 0.9919\n",
            "Epoch 10/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9910\n",
            "Epoch 00010: val_accuracy improved from 0.99208 to 0.99217, saving model to multi_layer_norm_model.h5\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.0285 - val_accuracy: 0.9922\n",
            "Epoch 11/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9906\n",
            "Epoch 00011: val_accuracy did not improve from 0.99217\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 0.0291 - val_accuracy: 0.9915\n",
            "Epoch 12/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9925\n",
            "Epoch 00012: val_accuracy did not improve from 0.99217\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 0.0315 - val_accuracy: 0.9904\n",
            "Epoch 13/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0246 - accuracy: 0.9923\n",
            "Epoch 00013: val_accuracy did not improve from 0.99217\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.0303 - val_accuracy: 0.9916\n",
            "Epoch 14/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0236 - accuracy: 0.9924\n",
            "Epoch 00014: val_accuracy did not improve from 0.99217\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 0.0302 - val_accuracy: 0.9913\n",
            "Epoch 15/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9929\n",
            "Epoch 00015: val_accuracy improved from 0.99217 to 0.99242, saving model to multi_layer_norm_model.h5\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0233 - accuracy: 0.9929 - val_loss: 0.0263 - val_accuracy: 0.9924\n",
            "Epoch 16/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9933\n",
            "Epoch 00016: val_accuracy improved from 0.99242 to 0.99408, saving model to multi_layer_norm_model.h5\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.0228 - val_accuracy: 0.9941\n",
            "Epoch 17/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0211 - accuracy: 0.9929\n",
            "Epoch 00017: val_accuracy did not improve from 0.99408\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.0207 - val_accuracy: 0.9939\n",
            "Epoch 18/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9935\n",
            "Epoch 00018: val_accuracy did not improve from 0.99408\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.0219 - val_accuracy: 0.9938\n",
            "Epoch 19/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9937\n",
            "Epoch 00019: val_accuracy did not improve from 0.99408\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.0234 - val_accuracy: 0.9933\n",
            "Epoch 20/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9946\n",
            "Epoch 00020: val_accuracy did not improve from 0.99408\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.0269 - val_accuracy: 0.9922\n",
            "Epoch 21/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9946\n",
            "Epoch 00021: val_accuracy did not improve from 0.99408\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.0224 - val_accuracy: 0.9935\n",
            "Epoch 22/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9945\n",
            "Epoch 00022: val_accuracy did not improve from 0.99408\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0261 - val_accuracy: 0.9927\n",
            "Epoch 23/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9950\n",
            "Epoch 00023: val_accuracy did not improve from 0.99408\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0157 - accuracy: 0.9950 - val_loss: 0.0232 - val_accuracy: 0.9940\n",
            "Epoch 24/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9951\n",
            "Epoch 00024: val_accuracy did not improve from 0.99408\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0164 - accuracy: 0.9951 - val_loss: 0.0334 - val_accuracy: 0.9912\n",
            "Epoch 25/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9944\n",
            "Epoch 00025: val_accuracy did not improve from 0.99408\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0251 - val_accuracy: 0.9932\n",
            "Epoch 26/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9954\n",
            "Epoch 00026: val_accuracy improved from 0.99408 to 0.99417, saving model to multi_layer_norm_model.h5\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0231 - val_accuracy: 0.9942\n",
            "Epoch 27/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9948\n",
            "Epoch 00027: val_accuracy did not improve from 0.99417\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 0.0260 - val_accuracy: 0.9941\n",
            "Epoch 28/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9958\n",
            "Epoch 00028: val_accuracy improved from 0.99417 to 0.99442, saving model to multi_layer_norm_model.h5\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.0220 - val_accuracy: 0.9944\n",
            "Epoch 29/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9954\n",
            "Epoch 00029: val_accuracy improved from 0.99442 to 0.99475, saving model to multi_layer_norm_model.h5\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0200 - val_accuracy: 0.9948\n",
            "Epoch 30/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9957\n",
            "Epoch 00030: val_accuracy did not improve from 0.99475\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0238 - val_accuracy: 0.9938\n",
            "Epoch 31/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9958\n",
            "Epoch 00031: val_accuracy did not improve from 0.99475\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0239 - val_accuracy: 0.9935\n",
            "Epoch 32/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9960\n",
            "Epoch 00032: val_accuracy did not improve from 0.99475\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.0262 - val_accuracy: 0.9933\n",
            "Epoch 33/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9956\n",
            "Epoch 00033: val_accuracy improved from 0.99475 to 0.99483, saving model to multi_layer_norm_model.h5\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0205 - val_accuracy: 0.9948\n",
            "Epoch 34/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9963\n",
            "Epoch 00034: val_accuracy did not improve from 0.99483\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0236 - val_accuracy: 0.9935\n",
            "Epoch 35/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9959\n",
            "Epoch 00035: val_accuracy did not improve from 0.99483\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0213 - val_accuracy: 0.9941\n",
            "Epoch 36/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9960\n",
            "Epoch 00036: val_accuracy did not improve from 0.99483\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0249 - val_accuracy: 0.9942\n",
            "Epoch 37/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9962\n",
            "Epoch 00037: val_accuracy did not improve from 0.99483\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.0208 - val_accuracy: 0.9947\n",
            "Epoch 38/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9969\n",
            "Epoch 00038: val_accuracy did not improve from 0.99483\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.0236 - val_accuracy: 0.9933\n",
            "Epoch 39/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9960\n",
            "Epoch 00039: val_accuracy improved from 0.99483 to 0.99492, saving model to multi_layer_norm_model.h5\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.0245 - val_accuracy: 0.9949\n",
            "Epoch 40/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.9967\n",
            "Epoch 00040: val_accuracy did not improve from 0.99492\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0208 - val_accuracy: 0.9944\n",
            "Epoch 41/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9967\n",
            "Epoch 00041: val_accuracy did not improve from 0.99492\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0230 - val_accuracy: 0.9944\n",
            "Epoch 42/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.9967\n",
            "Epoch 00042: val_accuracy did not improve from 0.99492\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0268 - val_accuracy: 0.9929\n",
            "Epoch 43/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9969\n",
            "Epoch 00043: val_accuracy did not improve from 0.99492\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.0233 - val_accuracy: 0.9944\n",
            "Epoch 44/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9967\n",
            "Epoch 00044: val_accuracy did not improve from 0.99492\n",
            "188/188 [==============================] - 4s 21ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0211 - val_accuracy: 0.9944\n",
            "Epoch 45/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9967\n",
            "Epoch 00045: val_accuracy did not improve from 0.99492\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0258 - val_accuracy: 0.9937\n",
            "Epoch 46/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9976\n",
            "Epoch 00046: val_accuracy did not improve from 0.99492\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0239 - val_accuracy: 0.9942\n",
            "Epoch 47/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9970\n",
            "Epoch 00047: val_accuracy did not improve from 0.99492\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.0253 - val_accuracy: 0.9939\n",
            "Epoch 48/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9972\n",
            "Epoch 00048: val_accuracy improved from 0.99492 to 0.99508, saving model to multi_layer_norm_model.h5\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.0189 - val_accuracy: 0.9951\n",
            "Epoch 49/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9969\n",
            "Epoch 00049: val_accuracy did not improve from 0.99508\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0217 - val_accuracy: 0.9942\n",
            "Epoch 50/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9971\n",
            "Epoch 00050: val_accuracy did not improve from 0.99508\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.0227 - val_accuracy: 0.9944\n",
            "Epoch 51/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9969\n",
            "Epoch 00051: val_accuracy did not improve from 0.99508\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0276 - val_accuracy: 0.9934\n",
            "Epoch 52/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9971\n",
            "Epoch 00052: val_accuracy did not improve from 0.99508\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0264 - val_accuracy: 0.9939\n",
            "Epoch 53/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9973\n",
            "Epoch 00053: val_accuracy did not improve from 0.99508\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0259 - val_accuracy: 0.9936\n",
            "Epoch 54/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9974\n",
            "Epoch 00054: val_accuracy did not improve from 0.99508\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0281 - val_accuracy: 0.9929\n",
            "Epoch 55/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9974\n",
            "Epoch 00055: val_accuracy did not improve from 0.99508\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0222 - val_accuracy: 0.9946\n",
            "Epoch 56/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.9968\n",
            "Epoch 00056: val_accuracy did not improve from 0.99508\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0093 - accuracy: 0.9968 - val_loss: 0.0263 - val_accuracy: 0.9937\n",
            "Epoch 57/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9976\n",
            "Epoch 00057: val_accuracy did not improve from 0.99508\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0217 - val_accuracy: 0.9944\n",
            "Epoch 58/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9976\n",
            "Epoch 00058: val_accuracy improved from 0.99508 to 0.99525, saving model to multi_layer_norm_model.h5\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0205 - val_accuracy: 0.9952\n",
            "Epoch 59/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9976\n",
            "Epoch 00059: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0232 - val_accuracy: 0.9948\n",
            "Epoch 60/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0081 - accuracy: 0.9971\n",
            "Epoch 00060: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.0205 - val_accuracy: 0.9952\n",
            "Epoch 61/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9979\n",
            "Epoch 00061: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0215 - val_accuracy: 0.9942\n",
            "Epoch 62/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9975\n",
            "Epoch 00062: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.0213 - val_accuracy: 0.9945\n",
            "Epoch 63/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9981\n",
            "Epoch 00063: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0251 - val_accuracy: 0.9937\n",
            "Epoch 64/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9977\n",
            "Epoch 00064: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0201 - val_accuracy: 0.9948\n",
            "Epoch 65/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9977\n",
            "Epoch 00065: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.0215 - val_accuracy: 0.9944\n",
            "Epoch 66/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9981\n",
            "Epoch 00066: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0239 - val_accuracy: 0.9944\n",
            "Epoch 67/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9977\n",
            "Epoch 00067: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0257 - val_accuracy: 0.9937\n",
            "Epoch 68/10000\n",
            "187/188 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9978\n",
            "Epoch 00068: val_accuracy did not improve from 0.99525\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0253 - val_accuracy: 0.9944\n",
            "Epoch 00068: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Jc_iu-TkGV4"
      },
      "source": [
        "and draw the plots:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G9GctMNmkGV4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "c907bcfa-04a5-4ba9-c216-38c84da32e5f"
      },
      "source": [
        "  fig, (loss_ax, acc_ax) = plt.subplots(1, 2, figsize=(20,7))\n",
        "  loss_ax.set_title('Loss')\n",
        "  loss_ax.plot(multi_layer_norm_train.history['loss'], '-r', label='Train norm')\n",
        "  loss_ax.plot(multi_layer_norm_train.history['val_loss'], '-g', label='Validation norm')\n",
        "  loss_ax.plot(dropout_convolutional_train.history['loss'], '-b', label='Train 4')\n",
        "  loss_ax.plot(dropout_convolutional_train.history['val_loss'], '-y', label='Validation 4')\n",
        "\n",
        "  acc_ax.set_title('Accuracy')\n",
        "  acc_ax.plot(multi_layer_norm_train.history['accuracy'], '-r', label='Train norm')\n",
        "  acc_ax.plot(multi_layer_norm_train.history['val_accuracy'], '-g', label='Validation norm')\n",
        "  acc_ax.plot(dropout_convolutional_train.history['accuracy'], '-b', label='Train 4')\n",
        "  acc_ax.plot(dropout_convolutional_train.history['val_accuracy'], '-y', label='Validation 4')\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4OGp7ZeZkGV6"
      },
      "source": [
        "The plots show that normalization made convergence much slower, taking 3 times us much updates while still scoring less."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ePukPVwQkGV6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4284d3ea-3e0c-407c-f74d-b6c40de4e14e"
      },
      "source": [
        "dropout_convolutional_model.load_weights('dropout_convolutional_model.h5')\n",
        "multi_layer_norm_model.load_weights('multi_layer_norm_model.h5')\n",
        "loss, acc4 = dropout_convolutional_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "loss, acc4norm = multi_layer_norm_model.evaluate(mnist_test_x, mnist_test_y)\n",
        "print('Accuracy for baseline: {}, Accuracy for normalized: {}'.format(acc4, acc4norm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0229 - accuracy: 0.9944\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0206 - accuracy: 0.9941\n",
            "Accuracy for baseline: 0.9944000244140625, Accuracy for normalized: 0.9940999746322632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TxhGuSyPkGV7"
      },
      "source": [
        "Even though the validation accuracies promissed a higher accuracy, in the test set this is not verified. Our best value is the convutional NN without dropout or normalization, at 99.45%."
      ]
    }
  ]
}